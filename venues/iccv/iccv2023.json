[
    {
        "title": "2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_2D-3D_Interlaced_Transformer_for_Point_Cloud_Segmentation_with_Scene-Level_Supervision_ICCV_2023_paper.html",
        "author": "Cheng-Kun Yang, Min-Hung Chen, Yung-Yu Chuang, Yen-Yu Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_2D-3D_Interlaced_Transformer_for_Point_Cloud_Segmentation_with_Scene-Level_Supervision_ICCV_2023_paper.pdf",
        "aff": "NVIDIA; National Taiwan University; National Yang Ming Chiao Tung University",
        "project": "https://jimmy15923.github.io/mit_web/",
        "github": "https://jimmy15923.github.io/mit_web/",
        "arxiv": ""
    },
    {
        "title": "2D3D-MATR: 2D-3D Matching Transformer for Detection-Free Registration Between Images and Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.html",
        "author": "Minhao Li, Zheng Qin, Zhirui Gao, Renjiao Yi, Chenyang Zhu, Yulan Guo, Kai Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.pdf",
        "aff": "Defense Innovation Institute, Academy of Military Sciences; Sun Yat-sen University; National University of Defense Technology",
        "project": "",
        "github": "https://github.com/minhaolee/2D3DMATR",
        "arxiv": ""
    },
    {
        "title": "360VOT: A New Benchmark Dataset for Omnidirectional Visual Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_360VOT_A_New_Benchmark_Dataset_for_Omnidirectional_Visual_Object_Tracking_ICCV_2023_paper.html",
        "author": "Huajian Huang, Yinzhe Xu, Yingshu Chen, Sai-Kit Yeung",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_360VOT_A_New_Benchmark_Dataset_for_Omnidirectional_Visual_Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology",
        "project": "https://360vot.hkustvgd.com",
        "github": "",
        "arxiv": "2307.14630"
    },
    {
        "title": "3D Distillation: Improving Self-Supervised Monocular Depth Estimation on Reflective Surfaces",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.html",
        "author": "Xuepeng Shi, Georgi Dikov, Gerhard Reitmayr, Tae-Kyun Kim, Mohsen Ghafoorian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.pdf",
        "aff": "Qualcomm; KAIST; Imperial College London",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "3D Human Mesh Recovery with Sequentially Global Rotation Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_3D_Human_Mesh_Recovery_with_Sequentially_Global_Rotation_Estimation_ICCV_2023_paper.html",
        "author": "Dongkai Wang, Shiliang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_3D_Human_Mesh_Recovery_with_Sequentially_Global_Rotation_Estimation_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University",
        "project": "",
        "github": "https://github.com/kennethwdk/SGRE",
        "arxiv": ""
    },
    {
        "title": "3D Implicit Transporter for Temporally Consistent Keypoint Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_3D_Implicit_Transporter_for_Temporally_Consistent_Keypoint_Discovery_ICCV_2023_paper.html",
        "author": "Chengliang Zhong, Yuhang Zheng, Yupeng Zheng, Hao Zhao, Li Yi, Xiaodong Mu, Ling Wang, Pengfei Li, Guyue Zhou, Chao Yang, Xinliang Zhang, Jian Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_3D_Implicit_Transporter_for_Temporally_Consistent_Keypoint_Discovery_ICCV_2023_paper.pdf",
        "aff": "Xi\u2019an Research Institute of High-Tech, AIR, Tsinghua University; AIR, Tsinghua University; Institute of Automation, Chinese Academy of Sciences; Xi\u2019an Research Institute of High-Tech; Institute of North Electronic Equipment, Intelligent Game and Decision Laboratory, Peng Cheng Laboratory; Beihang University; Shanghai AI Laboratory; IIIS, Tsinghua University",
        "project": "",
        "github": "https://github.com/zhongcl-thu/3D-Implicit-Transporter",
        "arxiv": "2309.05098"
    },
    {
        "title": "3D Instance Segmentation via Enhanced Spatial and Semantic Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Al_Khatib_3D_Instance_Segmentation_via_Enhanced_Spatial_and_Semantic_Supervision_ICCV_2023_paper.html",
        "author": "Salwa Al Khatib, Mohamed El Amine Boudjoghra, Jean Lahoud, Fahad Shahbaz Khan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Al_Khatib_3D_Instance_Segmentation_via_Enhanced_Spatial_and_Semantic_Supervision_ICCV_2023_paper.pdf",
        "aff": "Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), UAE and Link\u00f6ping University, Sweden; Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), UAE",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "3D Motion Magnification: Visualizing Subtle Motions from Time-Varying Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_3D_Motion_Magnification_Visualizing_Subtle_Motions_from_Time-Varying_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Brandon Y. Feng, Hadi Alzayer, Michael Rubinstein, William T. Freeman, Jia-bin Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_3D_Motion_Magnification_Visualizing_Subtle_Motions_from_Time-Varying_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "University of Maryland; Google Research, MIT; Google Research",
        "project": "https://3d-motion-magnification.github.io/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for Robust 6D Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_3D_Neural_Embedding_Likelihood_Probabilistic_Inverse_Graphics_for_Robust_6D_ICCV_2023_paper.html",
        "author": "Guangyao Zhou, Nishad Gothoskar, Lirui Wang, Joshua B. Tenenbaum, Dan Gutfreund, Miguel L\u00e1zaro-Gredilla, Dileep George, Vikash K. Mansinghka",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_3D_Neural_Embedding_Likelihood_Probabilistic_Inverse_Graphics_for_Robust_6D_ICCV_2023_paper.pdf",
        "aff": "Google DeepMind; MIT-IBM Watson AI Lab; MIT",
        "project": "",
        "github": "",
        "arxiv": "2302.03744"
    },
    {
        "title": "3D Segmentation of Humans in Point Clouds with Synthetic Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Takmaz_3D_Segmentation_of_Humans_in_Point_Clouds_with_Synthetic_Data_ICCV_2023_paper.html",
        "author": "Ay\u00e7a Takmaz, Jonas Schult, Irem Kaftan, Mertcan Ak\u00e7ay, Bastian Leibe, Robert Sumner, Francis Engelmann, Siyu Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Takmaz_3D_Segmentation_of_Humans_in_Point_Clouds_with_Synthetic_Data_ICCV_2023_paper.pdf",
        "aff": "ETH AI Center, Switzerland; ETH Z \u00a8urich, Switzerland; RWTH Aachen University, Germany",
        "project": "",
        "github": "https://human-3d.github.io",
        "arxiv": "2212.00786"
    },
    {
        "title": "3D Semantic Subspace Traverser: Empowering 3D Generative Model with Shape Editing Capability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_3D_Semantic_Subspace_Traverser_Empowering_3D_Generative_Model_with_Shape_ICCV_2023_paper.html",
        "author": "Ruowei Wang, Yu Liu, Pei Su, Jianwei Zhang, Qijun Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_3D_Semantic_Subspace_Traverser_Empowering_3D_Generative_Model_with_Shape_ICCV_2023_paper.pdf",
        "aff": "Sichuan University",
        "project": "",
        "github": "https://github.com/TrepangCat/3D Semantic Subspace Traverser",
        "arxiv": "2307.14051"
    },
    {
        "title": "3D VR Sketch Guided 3D Shape Prototyping and Exploration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_3D_VR_Sketch_Guided_3D_Shape_Prototyping_and_Exploration_ICCV_2023_paper.html",
        "author": "Ling Luo, Pinaki Nath Chowdhury, Tao Xiang, Yi-Zhe Song, Yulia Gryaditskaya",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_3D_VR_Sketch_Guided_3D_Shape_Prototyping_and_Exploration_ICCV_2023_paper.pdf",
        "aff": "SketchX, CVSSP, University of Surrey, United Kingdom; iFlyTek-Surrey Joint Research Center on Artificial Intelligence; CCM, Surrey Institute for People-Centered AI and CVSSP, University of Surrey, United Kingdom",
        "project": "",
        "github": "https://github.com/Rowl1ng/3Dsketch2shape",
        "arxiv": "2306.10830"
    },
    {
        "title": "3D-Aware Generative Model for Improved Side-View Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.html",
        "author": "Kyungmin Jo, Wonjoon Jin, Jaegul Choo, Hyunjoon Lee, Sunghyun Cho",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Kakao Brain, Seongnam-si, Gyeonggi-do, Korea; POSTECH, Pohang, Gyeongbuk, Korea; KAIST, Daejeon, Korea",
        "project": "",
        "github": "",
        "arxiv": "2309.10388"
    },
    {
        "title": "3D-Aware Neural Body Fitting for Occlusion Robust 3D Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_3D-Aware_Neural_Body_Fitting_for_Occlusion_Robust_3D_Human_Pose_ICCV_2023_paper.html",
        "author": "Yi Zhang, Pengliang Ji, Angtian Wang, Jieru Mei, Adam Kortylewski, Alan Yuille",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_3D-Aware_Neural_Body_Fitting_for_Occlusion_Robust_3D_Human_Pose_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; Max Planck Institute for Informatics, University of Freiburg; Beihang University",
        "project": "",
        "github": "https://github.com/edz-o/3DNBF",
        "arxiv": "2308.10123"
    },
    {
        "title": "3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_3D-VisTA_Pre-trained_Transformer_for_3D_Vision_and_Text_Alignment_ICCV_2023_paper.html",
        "author": "Ziyu Zhu, Xiaojian Ma, Yixin Chen, Zhidong Deng, Siyuan Huang, Qing Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_3D-VisTA_Pre-trained_Transformer_for_3D_Vision_and_Text_Alignment_ICCV_2023_paper.pdf",
        "aff": "1Tsinghua University; 2National Key Laboratory of General Artificial Intelligence, BIGAI, China",
        "project": "",
        "github": "https://3d-vista.github.io",
        "arxiv": ""
    },
    {
        "title": "3D-aware Blending with Generative NeRFs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_3D-aware_Blending_with_Generative_NeRFs_ICCV_2023_paper.html",
        "author": "Hyunsu Kim, Gayoung Lee, Yunjey Choi, Jin-Hwa Kim, Jun-Yan Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_3D-aware_Blending_with_Generative_NeRFs_ICCV_2023_paper.pdf",
        "aff": "CMU; NAVER AI Lab; NAVER AI Lab, SNU AIIS",
        "project": "",
        "github": "",
        "arxiv": "2302.06608"
    },
    {
        "title": "3D-aware Image Generation using 2D Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Jianfeng Xiang, Jiaolong Yang, Binbin Huang, Xin Tong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; Tsinghua University and Microsoft Research Asia; ShanghaiTech University",
        "project": "https://jeffreyxiang.github.io/ivid/",
        "github": "",
        "arxiv": "2303.17905"
    },
    {
        "title": "3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D Point Cloud Attack",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tao_3DHacker_Spectrum-based_Decision_Boundary_Generation_for_Hard-label_3D_Point_Cloud_ICCV_2023_paper.html",
        "author": "Yunbo Tao, Daizong Liu, Pan Zhou, Yulai Xie, Wei Du, Wei Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_3DHacker_Spectrum-based_Decision_Boundary_Generation_for_Hard-label_3D_Point_Cloud_ICCV_2023_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University; Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Huazhong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2308.07546"
    },
    {
        "title": "3DHumanGAN: 3D-Aware Human Image Generation with 3D Pose Mapping",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.html",
        "author": "Zhuoqian Yang, Shikai Li, Wayne Wu, Bo Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.pdf",
        "aff": "Shanghai AI Laboratory, School of Computer and Communication Sciences, EPFL; Shanghai AI Laboratory",
        "project": "https://3dhumangan.github.io/",
        "github": "",
        "arxiv": "2212.07378"
    },
    {
        "title": "3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.html",
        "author": "Shuxiao Ding, Eike Rehder, Lukas Schneider, Marius Cordts, Juergen Gall",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "Mercedes-Benz AG, Sindelfingen, Germany and University of Bonn, Bonn, Germany; University of Bonn, Bonn, Germany and Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Robert Bosch GmbH, Stuttgart, Germany; Mercedes-Benz AG, Sindelfingen, Germany",
        "project": "",
        "github": "https://github.com/dsx0511/3DMOTFormer",
        "arxiv": "2308.06635"
    },
    {
        "title": "3DMiner: Discovering Shapes from Large-Scale Unannotated Image Datasets",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.html",
        "author": "Ta-Ying Cheng, Matheus Gadelha, S\u00f6ren Pirk, Thibault Groueix, Radom\u00edr M\u011bch, Andrew Markham, Niki Trigoni",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; University of Oxford",
        "project": "https://ttchengab.github.io/3dminer",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "3DPPE: 3D Point Positional Encoding for Transformer-based Multi-Camera 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.html",
        "author": "Changyong Shu, Jiajun Deng, Fisher Yu, Yifan Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.pdf",
        "aff": "3DPPE: 3D Point Positional Encoding for Transformer-based\nMulti-Camera 3D Object Detection\nChangyong Shu1*Jiajun Deng2*Fisher Yu3Yifan Liu4\u2020\n1Houmo AI,2University of Sydney,3ETH Z \u00a8urich,4University of Adelaide,\nchangyong.shu89@gmail.com ,jiajun.deng@sydney.edu.au\nfisheryu@ethz.ch, yifan.liu04@adelaide.edu.au\nAbstract\nTransformer-based methods have swept the benchmarks\non 2D and 3D detection on images. Because tokenization\nbefore the attention mechanism drops the spatial informa-\ntion, positional encoding becomes critical for those meth-\nods. Recent works found that encodings based on samples\nof the 3D viewing rays can significantly improve the qual-\nity of multi-camera 3D object detection. We hypothesize\nthat 3D point locations can provide more information than\nrays. Therefore, we introduce 3D point positional encod-\ning, 3DPPE, to the 3D detection Transformer decoder. Al-\nthough 3D measurements are not available at the inference\ntime of monocular 3D object detection, 3DPPE uses pre-\ndicted depth to approximate the real point positions. Our\nhybrid-depth module combines direct and categorical depth\nto estimate the refined depth of each pixel. Despite the ap-\nproximation, 3DPPE achieves 46.0 mAP and 51.4 NDS on\nthe competitive nuScenes dataset, significantly outperform-\ning encodings based on ray samples. The code is available\nathttps://github.com/drilistbox/3DPPE .\n1. Introduction\n3D object detection is a vital component of autonomous\ndriving perception systems. Particularly, image-based 3D\nobject detection has received increasing attention from both\nacademia and industry due to its lower cost compared\nto LiDAR-dependent solutions. Despite the fact that au-\ntonomous driving vehicles are equipped with multiple cam-\neras, early attempts at image-based 3D object detection, as\nseen in previous works [17, 19], focus on monocular detec-\ntion and combine the detection results from multiple cam-\neras. This kind of solution is unable to make use of cor-\nrespondence in the overlapping area of adjacent cameras,\nand the paradigm to individually detect objects in each view\n*These authors contributed equally to this work.\n\u2020Corresponding authors.\n(a). 3D Camera -Ray PE\n(b). 3D Point PE\nFigure 1. An illustration of (a) 3D camera-ray positional encoding\n(PE) and (b) our proposed 3D point PE. The 3D camera-ray PE\nrepresents camera-ray information by determining the positions of\na set number of discrete points along the direction from the camera\noptical center to the image plane pixel. This encoding approach\nis coarse-grained. On the other hand, the 3D point PE provides\nmore precise position information by encoding the location of a\nsingle point with an estimated depth. In the figure, four pixels are\nrandomly selected to demonstrate the methods.\ninvolves a large computational overhead. Alternatively, a\ngroup of recent studies [8, 7, 27, 29] follow the paradigm of\nLift-Splat-Shoot (LSS) [6] to first transform multi-camera\nimages to unified bird-eye-view (BEV) representation in\nparallel and then perform object detection on the BEV rep-\nresentation. However, such ill-posed view transformation\ninevitably causes error accumulation, which further affects\nthe accuracy of 3D object detection.\nAt the same time, the transformer-based (DETR-like) [1]\nscheme has also been explored in this field. Typically, the\nmethods following this scheme [3, 25, 26, 28, 32] utilizes\na set of learnable 3D object query to iteratively interact\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n3580\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "4D Myocardium Reconstruction with Decoupled Motion and Shape Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_4D_Myocardium_Reconstruction_with_Decoupled_Motion_and_Shape_Model_ICCV_2023_paper.html",
        "author": "Xiaohan Yuan, Cong Liu, Yangang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_4D_Myocardium_Reconstruction_with_Decoupled_Motion_and_Shape_Model_ICCV_2023_paper.pdf",
        "aff": "Southeast University, China",
        "project": "",
        "github": "",
        "arxiv": "2308.14083"
    },
    {
        "title": "4D Panoptic Segmentation as Invariant and Equivariant Field Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_4D_Panoptic_Segmentation_as_Invariant_and_Equivariant_Field_Prediction_ICCV_2023_paper.html",
        "author": "Minghan Zhu, Shizhong Han, Hong Cai, Shubhankar Borse, Maani Ghaffari, Fatih Porikli",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_4D_Panoptic_Segmentation_as_Invariant_and_Equivariant_Field_Prediction_ICCV_2023_paper.pdf",
        "aff": "University of Michigan, Ann Arbor; Qualcomm AI Research",
        "project": "",
        "github": "",
        "arxiv": "2303.15651"
    },
    {
        "title": "A 5-Point Minimal Solver for Event Camera Relative Motion Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_A_5-Point_Minimal_Solver_for_Event_Camera_Relative_Motion_Estimation_ICCV_2023_paper.html",
        "author": "Ling Gao, Hang Su, Daniel Gehrig, Marco Cannici, Davide Scaramuzza, Laurent Kneip",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_5-Point_Minimal_Solver_for_Event_Camera_Relative_Motion_Estimation_ICCV_2023_paper.pdf",
        "aff": "Mobile Perception Lab, ShanghaiTech University, China; Robotics and Perception Group, University of Zurich, Switzerland",
        "project": "https://mgaoling.github.io/eventail/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Benchmark for Chinese-English Scene Text Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.html",
        "author": "Jianqi Ma, Zhetong Liang, Wangmeng Xiang, Xi Yang, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong Polytechnic University; OPPO Research; The Hong Kong Polytechnic University; OPPO Research",
        "project": "",
        "github": "https://github.com/mjq11302010044/Real-CE",
        "arxiv": "2308.03262"
    },
    {
        "title": "A Complete Recipe for Diffusion Generative Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pandey_A_Complete_Recipe_for_Diffusion_Generative_Models_ICCV_2023_paper.html",
        "author": "Kushagra Pandey, Stephan Mandt",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pandey_A_Complete_Recipe_for_Diffusion_Generative_Models_ICCV_2023_paper.pdf",
        "aff": "Dept. of Computer Science, University of California, Irvine",
        "project": "",
        "github": "https://github.com/mandt-lab/PSLD",
        "arxiv": ""
    },
    {
        "title": "A Dynamic Dual-Processing Object Detection Framework Inspired by the Brain's Recognition Mechanism",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Dynamic_Dual-Processing_Object_Detection_Framework_Inspired_by_the_Brains_ICCV_2023_paper.html",
        "author": "Minying Zhang, Tianpeng Bu, Lulu Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Dynamic_Dual-Processing_Object_Detection_Framework_Inspired_by_the_Brains_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group, Hangzhou, Zhejiang, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Fast Unified System for 3D Object Detection and Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Heitzinger_A_Fast_Unified_System_for_3D_Object_Detection_and_Tracking_ICCV_2023_paper.html",
        "author": "Thomas Heitzinger, Martin Kampel",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Heitzinger_A_Fast_Unified_System_for_3D_Object_Detection_and_Tracking_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Lab, TU Wien, Vienna, Austria",
        "project": "",
        "github": "https://github.com/theitzin/FUS3D",
        "arxiv": ""
    },
    {
        "title": "A Game of Bundle Adjustment - Learning Efficient Convergence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Belder_A_Game_of_Bundle_Adjustment_-_Learning_Efficient_Convergence_ICCV_2023_paper.html",
        "author": "Amir Belder, Refael Vivanti, Ayellet Tal",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Belder_A_Game_of_Bundle_Adjustment_-_Learning_Efficient_Convergence_ICCV_2023_paper.pdf",
        "aff": "Technion and Reality Labs, Meta inc.; Reality Labs, Meta inc.; Technion and Cornel-Tech",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Generalist Framework for Panoptic Segmentation of Images and Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_A_Generalist_Framework_for_Panoptic_Segmentation_of_Images_and_Videos_ICCV_2023_paper.html",
        "author": "Ting Chen, Lala Li, Saurabh Saxena, Geoffrey Hinton, David J. Fleet",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_A_Generalist_Framework_for_Panoptic_Segmentation_of_Images_and_Videos_ICCV_2023_paper.pdf",
        "aff": "Google Deepmind",
        "project": "",
        "github": "https://github.com/google-research/pix2seq",
        "arxiv": "2210.06366"
    },
    {
        "title": "A Good Student is Cooperative and Reliable: CNN-Transformer Collaborative Learning for Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_A_Good_Student_is_Cooperative_and_Reliable_CNN-Transformer_Collaborative_Learning_ICCV_2023_paper.html",
        "author": "Jinjing Zhu, Yunhao Luo, Xu Zheng, Hao Wang, Lin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_A_Good_Student_is_Cooperative_and_Reliable_CNN-Transformer_Collaborative_Learning_ICCV_2023_paper.pdf",
        "aff": "Alibaba Cloud, Alibaba Group; AI Thrust, HKUST(GZ); Brown University; AI Thrust, HKUST(GZ) and Dept. of CSE, HKUST",
        "project": "https://vlislab22.github.io/CTCL/",
        "github": "",
        "arxiv": "2307.12574"
    },
    {
        "title": "A Large-Scale Outdoor Multi-Modal Dataset and Benchmark for Novel View Synthesis and Implicit Scene Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_A_Large-Scale_Outdoor_Multi-Modal_Dataset_and_Benchmark_for_Novel_View_ICCV_2023_paper.html",
        "author": "Chongshan Lu, Fukun Yin, Xin Chen, Wen Liu, Tao Chen, Gang Yu, Jiayuan Fan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_A_Large-Scale_Outdoor_Multi-Modal_Dataset_and_Benchmark_for_Novel_View_ICCV_2023_paper.pdf",
        "aff": "Academy for Engineering and Technology, Fudan University, China; Tencent PCG, China; School of Information Science and Technology, Fudan University, China",
        "project": "https://ommo.luchongshan.com/",
        "github": "",
        "arxiv": "2301.06782"
    },
    {
        "title": "A Large-scale Study of Spatiotemporal Representation Learning with a New Benchmark on Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deng_A_Large-scale_Study_of_Spatiotemporal_Representation_Learning_with_a_New_ICCV_2023_paper.html",
        "author": "Andong Deng, Taojiannan Yang, Chen Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_A_Large-scale_Study_of_Spatiotemporal_Representation_Learning_with_a_New_ICCV_2023_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida, USA",
        "project": "",
        "github": "https://github.com/AndongDeng/BEAR",
        "arxiv": "2303.13505"
    },
    {
        "title": "A Latent Space of Stochastic Diffusion Models for Zero-Shot Image Editing and Guidance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.html",
        "author": "Chen Henry Wu, Fernando De la Torre",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.pdf",
        "aff": "Robotics Institute, Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/humansensinglab/cycle-diffusion",
        "arxiv": ""
    },
    {
        "title": "A Low-Shot Object Counting Network With Iterative Prototype Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dukic_A_Low-Shot_Object_Counting_Network_With_Iterative_Prototype_Adaptation_ICCV_2023_paper.html",
        "author": "Nikola \u0110uki\u0107, Alan Luke\u017ei\u010d, Vitjan Zavrtanik, Matej Kristan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dukic_A_Low-Shot_Object_Counting_Network_With_Iterative_Prototype_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Faculty of Computer and Information Science, University of Ljubljana, Slovenia",
        "project": "",
        "github": "https://github.com/djukicn/loca",
        "arxiv": ""
    },
    {
        "title": "A Multidimensional Analysis of Social Biases in Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Brinkmann_A_Multidimensional_Analysis_of_Social_Biases_in_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Jannik Brinkmann, Paul Swoboda, Christian Bartelt",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Brinkmann_A_Multidimensional_Analysis_of_Social_Biases_in_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "University of Mannheim",
        "project": "",
        "github": "github.com/jannik-brinkmann/social-biases-in-vision-transformers",
        "arxiv": "2308.01948"
    },
    {
        "title": "A Parse-Then-Place Approach for Generating Graphic Layouts from Textual Descriptions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.html",
        "author": "Jiawei Lin, Jiaqi Guo, Shizhao Sun, Weijiang Xu, Ting Liu, Jian-Guang Lou, Dongmei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": "2308.12700"
    },
    {
        "title": "A Retrospect to Multi-prompt Learning across Vision and Language",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_A_Retrospect_to_Multi-prompt_Learning_across_Vision_and_Language_ICCV_2023_paper.html",
        "author": "Ziliang Chen, Xin Huang, Quanlong Guan, Liang Lin, Weiqi Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_A_Retrospect_to_Multi-prompt_Learning_across_Vision_and_Language_ICCV_2023_paper.pdf",
        "aff": "Sun Yat-sen University; Jinan University, Pazhou Laboratory; Jinan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Sentence Speaks a Thousand Images: Domain Generalization through Distilling CLIP with Language Guidance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_A_Sentence_Speaks_a_Thousand_Images_Domain_Generalization_through_Distilling_ICCV_2023_paper.html",
        "author": "Zeyi Huang, Andy Zhou, Zijian Ling, Mu Cai, Haohan Wang, Yong Jae Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_A_Sentence_Speaks_a_Thousand_Images_Domain_Generalization_through_Distilling_ICCV_2023_paper.pdf",
        "aff": "University of Illinois Urbana-Champaign; University of Wisconsin-Madison; Imperial College London",
        "project": "",
        "github": "github.com/OoDBag/RISE",
        "arxiv": ""
    },
    {
        "title": "A Simple Framework for Open-Vocabulary Segmentation and Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Simple_Framework_for_Open-Vocabulary_Segmentation_and_Detection_ICCV_2023_paper.html",
        "author": "Hao Zhang, Feng Li, Xueyan Zou, Shilong Liu, Chunyuan Li, Jianwei Yang, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Framework_for_Open-Vocabulary_Segmentation_and_Detection_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research at Redmond; International Digital Economy Academy (IDEA), Dept. of CST., BNRist Center, Institute for AI, Tsinghua University; University of Wisconsin-Madison; The Hong Kong University of Science and Technology, International Digital Economy Academy (IDEA); International Digital Economy Academy (IDEA)",
        "project": "",
        "github": "https://github.com/IDEA-Research/OpenSeeD",
        "arxiv": "2303.08131"
    },
    {
        "title": "A Simple Recipe to Meta-Learn Forward and Backward Transfer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cetin_A_Simple_Recipe_to_Meta-Learn_Forward_and_Backward_Transfer_ICCV_2023_paper.html",
        "author": "Edoardo Cetin, Antonio Carta, Oya Celiktutan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cetin_A_Simple_Recipe_to_Meta-Learn_Forward_and_Backward_Transfer_ICCV_2023_paper.pdf",
        "aff": "King\u2019s College London, Department of Engineering; University of Pisa, Department of Computer Science",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Simple Vision Transformer for Weakly Semi-supervised 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Simple_Vision_Transformer_for_Weakly_Semi-supervised_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Dingyuan Zhang, Dingkang Liang, Zhikang Zou, Jingyu Li, Xiaoqing Ye, Zhe Liu, Xiao Tan, Xiang Bai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Vision_Transformer_for_Weakly_Semi-supervised_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Huazhong University of Science and Technology; Baidu Inc., China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Skeletonization Algorithm for Gradient-Based Optimization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Menten_A_Skeletonization_Algorithm_for_Gradient-Based_Optimization_ICCV_2023_paper.html",
        "author": "Martin J. Menten, Johannes C. Paetzold, Veronika A. Zimmer, Suprosanna Shit, Ivan Ezhov, Robbie Holland, Monika Probst, Julia A. Schnabel, Daniel Rueckert",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Menten_A_Skeletonization_Algorithm_for_Gradient-Based_Optimization_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich; Imperial College London",
        "project": "",
        "github": "",
        "arxiv": "2309.02527"
    },
    {
        "title": "A Soft Nearest-Neighbor Framework for Continual Semi-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kang_A_Soft_Nearest-Neighbor_Framework_for_Continual_Semi-Supervised_Learning_ICCV_2023_paper.html",
        "author": "Zhiqi Kang, Enrico Fini, Moin Nabi, Elisa Ricci, Karteek Alahari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_A_Soft_Nearest-Neighbor_Framework_for_Continual_Semi-Supervised_Learning_ICCV_2023_paper.pdf",
        "aff": "SAP AI Research; Inria\u2020; University of Trento; Fondazione Bruno Kessler",
        "project": "",
        "github": "https://github.com/kangzhiq/NNCSL",
        "arxiv": "2212.05102"
    },
    {
        "title": "A Theory of Topological Derivatives for Inverse Rendering of Geometry",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mehta_A_Theory_of_Topological_Derivatives_for_Inverse_Rendering_of_Geometry_ICCV_2023_paper.html",
        "author": "Ishit Mehta, Manmohan Chandraker, Ravi Ramamoorthi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mehta_A_Theory_of_Topological_Derivatives_for_Inverse_Rendering_of_Geometry_ICCV_2023_paper.pdf",
        "aff": "University of California San Diego",
        "project": "",
        "github": "",
        "arxiv": "2308.09865"
    },
    {
        "title": "A Unified Continual Learning Framework with General Parameter-Efficient Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_paper.html",
        "author": "Qiankun Gao, Chen Zhao, Yifan Sun, Teng Xi, Gang Zhang, Bernard Ghanem, Jian Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_paper.pdf",
        "aff": "Peking University Shenzhen Graduate School; King Abdullah University of Science and Technology (KAUST); Baidu Inc.",
        "project": "",
        "github": "https://github.com/gqk/LAE",
        "arxiv": "2303.10070"
    },
    {
        "title": "A Unified Framework for Robustness on Diverse Sampling Errors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_A_Unified_Framework_for_Robustness_on_Diverse_Sampling_Errors_ICCV_2023_paper.html",
        "author": "Myeongho Jeon, Myungjoo Kang, Joonseok Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_A_Unified_Framework_for_Robustness_on_Diverse_Sampling_Errors_ICCV_2023_paper.pdf",
        "aff": "Seoul National University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A step towards understanding why classification helps regression",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pintea_A_step_towards_understanding_why_classification_helps_regression_ICCV_2023_paper.html",
        "author": "Silvia L. Pintea, Yancong Lin, Jouke Dijkstra, Jan C. van Gemert",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pintea_A_step_towards_understanding_why_classification_helps_regression_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Lab, Delft University of Technology; Division of Image Processing (LKEB), Leiden University Medical Center; Intelligent Vehicles Group, Delft University of Technology",
        "project": "",
        "github": "",
        "arxiv": "2308.10603"
    },
    {
        "title": "A-STAR: Test-time Attention Segregation and Retention for Text-to-image Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.html",
        "author": "Aishwarya Agarwal, Srikrishna Karanam, K J Joseph, Apoorv Saxena, Koustava Goswami, Balaji Vasan Srinivasan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Adobe Research, Bengaluru India",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A2Q: Accumulator-Aware Quantization with Guaranteed Overflow Avoidance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Colbert_A2Q_Accumulator-Aware_Quantization_with_Guaranteed_Overflow_Avoidance_ICCV_2023_paper.html",
        "author": "Ian Colbert, Alessandro Pappalardo, Jakoba Petri-Koenig",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Colbert_A2Q_Accumulator-Aware_Quantization_with_Guaranteed_Overflow_Avoidance_ICCV_2023_paper.pdf",
        "aff": "Advanced Micro Devices, Inc.",
        "project": "",
        "github": "",
        "arxiv": "2308.13504"
    },
    {
        "title": "ACLS: Adaptive and Conditional Label Smoothing for Network Calibration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_ACLS_Adaptive_and_Conditional_Label_Smoothing_for_Network_Calibration_ICCV_2023_paper.html",
        "author": "Hyekang Park, Jongyoun Noh, Youngmin Oh, Donghyeon Baek, Bumsub Ham",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_ACLS_Adaptive_and_Conditional_Label_Smoothing_for_Network_Calibration_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; Yonsei University, Korea Institute of Science and Technology (KIST)",
        "project": "https://cvlab.yonsei.ac.kr/projects/ACLS",
        "github": "",
        "arxiv": "2308.11911"
    },
    {
        "title": "ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.html",
        "author": "Naufal Suryanto, Yongsu Kim, Harashta Tatimma Larasati, Hyoeun Kang, Thi-Thu-Huong Le, Yoonyoung Hong, Hunmin Yang, Se-Yoon Oh, Howon Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.pdf",
        "aff": "Pusan National University, South Korea; Agency for Defense Development (ADD), South Korea; Pusan National University, South Korea; SmartM2M, South Korea",
        "project": "https://islab-ai.github.io/active-iccv2023/",
        "github": "",
        "arxiv": "2308.07009"
    },
    {
        "title": "ADAPT: Efficient Multi-Agent Trajectory Prediction with Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Aydemir_ADAPT_Efficient_Multi-Agent_Trajectory_Prediction_with_Adaptation_ICCV_2023_paper.html",
        "author": "G\u00f6rkay Aydemir, Adil Kaan Akan, Fatma G\u00fcney",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Aydemir_ADAPT_Efficient_Multi-Agent_Trajectory_Prediction_with_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Engineering, Koc \u00b8 University; KUIS AI Center",
        "project": "https://KUIS-AI.github.io/adapt",
        "github": "https://github.com/KUIS-AI/adapt",
        "arxiv": ""
    },
    {
        "title": "ADNet: Lane Shape Prediction via Anchor Decomposition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiao_ADNet_Lane_Shape_Prediction_via_Anchor_Decomposition_ICCV_2023_paper.html",
        "author": "Lingyu Xiao, Xiang Li, Sen Yang, Wankou Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_ADNet_Lane_Shape_Prediction_via_Anchor_Decomposition_ICCV_2023_paper.pdf",
        "aff": "IMPlus@PCALab, VCIP, CS, Nankai University, China; School of Automation, Southeast University, China",
        "project": "",
        "github": "https://github.com/Sephirex-X/ADNet",
        "arxiv": "2308.10481"
    },
    {
        "title": "AG3D: Learning to Generate 3D Avatars from 2D Image Collections",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.html",
        "author": "Zijian Dong, Xu Chen, Jinlong Yang, Michael J. Black, Otmar Hilliges, Andreas Geiger",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.pdf",
        "aff": "ETH Z\u00fcrich, Department of Computer Science; Max Planck Institute for Intelligent Systems, T\u00fcbingen; University of T\u00fcbingen",
        "project": "",
        "github": "",
        "arxiv": "2305.02312"
    },
    {
        "title": "AGG-Net: Attention Guided Gated-Convolutional Network for Depth Image Completion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.html",
        "author": "Dongyue Chen, Tingxuan Huang, Zhimin Song, Shizhuo Deng, Tong Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.pdf",
        "aff": "College of Information Science and Engineering, Northeastern University Shenyang 110819, Liaoning, China; Foshan Graduate School of Innovation, Northeastern University, Foshan 528311, Guangdong, China; College of Information Science and Engineering, Northeastern University Shenyang 110819, Liaoning, China; National Frontiers Science Center for Industrial Intelligence and Systems Optimization, Northeastern University, Shenyang 110819, Liaoning, China; Foshan Graduate School of Innovation, Northeastern University, Foshan 528311, Guangdong, China; College of Information Science and Engineering, Northeastern University Shenyang 110819, Liaoning, China; College of Information Science and Engineering, Northeastern University Shenyang 110819, Liaoning, China; National Frontiers Science Center for Industrial Intelligence and Systems Optimization, Northeastern University, Shenyang 110819, Liaoning, China",
        "project": "",
        "github": "https://github.com/htx0601/AGG-Net",
        "arxiv": ""
    },
    {
        "title": "AIDE: A Vision-Driven Multi-View, Multi-Modal, Multi-Tasking Dataset for Assistive Driving Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_AIDE_A_Vision-Driven_Multi-View_Multi-Modal_Multi-Tasking_Dataset_for_Assistive_Driving_ICCV_2023_paper.html",
        "author": "Dingkang Yang, Shuai Huang, Zhi Xu, Zhenpeng Li, Shunli Wang, Mingcheng Li, Yuzheng Wang, Yang Liu, Kun Yang, Zhaoyu Chen, Yan Wang, Jing Liu, Peixuan Zhang, Peng Zhai, Lihua Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_AIDE_A_Vision-Driven_Multi-View_Multi-Modal_Multi-Tasking_Dataset_for_Assistive_Driving_ICCV_2023_paper.pdf",
        "aff": "Boli Technology Co., Ltd., Changchun, China; 1Academy for Engineering and Technology, Fudan University; 2Institute of Meta-Medical Engineering Research Center of AI and Robotics, Ministry of Education, Shanghai, China; 1Academy for Engineering and Technology, Fudan University; 1Academy for Engineering and Technology, Fudan University; 2Institute of Meta-Medical Engineering Research Center of AI and Robotics, Ministry of Education, Shanghai, China; 3AI and Unmanned Systems Engineering Research Center of Jilin Province, Changchun, China",
        "project": "",
        "github": "",
        "arxiv": "2307.13933"
    },
    {
        "title": "ALIP: Adaptive Language-Image Pre-Training with Synthetic Caption",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.html",
        "author": "Kaicheng Yang, Jiankang Deng, Xiang An, Jiawei Li, Ziyong Feng, Jia Guo, Jing Yang, Tongliang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.pdf",
        "aff": "ALIP: Adaptive Language-Image Pre-training with Synthetic Caption\nKaicheng Yang1, Jiankang Deng* 2, Xiang An1, Jiawei Li1, Ziyong Feng1,\nJia Guo3, Jing Yang3, Tongliang Liu4\n1DeepGlint2Huawei UKRD3InsightFace4University of Sydney\n{kaichengyang,xiangan,jiaweili,ziyongfeng }@deepglint.com, tongliang.liu@sydney.edu.au\n{jiankangdeng,guojia,y.jing2016 }@gmail.com\nAbstract\nContrastive Language-Image Pre-training (CLIP) has\nsignificantly boosted the performance of various vision-\nlanguage tasks by scaling up the dataset with image-text\npairs collected from the web. However, the presence of in-\ntrinsic noise and unmatched image-text pairs in web data\ncan potentially affect the performance of representation\nlearning. To address this issue, we first utilize the OFA\nmodel to generate synthetic captions that focus on the im-\nage content. The generated captions contain complemen-\ntary information that is beneficial for pre-training. Then, we\npropose an Adaptive Language-Image Pre-training (ALIP),\na bi-path model that integrates supervision from both raw\ntext and synthetic caption. As the core components of ALIP ,\nthe Language Consistency Gate (LCG) and Description\nConsistency Gate (DCG) dynamically adjust the weights\nof samples and image-text/caption pairs during the train-\ning process. Meanwhile, the adaptive contrastive loss\ncan effectively reduce the impact of noise data and en-\nhances the efficiency of pre-training data. We validate\nALIP with experiments on different scales of models and\npre-training datasets. Experiments results show that ALIP\nachieves state-of-the-art performance on multiple down-\nstream tasks including zero-shot image-text retrieval and\nlinear probe. To facilitate future research, the code and pre-\ntrained models are released at https://github.com/\ndeepglint/ALIP .\n1. Introduction\nWith the development of mobile networks and social\nplatforms, there has been an explosion in the production\nof image-text pairs on a massive scale [3, 13]. This un-\nprecedented abundance of data has laid a solid foundation\nfor vision-language pre-training [32, 15]. Through image-\ntext alignment on large-scale data, the Contrastive Lan-\n*corresponding author.\nFigure 1. Examples from the YFCC15M dataset to illustrate the\nmismatched (left) and matched (right) image-text pairs. The syn-\nthetic caption is generated from the OFA [37] model. The raw text\ndescription \u201cLeisure Sunday\u201d is less aligned with the raw image in\nthe left sample, while the synthetic caption \u201cA woman sitting on a\nstep reading a book\u201d is a more accurate representation.\nguage\u2013Image Pre-training (CLIP) method [32] has demon-\nstrated huge success in multi-modal learning. Specifically,\nCLIP learns two separate unimodal encoders for image and\ntext using a contrastive loss, one of the most effective losses\nfor representation learning [36, 14, 5, 7]. Nevertheless, the\nnegative impact of the noise in the web-crawled data has\nbeen largely overlooked, shadowed by the performance gain\nachieved from scaling up the training data [31, 1].\nTo facilitate research on large-scale multi-modal models,\nLAION400M [34] and LAION5B [33] were released, com-\nprising 400 million and 5 billion image-text pairs respec-\ntively, which were filtered using the CLIP model. How-\never, the current offline filtering approach results in a sub-\nstantial loss of training data, as the original dataset con-\ntains 5 billion image-text pairs. Furthermore, this ap-\nproach may introduce biases due to the limited represen-\ntation power of the pre-trained model used for filtering.\nDespite efforts to curate data for high-quality image-text\npairs ( e.g., LAION [34, 33] and YFCC100M [35]), noisy\nand poorly-aligned pairs still exist in existing image-text\ndatasets, which can potentially impact the performance of\nrepresentation learning.\nIn Fig. 1, we present two samples from YFCC15M. The\nraw text of the right sample (\u201cDrink beer\u201d) is correct and\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n2922\n",
        "project": "",
        "github": "",
        "arxiv": "2308.08428"
    },
    {
        "title": "ALWOD: Active Learning for Weakly-Supervised Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ALWOD_Active_Learning_for_Weakly-Supervised_Object_Detection_ICCV_2023_paper.html",
        "author": "Yuting Wang, Velibor Ilic, Jiatong Li, Branislav Kisa\u010danin, Vladimir Pavlovic",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ALWOD_Active_Learning_for_Weakly-Supervised_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "The Institute for Artificial Intelligence Research and Development of Serbia, Novi Sad, Serbia; Nvidia Corporation, TX, USA; Rutgers University, NJ, USA",
        "project": "",
        "github": "https://github.com/seqam-lab/ALWOD",
        "arxiv": "2309.07914"
    },
    {
        "title": "AREA: Adaptive Reweighting via Effective Area for Long-Tailed Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AREA_Adaptive_Reweighting_via_Effective_Area_for_Long-Tailed_Classification_ICCV_2023_paper.html",
        "author": "Xiaohua Chen, Yucan Zhou, Dayan Wu, Chule Yang, Bo Li, Qinghua Hu, Weiping Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AREA_Adaptive_Reweighting_via_Effective_Area_for_Long-Tailed_Classification_ICCV_2023_paper.pdf",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Defense Innovation Institute, Military Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Tianjin University",
        "project": "",
        "github": "https://github.com/xiaohua-chen/AREA",
        "arxiv": ""
    },
    {
        "title": "ARNOLD: A Benchmark for Language-Grounded Task Learning with Continuous States in Realistic 3D Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gong_ARNOLD_A_Benchmark_for_Language-Grounded_Task_Learning_with_Continuous_States_ICCV_2023_paper.html",
        "author": "Ran Gong, Jiangyong Huang, Yizhou Zhao, Haoran Geng, Xiaofeng Gao, Qingyang Wu, Wensi Ai, Ziheng Zhou, Demetri Terzopoulos, Song-Chun Zhu, Baoxiong Jia, Siyuan Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ARNOLD_A_Benchmark_for_Language-Grounded_Task_Learning_with_Continuous_States_ICCV_2023_paper.pdf",
        "aff": "University of California, Los Angeles; National Key Laboratory of General Artificial Intelligence, BIGAI; Columbia University; Peking University, Tsinghua University, National Key Laboratory of General Artificial Intelligence, BIGAI; Peking University, National Key Laboratory of General Artificial Intelligence, BIGAI",
        "project": "https://arnold-benchmark.github.io",
        "github": "",
        "arxiv": "2304.04321"
    },
    {
        "title": "ASAG: Building Strong One-Decoder-Layer Sparse Detectors via Adaptive Sparse Anchor Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fu_ASAG_Building_Strong_One-Decoder-Layer_Sparse_Detectors_via_Adaptive_Sparse_Anchor_ICCV_2023_paper.html",
        "author": "Shenghao Fu, Junkai Yan, Yipeng Gao, Xiaohua Xie, Wei-Shi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_ASAG_Building_Strong_One-Decoder-Layer_Sparse_Detectors_via_Adaptive_Sparse_Anchor_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China",
        "project": "",
        "github": "https://github.com/iSEE-Laboratory/ASAG",
        "arxiv": "2308.09242"
    },
    {
        "title": "ASIC: Aligning Sparse in-the-wild Image Collections",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.html",
        "author": "Kamal Gupta, Varun Jampani, Carlos Esteves, Abhinav Shrivastava, Ameesh Makadia, Noah Snavely, Abhishek Kar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; Google",
        "project": "https://kampta.github.io/asic",
        "github": "https://github.com/kampta/asic",
        "arxiv": "2303.16201"
    },
    {
        "title": "ASM: Adaptive Skinning Model for High-Quality 3D Face Modeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_ASM_Adaptive_Skinning_Model_for_High-Quality_3D_Face_Modeling_ICCV_2023_paper.html",
        "author": "Kai Yang, Hong Shang, Tianyang Shi, Xinghan Chen, Jingkai Zhou, Zhongqian Sun, Wei Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ASM_Adaptive_Skinning_Model_for_High-Quality_3D_Face_Modeling_ICCV_2023_paper.pdf",
        "aff": "Tencent AI Lab",
        "project": "",
        "github": "",
        "arxiv": "2304.09423"
    },
    {
        "title": "ATT3D: Amortized Text-to-3D Object Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lorraine_ATT3D_Amortized_Text-to-3D_Object_Synthesis_ICCV_2023_paper.html",
        "author": "Jonathan Lorraine, Kevin Xie, Xiaohui Zeng, Chen-Hsuan Lin, Towaki Takikawa, Nicholas Sharp, Tsung-Yi Lin, Ming-Yu Liu, Sanja Fidler, James Lucas",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lorraine_ATT3D_Amortized_Text-to-3D_Object_Synthesis_ICCV_2023_paper.pdf",
        "aff": "NVIDIA Corporation",
        "project": "https://www.example.com/projectpage",
        "github": "",
        "arxiv": "2306.07349"
    },
    {
        "title": "Ablating Concepts in Text-to-Image Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Nupur Kumari, Bingliang Zhang, Sheng-Yu Wang, Eli Shechtman, Richard Zhang, Jun-Yan Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Adobe Research; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2303.13516"
    },
    {
        "title": "AccFlow: Backward Accumulation for Long-Range Optical Flow",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_AccFlow_Backward_Accumulation_for_Long-Range_Optical_Flow_ICCV_2023_paper.html",
        "author": "Guangyang Wu, Xiaohong Liu, Kunming Luo, Xi Liu, Qingqing Zheng, Shuaicheng Liu, Xinyang Jiang, Guangtao Zhai, Wenyi Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_AccFlow_Backward_Accumulation_for_Long-Range_Optical_Flow_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; Shenzhen Institute of Advanced Technology; Shanghai Jiao Tong University; Microsoft Research Asia; Hong Kong University of Science and Technology",
        "project": "",
        "github": "https://github.com/mulns/AccFlow",
        "arxiv": "2308.13133"
    },
    {
        "title": "Accurate 3D Face Reconstruction with Facial Component Tokens",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Accurate_3D_Face_Reconstruction_with_Facial_Component_Tokens_ICCV_2023_paper.html",
        "author": "Tianke Zhang, Xuangeng Chu, Yunfei Liu, Lijian Lin, Zhendong Yang, Zhengzhuo Xu, Chengkun Cao, Fei Yu, Changyin Zhou, Chun Yuan, Yu Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Accurate_3D_Face_Reconstruction_with_Facial_Component_Tokens_ICCV_2023_paper.pdf",
        "aff": "Target Expressions\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n9033\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Accurate and Fast Compressed Video Captioning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Accurate_and_Fast_Compressed_Video_Captioning_ICCV_2023_paper.html",
        "author": "Yaojie Shen, Xin Gu, Kai Xu, Heng Fan, Longyin Wen, Libo Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Accurate_and_Fast_Compressed_Video_Captioning_ICCV_2023_paper.pdf",
        "aff": "Institute of Software, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; ByteDance Inc., San Jose, USA; Department of Computer Science and Engineering, University of North Texas, Denton TX, USA",
        "project": "",
        "github": "https://github.com/acherstyx/CoCap",
        "arxiv": "2309.12867"
    },
    {
        "title": "Achievement-Based Training Progress Balancing for Multi-Task Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yun_Achievement-Based_Training_Progress_Balancing_for_Multi-Task_Learning_ICCV_2023_paper.html",
        "author": "Hayoung Yun, Hanjoo Cho",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Achievement-Based_Training_Progress_Balancing_for_Multi-Task_Learning_ICCV_2023_paper.pdf",
        "aff": "Samsung Research",
        "project": "",
        "github": "https://github.com/samsung/Achievement-based-MTL",
        "arxiv": ""
    },
    {
        "title": "ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D Human Motion Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.html",
        "author": "Liang Xu, Ziyang Song, Dongliang Wang, Jing Su, Zhicheng Fang, Chenjing Ding, Weihao Gan, Yichao Yan, Xin Jin, Xiaokang Yang, Wenjun Zeng, Wei Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.pdf",
        "aff": "Eastern Institute of Technology, Ningbo; Mashang Consumer Finance Co., Ltd.; The Hong Kong Polytechnic University; Shanghai Jiao Tong University; Ningbo Institute of Digital Twin; SenseTime Research",
        "project": "https://liangxuy.github.io/actformer/",
        "github": "",
        "arxiv": "2203.07706"
    },
    {
        "title": "Action Sensitivity Learning for Temporal Action Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Action_Sensitivity_Learning_for_Temporal_Action_Localization_ICCV_2023_paper.html",
        "author": "Jiayi Shao, Xiaohan Wang, Ruijie Quan, Junjun Zheng, Jiang Yang, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Action_Sensitivity_Learning_for_Temporal_Action_Localization_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group; ReLER Lab, CCAI, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2305.15701"
    },
    {
        "title": "Activate and Reject: Towards Safe Domain Generalization under Category Shift",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Activate_and_Reject_Towards_Safe_Domain_Generalization_under_Category_Shift_ICCV_2023_paper.html",
        "author": "Chaoqi Chen, Luyao Tang, Leitian Tao, Hong-Yu Zhou, Yue Huang, Xiaoguang Han, Yizhou Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Activate_and_Reject_Towards_Safe_Domain_Generalization_under_Category_Shift_ICCV_2023_paper.pdf",
        "aff": "University of Wisconsin - Madison; The University of Hong Kong; Xiamen University; The Chinese University of Hong Kong (Shenzhen)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Active Neural Mapping",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Active_Neural_Mapping_ICCV_2023_paper.html",
        "author": "Zike Yan, Haoxiang Yang, Hongbin Zha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Active_Neural_Mapping_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Machine Perception (MOE), School of EECS, Peking University; PKU-SenseTime Machine Vision Joint Lab",
        "project": "",
        "github": "",
        "arxiv": "2308.16246"
    },
    {
        "title": "Active Self-Supervised Learning: A Few Low-Cost Relationships Are All You Need",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cabannes_Active_Self-Supervised_Learning_A_Few_Low-Cost_Relationships_Are_All_You_ICCV_2023_paper.html",
        "author": "Vivien Cabannes, Leon Bottou, Yann Lecun, Randall Balestriero",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cabannes_Active_Self-Supervised_Learning_A_Few_Low-Cost_Relationships_Are_All_You_ICCV_2023_paper.pdf",
        "aff": "Meta AI",
        "project": "",
        "github": "",
        "arxiv": "2303.15256"
    },
    {
        "title": "Active Stereo Without Pattern Projector",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bartolomei_Active_Stereo_Without_Pattern_Projector_ICCV_2023_paper.html",
        "author": "Luca Bartolomei, Matteo Poggi, Fabio Tosi, Andrea Conti, Stefano Mattoccia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bartolomei_Active_Stereo_Without_Pattern_Projector_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering (DISI), University of Bologna, Italy; Advanced Research Center on Electronic System (ARCES), Department of Computer Science and Engineering (DISI), University of Bologna, Italy",
        "project": "",
        "github": "https://vppstereo.github.io/",
        "arxiv": "2309.12315"
    },
    {
        "title": "ActorsNeRF: Animatable Few-shot Human Rendering with Generalizable NeRFs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mu_ActorsNeRF_Animatable_Few-shot_Human_Rendering_with_Generalizable_NeRFs_ICCV_2023_paper.html",
        "author": "Jiteng Mu, Shen Sang, Nuno Vasconcelos, Xiaolong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mu_ActorsNeRF_Animatable_Few-shot_Human_Rendering_with_Generalizable_NeRFs_ICCV_2023_paper.pdf",
        "aff": "UC San Diego; ByteDance",
        "project": "https://jitengmu.github.io/ActorsNeRF/",
        "github": "",
        "arxiv": "2304.14401"
    },
    {
        "title": "AdVerb: Visually Guided Audio Dereverberation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_AdVerb_Visually_Guided_Audio_Dereverberation_ICCV_2023_paper.html",
        "author": "Sanjoy Chowdhury, Sreyan Ghosh, Subhrajyoti Dasgupta, Anton Ratnarajah, Utkarsh Tyagi, Dinesh Manocha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_AdVerb_Visually_Guided_Audio_Dereverberation_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; Mila and Universit\u00e9 de Montr\u00e9al",
        "project": "https://gamma.umd.edu/researchdirections/speech/adverb",
        "github": "",
        "arxiv": "2308.12370"
    },
    {
        "title": "Ada3D : Exploiting the Spatial Redundancy with Adaptive Inference for Efficient 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Ada3D__Exploiting_the_Spatial_Redundancy_with_Adaptive_Inference_for_ICCV_2023_paper.html",
        "author": "Tianchen Zhao, Xuefei Ning, Ke Hong, Zhongyuan Qiu, Pu Lu, Yali Zhao, Linfeng Zhang, Lipu Zhou, Guohao Dai, Huazhong Yang, Yu Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Ada3D__Exploiting_the_Spatial_Redundancy_with_Adaptive_Inference_for_ICCV_2023_paper.pdf",
        "aff": "Shanghai Jiao Tong University; Meituan; Novauto; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2307.08209"
    },
    {
        "title": "AdaMV-MoE: Adaptive Multi-Task Vision Mixture-of-Experts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AdaMV-MoE_Adaptive_Multi-Task_Vision_Mixture-of-Experts_ICCV_2023_paper.html",
        "author": "Tianlong Chen, Xuxi Chen, Xianzhi Du, Abdullah Rashwan, Fan Yang, Huizhong Chen, Zhangyang Wang, Yeqing Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdaMV-MoE_Adaptive_Multi-Task_Vision_Mixture-of-Experts_ICCV_2023_paper.pdf",
        "aff": "Google; University of Texas at Austin; Apple",
        "project": "",
        "github": "https://github.com/google-research/google-research/tree/master/moe_mtl",
        "arxiv": ""
    },
    {
        "title": "AdaNIC: Towards Practical Neural Image Compression via Dynamic Transform Routing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tao_AdaNIC_Towards_Practical_Neural_Image_Compression_via_Dynamic_Transform_Routing_ICCV_2023_paper.html",
        "author": "Lvfang Tao, Wei Gao, Ge Li, Chenhao Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_AdaNIC_Towards_Practical_Neural_Image_Compression_via_Dynamic_Transform_Routing_ICCV_2023_paper.pdf",
        "aff": "Shenzhen Graduate School, Peking University; Tencent AI Lab",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adaptive Calibrator Ensemble: Navigating Test Set Difficulty in Out-of-Distribution Scenarios",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Adaptive_Calibrator_Ensemble_Navigating_Test_Set_Difficulty_in_Out-of-Distribution_Scenarios_ICCV_2023_paper.html",
        "author": "Yuli Zou, Weijian Deng, Liang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Adaptive_Calibrator_Ensemble_Navigating_Test_Set_Difficulty_in_Out-of-Distribution_Scenarios_ICCV_2023_paper.pdf",
        "aff": "The Australian National University; The Hong Kong Polytechnic University",
        "project": "",
        "github": "https://github.com/insysgroup/Adaptive-Calibrators-Ensemble.git",
        "arxiv": ""
    },
    {
        "title": "Adaptive Frequency Filters As Efficient Global Token Mixers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Adaptive_Frequency_Filters_As_Efficient_Global_Token_Mixers_ICCV_2023_paper.html",
        "author": "Zhipeng Huang, Zhizheng Zhang, Cuiling Lan, Zheng-Jun Zha, Yan Lu, Baining Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Adaptive_Frequency_Filters_As_Efficient_Global_Token_Mixers_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/microsoft/TokenMixers",
        "arxiv": "2307.14008"
    },
    {
        "title": "Adaptive Illumination Mapping for Shadow Detection in Raw Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Adaptive_Illumination_Mapping_for_Shadow_Detection_in_Raw_Images_ICCV_2023_paper.html",
        "author": "Jiayu Sun, Ke Xu, Youwei Pang, Lihe Zhang, Huchuan Lu, Gerhard Hancke, Rynson Lau",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Adaptive_Illumination_Mapping_for_Shadow_Detection_in_Raw_Images_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, City University of Hong Kong; School of Information and Communication Engineering, Dalian University of Technology",
        "project": "",
        "github": "https://github.com/jiayusun/SARA",
        "arxiv": ""
    },
    {
        "title": "Adaptive Image Anonymization in the Context of Image Classification with Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shvai_Adaptive_Image_Anonymization_in_the_Context_of_Image_Classification_with_ICCV_2023_paper.html",
        "author": "Nadiya Shvai, Arcadi Llanza Carmona, Amir Nakib",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shvai_Adaptive_Image_Anonymization_in_the_Context_of_Image_Classification_with_ICCV_2023_paper.pdf",
        "aff": "University Paris Est Cr\u00eateil, Laboratoire LISSI, Paris, France; Cyclope.ai, Paris, France; University Paris Est Cr\u00eateil, Laboratoire LISSI, Paris, France",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adaptive Nonlinear Latent Transformation for Conditional Face Editing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Adaptive_Nonlinear_Latent_Transformation_for_Conditional_Face_Editing_ICCV_2023_paper.html",
        "author": "Zhizhong Huang, Siteng Ma, Junping Zhang, Hongming Shan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Adaptive_Nonlinear_Latent_Transformation_for_Conditional_Face_Editing_ICCV_2023_paper.pdf",
        "aff": "Institute of Science and Technology for Brain-inspired Intelligence and MOE Frontiers Center for Brain Science, Fudan University, Shanghai 200433, China; Shanghai Center for Brain Science and Brain-inspired Technology, Shanghai 200031, China; Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai 200433, China",
        "project": "",
        "github": "https://github.com/Hzzone/AdaTrans",
        "arxiv": "2307.07790"
    },
    {
        "title": "Adaptive Positional Encoding for Bundle-Adjusting Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Adaptive_Positional_Encoding_for_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Zelin Gao, Weichen Dai, Yu Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Positional_Encoding_for_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University; Key Laboratory of Brain Machine Collaborative Intelligence of Zhejiang Province and School of Computer Science, Hangzhou Dianzi University; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University; Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems of Zhejiang Province",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adaptive Reordering Sampler with Neurally Guided MAGSAC",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Adaptive_Reordering_Sampler_with_Neurally_Guided_MAGSAC_ICCV_2023_paper.html",
        "author": "Tong Wei, Jiri Matas, Daniel Barath",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Adaptive_Reordering_Sampler_with_Neurally_Guided_MAGSAC_ICCV_2023_paper.pdf",
        "aff": "Computer Vision and Geometry Group, ETH Zurich; Visual Recognition Group, FEE, Czech Technical University in Prague",
        "project": "",
        "github": "https://github.com/weitong8591/ars_magsac",
        "arxiv": "2111.14093"
    },
    {
        "title": "Adaptive Rotated Convolution for Rotated Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pu_Adaptive_Rotated_Convolution_for_Rotated_Object_Detection_ICCV_2023_paper.html",
        "author": "Yifan Pu, Yiru Wang, Zhuofan Xia, Yizeng Han, Yulin Wang, Weihao Gan, Zidong Wang, Shiji Song, Gao Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pu_Adaptive_Rotated_Convolution_for_Rotated_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, BNRist, Tsinghua University; Beijing Academy of Artificial Intelligence; Mashang Consumer Finance Co., Ltd.; SenseTime Research",
        "project": "",
        "github": "https://github.com/LeapLabTHU/ARC",
        "arxiv": "2303.07820"
    },
    {
        "title": "Adaptive Similarity Bootstrapping for Self-Distillation Based Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lebailly_Adaptive_Similarity_Bootstrapping_for_Self-Distillation_Based_Representation_Learning_ICCV_2023_paper.html",
        "author": "Tim Lebailly, Thomas Stegm\u00fcller, Behzad Bozorgtabar, Jean-Philippe Thiran, Tinne Tuytelaars",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lebailly_Adaptive_Similarity_Bootstrapping_for_Self-Distillation_Based_Representation_Learning_ICCV_2023_paper.pdf",
        "aff": "EPFL; KU Leuven",
        "project": "",
        "github": "https://github.com/tileb1/AdaSim",
        "arxiv": ""
    },
    {
        "title": "Adaptive Spiral Layers for Efficient 3D Representation Learning on Meshes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Babiloni_Adaptive_Spiral_Layers_for_Efficient_3D_Representation_Learning_on_Meshes_ICCV_2023_paper.html",
        "author": "Francesca Babiloni, Matteo Maggioni, Thomas Tanay, Jiankang Deng, Ales Leonardis, Stefanos Zafeiriou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Babiloni_Adaptive_Spiral_Layers_for_Efficient_3D_Representation_Learning_on_Meshes_ICCV_2023_paper.pdf",
        "aff": "Imperial College London; Huawei, Noah\u2019s Ark Lab; Imperial College London; Huawei, Noah\u2019s Ark Lab",
        "project": "",
        "github": "https://github.com/Fb2221/DFC",
        "arxiv": ""
    },
    {
        "title": "Adaptive Superpixel for Active Learning in Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Adaptive_Superpixel_for_Active_Learning_in_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Hoyoung Kim, Minhyeon Oh, Sehyun Hwang, Suha Kwak, Jungseul Ok",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Adaptive_Superpixel_for_Active_Learning_in_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Graduate School of AI, POSTECH / Dept. of CSE, POSTECH; Graduate School of AI, POSTECH; Dept. of CSE, POSTECH",
        "project": "",
        "github": "",
        "arxiv": "2303.16817"
    },
    {
        "title": "Adaptive Template Transformer for Mitochondria Segmentation in Electron Microscopy Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Adaptive_Template_Transformer_for_Mitochondria_Segmentation_in_Electron_Microscopy_Images_ICCV_2023_paper.html",
        "author": "Yuwen Pan, Naisong Luo, Rui Sun, Meng Meng, Tianzhu Zhang, Zhiwei Xiong, Yongdong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Adaptive_Template_Transformer_for_Mitochondria_Segmentation_in_Electron_Microscopy_Images_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; University of Science and Technology of China, State Key Laboratory of Communication Content Cognition, People\u2019s Daily Online; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adaptive Testing of Computer Vision Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Adaptive_Testing_of_Computer_Vision_Models_ICCV_2023_paper.html",
        "author": "Irena Gao, Gabriel Ilharco, Scott Lundberg, Marco Tulio Ribeiro",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Testing_of_Computer_Vision_Models_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; Stanford University; University of Washington",
        "project": "",
        "github": "",
        "arxiv": "2212.02774"
    },
    {
        "title": "Adaptive and Background-Aware Vision Transformer for Real-Time UAV Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.html",
        "author": "Shuiwang Li, Yangxiang Yang, Dan Zeng, Xucheng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.pdf",
        "aff": "Research Institue of Trustworthy Autonomous Systems, Southern University of Science and Technology, China; College of Information Science and Engineering, Guilin University of Technology, China",
        "project": "",
        "github": "https://github.com/xyyang317/Aba-ViTrack",
        "arxiv": ""
    },
    {
        "title": "Adding Conditional Control to Text-to-Image Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Lvmin Zhang, Anyi Rao, Maneesh Agrawala",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Stanford University",
        "project": "",
        "github": "",
        "arxiv": "2302.05543"
    },
    {
        "title": "AdvDiffuser: Natural Adversarial Example Synthesis with Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AdvDiffuser_Natural_Adversarial_Example_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Xinquan Chen, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdvDiffuser_Natural_Adversarial_Example_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; State Key Lab of IOTSC, University of Macau, Macau S.A.R., China",
        "project": "",
        "github": "https://github.com/lafeat/advdiffuser",
        "arxiv": ""
    },
    {
        "title": "Advancing Example Exploitation Can Alleviate Critical Challenges in Adversarial Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Advancing_Example_Exploitation_Can_Alleviate_Critical_Challenges_in_Adversarial_Training_ICCV_2023_paper.html",
        "author": "Yao Ge, Yun Li, Keji Han, Junyi Zhu, Xianzhong Long",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Advancing_Example_Exploitation_Can_Alleviate_Critical_Challenges_in_Adversarial_Training_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Nanjing University of Posts and Telecommunications; College of Arts & Sciences, Boston University",
        "project": "",
        "github": "https://github.com/geyao1995/advancing-example-exploitation-in-adversarial-training",
        "arxiv": ""
    },
    {
        "title": "Advancing Referring Expression Segmentation Beyond Single Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Advancing_Referring_Expression_Segmentation_Beyond_Single_Image_ICCV_2023_paper.html",
        "author": "Yixuan Wu, Zhao Zhang, Chi Xie, Feng Zhu, Rui Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Advancing_Referring_Expression_Segmentation_Beyond_Single_Image_ICCV_2023_paper.pdf",
        "aff": "SenseTime Research, Tongji University; SenseTime Research, Zhejiang University; Qing Yuan Research Institute, Shanghai Jiao Tong University; SenseTime Research, Qing Yuan Research Institute, Shanghai Jiao Tong University; SenseTime Research",
        "project": "",
        "github": "https://github.com/shikras/d-cube",
        "arxiv": "2305.12452"
    },
    {
        "title": "Adversarial Bayesian Augmentation for Single-Source Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Adversarial_Bayesian_Augmentation_for_Single-Source_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Sheng Cheng, Tejas Gokhale, Yezhou Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Adversarial_Bayesian_Augmentation_for_Single-Source_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "Arizona State University; Arizona State University, University of Maryland, Baltimore County",
        "project": "",
        "github": "https://github.com/shengcheng/ABA",
        "arxiv": "2307.09520"
    },
    {
        "title": "Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Suzuki_Adversarial_Finetuning_with_Latent_Representation_Constraint_to_Mitigate_Accuracy-Robustness_Tradeoff_ICCV_2023_paper.html",
        "author": "Satoshi Suzuki, Shin'ya Yamaguchi, Shoichiro Takeda, Sekitoshi Kanai, Naoki Makishima, Atsushi Ando, Ryo Masumura",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Suzuki_Adversarial_Finetuning_with_Latent_Representation_Constraint_to_Mitigate_Accuracy-Robustness_Tradeoff_ICCV_2023_paper.pdf",
        "aff": "NTT Computer and Data Science Laboratories, Kyoto University; NTT Human Informatics Laboratories; NTT Computer and Data Science Laboratories, NTT Human Informatics Laboratories; NTT Computer and Data Science Laboratories",
        "project": "",
        "github": "",
        "arxiv": "2308.16454"
    },
    {
        "title": "Adverse Weather Removal with Codebook Priors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Adverse_Weather_Removal_with_Codebook_Priors_ICCV_2023_paper.html",
        "author": "Tian Ye, Sixiang Chen, Jinbin Bai, Jun Shi, Chenghao Xue, Jingxia Jiang, Junjie Yin, Erkang Chen, Yun Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Adverse_Weather_Removal_with_Codebook_Priors_ICCV_2023_paper.pdf",
        "aff": "School of Ocean Information Engineering, Jimei University; National University of Singapore; Xinjiang University; The Hong Kong University of Science and Technology (Guangzhou); College of Artificial Intelligence, Southwest University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "AerialVLN: Vision-and-Language Navigation for UAVs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_AerialVLN_Vision-and-Language_Navigation_for_UAVs_ICCV_2023_paper.html",
        "author": "Shubo Liu, Hongsheng Zhang, Yuankai Qi, Peng Wang, Yanning Zhang, Qi Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_AerialVLN_Vision-and-Language_Navigation_for_UAVs_ICCV_2023_paper.pdf",
        "aff": "Northwestern Polytechnical University; University of Adelaide",
        "project": "",
        "github": "",
        "arxiv": "2308.06735"
    },
    {
        "title": "AesPA-Net: Aesthetic Pattern-Aware Style Transfer Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hong_AesPA-Net_Aesthetic_Pattern-Aware_Style_Transfer_Networks_ICCV_2023_paper.html",
        "author": "Kibeom Hong, Seogkyu Jeon, Junsoo Lee, Namhyuk Ahn, Kunhee Kim, Pilhyeon Lee, Daesik Kim, Youngjung Uh, Hyeran Byun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_AesPA-Net_Aesthetic_Pattern-Aware_Style_Transfer_Networks_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; NAVER WEBTOON AI; Yonsei University, KAIST AI, SwatchOn, NAVER WEBTOON AI; KAIST AI",
        "project": "",
        "github": "https://github.com/Kibeom-Hong/AesPA-Net",
        "arxiv": ""
    },
    {
        "title": "Affective Image Filter: Reflecting Emotions from Text to Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.html",
        "author": "Shuchen Weng, Peixuan Zhang, Zheng Chang, Xinlong Wang, Si Li, Boxin Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.pdf",
        "aff": "Beijing Academy of Artificial Intelligence; School of Artificial Intelligence, Beijing University of Posts and Telecommunications; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Affine-Consistent Transformer for Multi-Class Cell Nuclei Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Affine-Consistent_Transformer_for_Multi-Class_Cell_Nuclei_Detection_ICCV_2023_paper.html",
        "author": "Junjia Huang, Haofeng Li, Xiang Wan, Guanbin Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Affine-Consistent_Transformer_for_Multi-Class_Cell_Nuclei_Detection_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Research Institute of Sun Yat-sen University in Shenzhen, Sun Yat-sen University, Guangzhou, China; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "AffordPose: A Large-Scale Dataset of Hand-Object Interactions with Affordance-Driven Hand Pose",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jian_AffordPose_A_Large-Scale_Dataset_of_Hand-Object_Interactions_with_Affordance-Driven_Hand_ICCV_2023_paper.html",
        "author": "Juntao Jian, Xiuping Liu, Manyi Li, Ruizhen Hu, Jian Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_AffordPose_A_Large-Scale_Dataset_of_Hand-Object_Interactions_with_Affordance-Driven_Hand_ICCV_2023_paper.pdf",
        "aff": "AffordPose: A Large-scale Dataset of Hand-Object Interactions with\nAffordance-driven Hand Pose\nJuntao Jian1Xiuping Liu1Manyi Li2\u22c6Ruizhen Hu3Jian Liu4\u22c6\n1Dalian University of Technology2Shandong University\n3Shenzhen University4Tsinghua University\nAbstract\nHow human interact with objects depends on the func-\ntional roles of the target objects, which introduces the prob-\nlem of affordance-aware hand-object interaction. It re-\nquires a large number of human demonstrations for the\nlearning and understanding of plausible and appropriate\nhand-object interactions. In this work, we present Af-\nfordPose, a large-scale dataset of hand-object interactions\nwith affordance-driven hand pose. We first annotate the\nspecific part-level affordance labels for each object, e.g.\ntwist, pull, handle-grasp, etc, instead of the general in-\ntents such as use or handover, to indicate the purpose and\nguide the localization of the hand-object interactions. The\nfine-grained hand-object interactions reveal the influence of\nhand-centered affordances on the detailed arrangement of\nthe hand poses, yet also exhibit a certain degree of diver-\nsity. We collect a total of 26.7K hand-object interactions,\neach including the 3D object shape, the part-level affor-\ndance label, and the manually adjusted hand poses. The\ncomprehensive data analysis shows the common character-\nistics and diversity of hand-object interactions per affor-\ndance via the parameter statistics and contacting compu-\ntation. We also conduct experiments on the tasks of hand-\nobject affordance understanding and affordance-oriented\nhand-object interaction generation, to validate the effec-\ntiveness of our dataset in learning the fine-grained hand-\nobject interactions. Project page: https://github.\ncom/GentlesJan/AffordPose\n1. Introduction\nOne of the long-standing goals of robotics is to imitate\nall kinds of human-centered interactions, especially hand-\nobject interactions, ranging from general grasping to func-\ntional interactions such as unscrewing a cap or even tool\nusage [22, 15]. Performing appropriate hand-object interac-\ntion is a complicated decision-making process. The agents\n\u22c6Corresponding Authors: manyili@sdu.edu.cn, jianliu2006@gmail.com\nFigure 1: A Gallery of AffordPose. AffordPose is the first\nlarge-scale dataset for fine-grained hand-object interactions\ndriven by the specific part-level affordance labeling, which\nreveals the high correlation between the object affordance\nand the detailed arrangement of hand poses.\nneed to understand the functional role of the object, select\nthe contacting location, and perform the specific hand pose\nto complete the task [7, 1, 39].\nThere has been a trend to develop deep learning solu-\ntions to predict diverse hand-object interactions. The re-\nsearchers build hand-object interaction datasets, such as\nHO-3D [13], DexYCB [5], Obman [16], and train differ-\nent networks [26, 44,43,27] to predict the hand poses for\nthe given objects. However, these works only consider the\ngeneral grasping task and focus on the stability of the gen-\nerated hand poses, but overlook the semantic meaning of\nthe hand-object interactions. Recently, many related works\ncollect additional annotations, e.g. contact maps [2, 3,24],\ngrasp type labels [8], and intent labels [40, 51], to learn how\nhuman use different objects with appropriate hand-object\n1\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n14713\n",
        "project": "",
        "github": "",
        "arxiv": "2309.08942"
    },
    {
        "title": "Agglomerative Transformer for Human-Object Interaction Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tu_Agglomerative_Transformer_for_Human-Object_Interaction_Detection_ICCV_2023_paper.html",
        "author": "Danyang Tu, Wei Sun, Guangtao Zhai, Wei Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Agglomerative_Transformer_for_Human-Object_Interaction_Detection_ICCV_2023_paper.pdf",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/six6607/AGER.git",
        "arxiv": "2308.08370"
    },
    {
        "title": "Aggregating Feature Point Cloud for Depth Completion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Aggregating_Feature_Point_Cloud_for_Depth_Completion_ICCV_2023_paper.html",
        "author": "Zhu Yu, Zehua Sheng, Zili Zhou, Lun Luo, Si-Yuan Cao, Hong Gu, Huaqi Zhang, Hui-Liang Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Aggregating_Feature_Point_Cloud_for_Depth_Completion_ICCV_2023_paper.pdf",
        "aff": "Ningbo Innovation Center, Zhejiang University; vivo Mobile Communication Company Ltd.; Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems of Zhejiang Province; College of Information Science and Electronic Engineering, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Agile Modeling: From Concept to Classifier in Minutes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Stretcu_Agile_Modeling_From_Concept_to_Classifier_in_Minutes_ICCV_2023_paper.html",
        "author": "Otilia Stretcu, Edward Vendrow, Kenji Hata, Krishnamurthy Viswanathan, Vittorio Ferrari, Sasan Tavakkol, Wenlei Zhou, Aditya Avinash, Emming Luo, Neil Gordon Alldrin, MohammadHossein Bateni, Gabriel Berger, Andrew Bunner, Chun-Ta Lu, Javier Rey, Giulia DeSalvo, Ranjay Krishna, Ariel Fuxman\u200e",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Stretcu_Agile_Modeling_From_Concept_to_Classifier_in_Minutes_ICCV_2023_paper.pdf",
        "aff": "Google Research, Stanford University; University of Washington; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2302.12948"
    },
    {
        "title": "Algebraically Rigorous Quaternion Framework for the Neural Network Pose Estimation Problem",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Algebraically_Rigorous_Quaternion_Framework_for_the_Neural_Network_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Chen Lin, Andrew J. Hanson, Sonya M. Hanson",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Algebraically_Rigorous_Quaternion_Framework_for_the_Neural_Network_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "Dept. of Computer Science, Indiana University, Bloomington, IN, USA; CCB & CCM, Flatiron Institute, New York, NY, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "AlignDet: Aligning Pre-training and Fine-tuning in Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_AlignDet_Aligning_Pre-training_and_Fine-tuning_in_Object_Detection_ICCV_2023_paper.html",
        "author": "Ming Li, Jie Wu, Xionghui Wang, Chen Chen, Jie Qin, Xuefeng Xiao, Rui Wang, Min Zheng, Xin Pan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AlignDet_Aligning_Pre-training_and_Fine-tuning_in_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida; ByteDance Inc",
        "project": "https://liming-ai.github.io/AlignDet",
        "github": "",
        "arxiv": "2307.11077"
    },
    {
        "title": "Alignment Before Aggregation: Trajectory Memory Retrieval Network for Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Alignment_Before_Aggregation_Trajectory_Memory_Retrieval_Network_for_Video_Object_ICCV_2023_paper.html",
        "author": "Rui Sun, Yuan Wang, Huayu Mai, Tianzhu Zhang, Feng Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Alignment_Before_Aggregation_Trajectory_Memory_Retrieval_Network_for_Video_Object_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; University of Science and Technology of China, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, Deep Space Exploration Lab; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Alignment-free HDR Deghosting with Semantics Consistent Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tel_Alignment-free_HDR_Deghosting_with_Semantics_Consistent_Transformer_ICCV_2023_paper.html",
        "author": "Steven Tel, Zongwei Wu, Yulun Zhang, Barth\u00e9l\u00e9my Heyrman, C\u00e9dric Demonceaux, Radu Timofte, Dominique Ginhac",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tel_Alignment-free_HDR_Deghosting_with_Semantics_Consistent_Transformer_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n12836\n",
        "project": "",
        "github": "",
        "arxiv": "2305.18135"
    },
    {
        "title": "All in Tokens: Unifying Output Space of Visual Tasks via Soft Token",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ning_All_in_Tokens_Unifying_Output_Space_of_Visual_Tasks_via_ICCV_2023_paper.html",
        "author": "Jia Ning, Chen Li, Zheng Zhang, Chunyu Wang, Zigang Geng, Qi Dai, Kun He, Han Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ning_All_in_Tokens_Unifying_Output_Space_of_Visual_Tasks_via_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China; Microsoft Research Asia; Huazhong University of Science and Technology; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Applications, and Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University",
        "project": "",
        "github": "https://github.com/SwinTransformer/AiT",
        "arxiv": "2301.02229"
    },
    {
        "title": "All-to-Key Attention for Arbitrary Style Transfer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_All-to-Key_Attention_for_Arbitrary_Style_Transfer_ICCV_2023_paper.html",
        "author": "Mingrui Zhu, Xiao He, Nannan Wang, Xiaoyu Wang, Xinbo Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_All-to-Key_Attention_for_Arbitrary_Style_Transfer_ICCV_2023_paper.pdf",
        "aff": "Xidian University, Xi\u2019an, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Chongqing University of Post and Telecommunications, Chongqing, China",
        "project": "",
        "github": "https://github.com/LearningHx/StyA2K",
        "arxiv": "2212.04105"
    },
    {
        "title": "All4One: Symbiotic Neighbour Contrastive Learning via Self-Attention and Redundancy Reduction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Estepa_All4One_Symbiotic_Neighbour_Contrastive_Learning_via_Self-Attention_and_Redundancy_Reduction_ICCV_2023_paper.html",
        "author": "Imanol G. Estepa, Ignacio Sarasua, Bhalaji Nagarajan, Petia Radeva",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Estepa_All4One_Symbiotic_Neighbour_Contrastive_Learning_via_Self-Attention_and_Redundancy_Reduction_ICCV_2023_paper.pdf",
        "aff": "Universitat de Barcelona, Barcelona, Spain; NVIDIA; Universitat de Barcelona, Computer Vision Center, Cerdanyola (Barcelona), Spain",
        "project": "",
        "github": "https://github.com/ImaGonEs/all4one",
        "arxiv": "2303.09417"
    },
    {
        "title": "Alleviating Catastrophic Forgetting of Incremental Object Detection via Within-Class and Between-Class Knowledge Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Alleviating_Catastrophic_Forgetting_of_Incremental_Object_Detection_via_Within-Class_and_ICCV_2023_paper.html",
        "author": "Mengxue Kang, Jinpeng Zhang, Jinming Zhang, Xiashuang Wang, Yang Chen, Zhe Ma, Xuhui Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Alleviating_Catastrophic_Forgetting_of_Incremental_Object_Detection_via_Within-Class_and_ICCV_2023_paper.pdf",
        "aff": "The Second Academy of China Aerospace Science and Industry Corporation, Beijing 100854, China; Intelligent Science & Technology Academy of CASIC, Beijing 100043, China; Xinjiang University, Xinjiang, 830046, China; Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Among Us: Adversarially Robust Collaborative Perception by Consensus",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Among_Us_Adversarially_Robust_Collaborative_Perception_by_Consensus_ICCV_2023_paper.html",
        "author": "Yiming Li, Qi Fang, Jiamu Bai, Siheng Chen, Felix Juefei-Xu, Chen Feng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Among_Us_Adversarially_Robust_Collaborative_Perception_by_Consensus_ICCV_2023_paper.pdf",
        "aff": "Shanghai Jiao Tong University, Shanghai AI Laboratory; Meta AI; New York University",
        "project": "",
        "github": "https://github.com/coperception/ROBOSAC",
        "arxiv": "2303.09495"
    },
    {
        "title": "An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial Transferability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_An_Adaptive_Model_Ensemble_Adversarial_Attack_for_Boosting_Adversarial_Transferability_ICCV_2023_paper.html",
        "author": "Bin Chen, Jiali Yin, Shukai Chen, Bohao Chen, Ximeng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_An_Adaptive_Model_Ensemble_Adversarial_Attack_for_Boosting_Adversarial_Transferability_ICCV_2023_paper.pdf",
        "aff": "Yuan Ze University, Taipei, Taiwan; Fuzhou University, Fujian, China",
        "project": "",
        "github": "https://github.com/CHENBIN99/AdaEA",
        "arxiv": "2308.02897"
    },
    {
        "title": "An Embarrassingly Simple Backdoor Attack on Self-supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_An_Embarrassingly_Simple_Backdoor_Attack_on_Self-supervised_Learning_ICCV_2023_paper.html",
        "author": "Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, Shouling Ji, Yuan Yao, Ting Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_An_Embarrassingly_Simple_Backdoor_Attack_on_Self-supervised_Learning_ICCV_2023_paper.pdf",
        "aff": "Nanjing University; Zhejiang University; Pennsylvania State University",
        "project": "",
        "github": "https://github.com/meet-cjli/CTRL",
        "arxiv": "2210.07346"
    },
    {
        "title": "Anatomical Invariance Modeling and Semantic Alignment for Self-supervised Learning in 3D Medical Image Analysis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Anatomical_Invariance_Modeling_and_Semantic_Alignment_for_Self-supervised_Learning_in_ICCV_2023_paper.html",
        "author": "Yankai Jiang, Mingze Sun, Heng Guo, Xiaoyu Bai, Ke Yan, Le Lu, Minfeng Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Anatomical_Invariance_Modeling_and_Semantic_Alignment_for_Self-supervised_Learning_in_ICCV_2023_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group; DAMO Academy, Alibaba Group; College of Computer Science and Technology, Zhejiang University; DAMO Academy, Alibaba Group; Tsinghua Shenzhen International Graduate School, Tsinghua-Berkeley Shenzhen Institute, China; DAMO Academy, Alibaba Group; Hupan Lab",
        "project": "",
        "github": "https://github.com/alibaba-damo-academy/alice",
        "arxiv": "2302.05615"
    },
    {
        "title": "Anchor Structure Regularization Induced Multi-view Subspace Clustering via Enhanced Tensor Rank Minimization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Anchor_Structure_Regularization_Induced_Multi-view_Subspace_Clustering_via_Enhanced_Tensor_ICCV_2023_paper.html",
        "author": "Jintian Ji, Songhe Feng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Anchor_Structure_Regularization_Induced_Multi-view_Subspace_Clustering_via_Enhanced_Tensor_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Big Data & Artificial Intelligence in Transportation, Ministry of Education, Beijing Jiaotong University, Beijing, 100044, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, 100044, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Anchor-Intermediate Detector: Decoupling and Coupling Bounding Boxes for Accurate Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lv_Anchor-Intermediate_Detector_Decoupling_and_Coupling_Bounding_Boxes_for_Accurate_Object_ICCV_2023_paper.html",
        "author": "Yilong Lv, Min Li, Yujie He, Shaopeng Li, Zhuzhen He, Aitao Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lv_Anchor-Intermediate_Detector_Decoupling_and_Coupling_Bounding_Boxes_for_Accurate_Object_ICCV_2023_paper.pdf",
        "aff": "National University of Defense Technology; Tsinghua University, Department of Automation; Xi\u2019an Institute of High Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Animal3D: A Comprehensive Dataset of 3D Animal Pose and Shape",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Animal3D_A_Comprehensive_Dataset_of_3D_Animal_Pose_and_Shape_ICCV_2023_paper.html",
        "author": "Jiacong Xu, Yi Zhang, Jiawei Peng, Wufei Ma, Artur Jesslen, Pengliang Ji, Qixin Hu, Jiehua Zhang, Qihao Liu, Jiahao Wang, Wei Ji, Chen Wang, Xiaoding Yuan, Prakhar Kaushik, Guofeng Zhang, Jie Liu, Yushan Xie, Yawen Cui, Alan Yuille, Adam Kortylewski",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Animal3D_A_Comprehensive_Dataset_of_3D_Animal_Pose_and_Shape_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; HUST; University of Alberta; UCLA; Johns Hopkins University; East China Normal University; Tsinghua University; University of Freiburg; University of Oulu; Beihang University",
        "project": "",
        "github": "",
        "arxiv": "2308.11737"
    },
    {
        "title": "Anomaly Detection Under Distribution Shift",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Anomaly_Detection_Under_Distribution_Shift_ICCV_2023_paper.html",
        "author": "Tri Cao, Jiawen Zhu, Guansong Pang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Anomaly_Detection_Under_Distribution_Shift_ICCV_2023_paper.pdf",
        "aff": "School of Computing and Information Systems, Singapore Management University",
        "project": "",
        "github": "https://github.com/mala-lab/ADShift",
        "arxiv": "2303.13845"
    },
    {
        "title": "Anomaly Detection using Score-based Perturbation Resilience",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shin_Anomaly_Detection_using_Score-based_Perturbation_Resilience_ICCV_2023_paper.html",
        "author": "Woosang Shin, Jonghyeon Lee, Taehan Lee, Sangmoon Lee, Jong Pil Yun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_Anomaly_Detection_using_Score-based_Perturbation_Resilience_ICCV_2023_paper.pdf",
        "aff": "Korea Institute of Industrial Technology (KITECH), South Korea; University of Science and Technology (UST), South Korea; Kyungpook National University (KNU), South Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Anti-DreamBooth: Protecting Users from Personalized Text-to-image Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.html",
        "author": "Thanh Van Le, Hao Phung, Thuan Hoang Nguyen, Quan Dao, Ngoc N. Tran, Anh Tran",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Vanderbilt University; VinAI Research",
        "project": "",
        "github": "https://github.com/VinAIResearch/Anti-DreamBooth.git",
        "arxiv": ""
    },
    {
        "title": "Aperture Diffraction for Compact Snapshot Spectral Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lv_Aperture_Diffraction_for_Compact_Snapshot_Spectral_Imaging_ICCV_2023_paper.html",
        "author": "Tao Lv, Hao Ye, Quan Yuan, Zhan Shi, Yibo Wang, Shuming Wang, Xun Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lv_Aperture_Diffraction_for_Compact_Snapshot_Spectral_Imaging_ICCV_2023_paper.pdf",
        "aff": "Nanjing University, Nanjing, China",
        "project": "",
        "github": "https://github.com/Krito-ex/CSST",
        "arxiv": ""
    },
    {
        "title": "Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Aria_Digital_Twin_A_New_Benchmark_Dataset_for_Egocentric_3D_ICCV_2023_paper.html",
        "author": "Xiaqing Pan, Nicholas Charron, Yongqian Yang, Scott Peters, Thomas Whelan, Chen Kong, Omkar Parkhi, Richard Newcombe, Yuheng (Carl) Ren",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Aria_Digital_Twin_A_New_Benchmark_Dataset_for_Egocentric_3D_ICCV_2023_paper.pdf",
        "aff": "Meta Reality Labs",
        "project": "https://www.projectaria.com/datasets/adt",
        "github": "",
        "arxiv": "2306.06362"
    },
    {
        "title": "AssetField: Assets Mining and Reconfiguration in Ground Feature Plane Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiangli_AssetField_Assets_Mining_and_Reconfiguration_in_Ground_Feature_Plane_Representation_ICCV_2023_paper.html",
        "author": "Yuanbo Xiangli, Linning Xu, Xingang Pan, Nanxuan Zhao, Bo Dai, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiangli_AssetField_Assets_Mining_and_Reconfiguration_in_Ground_Feature_Plane_Representation_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; Adobe Research; Max Planck Institute for Informatics, Nanyang Technological University; The Chinese University of Hong Kong, Shanghai AI Laboratory; Shanghai AI Laboratory",
        "project": "",
        "github": "",
        "arxiv": "2303.13953"
    },
    {
        "title": "Atmospheric Transmission and Thermal Inertia Induced Blind Road Segmentation with a Large-Scale Dataset TBRSD",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Atmospheric_Transmission_and_Thermal_Inertia_Induced_Blind_Road_Segmentation_with_ICCV_2023_paper.html",
        "author": "Junzhang Chen, Xiangzhi Bai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Atmospheric_Transmission_and_Thermal_Inertia_Induced_Blind_Road_Segmentation_with_ICCV_2023_paper.pdf",
        "aff": "Image Processing Center, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; Advanced Innovation Center for Biomedical Engineering, Beihang University",
        "project": "http://xzbai.buaa.edu.cn/datasets.html",
        "github": "https://github.com/chenjzBUAA/TBRSD",
        "arxiv": ""
    },
    {
        "title": "AttT2M: Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_AttT2M_Text-Driven_Human_Motion_Generation_with_Multi-Perspective_Attention_Mechanism_ICCV_2023_paper.html",
        "author": "Chongyang Zhong, Lei Hu, Zihao Zhang, Shihong Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_AttT2M_Text-Driven_Human_Motion_Generation_with_Multi-Perspective_Attention_Mechanism_ICCV_2023_paper.pdf",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/ZcyMonkey/AttT2M",
        "arxiv": "2309.00796"
    },
    {
        "title": "Attention Discriminant Sampling for Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Attention_Discriminant_Sampling_for_Point_Clouds_ICCV_2023_paper.html",
        "author": "Cheng-Yao Hong, Yu-Ying Chou, Tyng-Luh Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Attention_Discriminant_Sampling_for_Point_Clouds_ICCV_2023_paper.pdf",
        "aff": "Institute of Information Science, Academia Sinica, Taiwan; National Taiwan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Attention Where It Matters: Rethinking Visual Document Understanding with Selective Region Concentration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Attention_Where_It_Matters_Rethinking_Visual_Document_Understanding_with_Selective_ICCV_2023_paper.html",
        "author": "Haoyu Cao, Changcun Bao, Chaohu Liu, Huang Chen, Kun Yin, Hao Liu, Yinsong Liu, Deqiang Jiang, Xing Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Attention_Where_It_Matters_Rethinking_Visual_Document_Understanding_with_Selective_ICCV_2023_paper.pdf",
        "aff": "Tencent YouTu Lab, University of Science and Technology of China; Tencent YouTu Lab",
        "project": "",
        "github": "",
        "arxiv": "2309.01131"
    },
    {
        "title": "Attentive Mask CLIP",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Attentive_Mask_CLIP_ICCV_2023_paper.html",
        "author": "Yifan Yang, Weiquan Huang, Yixuan Wei, Houwen Peng, Xinyang Jiang, Huiqiang Jiang, Fangyun Wei, Yin Wang, Han Hu, Lili Qiu, Yuqing Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Attentive_Mask_CLIP_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; Tongji University; Tsinghua University",
        "project": "",
        "github": "https://github.com/microsoft/A-CLIP",
        "arxiv": "2212.08653"
    },
    {
        "title": "Audio-Enhanced Text-to-Video Retrieval using Text-Conditioned Feature Alignment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ibrahimi_Audio-Enhanced_Text-to-Video_Retrieval_using_Text-Conditioned_Feature_Alignment_ICCV_2023_paper.html",
        "author": "Sarah Ibrahimi, Xiaohang Sun, Pichao Wang, Amanmeet Garg, Ashutosh Sanan, Mohamed Omar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ibrahimi_Audio-Enhanced_Text-to-Video_Retrieval_using_Text-Conditioned_Feature_Alignment_ICCV_2023_paper.pdf",
        "aff": "University of Amsterdam; Amazon Prime Video",
        "project": "",
        "github": "",
        "arxiv": "2307.12964"
    },
    {
        "title": "Audio-Visual Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pian_Audio-Visual_Class-Incremental_Learning_ICCV_2023_paper.html",
        "author": "Weiguo Pian, Shentong Mo, Yunhui Guo, Yapeng Tian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pian_Audio-Visual_Class-Incremental_Learning_ICCV_2023_paper.pdf",
        "aff": "The University of Texas at Dallas; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/weiguoPian/AV-CIL_ICCV2023",
        "arxiv": "2308.11073"
    },
    {
        "title": "Audio-Visual Deception Detection: DOLOS Dataset and Parameter-Efficient Crossmodal Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Audio-Visual_Deception_Detection_DOLOS_Dataset_and_Parameter-Efficient_Crossmodal_Learning_ICCV_2023_paper.html",
        "author": "Xiaobao Guo, Nithish Muthuchamy Selvaraj, Zitong Yu, Adams Wai-Kin Kong, Bingquan Shen, Alex Kot",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Audio-Visual_Deception_Detection_DOLOS_Dataset_and_Parameter-Efficient_Crossmodal_Learning_ICCV_2023_paper.pdf",
        "aff": "School of Electrical & Electronic Engineering, NTU; School of Computer Science and Engineering, NTU; DSO National Laboratories, Singapore; Rapid-Rich Object Search (ROSE) Lab, Interdisciplinary Graduate Programme, Nanyang Technological University",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2303.12745"
    },
    {
        "title": "Audio-Visual Glance Network for Efficient Video Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nugroho_Audio-Visual_Glance_Network_for_Efficient_Video_Recognition_ICCV_2023_paper.html",
        "author": "Muhammad Adi Nugroho, Sangmin Woo, Sumin Lee, Changick Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nugroho_Audio-Visual_Glance_Network_for_Efficient_Video_Recognition_ICCV_2023_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST)",
        "project": "",
        "github": "",
        "arxiv": "2308.09322"
    },
    {
        "title": "Audiovisual Masked Autoencoders",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Georgescu_Audiovisual_Masked_Autoencoders_ICCV_2023_paper.html",
        "author": "Mariana-Iuliana Georgescu, Eduardo Fonseca, Radu Tudor Ionescu, Mario Lucic, Cordelia Schmid, Anurag Arnab",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Georgescu_Audiovisual_Masked_Autoencoders_ICCV_2023_paper.pdf",
        "aff": "Google Research, University of Bucharest; University of Bucharest; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2212.05922"
    },
    {
        "title": "Augmented Box Replay: Overcoming Foreground Shift for Incremental Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Augmented_Box_Replay_Overcoming_Foreground_Shift_for_Incremental_Object_Detection_ICCV_2023_paper.html",
        "author": "Yuyang Liu, Yang Cong, Dipam Goswami, Xialei Liu, Joost van de Weijer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Augmented_Box_Replay_Overcoming_Foreground_Shift_for_Incremental_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "VCIP, CS, Nankai University; Computer Vision Center, Barcelona; Department of Computer Science, Universitat Aut `onoma de Barcelona; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences; University of Chinese Academy of Sciences; South China University of Technology",
        "project": "",
        "github": "https://github.com/YuyangSunshine/ABRIOD.git",
        "arxiv": "2307.12427"
    },
    {
        "title": "Augmenting and Aligning Snippets for Few-Shot Video Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Augmenting_and_Aligning_Snippets_for_Few-Shot_Video_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Yuecong Xu, Jianfei Yang, Yunjiao Zhou, Zhenghua Chen, Min Wu, Xiaoli Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Augmenting_and_Aligning_Snippets_for_Few-Shot_Video_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Institute for Infocomm Research, A*STAR, Singapore; Nanyang Technological University",
        "project": "",
        "github": "https://github.com/xuyu0010/SSA2lign",
        "arxiv": "2303.10451"
    },
    {
        "title": "AutoAD II: The Sequel - Who, When, and What in Movie Audio Description",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_AutoAD_II_The_Sequel_-_Who_When_and_What_in_ICCV_2023_paper.html",
        "author": "Tengda Han, Max Bain, Arsha Nagrani, Gul Varol, Weidi Xie, Andrew Zisserman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_AutoAD_II_The_Sequel_-_Who_When_and_What_in_ICCV_2023_paper.pdf",
        "aff": "Visual Geometry Group, University of Oxford; CMIC, Shanghai Jiao Tong University; Visual Geometry Group, University of Oxford; Visual Geometry Group, University of Oxford; LIGM, \u00b4Ecole des Ponts ParisTech",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "AutoDiffusion: Training-Free Optimization of Time Steps and Architectures for Automated Diffusion Model Acceleration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.html",
        "author": "Lijiang Li, Huixia Li, Xiawu Zheng, Jie Wu, Xuefeng Xiao, Rui Wang, Min Zheng, Xin Pan, Fei Chao, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Department of Artificial Intelligence, School of Informatics, Xiamen University; Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Department of Artificial Intelligence, School of Informatics, Xiamen University, Peng Cheng Laboratory, Institute of Artificial Intelligence, Xiamen University, Fujian Engineering Research Center of Trusted Artificial Intelligence Analysis and Application, Xiamen University; ByteDance Inc.",
        "project": "",
        "github": "",
        "arxiv": "2309.10438"
    },
    {
        "title": "AutoReP: Automatic ReLU Replacement for Fast Private Network Inference",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Peng_AutoReP_Automatic_ReLU_Replacement_for_Fast_Private_Network_Inference_ICCV_2023_paper.html",
        "author": "Hongwu Peng, Shaoyi Huang, Tong Zhou, Yukui Luo, Chenghong Wang, Zigeng Wang, Jiahui Zhao, Xi Xie, Ang Li, Tony Geng, Kaleel Mahmood, Wujie Wen, Xiaolin Xu, Caiwen Ding",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_AutoReP_Automatic_ReLU_Replacement_for_Fast_Private_Network_Inference_ICCV_2023_paper.pdf",
        "aff": "University of Connecticut; North Carolina State University; University of Rochester; Northeastern University; Duke University; Pacific Northwest National Laboratory",
        "project": "",
        "github": "https://github.com/HarveyP123/AutoReP",
        "arxiv": "2308.10134"
    },
    {
        "title": "AutoSynth: Learning to Generate 3D Training Data for Object Point Cloud Registration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dang_AutoSynth_Learning_to_Generate_3D_Training_Data_for_Object_Point_ICCV_2023_paper.html",
        "author": "Zheng Dang, Mathieu Salzmann",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dang_AutoSynth_Learning_to_Generate_3D_Training_Data_for_Object_Point_ICCV_2023_paper.pdf",
        "aff": "CVLab, EPFL, Switzerland; CVLab, EPFL, Switzerland and ClearSpace, Switzerland",
        "project": "",
        "github": "",
        "arxiv": "2309.11170"
    },
    {
        "title": "Automated Knowledge Distillation via Monte Carlo Tree Search",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Automated_Knowledge_Distillation_via_Monte_Carlo_Tree_Search_ICCV_2023_paper.html",
        "author": "Lujun Li, Peijie Dong, Zimian Wei, Ya Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Automated_Knowledge_Distillation_via_Monte_Carlo_Tree_Search_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; The Hong Kong University of Science and Technology; National University of Defense Technology",
        "project": "",
        "github": "https://github.com/lilujunai/Auto-KD",
        "arxiv": ""
    },
    {
        "title": "Automatic Animation of Hair Blowing in Still Portrait Photos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiao_Automatic_Animation_of_Hair_Blowing_in_Still_Portrait_Photos_ICCV_2023_paper.html",
        "author": "Wenpeng Xiao, Wentao Liu, Yitong Wang, Bernard Ghanem, Bing Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_Automatic_Animation_of_Hair_Blowing_in_Still_Portrait_Photos_ICCV_2023_paper.pdf",
        "aff": "King Abdullah University of Science and Technology (KAUST); ByteDance Intelligent Creation Lab",
        "project": "",
        "github": "https://nevergiveu.github.io/AutomaticHairBlowing/",
        "arxiv": "2309.14207"
    },
    {
        "title": "Automatic Network Pruning via Hilbert-Schmidt Independence Criterion Lasso under Information Bottleneck Principle",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Automatic_Network_Pruning_via_Hilbert-Schmidt_Independence_Criterion_Lasso_under_Information_ICCV_2023_paper.html",
        "author": "Song Guo, Lei Zhang, Xiawu Zheng, Yan Wang, Yuchao Li, Fei Chao, Chenglin Wu, Shengchuan Zhang, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Automatic_Network_Pruning_via_Hilbert-Schmidt_Independence_Criterion_Lasso_under_Information_ICCV_2023_paper.pdf",
        "aff": "Samsara Inc.; Institute of Artificial Intelligence, Xiamen University; Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Department of Artificial Intelligence, School of Informatics, Xiamen University; Deep Wisdom Inc.; Peng Cheng Laboratory; Alibaba Group",
        "project": "",
        "github": "https://github.com/sunggo/APIB",
        "arxiv": ""
    },
    {
        "title": "Auxiliary Tasks Benefit 3D Skeleton-based Human Motion Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction_ICCV_2023_paper.html",
        "author": "Chenxin Xu, Robby T. Tan, Yuhong Tan, Siheng Chen, Xinchao Wang, Yanfeng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction_ICCV_2023_paper.pdf",
        "aff": "Shanghai AI Laboratory; Shanghai Jiao Tong University; National University of Singapore",
        "project": "",
        "github": "https://github.com/MediaBrain-SJTU/AuxFormer",
        "arxiv": "2308.08942"
    },
    {
        "title": "AvatarCraft: Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_AvatarCraft_Transforming_Text_into_Neural_Human_Avatars_with_Parameterized_Shape_ICCV_2023_paper.html",
        "author": "Ruixiang Jiang, Can Wang, Jingbo Zhang, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_AvatarCraft_Transforming_Text_into_Neural_Human_Avatars_with_Parameterized_Shape_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; Google; The Hong Kong Polytechnic University; Netflix; Microsoft Cloud AI",
        "project": "https://avatar-craft.github.io/",
        "github": "https://github.com/Avatar-Craft",
        "arxiv": "2303.17606"
    },
    {
        "title": "BANSAC: A Dynamic BAyesian Network for Adaptive SAmple Consensus",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Piedade_BANSAC_A_Dynamic_BAyesian_Network_for_Adaptive_SAmple_Consensus_ICCV_2023_paper.html",
        "author": "Valter Piedade, Pedro Miraldo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Piedade_BANSAC_A_Dynamic_BAyesian_Network_for_Adaptive_SAmple_Consensus_ICCV_2023_paper.pdf",
        "aff": "Mitsubishi Electric Research Labs; Instituto Superior T\u00e9cnico, Lisboa",
        "project": "",
        "github": "https://github.com/merlresearch/bansac",
        "arxiv": "2309.08690"
    },
    {
        "title": "BEV-DG: Cross-Modal Learning under Bird's-Eye View for Domain Generalization of 3D Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.html",
        "author": "Miaoyu Li, Yachao Zhang, Xu Ma, Yanyun Qu, Yun Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.pdf",
        "aff": "School of Informatics, Xiamen University; Department of ECE, Northeastern University; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "BEVPlace: Learning LiDAR-based Place Recognition using Bird's Eye View Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_BEVPlace_Learning_LiDAR-based_Place_Recognition_using_Birds_Eye_View_Images_ICCV_2023_paper.html",
        "author": "Lun Luo, Shuhang Zheng, Yixuan Li, Yongzhi Fan, Beinan Yu, Si-Yuan Cao, Junwei Li, Hui-Liang Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_BEVPlace_Learning_LiDAR-based_Place_Recognition_using_Birds_Eye_View_Images_ICCV_2023_paper.pdf",
        "aff": "Ningbo Innovation Center, Zhejiang University; College of Information Science and Electronic Engineering, Zhejiang University; Ningbo Innovation Center, College of Information Science and Electronic Engineering, Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems of Zhejiang Province",
        "project": "",
        "github": "https://github.com/zjuluolun/BEVPlace",
        "arxiv": ""
    },
    {
        "title": "BT^2: Backward-compatible Training with Basis Transformation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_BT2_Backward-compatible_Training_with_Basis_Transformation_ICCV_2023_paper.html",
        "author": "Yifei Zhou, Zilu Li, Abhinav Shrivastava, Hengshuang Zhao, Antonio Torralba, Taipeng Tian, Ser-Nam Lim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_BT2_Backward-compatible_Training_with_Basis_Transformation_ICCV_2023_paper.pdf",
        "aff": "University of Hong Kong; Cornell University; Meta AI; University of Maryland, College Park; University of California, Berkeley; MIT",
        "project": "",
        "github": "https://github.com/YifeiZhou02/BT-2",
        "arxiv": ""
    },
    {
        "title": "BUS: Efficient and Effective Vision-Language Pre-Training with Bottom-Up Patch Summarization.",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_BUS_Efficient_and_Effective_Vision-Language_Pre-Training_with_Bottom-Up_Patch_Summarization._ICCV_2023_paper.html",
        "author": "Chaoya Jiang, Haiyang Xu, Wei Ye, Qinghao Ye, Chenliang Li, Ming Yan, Bin Bi, Shikun Zhang, Fei Huang, Songfang Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_BUS_Efficient_and_Effective_Vision-Language_Pre-Training_with_Bottom-Up_Patch_Summarization._ICCV_2023_paper.pdf",
        "aff": "National Engineering Research Center for Software Engineering, Peking University; DAMO Academy, Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": "2307.08504"
    },
    {
        "title": "BaRe-ESA: A Riemannian Framework for Unregistered Human Body Shapes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hartman_BaRe-ESA_A_Riemannian_Framework_for_Unregistered_Human_Body_Shapes_ICCV_2023_paper.html",
        "author": "Emmanuel Hartman, Emery Pierson, Martin Bauer, Nicolas Charon, Mohamed Daoudi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hartman_BaRe-ESA_A_Riemannian_Framework_for_Unregistered_Human_Body_Shapes_ICCV_2023_paper.pdf",
        "aff": "University of Vienna, Vienna, Austria; University of Houston, Houston, Texas, USA; Univ. Lille, CNRS, Centrale Lille, Institut Mines-T\u00e9l\u00e9com, UMR 9189 CRIStAL, Lille, F-59000, France; Florida State University, Tallahassee, Florida, USA; IMT Nord Europe, Institut Mines-T\u00e9l\u00e9com, Univ. Lille, Centre for Digital Systems, Lille, F-59000, France",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Backpropagation Path Search On Adversarial Transferability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Backpropagation_Path_Search_On_Adversarial_Transferability_ICCV_2023_paper.html",
        "author": "Zhuoer Xu, Zhangxuan Gu, Jianping Zhang, Shiwen Cui, Changhua Meng, Weiqiang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Backpropagation_Path_Search_On_Adversarial_Transferability_ICCV_2023_paper.pdf",
        "aff": "Tiansuan Lab, Ant Group; Department of Computer Science and Engineering, The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2308.07625"
    },
    {
        "title": "BallGAN: 3D-aware Image Synthesis with a Spherical Background",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.html",
        "author": "Minjung Shin, Yunji Seo, Jeongmin Bae, Young Sun Choi, Hyunsu Kim, Hyeran Byun, Youngjung Uh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; NA VER AI Lab",
        "project": "https://minjung-s.github.io/ballgan/",
        "github": "",
        "arxiv": "2301.09091"
    },
    {
        "title": "Batch-based Model Registration for Fast 3D Sherd Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Batch-based_Model_Registration_for_Fast_3D_Sherd_Reconstruction_ICCV_2023_paper.html",
        "author": "Jiepeng Wang, Congyi Zhang, Peng Wang, Xin Li, Peter J. Cobb, Christian Theobalt, Wenping Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Batch-based_Model_Registration_for_Fast_3D_Sherd_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Texas A&M University; Max Planck Institute for Informatics; The University of Hong Kong",
        "project": "https://jiepengwang.github.io/FIRES/",
        "github": "https://github.com/jiepengwang/FIRES",
        "arxiv": "2211.06897"
    },
    {
        "title": "Bayesian Optimization Meets Self-Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Bayesian_Optimization_Meets_Self-Distillation_ICCV_2023_paper.html",
        "author": "HyunJae Lee, Heon Song, Hyeonsoo Lee, Gi-hyeon Lee, Suyeong Park, Donggeun Yoo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Bayesian_Optimization_Meets_Self-Distillation_ICCV_2023_paper.pdf",
        "aff": "Lunit Inc.",
        "project": "",
        "github": "https://github.com/sooperset/boss",
        "arxiv": "2304.12666"
    },
    {
        "title": "Bayesian Prompt Learning for Image-Language Model Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Derakhshani_Bayesian_Prompt_Learning_for_Image-Language_Model_Generalization_ICCV_2023_paper.html",
        "author": "Mohammad Mahdi Derakhshani, Enrique Sanchez, Adrian Bulat, Victor G. Turrisi da Costa, Cees G.M. Snoek, Georgios Tzimiropoulos, Brais Martinez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Derakhshani_Bayesian_Prompt_Learning_for_Image-Language_Model_Generalization_ICCV_2023_paper.pdf",
        "aff": "Queen Mary University of London; University of Amsterdam; University of Trento; Samsung AI Cambridge",
        "project": "",
        "github": "https://github.com/saic-fi/Bayesian-Prompt-Learning",
        "arxiv": "2210.02390"
    },
    {
        "title": "Be Everywhere - Hear Everything (BEE): Audio Scene Reconstruction by Sparse Audio-Visual Samples",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Be_Everywhere_-_Hear_Everything_BEE_Audio_Scene_Reconstruction_by_ICCV_2023_paper.html",
        "author": "Mingfei Chen, Kun Su, Eli Shlizerman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Be_Everywhere_-_Hear_Everything_BEE_Audio_Scene_Reconstruction_by_ICCV_2023_paper.pdf",
        "aff": "Department of Electrical & Computer Engineering, University of Washington; Department of Electrical & Computer Engineering, University of Washington and Department of Applied Mathematics, University of Washington",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Barquero_BeLFusion_Latent_Diffusion_for_Behavior-Driven_Human_Motion_Prediction_ICCV_2023_paper.html",
        "author": "German Barquero, Sergio Escalera, Cristina Palmero",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Barquero_BeLFusion_Latent_Diffusion_for_Behavior-Driven_Human_Motion_Prediction_ICCV_2023_paper.pdf",
        "aff": "Universitat de Barcelona and Computer Vision Center, Spain",
        "project": "https://barquerogerman.github.io/BeLFusion/",
        "github": "",
        "arxiv": "2211.14304"
    },
    {
        "title": "Beating Backdoor Attack at Its Own Game",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Beating_Backdoor_Attack_at_Its_Own_Game_ICCV_2023_paper.html",
        "author": "Min Liu, Alberto Sangiovanni-Vincentelli, Xiangyu Yue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beating_Backdoor_Attack_at_Its_Own_Game_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; The Chinese University of Hong Kong; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/damianliumin/non-adversarial backdoor",
        "arxiv": "2307.15539"
    },
    {
        "title": "Benchmarking Algorithmic Bias in Face Recognition: An Experimental Approach Using Synthetic Faces and Human Evaluation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Benchmarking_Algorithmic_Bias_in_Face_Recognition_An_Experimental_Approach_Using_ICCV_2023_paper.html",
        "author": "Hao Liang, Pietro Perona, Guha Balakrishnan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Benchmarking_Algorithmic_Bias_in_Face_Recognition_An_Experimental_Approach_Using_ICCV_2023_paper.pdf",
        "aff": "Rice University; California Institute of Technology and AWS",
        "project": "",
        "github": "",
        "arxiv": "2308.05441"
    },
    {
        "title": "Benchmarking Low-Shot Robustness to Natural Distribution Shifts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Singh_Benchmarking_Low-Shot_Robustness_to_Natural_Distribution_Shifts_ICCV_2023_paper.html",
        "author": "Aaditya Singh, Kartik Sarangmath, Prithvijit Chattopadhyay, Judy Hoffman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Benchmarking_Low-Shot_Robustness_to_Natural_Distribution_Shifts_ICCV_2023_paper.pdf",
        "aff": "Georgia Institute of Technology",
        "project": "",
        "github": "https://this.url",
        "arxiv": "2304.11263"
    },
    {
        "title": "Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Benchmarking_and_Analyzing_Robust_Point_Cloud_Recognition_Bag_of_Tricks_ICCV_2023_paper.html",
        "author": "Qiufan Ji, Lin Wang, Cong Shi, Shengshan Hu, Yingying Chen, Lichao Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Benchmarking_and_Analyzing_Robust_Point_Cloud_Recognition_Bag_of_Tricks_ICCV_2023_paper.pdf",
        "aff": "HUST; New Jersey Institute of Technology; Rutgers University; Lehigh University; AI Thrust, HKUST(GZ), Dept. of CSE, HKUST",
        "project": "",
        "github": "https://github.com/qiufan319/benchmark_pc_attack.git",
        "arxiv": "2307.16361"
    },
    {
        "title": "Betrayed by Captions: Joint Caption Grounding and Generation for Open Vocabulary Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Betrayed_by_Captions_Joint_Caption_Grounding_and_Generation_for_Open_ICCV_2023_paper.html",
        "author": "Jianzong Wu, Xiangtai Li, Henghui Ding, Xia Li, Guangliang Cheng, Yunhai Tong, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Betrayed_by_Captions_Joint_Caption_Grounding_and_Generation_for_Open_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Machine Perception, MOE, School of Artificial Intelligence, Peking University; ETH Zurich; SenseTime Research; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/jianzongwu/betrayed-by-captions",
        "arxiv": "2301.00805"
    },
    {
        "title": "Better May Not Be Fairer: A Study on Subgroup Discrepancy in Image Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chiu_Better_May_Not_Be_Fairer_A_Study_on_Subgroup_Discrepancy_ICCV_2023_paper.html",
        "author": "Ming-Chang Chiu, Pin-Yu Chen, Xuezhe Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chiu_Better_May_Not_Be_Fairer_A_Study_on_Subgroup_Discrepancy_ICCV_2023_paper.pdf",
        "aff": "University of Southern California, Los Angeles, CA; IBM Research, Boston, MA",
        "project": "",
        "github": "https://github.com/charismaticchiu/CIFAR-B",
        "arxiv": "2212.08649"
    },
    {
        "title": "Beyond Image Borders: Learning Feature Extrapolation for Unbounded Image Composition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Beyond_Image_Borders_Learning_Feature_Extrapolation_for_Unbounded_Image_Composition_ICCV_2023_paper.html",
        "author": "Xiaoyu Liu, Ming Liu, Junyi Li, Shuai Liu, Xiaotao Wang, Lei Lei, Wangmeng Zuo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beyond_Image_Borders_Learning_Feature_Extrapolation_for_Unbounded_Image_Composition_ICCV_2023_paper.pdf",
        "aff": "Not provided in the text; Harbin Institute of Technology, Harbin, China; Peng Cheng Laboratory, Shenzhen, China; Harbin Institute of Technology, Harbin, China",
        "project": "",
        "github": "https://github.com/liuxiaoyu1104/UNIC",
        "arxiv": "2309.12042"
    },
    {
        "title": "Beyond Object Recognition: A New Benchmark towards Object Concept Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Beyond_Object_Recognition_A_New_Benchmark_towards_Object_Concept_Learning_ICCV_2023_paper.html",
        "author": "Yong-Lu Li, Yue Xu, Xinyu Xu, Xiaohan Mao, Yuan Yao, Siqi Liu, Cewu Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Beyond_Object_Recognition_A_New_Benchmark_towards_Object_Concept_Learning_ICCV_2023_paper.pdf",
        "aff": "Shanghai Jiao Tong University",
        "project": "",
        "github": "https://mvig-rhos.com/ocl",
        "arxiv": "2212.02710"
    },
    {
        "title": "Beyond One-to-One: Rethinking the Referring Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.html",
        "author": "Yutao Hu, Qixiong Wang, Wenqi Shao, Enze Xie, Zhenguo Li, Jungong Han, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.pdf",
        "aff": "The University of Sheffield; The University of Hong Kong; Huawei Noah\u2019s Ark Lab; The University of Hong Kong, Shanghai AI Laboratory; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/toggle1995/RIS-DMMI",
        "arxiv": ""
    },
    {
        "title": "Beyond Single Path Integrated Gradients for Reliable Input Attribution via Randomized Path Sampling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_Beyond_Single_Path_Integrated_Gradients_for_Reliable_Input_Attribution_via_ICCV_2023_paper.html",
        "author": "Giyoung Jeon, Haedong Jeong, Jaesik Choi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Beyond_Single_Path_Integrated_Gradients_for_Reliable_Input_Attribution_via_ICCV_2023_paper.pdf",
        "aff": "LG AI Research; KAIST, INEEJI; UNIST, KAIST",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Beyond Skin Tone: A Multidimensional Measure of Apparent Skin Color",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Thong_Beyond_Skin_Tone_A_Multidimensional_Measure_of_Apparent_Skin_Color_ICCV_2023_paper.html",
        "author": "William Thong, Przemyslaw Joniak, Alice Xiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Thong_Beyond_Skin_Tone_A_Multidimensional_Measure_of_Apparent_Skin_Color_ICCV_2023_paper.pdf",
        "aff": "Sony AI; The University of Tokyo",
        "project": "",
        "github": "",
        "arxiv": "2309.05148"
    },
    {
        "title": "Beyond the Limitation of Monocular 3D Detector via Knowledge Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.html",
        "author": "Yiran Yang, Dongshuo Yin, Xuee Rong, Xian Sun, Wenhui Diao, Xinming Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Network Information System Technology, Aerospace Information Research Institute, Chinese Academy of Sciences and School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences; Key Laboratory of Network Information System Technology, Aerospace Information Research Institute, Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Beyond the Pixel: a Photometrically Calibrated HDR Dataset for Luminance and Color Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bolduc_Beyond_the_Pixel_a_Photometrically_Calibrated_HDR_Dataset_for_Luminance_ICCV_2023_paper.html",
        "author": "Christophe Bolduc, Justine Giroux, Marc H\u00e9bert, Claude Demers, Jean-Fran\u00e7ois Lalonde",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bolduc_Beyond_the_Pixel_a_Photometrically_Calibrated_HDR_Dataset_for_Luminance_ICCV_2023_paper.pdf",
        "aff": "Universit \u00b4e Laval",
        "project": "https://lvsn.github.io/beyondthepixel/",
        "github": "https://github.com/lvsn/beyondthepixel",
        "arxiv": ""
    },
    {
        "title": "BiFF: Bi-level Future Fusion with Polyline-based Coordinate for Interactive Trajectory Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_BiFF_Bi-level_Future_Fusion_with_Polyline-based_Coordinate_for_Interactive_Trajectory_ICCV_2023_paper.html",
        "author": "Yiyao Zhu, Di Luan, Shaojie Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_BiFF_Bi-level_Future_Fusion_with_Polyline-based_Coordinate_for_Interactive_Trajectory_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2306.14161"
    },
    {
        "title": "BiViT: Extremely Compressed Binary Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Yefei He, Zhenyu Lou, Luoming Zhang, Jing Liu, Weijia Wu, Hong Zhou, Bohan Zhuang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University, China; ZIP Lab, Monash University, Australia",
        "project": "",
        "github": "",
        "arxiv": "2211.07091"
    },
    {
        "title": "Bidirectional Alignment for Domain Adaptive Detection with Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Bidirectional_Alignment_for_Domain_Adaptive_Detection_with_Transformers_ICCV_2023_paper.html",
        "author": "Liqiang He, Wei Wang, Albert Chen, Min Sun, Cheng-Hao Kuo, Sinisa Todorovic",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Bidirectional_Alignment_for_Domain_Adaptive_Detection_with_Transformers_ICCV_2023_paper.pdf",
        "aff": "Amazon, Bellevue, WA, USA; Oregon State University, Corvallis, OR, USA",
        "project": "",
        "github": "https://github.com/helq2612/biADT",
        "arxiv": ""
    },
    {
        "title": "Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Bidirectionally_Deformable_Motion_Modulation_For_Video-based_Human_Pose_Transfer_ICCV_2023_paper.html",
        "author": "Wing-Yin Yu, Lai-Man Po, Ray C.C. Cheung, Yuzhi Zhao, Yu Xue, Kun Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Bidirectionally_Deformable_Motion_Modulation_For_Video-based_Human_Pose_Transfer_ICCV_2023_paper.pdf",
        "aff": "Department of Electrical Engineering, City University of Hong Kong, Hong Kong, China",
        "project": "",
        "github": "github.com/rocketappslab/bdmm",
        "arxiv": "2307.07754"
    },
    {
        "title": "Bird's-Eye-View Scene Graph for Vision-Language Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Birds-Eye-View_Scene_Graph_for_Vision-Language_Navigation_ICCV_2023_paper.html",
        "author": "Rui Liu, Xiaohan Wang, Wenguan Wang, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Birds-Eye-View_Scene_Graph_for_Vision-Language_Navigation_ICCV_2023_paper.pdf",
        "aff": "ReLER, CCAI, Zhejiang University",
        "project": "",
        "github": "https://github.com/DefaultRui/BEV-Scene-Graph",
        "arxiv": ""
    },
    {
        "title": "Black Box Few-Shot Adaptation for Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Yassine Ouali, Adrian Bulat, Brais Matinez, Georgios Tzimiropoulos",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "Samsung AI Cambridge and Queen Mary University of London; Samsung AI Cambridge",
        "project": "",
        "github": "https://github.com/saic-fi/LFA",
        "arxiv": ""
    },
    {
        "title": "Black-Box Unsupervised Domain Adaptation with Bi-Directional Atkinson-Shiffrin Memory",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.html",
        "author": "Jingyi Zhang, Jiaxing Huang, Xueying Jiang, Shijian Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.pdf",
        "aff": "S-lab, Nanyang Technological University",
        "project": "",
        "github": "",
        "arxiv": "2308.13236"
    },
    {
        "title": "BlendFace: Re-designing Identity Encoders for Face-Swapping",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shiohara_BlendFace_Re-designing_Identity_Encoders_for_Face-Swapping_ICCV_2023_paper.html",
        "author": "Kaede Shiohara, Xingchao Yang, Takafumi Taketomi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shiohara_BlendFace_Re-designing_Identity_Encoders_for_Face-Swapping_ICCV_2023_paper.pdf",
        "aff": "The University of Tokyo; CyberAgent AI Lab",
        "project": "",
        "github": "https://github.com/mapooon/BlendFace",
        "arxiv": "2307.10854"
    },
    {
        "title": "Blending-NeRF: Text-Driven Localized Editing in Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_Blending-NeRF_Text-Driven_Localized_Editing_in_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Hyeonseop Song, Seokhun Choi, Hoseok Do, Chul Lee, Taehyeong Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Blending-NeRF_Text-Driven_Localized_Editing_in_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "Dept. of Biosystems Engineering, Seoul National University, Republic of Korea; AI Lab, CTO Division, LG Electronics, Republic of Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "BlindHarmony: \"Blind\" Harmonization for MR Images via Flow Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jeong_BlindHarmony_Blind_Harmonization_for_MR_Images_via_Flow_Model_ICCV_2023_paper.html",
        "author": "Hwihun Jeong, Heejoon Byun, Dong Un Kang, Jongho Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jeong_BlindHarmony_Blind_Harmonization_for_MR_Images_via_Flow_Model_ICCV_2023_paper.pdf",
        "aff": "Department of ECE, Seoul National University, Republic of Korea",
        "project": "",
        "github": "https://github.com/SNU-LIST/BlindHarmony",
        "arxiv": "2305.10732"
    },
    {
        "title": "BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_BoMD_Bag_of_Multi-label_Descriptors_for_Noisy_Chest_X-ray_Classification_ICCV_2023_paper.html",
        "author": "Yuanhong Chen, Fengbei Liu, Hu Wang, Chong Wang, Yuyuan Liu, Yu Tian, Gustavo Carneiro",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_BoMD_Bag_of_Multi-label_Descriptors_for_Noisy_Chest_X-ray_Classification_ICCV_2023_paper.pdf",
        "aff": "Harvard Medical School, Harvard University; Centre for Vision, Speech and Signal Processing, University of Surrey; Australian Institute for Machine Learning, University of Adelaide",
        "project": "",
        "github": "https://github.com/cyh-0/BoMD",
        "arxiv": ""
    },
    {
        "title": "Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Body_Knowledge_and_Uncertainty_Modeling_for_Monocular_3D_Human_Body_ICCV_2023_paper.html",
        "author": "Yufei Zhang, Hanjing Wang, Jeffrey O. Kephart, Qiang Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Body_Knowledge_and_Uncertainty_Modeling_for_Monocular_3D_Human_Body_ICCV_2023_paper.pdf",
        "aff": "IBM Research; Rensselaer Polytechnic Institute",
        "project": "",
        "github": "",
        "arxiv": "2308.00799"
    },
    {
        "title": "Bold but Cautious: Unlocking the Potential of Personalized Federated Learning through Cautiously Aggressive Collaboration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Bold_but_Cautious_Unlocking_the_Potential_of_Personalized_Federated_Learning_ICCV_2023_paper.html",
        "author": "Xinghao Wu, Xuefeng Liu, Jianwei Niu, Guogang Zhu, Shaojie Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Bold_but_Cautious_Unlocking_the_Potential_of_Personalized_Federated_Learning_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; Zhongguancun Laboratory, Beijing, China; Zhengzhou University Research Institute of Industrial Technology, School of Information Engineering, Zhengzhou University, Zhengzhou, China; Jindal School of Management, University of Texas at Dallas, USA; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; Zhongguancun Laboratory, Beijing, China",
        "project": "",
        "github": "https://github.com/kxzxvbk/Fling",
        "arxiv": "2309.11103"
    },
    {
        "title": "Boosting 3-DoF Ground-to-Satellite Camera Localization Accuracy via Geometry-Guided Cross-View Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Boosting_3-DoF_Ground-to-Satellite_Camera_Localization_Accuracy_via_Geometry-Guided_Cross-View_Transformer_ICCV_2023_paper.html",
        "author": "Yujiao Shi, Fei Wu, Akhil Perincherry, Ankit Vora, Hongdong Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Boosting_3-DoF_Ground-to-Satellite_Camera_Localization_Accuracy_via_Geometry-Guided_Cross-View_Transformer_ICCV_2023_paper.pdf",
        "aff": "Ford Motor Company; The Australian National University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Boosting Adversarial Transferability via Gradient Relevance Attack",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Boosting_Adversarial_Transferability_via_Gradient_Relevance_Attack_ICCV_2023_paper.html",
        "author": "Hegui Zhu, Yuchen Ren, Xiaoyan Sui, Lianping Yang, Wuming Jiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Boosting_Adversarial_Transferability_via_Gradient_Relevance_Attack_ICCV_2023_paper.pdf",
        "aff": "College of Sciences, Northeastern University, Shenyang, China; Beijing EyeCool Technology, Beijing, China",
        "project": "",
        "github": "https://github.com/RYC-98/GRA",
        "arxiv": ""
    },
    {
        "title": "Boosting Few-shot Action Recognition with Graph-guided Hybrid Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xing_Boosting_Few-shot_Action_Recognition_with_Graph-guided_Hybrid_Matching_ICCV_2023_paper.html",
        "author": "Jiazheng Xing, Mengmeng Wang, Yudi Ruan, Bofan Chen, Yaowei Guo, Boyu Mu, Guang Dai, Jingdong Wang, Yong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_Boosting_Few-shot_Action_Recognition_with_Graph-guided_Hybrid_Matching_ICCV_2023_paper.pdf",
        "aff": "SGIT AI Lab, State Grid Corporation of China; Baidu Inc.; Zhejiang University",
        "project": "",
        "github": "https://github.com/jiazheng-xing/GgHM",
        "arxiv": "2308.09346"
    },
    {
        "title": "Boosting Long-tailed Object Detection via Step-wise Learning on Smooth-tail Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Boosting_Long-tailed_Object_Detection_via_Step-wise_Learning_on_Smooth-tail_Data_ICCV_2023_paper.html",
        "author": "Na Dong, Yongqiang Zhang, Mingli Ding, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Boosting_Long-tailed_Object_Detection_via_Step-wise_Learning_on_Smooth-tail_Data_ICCV_2023_paper.pdf",
        "aff": "School of Instrument Science and Engineering, Harbin Institute of Technology; Department of Computer Science, National University of Singapore",
        "project": "",
        "github": "https://github.com/dongnana777/Long-tailed-object-detection",
        "arxiv": "2305.12833"
    },
    {
        "title": "Boosting Multi-modal Model Performance with Adaptive Gradient Modulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Boosting_Multi-modal_Model_Performance_with_Adaptive_Gradient_Modulation_ICCV_2023_paper.html",
        "author": "Hong Li, Xingyu Li, Pengbo Hu, Yinuo Lei, Chunxiao Li, Yi Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Boosting_Multi-modal_Model_Performance_with_Adaptive_Gradient_Modulation_ICCV_2023_paper.pdf",
        "aff": "School of Information Science and Technology, ShanghaiTech University; School of Management, University of Science and Technology of China, Hefei, China; SIST, University of Science and Technology of China, Hefei, China; Shanghai Center for Brain Science and Brain-Inspired Technology, Shanghai, China",
        "project": "",
        "github": "https://github.com/lihong2303/AGM_ICCV2023",
        "arxiv": "2308.07686"
    },
    {
        "title": "Boosting Novel Category Discovery Over Domains with Soft Contrastive Learning and All in One Classifier",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zang_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_ICCV_2023_paper.html",
        "author": "Zelin Zang, Lei Shang, Senqiao Yang, Fei Wang, Baigui Sun, Xuansong Xie, Stan Z. Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zang_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group; Westlake University",
        "project": "",
        "github": "",
        "arxiv": "2211.11262"
    },
    {
        "title": "Boosting Positive Segments for Weakly-Supervised Audio-Visual Video Parsing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rachavarapu_Boosting_Positive_Segments_for_Weakly-Supervised_Audio-Visual_Video_Parsing_ICCV_2023_paper.html",
        "author": "Kranthi Kumar Rachavarapu, Rajagopalan A. N.",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rachavarapu_Boosting_Positive_Segments_for_Weakly-Supervised_Audio-Visual_Video_Parsing_ICCV_2023_paper.pdf",
        "aff": "Indian Institute of Technology Madras, India",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Boosting Semantic Segmentation from the Perspective of Explicit Class Embeddings",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Boosting_Semantic_Segmentation_from_the_Perspective_of_Explicit_Class_Embeddings_ICCV_2023_paper.html",
        "author": "Yuhe Liu, Chuanjian Liu, Kai Han, Quan Tang, Zengchang Qin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Boosting_Semantic_Segmentation_from_the_Perspective_of_Explicit_Class_Embeddings_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; South China University of Technology; Beihang University",
        "project": "https://gitee.com/mindspore/models",
        "github": "https://github.com/Carol-lyh/ECENet",
        "arxiv": "2308.12894"
    },
    {
        "title": "Boosting Single Image Super-Resolution via Partial Channel Shifting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.html",
        "author": "Xiaoming Zhang, Tianrui Li, Xiaole Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.pdf",
        "aff": "Southwest Jiaotong University, China",
        "project": "",
        "github": "https://github.com/OwXiaoM/PCS",
        "arxiv": ""
    },
    {
        "title": "Boosting Whole Slide Image Classification from the Perspectives of Distribution, Correlation and Magnification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.html",
        "author": "Linhao Qu, Zhiwei Yang, Minghong Duan, Yingfan Ma, Shuo Wang, Manning Wang, Zhijian Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.pdf",
        "aff": "Digital Medical Research Center, School of Basic Medical Science, Fudan University",
        "project": "",
        "github": "https://github.com/miccaiif/MILBooster",
        "arxiv": ""
    },
    {
        "title": "Bootstrap Motion Forecasting With Self-Consistent Constraints",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Bootstrap_Motion_Forecasting_With_Self-Consistent_Constraints_ICCV_2023_paper.html",
        "author": "Maosheng Ye, Jiamiao Xu, Xunnong Xu, Tengfei Wang, Tongyi Cao, Qifeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Bootstrap_Motion_Forecasting_With_Self-Consistent_Constraints_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology; DeepRoute.AI",
        "project": "",
        "github": "",
        "arxiv": "2204.05859"
    },
    {
        "title": "Borrowing Knowledge From Pre-trained Language Model: A New Data-efficient Visual Learning Paradigm",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Borrowing_Knowledge_From_Pre-trained_Language_Model_A_New_Data-efficient_Visual_ICCV_2023_paper.html",
        "author": "Wenxuan Ma, Shuang Li, JinMing Zhang, Chi Harold Liu, Jingxuan Kang, Yulin Wang, Gao Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Borrowing_Knowledge_From_Pre-trained_Language_Model_A_New_Data-efficient_Visual_ICCV_2023_paper.pdf",
        "aff": "University of Liverpool; Beijing Institute of Technology; Tsinghua University",
        "project": "",
        "github": "https://github.com/BIT-DA/BorLan",
        "arxiv": ""
    },
    {
        "title": "Both Diverse and Realism Matter: Physical Attribute and Style Alignment for Rainy Image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Both_Diverse_and_Realism_Matter_Physical_Attribute_and_Style_Alignment_ICCV_2023_paper.html",
        "author": "Changfeng Yu, Shiming Chen, Yi Chang, Yibing Song, Luxin Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Both_Diverse_and_Realism_Matter_Physical_Attribute_and_Style_Alignment_ICCV_2023_paper.pdf",
        "aff": "AI3Institute, Fudan University; Carnegie Mellon University, Mohamed bin Zayed University of Artificial Intelligence; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Boundary-Aware Divide and Conquer: A Diffusion-Based Solution for Unsupervised Shadow Removal",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Boundary-Aware_Divide_and_Conquer_A_Diffusion-Based_Solution_for_Unsupervised_Shadow_ICCV_2023_paper.html",
        "author": "Lanqing Guo, Chong Wang, Wenhan Yang, Yufei Wang, Bihan Wen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Boundary-Aware_Divide_and_Conquer_A_Diffusion-Based_Solution_for_Unsupervised_Shadow_ICCV_2023_paper.pdf",
        "aff": "Peng Cheng Laboratory, China; Nanyang Technological University, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Box-based Refinement for Weakly Supervised and Unsupervised Localization Tasks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gomel_Box-based_Refinement_for_Weakly_Supervised_and_Unsupervised_Localization_Tasks_ICCV_2023_paper.html",
        "author": "Eyal Gomel, Tal Shaharbany, Lior Wolf",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gomel_Box-based_Refinement_for_Weakly_Supervised_and_Unsupervised_Localization_Tasks_ICCV_2023_paper.pdf",
        "aff": "Tel Aviv University",
        "project": "",
        "github": "https://github.com/eyalgomel/box-based-refinement",
        "arxiv": ""
    },
    {
        "title": "BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.html",
        "author": "Jinheng Xie, Yuexiang Li, Yawen Huang, Haozhe Liu, Wentian Zhang, Yefeng Zheng, Mike Zheng Shou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.pdf",
        "aff": "Jarvis Lab, Tencent; AI Initiative, King Abdullah University of Science and Technology; Show Lab, National University of Singapore",
        "project": "",
        "github": "https://github.com/showlab/BoxDiff",
        "arxiv": "2307.10816"
    },
    {
        "title": "BoxSnake: Polygonal Instance Segmentation with Box Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_BoxSnake_Polygonal_Instance_Segmentation_with_Box_Supervision_ICCV_2023_paper.html",
        "author": "Rui Yang, Lin Song, Yixiao Ge, Xiu Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_BoxSnake_Polygonal_Instance_Segmentation_with_Box_Supervision_ICCV_2023_paper.pdf",
        "aff": "Tencent AI Lab; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "project": "",
        "github": "https://github.com/Yangr116/BoxSnake",
        "arxiv": "2303.11630"
    },
    {
        "title": "Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bitton-Guetta_Breaking_Common_Sense_WHOOPS_A_Vision-and-Language_Benchmark_of_Synthetic_and_ICCV_2023_paper.html",
        "author": "Nitzan Bitton-Guetta, Yonatan Bitton, Jack Hessel, Ludwig Schmidt, Yuval Elovici, Gabriel Stanovsky, Roy Schwartz",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bitton-Guetta_Breaking_Common_Sense_WHOOPS_A_Vision-and-Language_Benchmark_of_Synthetic_and_ICCV_2023_paper.pdf",
        "aff": "Ben Gurion University of the Negev; The Hebrew University of Jerusalem; Allen Institute for Artificial Intelligence; University of Washington",
        "project": "whoops-benchmark.github.io/",
        "github": "https://github.com/whoops-benchmark",
        "arxiv": "2303.07274"
    },
    {
        "title": "Breaking Temporal Consistency: Generating Video Universal Adversarial Perturbations Using Image Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.html",
        "author": "Hee-Seon Kim, Minji Son, Minbeom Kim, Myung-Joon Kwon, Changick Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Breaking The Limits of Text-conditioned 3D Motion Synthesis with Elaborative Descriptions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Breaking_The_Limits_of_Text-conditioned_3D_Motion_Synthesis_with_Elaborative_ICCV_2023_paper.html",
        "author": "Yijun Qian, Jack Urbanek, Alexander G. Hauptmann, Jungdam Won",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Breaking_The_Limits_of_Text-conditioned_3D_Motion_Synthesis_with_Elaborative_ICCV_2023_paper.pdf",
        "aff": "META AI; Seoul National University; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Bridging Cross-task Protocol Inconsistency for Distillation in Dense Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Bridging_Cross-task_Protocol_Inconsistency_for_Distillation_in_Dense_Object_Detection_ICCV_2023_paper.html",
        "author": "Longrong Yang, Xianpan Zhou, Xuewei Li, Liang Qiao, Zheyang Li, Ziwei Yang, Gaoang Wang, Xi Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Bridging_Cross-task_Protocol_Inconsistency_for_Distillation_in_Dense_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "College of Computer Science & Technology, Zhejiang University; Shanghai Institute for Advanced Study of Zhejiang University; Hikvision Research Institute; Polytechnic Institute, Zhejiang University; ZJU \u2013 UIUC Institute, Zhejiang University",
        "project": "",
        "github": "https://github.com/TinyTigerPan/BCKD",
        "arxiv": "2308.14286"
    },
    {
        "title": "Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.html",
        "author": "Zunnan Xu, Zhihong Chen, Yong Zhang, Yibing Song, Xiang Wan, Guanbin Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.pdf",
        "aff": "Shenzhen Research Institute of Big Data; Sun Yat-sen University; The Chinese University of Hong Kong, Shenzhen; AI3Institute, Fudan University",
        "project": "",
        "github": "https://github.com/kkakkkka/ETRIS",
        "arxiv": "2307.11545"
    },
    {
        "title": "Bring Clipart to Life",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Bring_Clipart_to_Life_ICCV_2023_paper.html",
        "author": "Nanxuan Zhao, Shengqi Dang, Hexun Lin, Yang Shi, Nan Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Bring_Clipart_to_Life_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; Intelligent Big Data Visualization Lab, Tongji University",
        "project": "",
        "github": "https://github.com/dangsq/ClipFaceShop",
        "arxiv": ""
    },
    {
        "title": "Building Bridge Across the Time: Disruption and Restoration of Murals In the Wild",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Building_Bridge_Across_the_Time_Disruption_and_Restoration_of_Murals_ICCV_2023_paper.html",
        "author": "Huiyang Shao, Qianqian Xu, Peisong Wen, Peifeng Gao, Zhiyong Yang, Qingming Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Building_Bridge_Across_the_Time_Disruption_and_Restoration_of_Murals_ICCV_2023_paper.pdf",
        "aff": "2School of Computer Science and Tech., University of Chinese Academy of Sciences; 1Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS; 2School of Computer Science and Tech., University of Chinese Academy of Sciences; 3State Key Lab of Info. Security, Inst. of Info. Engineering, CAS; 4School of Cyber Security, University of Chinese Academy of Sciences; 1Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS; 1Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS; 2School of Computer Science and Tech., University of Chinese Academy of Sciences; 5BDKM, University of Chinese Academy of Sciences; 6Peng Cheng Laboratory",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Building Vision Transformers with Hierarchy Aware Feature Aggregation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Building_Vision_Transformers_with_Hierarchy_Aware_Feature_Aggregation_ICCV_2023_paper.html",
        "author": "Yongjie Chen, Hongmin Liu, Haoran Yin, Bin Fan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Building_Vision_Transformers_with_Hierarchy_Aware_Feature_Aggregation_ICCV_2023_paper.pdf",
        "aff": "Horizon Robotics; School of Intelligence Science and Technology, University of Science and Technology Beijing; Institute of Artificial Intelligence, University of Science and Technology Beijing",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.html",
        "author": "Vimal K B, Saketh Bachu, Tanmay Garg, Niveditha Lakshmi Narasimhan, Raghavan Konuru, Vineeth N Balasubramanian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.pdf",
        "aff": "Indian Institute of Technology, Hyderabad; KLA",
        "project": "",
        "github": "",
        "arxiv": "2309.02429"
    },
    {
        "title": "Building3D: A Urban-Scale Dataset and Benchmarks for Learning Roof Structures from Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Building3D_A_Urban-Scale_Dataset_and_Benchmarks_for_Learning_Roof_Structures_ICCV_2023_paper.html",
        "author": "Ruisheng Wang, Shangfeng Huang, Hongxin Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Building3D_A_Urban-Scale_Dataset_and_Benchmarks_for_Learning_Roof_Structures_ICCV_2023_paper.pdf",
        "aff": "University of Calgary, AB, Canada",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_C2F2NeUS_Cascade_Cost_Frustum_Fusion_for_High_Fidelity_and_Generalizable_ICCV_2023_paper.html",
        "author": "Luoyuan Xu, Tao Guan, Yuesong Wang, Wenkai Liu, Zhaojie Zeng, Junle Wang, Wei Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_C2F2NeUS_Cascade_Cost_Frustum_Fusion_for_High_Fidelity_and_Generalizable_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Technology, Huazhong University of Science and Technology; Tencent",
        "project": "",
        "github": "",
        "arxiv": "2306.10003"
    },
    {
        "title": "C2ST: Cross-Modal Contextualized Sequence Transduction for Continuous Sign Language Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_C2ST_Cross-Modal_Contextualized_Sequence_Transduction_for_Continuous_Sign_Language_Recognition_ICCV_2023_paper.html",
        "author": "Huaiwen Zhang, Zihang Guo, Yang Yang, Xin Liu, De Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_C2ST_Cross-Modal_Contextualized_Sequence_Transduction_for_Continuous_Sign_Language_Recognition_ICCV_2023_paper.pdf",
        "aff": "College of Computer Science, Inner Mongolia University, Hohhot, 010021, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CAD-Estate: Large-scale CAD Model Annotation in RGB Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Maninis_CAD-Estate_Large-scale_CAD_Model_Annotation_in_RGB_Videos_ICCV_2023_paper.html",
        "author": "Kevis-Kokitsi Maninis, Stefan Popov, Matthias Nie\u00dfner, Vittorio Ferrari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Maninis_CAD-Estate_Large-scale_CAD_Model_Annotation_in_RGB_Videos_ICCV_2023_paper.pdf",
        "aff": "TUM; Google Research",
        "project": "",
        "github": "https://github.com/google-research/cad-estate",
        "arxiv": ""
    },
    {
        "title": "CAFA: Class-Aware Feature Alignment for Test-Time Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jung_CAFA_Class-Aware_Feature_Alignment_for_Test-Time_Adaptation_ICCV_2023_paper.html",
        "author": "Sanghun Jung, Jungsoo Lee, Nanhee Kim, Amirreza Shaban, Byron Boots, Jaegul Choo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_CAFA_Class-Aware_Feature_Alignment_for_Test-Time_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Enssel Inc.; KAIST AI; University of Washington",
        "project": "",
        "github": "",
        "arxiv": "2206.00205"
    },
    {
        "title": "CAME: Contrastive Automated Model Evaluation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Peng_CAME_Contrastive_Automated_Model_Evaluation_ICCV_2023_paper.html",
        "author": "Ru Peng, Qiuyang Duan, Haobo Wang, Jiachen Ma, Yanbo Jiang, Yongjun Tu, Xiu Jiang, Junbo Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_CAME_Contrastive_Automated_Model_Evaluation_ICCV_2023_paper.pdf",
        "aff": "DI-Lab, Zhejiang University; OPPO; Zhejiang University",
        "project": "",
        "github": "https://github.com/pengr/Contrastive_AutoEval",
        "arxiv": "2308.11111"
    },
    {
        "title": "CASSPR: Cross Attention Single Scan Place Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_CASSPR_Cross_Attention_Single_Scan_Place_Recognition_ICCV_2023_paper.html",
        "author": "Yan Xia, Mariia Gladkova, Rui Wang, Qianyun Li, Uwe Stilla, Jo\u00e3o F Henriques, Daniel Cremers",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CASSPR_Cross_Attention_Single_Scan_Place_Recognition_ICCV_2023_paper.pdf",
        "aff": "1Technical University of Munich, 2Munich Center for Machine Learning (MCML), 3Visual Geometry Group, University of Oxford, 4Microsoft Zurich, 5Munich Data Science Institute; 1Technical University of Munich, 2Munich Center for Machine Learning (MCML), 3Visual Geometry Group, University of Oxford, 5Munich Data Science Institute; Visual Geometry Group, University of Oxford; Technical University of Munich; 1Technical University of Munich, 5Munich Data Science Institute; Microsoft Zurich",
        "project": "",
        "github": "https://github.com/Yan-Xia/CASSPR",
        "arxiv": "2211.12542"
    },
    {
        "title": "CBA: Improving Online Continual Learning via Continual Bias Adaptor",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CBA_Improving_Online_Continual_Learning_via_Continual_Bias_Adaptor_ICCV_2023_paper.html",
        "author": "Quanziang Wang, Renzhen Wang, Yichen Wu, Xixi Jia, Deyu Meng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CBA_Improving_Online_Continual_Learning_via_Continual_Bias_Adaptor_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; Xidian University; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "https://github.com/wqza/CBA-online-CL",
        "arxiv": "2308.06925"
    },
    {
        "title": "CC3D: Layout-Conditioned Generation of Compositional 3D Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.html",
        "author": "Sherwin Bahmani, Jeong Joon Park, Despoina Paschalidou, Xingguang Yan, Gordon Wetzstein, Leonidas Guibas, Andrea Tagliasacchi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.pdf",
        "aff": "University of Toronto; Simon Fraser University; Stanford University",
        "project": "https://sherwinbahmani.github.io/cc3d",
        "github": "https://github.com/sherwinbahmani/cc3d",
        "arxiv": "2303.12074"
    },
    {
        "title": "CDAC: Cross-domain Attention Consistency in Transformer for Domain Adaptive Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CDAC_Cross-domain_Attention_Consistency_in_Transformer_for_Domain_Adaptive_Semantic_ICCV_2023_paper.html",
        "author": "Kaihong Wang, Donghyun Kim, Rogerio Feris, Margrit Betke",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CDAC_Cross-domain_Attention_Consistency_in_Transformer_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf",
        "aff": "Korea University; Boston University; MIT-IBM Watson AI Lab",
        "project": "",
        "github": "https://github.com/wangkaihong/CDAC",
        "arxiv": ""
    },
    {
        "title": "CDFSL-V: Cross-Domain Few-Shot Learning for Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_Learning_for_Videos_ICCV_2023_paper.html",
        "author": "Sarinda Samarasinghe, Mamshad Nayeem Rizve, Navid Kardan, Mubarak Shah",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_Learning_for_Videos_ICCV_2023_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida, Orlando, Florida, USA",
        "project": "",
        "github": "https://github.com/Sarinda251/CDFSL-V1",
        "arxiv": ""
    },
    {
        "title": "CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Abdelfattah_CDUL_CLIP-Driven_Unsupervised_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.html",
        "author": "Rabab Abdelfattah, Qing Guo, Xiaoguang Li, Xiaofeng Wang, Song Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelfattah_CDUL_CLIP-Driven_Unsupervised_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf",
        "aff": "University of South Carolina, USA; University of Southern Mississippi, USA; IHPC and CFAR, Agency for Science, Technology and Research, Singapore",
        "project": "",
        "github": "",
        "arxiv": "2307.16634"
    },
    {
        "title": "CFCG: Semi-Supervised Semantic Segmentation via Cross-Fusion and Contour Guidance Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_CFCG_Semi-Supervised_Semantic_Segmentation_via_Cross-Fusion_and_Contour_Guidance_Supervision_ICCV_2023_paper.html",
        "author": "Shuo Li, Yue He, Weiming Zhang , Wei Zhang, Xiao Tan, Junyu Han, Errui Ding, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CFCG_Semi-Supervised_Semantic_Segmentation_via_Cross-Fusion_and_Contour_Guidance_Supervision_ICCV_2023_paper.pdf",
        "aff": "Baidu Inc",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CGBA: Curvature-aware Geometric Black-box Attack",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Reza_CGBA_Curvature-aware_Geometric_Black-box_Attack_ICCV_2023_paper.html",
        "author": "Md Farhamdur Reza, Ali Rahmati, Tianfu Wu, Huaiyu Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Reza_CGBA_Curvature-aware_Geometric_Black-box_Attack_ICCV_2023_paper.pdf",
        "aff": "Department of ECE, North Carolina State University",
        "project": "",
        "github": "https://github.com/Farhamdur/CGBA",
        "arxiv": "2308.03163"
    },
    {
        "title": "CHAMPAGNE: Learning Real-world Conversation from Large-Scale Web Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_CHAMPAGNE_Learning_Real-world_Conversation_from_Large-Scale_Web_Videos_ICCV_2023_paper.html",
        "author": "Seungju Han, Jack Hessel, Nouha Dziri, Yejin Choi, Youngjae Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_CHAMPAGNE_Learning_Real-world_Conversation_from_Large-Scale_Web_Videos_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; Allen Institute for Artificial Intelligence; Seoul National University; University of Washington",
        "project": "",
        "github": "https://seungjuhan.me/champagne",
        "arxiv": "2303.09713"
    },
    {
        "title": "CHORD: Category-level Hand-held Object Reconstruction via Shape Deformation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_CHORD_Category-level_Hand-held_Object_Reconstruction_via_Shape_Deformation_ICCV_2023_paper.html",
        "author": "Kailin Li, Lixin Yang, Haoyu Zhen, Zenan Lin, Xinyu Zhan, Licheng Zhong, Jian Xu, Kejian Wu, Cewu Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CHORD_Category-level_Hand-held_Object_Reconstruction_via_Shape_Deformation_ICCV_2023_paper.pdf",
        "aff": "XREAL; South China University of Technology; Shanghai Jiao Tong University, Shanghai Qi Zhi Institute; Shanghai Jiao Tong University",
        "project": "",
        "github": "https://kailinli.github.io/CHORD",
        "arxiv": "2308.10574"
    },
    {
        "title": "CHORUS : Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_CHORUS__Learning_Canonicalized_3D_Human-Object_Spatial_Relations_from_Unbounded_ICCV_2023_paper.html",
        "author": "Sookwan Han, Hanbyul Joo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_CHORUS__Learning_Canonicalized_3D_Human-Object_Spatial_Relations_from_Unbounded_ICCV_2023_paper.pdf",
        "aff": "Seoul National University",
        "project": "https://jellyheadandrew.github.io/projects/chorus",
        "github": "",
        "arxiv": "2308.12288"
    },
    {
        "title": "CIRI: Curricular Inactivation for Residue-aware One-shot Video Inpainting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_CIRI_Curricular_Inactivation_for_Residue-aware_One-shot_Video_Inpainting_ICCV_2023_paper.html",
        "author": "Weiying Zheng, Cheng Xu, Xuemiao Xu, Wenxi Liu, Shengfeng He",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_CIRI_Curricular_Inactivation_for_Residue-aware_One-shot_Video_Inpainting_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology, State Key Laboratory of Subtropical Building Science, Ministry of Education Key Laboratory of Big Data and Intelligent Robot, Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information; South China University of Technology; Fuzhou University; Singapore Management University",
        "project": "",
        "github": "https://github.com/Arise-zwy/CIRI",
        "arxiv": ""
    },
    {
        "title": "CL-MVSNet: Unsupervised Multi-View Stereo with Dual-Level Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_paper.html",
        "author": "Kaiqiang Xiong, Rui Peng, Zhe Zhang, Tianxing Feng, Jianbo Jiao, Feng Gao, Ronggang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_paper.pdf",
        "aff": "School of Electronic and Computer Engineering, Peking University; School of Arts, Peking University; School of Computer Science, University of Birmingham; School of Electronic and Computer Engineering, Peking University, Peng Cheng Laboratory, Migu Culture Technology Co., Ltd",
        "project": "",
        "github": "https://KaiqiangXiong.github.io/CL-MVSNet/",
        "arxiv": ""
    },
    {
        "title": "CLIP-Cluster: CLIP-Guided Attribute Hallucination for Face Clustering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shen_CLIP-Cluster_CLIP-Guided_Attribute_Hallucination_for_Face_Clustering_ICCV_2023_paper.html",
        "author": "Shuai Shen, Wanhua Li, Xiaobing Wang, Dafeng Zhang, Zhezhu Jin, Jie Zhou, Jiwen Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_CLIP-Cluster_CLIP-Guided_Attribute_Hallucination_for_Face_Clustering_ICCV_2023_paper.pdf",
        "aff": "Samsung Research China-Beijing (SRC-B); Department of Automation, Tsinghua University, China; Beijing National Research Center for Information Science and Technology, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.html",
        "author": "Jie Liu, Yixiao Zhang, Jie-Neng Chen, Junfei Xiao, Yongyi Lu, Bennett A Landman, Yixuan Yuan, Alan Yuille, Yucheng Tang, Zongwei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; City University of Hong Kong; Chinese University of Hong Kong; Vanderbilt University",
        "project": "",
        "github": "https://github.com/ljwztc/CLIP-Driven-Universal-Model",
        "arxiv": "2301.00785"
    },
    {
        "title": "CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth Pre-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_CLIP2Point_Transfer_CLIP_to_Point_Cloud_Classification_with_Image-Depth_Pre-Training_ICCV_2023_paper.html",
        "author": "Tianyu Huang, Bowen Dong, Yunhan Yang, Xiaoshui Huang, Rynson W.H. Lau, Wanli Ouyang, Wangmeng Zuo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_CLIP2Point_Transfer_CLIP_to_Point_Cloud_Classification_with_Image-Depth_Pre-Training_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; Harbin Institute of Technology; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/tyhuang0428/CLIP2Point",
        "arxiv": "2210.01055"
    },
    {
        "title": "CLIPN for Zero-Shot OOD Detection: Teaching CLIP to Say No",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CLIPN_for_Zero-Shot_OOD_Detection_Teaching_CLIP_to_Say_No_ICCV_2023_paper.html",
        "author": "Hualiang Wang, Yi Li, Huifeng Yao, Xiaomeng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CLIPN_for_Zero-Shot_OOD_Detection_Teaching_CLIP_to_Say_No_ICCV_2023_paper.pdf",
        "aff": "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology",
        "project": "",
        "github": "https://github.com/xmed-lab/CLIPN",
        "arxiv": "2308.12213"
    },
    {
        "title": "CLIPTER: Looking at the Bigger Picture in Scene Text Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Aberdam_CLIPTER_Looking_at_the_Bigger_Picture_in_Scene_Text_Recognition_ICCV_2023_paper.html",
        "author": "Aviad Aberdam, David Bensaid, Alona Golts, Roy Ganz, Oren Nuriel, Royee Tichauer, Shai Mazor, Ron Litman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Aberdam_CLIPTER_Looking_at_the_Bigger_Picture_in_Scene_Text_Recognition_ICCV_2023_paper.pdf",
        "aff": "AWS AI Labs; Technion, Israel",
        "project": "",
        "github": "",
        "arxiv": "2301.07464"
    },
    {
        "title": "CLIPTrans: Transferring Visual Knowledge with Pre-trained Models for Multimodal Machine Translation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_CLIPTrans_Transferring_Visual_Knowledge_with_Pre-trained_Models_for_Multimodal_Machine_ICCV_2023_paper.html",
        "author": "Devaansh Gupta, Siddhant Kharbanda, Jiawei Zhou, Wanhua Li, Hanspeter Pfister, Donglai Wei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_CLIPTrans_Transferring_Visual_Knowledge_with_Pre-trained_Models_for_Multimodal_Machine_ICCV_2023_paper.pdf",
        "aff": "Microsoft India; Boston College; Harvard University",
        "project": "",
        "github": "www.github.com/devaansh100/CLIPTrans",
        "arxiv": "2308.15226"
    },
    {
        "title": "CLIPascene: Scene Sketching with Different Types and Levels of Abstraction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Vinker_CLIPascene_Scene_Sketching_with_Different_Types_and_Levels_of_Abstraction_ICCV_2023_paper.html",
        "author": "Yael Vinker, Yuval Alaluf, Daniel Cohen-Or, Ariel Shamir",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Vinker_CLIPascene_Scene_Sketching_with_Different_Types_and_Levels_of_Abstraction_ICCV_2023_paper.pdf",
        "aff": "Reichman University; Tel Aviv University",
        "project": "https://clipascene.github.io/CLIPascene/",
        "github": "https://github.com/clipascene/CLIPascene",
        "arxiv": "2211.17256"
    },
    {
        "title": "CLNeRF: Continual Learning Meets NeRF",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_CLNeRF_Continual_Learning_Meets_NeRF_ICCV_2023_paper.html",
        "author": "Zhipeng Cai, Matthias M\u00fcller",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_CLNeRF_Continual_Learning_Meets_NeRF_ICCV_2023_paper.pdf",
        "aff": "Intel Labs",
        "project": "",
        "github": "https://github.com/IntelLabs/CLNeRF",
        "arxiv": ""
    },
    {
        "title": "CLR: Channel-wise Lightweight Reprogramming for Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ge_CLR_Channel-wise_Lightweight_Reprogramming_for_Continual_Learning_ICCV_2023_paper.html",
        "author": "Yunhao Ge, Yuecheng Li, Shuo Ni, Jiaping Zhao, Ming-Hsuan Yang, Laurent Itti",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_CLR_Channel-wise_Lightweight_Reprogramming_for_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "University of Southern California; Google Research",
        "project": "",
        "github": "https://github.com/gyhandy/Channel-wise-Lightweight-Reprogramming",
        "arxiv": "2307.11386"
    },
    {
        "title": "CMDA: Cross-Modality Domain Adaptation for Nighttime Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_CMDA_Cross-Modality_Domain_Adaptation_for_Nighttime_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Ruihao Xia, Chaoqiang Zhao, Meng Zheng, Ziyan Wu, Qiyu Sun, Yang Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CMDA_Cross-Modality_Domain_Adaptation_for_Nighttime_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "United Imaging Intelligence; East China University of Science and Technology",
        "project": "",
        "github": "https://github.com/XiaRho/CMDA",
        "arxiv": "2307.15942"
    },
    {
        "title": "CO-Net: Learning Multiple Point Cloud Tasks at Once with A Cohesive Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_CO-Net_Learning_Multiple_Point_Cloud_Tasks_at_Once_with_A_ICCV_2023_paper.html",
        "author": "Tao Xie, Ke Wang, Siyi Lu, Yukun Zhang, Kun Dai, Xiaoyu Li, Jie Xu, Li Wang, Lijun Zhao, Xinyu Zhang, Ruifeng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_CO-Net_Learning_Multiple_Point_Cloud_Tasks_at_Once_with_A_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of Technology; Harbin Institute of Technology, Zhengzhou Research Institute; China Coal Science and Technology Intelligent Storage Technology Co., Ltd.; Tsinghua University; Harbin Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CO-PILOT: Dynamic Top-Down Point Cloud with Conditional Neighborhood Aggregation for Multi-Gigapixel Histopathology Image Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.html",
        "author": "Ramin Nakhli, Allen Zhang, Ali Mirabadi, Katherine Rich, Maryam Asadi, Blake Gilks, Hossein Farahani, Ali Bashashati",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.pdf",
        "aff": "University of British Columbia",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "COCO-O: A Benchmark for Object Detectors under Natural Distribution Shifts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.html",
        "author": "Xiaofeng Mao, Yuefeng Chen, Yao Zhu, Da Chen, Hang Su, Rong Zhang, Hui Xue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Alibaba Group; University of Bath; Zhejiang University",
        "project": "",
        "github": "https://github.com/alibaba/easyrobust/tree/main/benchmarks/coco_o",
        "arxiv": ""
    },
    {
        "title": "COMPASS: High-Efficiency Deep Image Compression with Arbitrary-scale Spatial Scalability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_COMPASS_High-Efficiency_Deep_Image_Compression_with_Arbitrary-scale_Spatial_Scalability_ICCV_2023_paper.html",
        "author": "Jongmin Park, Jooyoung Lee, Munchurl Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_COMPASS_High-Efficiency_Deep_Image_Compression_with_Arbitrary-scale_Spatial_Scalability_ICCV_2023_paper.pdf",
        "aff": "KAIST; ETRI",
        "project": "",
        "github": "",
        "arxiv": "2309.07926"
    },
    {
        "title": "COOL-CHIC: Coordinate-based Low Complexity Hierarchical Image Codec",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.html",
        "author": "Th\u00e9o Ladune, Pierrick Philippe, F\u00e9lix Henry, Gordon Clare, Thomas Leguay",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.pdf",
        "aff": "Orange Innovation, France",
        "project": "https://orange-opensource.github.io/Cool-Chic/",
        "github": "https://github.com/orange-opensource/Cool-Chic",
        "arxiv": ""
    },
    {
        "title": "COOP: Decoupling and Coupling of Whole-Body Grasping Pose Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_COOP_Decoupling_and_Coupling_of_Whole-Body_Grasping_Pose_Generation_ICCV_2023_paper.html",
        "author": "Yanzhao Zheng, Yunzhou Shi, Yuhao Cui, Zhongzhou Zhao, Zhiling Luo, Wei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_COOP_Decoupling_and_Coupling_of_Whole-Body_Grasping_Pose_Generation_ICCV_2023_paper.pdf",
        "aff": "Alibaba DAMO Academy",
        "project": "",
        "github": "https://github.com/zhengyanzhao1997/COOP",
        "arxiv": ""
    },
    {
        "title": "COPILOT: Human-Environment Collision Prediction and Localization from Egocentric Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_COPILOT_Human-Environment_Collision_Prediction_and_Localization_from_Egocentric_Videos_ICCV_2023_paper.html",
        "author": "Boxiao Pan, Bokui Shen, Davis Rempe, Despoina Paschalidou, Kaichun Mo, Yanchao Yang, Leonidas J. Guibas",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_COPILOT_Human-Environment_Collision_Prediction_and_Localization_from_Egocentric_Videos_ICCV_2023_paper.pdf",
        "aff": "Stanford University; Stanford University, NVIDIA Research; Stanford University, The University of Hong Kong",
        "project": "https://sites.google.com/stanford.edu/copilot",
        "github": "",
        "arxiv": "2210.01781"
    },
    {
        "title": "CORE: Co-planarity Regularized Monocular Geometry Estimation with Weak Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_CORE_Co-planarity_Regularized_Monocular_Geometry_Estimation_with_Weak_Supervision_ICCV_2023_paper.html",
        "author": "Yuguang Li, Kai Wang, Hui Li, Seon-Min Rhee, Seungju Han, Jihye Kim, Min Yang, Ran Yang, Feng Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CORE_Co-planarity_Regularized_Monocular_Geometry_Estimation_with_Weak_Supervision_ICCV_2023_paper.pdf",
        "aff": "Samsung Advanced Institute of Technology (SAIT), South Korea; Samsung R&D Institute China Xi'an (SRCX)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CORE: Cooperative Reconstruction for Multi-Agent Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CORE_Cooperative_Reconstruction_for_Multi-Agent_Perception_ICCV_2023_paper.html",
        "author": "Binglu Wang, Lei Zhang, Zhaozhong Wang, Yongqiang Zhao, Tianfei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CORE_Cooperative_Reconstruction_for_Multi-Agent_Perception_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of Technology, Computer Vision Lab, ETH Zurich; Northwestern Polytechnical University",
        "project": "",
        "github": "https://github.com/zllxot/CORE",
        "arxiv": "2307.11514"
    },
    {
        "title": "CPCM: Contextual Point Cloud Modeling for Weakly-supervised Point Cloud Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_CPCM_Contextual_Point_Cloud_Modeling_for_Weakly-supervised_Point_Cloud_Semantic_ICCV_2023_paper.html",
        "author": "Lizhao Liu, Zhuangwei Zhuang, Shangxin Huang, Xunlong Xiao, Tianhang Xiang, Cen Chen, Jingdong Wang, Mingkui Tan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CPCM_Contextual_Point_Cloud_Modeling_for_Weakly-supervised_Point_Cloud_Semantic_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology; Baidu Inc.; South China University of Technology, Pazhou Lab",
        "project": "",
        "github": "",
        "arxiv": "2307.10316"
    },
    {
        "title": "CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_CRN_Camera_Radar_Net_for_Accurate_Robust_Efficient_3D_Perception_ICCV_2023_paper.html",
        "author": "Youngseok Kim, Juyeb Shin, Sanmin Kim, In-Jae Lee, Jun Won Choi, Dongsuk Kum",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_CRN_Camera_Radar_Net_for_Accurate_Robust_Efficient_3D_Perception_ICCV_2023_paper.pdf",
        "aff": "Hanyang University; KAIST",
        "project": "",
        "github": "",
        "arxiv": "2304.00670"
    },
    {
        "title": "CROSSFIRE: Camera Relocalization On Self-Supervised Features from an Implicit Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Moreau_CROSSFIRE_Camera_Relocalization_On_Self-Supervised_Features_from_an_Implicit_Representation_ICCV_2023_paper.html",
        "author": "Arthur Moreau, Nathan Piasco, Moussab Bennehar, Dzmitry Tsishkou, Bogdan Stanciulescu, Arnaud de La Fortelle",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Moreau_CROSSFIRE_Camera_Relocalization_On_Self-Supervised_Features_from_an_Implicit_Representation_ICCV_2023_paper.pdf",
        "aff": "Noah\u2019s Ark IoV team, Huawei France; Mines Paris, PSL University, Centre for robotics",
        "project": "",
        "github": "",
        "arxiv": "2303.04869"
    },
    {
        "title": "CSDA: Learning Category-Scale Joint Feature for Domain Adaptive Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.html",
        "author": "Changlong Gao, Chengxu Liu, Yujie Dun, Xueming Qian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Xi\u2019an Jiaotong University, Shaanxi Yulan Jiuzhou Intelligent Optoelectronic Technology Co., Ltd; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CTP:Towards Vision-Language Continual Pretraining via Compatible Momentum Contrast and Topology Preservation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_CTPTowards_Vision-Language_Continual_Pretraining_via_Compatible_Momentum_Contrast_and_Topology_ICCV_2023_paper.html",
        "author": "Hongguang Zhu, Yunchao Wei, Xiaodan Liang, Chunjie Zhang, Yao Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_CTPTowards_Vision-Language_Continual_Pretraining_via_Compatible_Momentum_Contrast_and_Topology_ICCV_2023_paper.pdf",
        "aff": "Institute of Information Science, Beijing Jiaotong University; Beijing Key Laboratory of Advanced Information Science and Network; Peng Cheng Laboratory; Peng Cheng Laboratory; Sun Yat-sen University; MBZUAI; Institute of Information Science, Beijing Jiaotong University; Beijing Key Laboratory of Advanced Information Science and Network",
        "project": "",
        "github": "https://github.com/KevinLight831/CTP",
        "arxiv": "2308.07146"
    },
    {
        "title": "CTVIS: Consistent Training for Online Video Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ying_CTVIS_Consistent_Training_for_Online_Video_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Kaining Ying, Qing Zhong, Weian Mao, Zhenhua Wang, Hao Chen, Lin Yuanbo Wu, Yifan Liu, Chengxiang Fan, Yunzhi Zhuge, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ying_CTVIS_Consistent_Training_for_Online_Video_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "CTVIS: Consistent Training for Online Video Instance Segmentation\nKaining Ying1,2*Qing Zhong4*Weian Mao4Zhenhua Wang3\u2020Hao Chen1\u2020\nLin Yuanbo Wu5Yifan Liu4Chengxiang Fan1Yunzhi Zhuge4Chunhua Shen1\n1Zhejiang University2College of Computer Science and Technology, Zhejiang University of Technology\n3College of Information Engineering, Northwest A&F University\n4The University of Adelaide, Australia5Swansea University, UK\nhttps://github.com/KainingYing/CTVIS\nAbstract\nThe discrimination of instance embeddings plays a vital\nrole in associating instances across time for online video\ninstance segmentation (VIS). Instance embedding learn-\ning is directly supervised by the contrastive loss computed\nupon the contrastive items (CIs), which are sets of an-\nchor/positive/negative embeddings. Recent online VIS meth-\nods leverage CIs sourced from one reference frame only,\nwhich we argue is insufficient for learning highly discrimina-\ntive embeddings. Intuitively, a possible strategy to enhance\nCIs is replicating the inference phase during training. To\nthis end, we propose a simple yet effective training strategy,\ncalled Consistent Training for Online VIS(CTVIS ), which\ndevotes to aligning the training and inference pipelines in\nterms of building CIs. Specifically, CTVIS constructs CIs by\nreferring inference the momentum-averaged embedding and\nthe memory bank storage mechanisms, and adding noise to\nthe relevant embeddings. Such an extension allows a reliable\ncomparison between embeddings of current instances and\nthe stable representations of historical instances, thereby\nconferring an advantage in modeling VIS challenges such as\nocclusion, re-identification, and deformation. Empirically,\nCTVIS outstrips the SOTA VIS models by up to +5.0 points\non three VIS benchmarks, including YTVIS19 (55.1% AP),\nYTVIS21 (50.1% AP) and OVIS (35.5% AP). Furthermore,\nwe find that pseudo-videos transformed from images can\ntrain robust models surpassing fully-supervised ones.\n1. Introduction\nVideo instance segmentation is a joint vision task involv-\ning classifying, segmenting, and tracking interested instances\n*KY (email: kaining .ying .cv@gmail .com) and QZ contributed\nequally to this work. This work was done when KY , QZ, WM, YZ were\nvisiting Zhejiang University.\n\u2020Correponding authors.\nKey Ref.\nMemory Bank(a) Previous (e.g. ,IDOL)\n(b) CTVIS (Ours)Training\nMemory Bank\nFrame\nUpdate Build CIAssociationInference\nUpdate with NoiseFigure 1. Comparison of inconsistent and consistent training (Ours).\n(a) Previous methods typically build contrastive items (CIs) and su-\npervise the instance embeddings between key and reference frames.\nWe call this paradigm inconsistent training, where the interaction\nwith the long-term memory bank during training and the lack of\nmodeling for long video in real inference scenarios is overlooked.\n(b) The purpose of CTVIS is to align the training and inference\npipelines. Specifically, CTVIS constructs training stage CIs by\nleveraging the memory bank and incorporates noise during the\nmemory bank updating to simulate real-world scenarios, such as\nID switching, that can occur during inference.\nacross videos [27]. It is critical in many video-based applica-\ntions, such as video surveillance, video editing, autonomous\ndriving, augmented reality, etc. Current mainstream VIS\nmethods [4,11 \u201313,15,24 \u201328] can be categorized into offline\nand online groups. The former [4, 11, 13, 24, 25] segments\nand classifies all video frames simultaneously and makes the\ninstance association in a single step. The latter [12, 26 \u201328]\ntakes as input a video in a frame-by-frame fashion, detecting\nand segmenting objects per frame while associating instances\nacross time. In this paper, we focus on the online branch.\nOnline methods are typically built upon image-level in-\nstance segmentation models [5, 8, 22, 34, 35]. Several works\n[17, 21, 27] utilize convolution-based instance segmentation\nmodels to segment each frame and associate instances by\nincorporating heuristic clues, such as mask-overlapping ra-\ntios and the similarity of appearance. However, these hand-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n899\n",
        "project": "",
        "github": "",
        "arxiv": "2307.12616"
    },
    {
        "title": "CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_CVRecon_Rethinking_3D_Geometric_Feature_Learning_For_Neural_Reconstruction_ICCV_2023_paper.html",
        "author": "Ziyue Feng, Liang Yang, Pengsheng Guo, Bing Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_CVRecon_Rethinking_3D_Geometric_Feature_Learning_For_Neural_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "City University of New York; Clemson University; Carnegie Mellon University",
        "project": "https://cvrecon.ziyue.cool",
        "github": "",
        "arxiv": "2304.14633"
    },
    {
        "title": "CVSformer: Cross-View Synthesis Transformer for Semantic Scene Completion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_CVSformer_Cross-View_Synthesis_Transformer_for_Semantic_Scene_Completion_ICCV_2023_paper.html",
        "author": "Haotian Dong, Enhui Ma, Lubo Wang, Miaohui Wang, Wuyuan Xie, Qing Guo, Ping Li, Lingyu Liang, Kairui Yang, Di Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_CVSformer_Cross-View_Synthesis_Transformer_for_Semantic_Scene_Completion_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong Polytechnic University; Tianjin University; Alibaba Damo Academy; IHPC and CFAR, Agency for Science, Technology and Research, Singapore; Shenzhen University; Pazhou Lab, South China University of Technology",
        "project": "",
        "github": "https://github.com/donghaotian123/CVSformer",
        "arxiv": "2307.07938"
    },
    {
        "title": "CaPhy: Capturing Physical Properties for Animatable Human Avatars",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Su_CaPhy_Capturing_Physical_Properties_for_Animatable_Human_Avatars_ICCV_2023_paper.html",
        "author": "Zhaoqi Su, Liangxiao Hu, Siyou Lin, Hongwen Zhang, Shengping Zhang, Justus Thies, Yebin Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Su_CaPhy_Capturing_Physical_Properties_for_Animatable_Human_Avatars_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00a8ubingen, Germany; Tsinghua University, Beijing, China; Harbin Institute of Technology, Weihai, Shandong, China",
        "project": "",
        "github": "",
        "arxiv": "2308.05925"
    },
    {
        "title": "Calibrating Panoramic Depth Estimation for Practical Localization and Mapping",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_paper.html",
        "author": "Junho Kim, Eun Sun Lee, Young Min Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_paper.pdf",
        "aff": "Dept. of Electrical and Computer Engineering, Seoul National University and Interdisciplinary Program in Artificial Intelligence and INMC, Seoul National University; Dept. of Electrical and Computer Engineering, Seoul National University",
        "project": "",
        "github": "",
        "arxiv": "2308.14005"
    },
    {
        "title": "Calibrating Uncertainty for Semi-Supervised Crowd Counting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/LI_Calibrating_Uncertainty_for_Semi-Supervised_Crowd_Counting_ICCV_2023_paper.html",
        "author": "Chen LI, Xiaoling Hu, Shahira Abousamra, Chao Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/LI_Calibrating_Uncertainty_for_Semi-Supervised_Crowd_Counting_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n16731\n",
        "project": "",
        "github": "",
        "arxiv": "2308.09887"
    },
    {
        "title": "Camera-Driven Representation Learning for Unsupervised Domain Adaptive Person Re-identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Camera-Driven_Representation_Learning_for_Unsupervised_Domain_Adaptive_Person_Re-identification_ICCV_2023_paper.html",
        "author": "Geon Lee, Sanghoon Lee, Dohyung Kim, Younghoon Shin, Yongsang Yoon, Bumsub Ham",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Camera-Driven_Representation_Learning_for_Unsupervised_Domain_Adaptive_Person_Re-identification_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; Robotics Lab, Hyundai Motor Company",
        "project": "https://cvlab.yonsei.ac.kr/projects/CaCL",
        "github": "",
        "arxiv": "2308.11901"
    },
    {
        "title": "Can Language Models Learn to Listen?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ng_Can_Language_Models_Learn_to_Listen_ICCV_2023_paper.html",
        "author": "Evonne Ng, Sanjay Subramanian, Dan Klein, Angjoo Kanazawa, Trevor Darrell, Shiry Ginosar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ng_Can_Language_Models_Learn_to_Listen_ICCV_2023_paper.pdf",
        "aff": "University of California Berkeley",
        "project": "https://youtu.be/djpSOhdIU8M",
        "github": "",
        "arxiv": "2308.10897"
    },
    {
        "title": "CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_CancerUniT_Towards_a_Single_Unified_Model_for_Effective_Detection_Segmentation_ICCV_2023_paper.html",
        "author": "Jieneng Chen, Yingda Xia, Jiawen Yao, Ke Yan, Jianpeng Zhang, Le Lu, Fakai Wang, Bo Zhou, Mingyan Qiu, Qihang Yu, Mingze Yuan, Wei Fang, Yuxing Tang, Minfeng Xu, Jian Zhou, Yuqian Zhao, Qifeng Wang, Xianghua Ye, Xiaoli Yin, Yu Shi, Xin Chen, Jingren Zhou, Alan Yuille, Zaiyi Liu, Ling Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CancerUniT_Towards_a_Single_Unified_Model_for_Effective_Detection_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Guangdong Provincial People\u2019s Hospital; Hupan Lab, 310023, Hangzhou, China; Johns Hopkins University; Shengjing Hospital of China Medical University; DAMO Academy, Alibaba Group; The First Affiliated Hospital of Zhejiang University; Guangdong Key Laboratory of Artificial Intelligence in Medical Image Analysis and Application; Sun Yat-sen University Cancer Center; Sichuan Cancer Hospital",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Candidate-aware Selective Disambiguation Based On Normalized Entropy for Instance-dependent Partial-label Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Candidate-aware_Selective_Disambiguation_Based_On_Normalized_Entropy_for_Instance-dependent_Partial-label_ICCV_2023_paper.html",
        "author": "Shuo He, Guowu Yang, Lei Feng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Candidate-aware_Selective_Disambiguation_Based_On_Normalized_Entropy_for_Instance-dependent_Partial-label_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; Nanyang Technological University, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Canonical Factors for Hybrid Neural Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Canonical_Factors_for_Hybrid_Neural_Fields_ICCV_2023_paper.html",
        "author": "Brent Yi, Weijia Zeng, Sam Buchanan, Yi Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Canonical_Factors_for_Hybrid_Neural_Fields_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; TTI-Chicago",
        "project": "",
        "github": "",
        "arxiv": "2308.15461"
    },
    {
        "title": "Cascade-DETR: Delving into High-Quality Universal Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Cascade-DETR_Delving_into_High-Quality_Universal_Object_Detection_ICCV_2023_paper.html",
        "author": "Mingqiao Ye, Lei Ke, Siyuan Li, Yu-Wing Tai, Chi-Keung Tang, Martin Danelljan, Fisher Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Cascade-DETR_Delving_into_High-Quality_Universal_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "HKUST; Dartmouth College; ETH Z\u00fcrich; ETH Z\u00fcrich, HKUST",
        "project": "",
        "github": "https://github.com/SysCV/cascade-detr",
        "arxiv": ""
    },
    {
        "title": "Category-aware Allocation Transformer for Weakly Supervised Object Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Category-aware_Allocation_Transformer_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html",
        "author": "Zhiwei Chen, Jinren Ding, Liujuan Cao, Yunhang Shen, Shengchuan Zhang, Guannan Jiang, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Category-aware_Allocation_Transformer_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf",
        "aff": "CATL, China; Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University, China; Tencent Youtu Lab, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CauSSL: Causality-inspired Semi-supervised Learning for Medical Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.html",
        "author": "Juzheng Miao, Cheng Chen, Furui Liu, Hao Wei, Pheng-Ann Heng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Institute of Medical Intelligence and XR, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Zhejiang Lab; Department of Biomedical Engineering, The Chinese University of Hong Kong; Center for Advanced Medical Computing and Analysis, Harvard Medical School and Massachusetts General Hospital",
        "project": "",
        "github": "https://github.com/JuzhengMiao/CauSSL",
        "arxiv": ""
    },
    {
        "title": "Causal-DFQ: Causality Guided Data-Free Network Quantization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shang_Causal-DFQ_Causality_Guided_Data-Free_Network_Quantization_ICCV_2023_paper.html",
        "author": "Yuzhang Shang, Bingxin Xu, Gaowen Liu, Ramana Rao Kompella, Yan Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shang_Causal-DFQ_Causality_Guided_Data-Free_Network_Quantization_ICCV_2023_paper.pdf",
        "aff": "Cisco Research; Illinois Institute of Technology",
        "project": "",
        "github": "Causal-DFQ",
        "arxiv": ""
    },
    {
        "title": "Center-Based Decoupled Point-cloud Registration for 6D Object Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Center-Based_Decoupled_Point-cloud_Registration_for_6D_Object_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Haobo Jiang, Zheng Dang, Shuo Gu, Jin Xie, Mathieu Salzmann, Jian Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Center-Based_Decoupled_Point-cloud_Registration_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "CVLab, EPFL, Switzerland; PCA Lab, Nanjing University of Science and Technology, China",
        "project": "",
        "github": "https://github.com/Jiang-HB/CenterReg",
        "arxiv": ""
    },
    {
        "title": "Chaotic World: A Large and Challenging Benchmark for Human Behavior Understanding in Chaotic Events",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ong_Chaotic_World_A_Large_and_Challenging_Benchmark_for_Human_Behavior_ICCV_2023_paper.html",
        "author": "Kian Eng Ong, Xun Long Ng, Yanchao Li, Wenjie Ai, Kuangyi Zhao, Si Yong Yeo, Jun Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ong_Chaotic_World_A_Large_and_Challenging_Benchmark_for_Human_Behavior_ICCV_2023_paper.pdf",
        "aff": "Information Systems Technology and Design, Singapore University of Technology and Design, Singapore; Information Systems Technology and Design, Singapore University of Technology and Design, Singapore; Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore",
        "project": "",
        "github": "https://github.com/sutdcv/Chaotic-World",
        "arxiv": ""
    },
    {
        "title": "ChartReader: A Unified Framework for Chart Derendering and Comprehension without Heuristic Rules",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_ChartReader_A_Unified_Framework_for_Chart_Derendering_and_Comprehension_without_ICCV_2023_paper.html",
        "author": "Zhi-Qi Cheng, Qi Dai, Alexander G. Hauptmann",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_ChartReader_A_Unified_Framework_for_Chart_Derendering_and_Comprehension_without_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; Language Technologies Institute, Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/zhiqic/ChartReader",
        "arxiv": "2304.02173"
    },
    {
        "title": "Chasing Clouds: Differentiable Volumetric Rasterisation of Point Clouds as a Highly Efficient and Accurate Loss for Large-Scale Deformable 3D Registration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Heinrich_Chasing_Clouds_Differentiable_Volumetric_Rasterisation_of_Point_Clouds_as_a_ICCV_2023_paper.html",
        "author": "Mattias P. Heinrich, Alexander Bigalke, Christoph Gro\u00dfbr\u00f6hmer, Lasse Hansen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Heinrich_Chasing_Clouds_Differentiable_Volumetric_Rasterisation_of_Point_Clouds_as_a_ICCV_2023_paper.pdf",
        "aff": "EchoScout GmbH Germany; Institute of Medical Informatics, University of L\u00fcbeck",
        "project": "",
        "github": "https://github.com/mattiaspaul/ChasingClouds",
        "arxiv": ""
    },
    {
        "title": "CheckerPose: Progressive Dense Keypoint Localization for Object Pose Estimation with Graph Neural Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lian_CheckerPose_Progressive_Dense_Keypoint_Localization_for_Object_Pose_Estimation_with_ICCV_2023_paper.html",
        "author": "Ruyi Lian, Haibin Ling",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lian_CheckerPose_Progressive_Dense_Keypoint_Localization_for_Object_Pose_Estimation_with_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Stony Brook University, Stony Brook, NY 11794-2424, USA",
        "project": "",
        "github": "https://github.com/RuyiLian/CheckerPose",
        "arxiv": "2303.16874"
    },
    {
        "title": "ChildPlay: A New Benchmark for Understanding Children's Gaze Behaviour",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tafasca_ChildPlay_A_New_Benchmark_for_Understanding_Childrens_Gaze_Behaviour_ICCV_2023_paper.html",
        "author": "Samy Tafasca, Anshul Gupta, Jean-Marc Odobez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tafasca_ChildPlay_A_New_Benchmark_for_Understanding_Childrens_Gaze_Behaviour_ICCV_2023_paper.pdf",
        "aff": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Idiap Research Institute, Martigny, Switzerland",
        "project": "https://www.idiap.ch/en/dataset/childplay-gaze",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through Image-IDS Aligning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_paper.html",
        "author": "Haiyang Yu, Xiaocong Wang, Bin Li, Xiangyang Xue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_paper.pdf",
        "aff": "Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University",
        "project": "",
        "github": "https://github.com/FudanVI/FudanOCR/tree/main/image-ids-CTR",
        "arxiv": "2309.01083"
    },
    {
        "title": "Chop & Learn: Recognizing and Generating Object-State Compositions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Saini_Chop__Learn_Recognizing_and_Generating_Object-State_Compositions_ICCV_2023_paper.html",
        "author": "Nirat Saini, Hanyu Wang, Archana Swaminathan, Vinoj Jayasundara, Bo He, Kamal Gupta, Abhinav Shrivastava",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Saini_Chop__Learn_Recognizing_and_Generating_Object-State_Compositions_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park",
        "project": "https://chopnlearn.github.io",
        "github": "",
        "arxiv": "2309.14339"
    },
    {
        "title": "Chordal Averaging on Flag Manifolds and Its Applications",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mankovich_Chordal_Averaging_on_Flag_Manifolds_and_Its_Applications_ICCV_2023_paper.html",
        "author": "Nathan Mankovich, Tolga Birdal",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mankovich_Chordal_Averaging_on_Flag_Manifolds_and_Its_Applications_ICCV_2023_paper.pdf",
        "aff": "Colorado State University; Imperial College London",
        "project": "",
        "github": "",
        "arxiv": "2303.13501"
    },
    {
        "title": "Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Chupa_Carving_3D_Clothed_Humans_from_Skinned_Shape_Priors_using_ICCV_2023_paper.html",
        "author": "Byungjun Kim, Patrick Kwon, Kwangho Lee, Myunggi Lee, Sookwan Han, Daesik Kim, Hanbyul Joo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Chupa_Carving_3D_Clothed_Humans_from_Skinned_Shape_Priors_using_ICCV_2023_paper.pdf",
        "aff": "Seoul National University; Naver Webtoon AI",
        "project": "https://snuvclab.github.io/chupa/",
        "github": "",
        "arxiv": "2305.11870"
    },
    {
        "title": "CiT: Curation in Training for Effective Vision-Language Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_CiT_Curation_in_Training_for_Effective_Vision-Language_Data_ICCV_2023_paper.html",
        "author": "Hu Xu, Saining Xie, Po-Yao Huang, Licheng Yu, Russell Howes, Gargi Ghosh, Luke Zettlemoyer, Christoph Feichtenhofer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_CiT_Curation_in_Training_for_Effective_Vision-Language_Data_ICCV_2023_paper.pdf",
        "aff": "Meta AI, FAIR",
        "project": "",
        "github": "https://github.com/facebookresearch/CiT",
        "arxiv": "2301.02241"
    },
    {
        "title": "CiteTracker: Correlating Image and Text for Visual Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.html",
        "author": "Xin Li, Yuqing Huang, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.pdf",
        "aff": "UC Merced and Yonsei University; Dalian University of Technology; Harbin Institute of Technology, Shenzhen; Peng Cheng Laboratory",
        "project": "",
        "github": "https://github.com/NorahGreen/CiteTracker",
        "arxiv": "2308.11322"
    },
    {
        "title": "Class Prior-Free Positive-Unlabeled Learning with Taylor Variational Loss for Hyperspectral Remote Sensing Imagery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Class_Prior-Free_Positive-Unlabeled_Learning_with_Taylor_Variational_Loss_for_Hyperspectral_ICCV_2023_paper.html",
        "author": "Hengwei Zhao, Xinyu Wang, Jingtao Li, Yanfei Zhong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Class_Prior-Free_Positive-Unlabeled_Learning_with_Taylor_Variational_Loss_for_Hyperspectral_ICCV_2023_paper.pdf",
        "aff": "Wuhan University, Wuhan, China",
        "project": "",
        "github": "https://github.com/Hengwei-Zhao96/T-HOneCls",
        "arxiv": "2308.15081"
    },
    {
        "title": "Class-Aware Patch Embedding Adaptation for Few-Shot Image Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.html",
        "author": "Fusheng Hao, Fengxiang He, Liu Liu, Fuxiang Wu, Dacheng Tao, Jun Cheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.pdf",
        "aff": "Class-Aware Patch Embedding Adaptation for Few-Shot Image Classification\nFusheng Hao1,2Fengxiang He3Liu Liu4Fuxiang Wu1,2Dacheng Tao4Jun Cheng1,2*\n1Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems,\nShenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China\n2The Chinese University of Hong Kong, Hong Kong, China\n3AIAI, School of Informatics, University of Edinburgh, United Kingdom\n4School of Computer Science, Faculty of Engineering, The University of Sydney, Australia\nAbstract\n\u201cA picture is worth a thousand words\u201d, significantly be-\nyond mere a categorization. Accompanied by that, many\npatches of the image could have completely irrelevant\nmeanings with the categorization if they were indepen-\ndently observed. This could significantly reduce the effi-\nciency of a large family of few-shot learning algorithms,\nwhich have limited data and highly rely on the compari-\nson of image patches. To address this issue, we propose a\nClass-aware Patch Embedding Adaptation (CPEA) method\nto learn \u201cclass-aware embeddings\u201d of the image patches.\nThe key idea of CPEA is to integrate patch embeddings with\nclass-aware embeddings to make them class-relevant. Fur-\nthermore, we define a dense score matrix between class-\nrelevant patch embeddings across images, based on which\nthe degree of similarity between paired images is quantified.\nVisualization results show that CPEA concentrates patch\nembeddings by class, thus making them class-relevant.\nExtensive experiments on four benchmark datasets, mini-\nImageNet, tieredImageNet, CIFAR-FS, and FC-100, indi-\ncate that our CPEA significantly outperforms the existing\nstate-of-the-art methods. The source code is available at\nhttps://github.com/FushengHao/CPEA .\n1. Introduction\nReal-world images are usually composed of many dif-\nferent entities, e.g., two oxen grazing surrounded by a barn,\na fence and trees as shown in Figure 1. Assigning a sin-\ngle annotation to each image that corresponds to only one\ntype of entity is a common practice to construct computer\nvision datasets, e.g., CIFAR [33] and ImageNet [54]. Such\nan annotation can only describe part of an image\u2019 contents.\nThis is acceptable in many classification scenarios, because\nthe interference caused by other image contents can be mit-\n*Corresponding author (email: jun.cheng@siat.ac.cn).\nFigure 1. Illustration of multiple entities from different classes si-\nmultaneously existing in a real-world image. Despite being anno-\ntated as \u201cox\u201d, the image contains entities of other classes, such as\n\u201cfence\u201d, \u201cbarn\u201d, \u201ctree\u201d, etc. The core idea of CPEA is to learn\n\u201cclass-aware embeddings\u201d of the image patches.\nigated by the use of a large number of labeled images.\nSpecifically, since each class contains a sufficient number\nof labeled images that vary greatly within the class and the\ncorresponding entities always appear in these images, deep\nmodels trained on such data tend to pay attention to the fre-\nquently occurring class-relevant entities ( e.g., \u201cox\u201d in Fig-\nure 1) while ignoring other irrelevant ones, especially those\nthat frequently appear across classes [26].\nBig challenges, however, arise in the context of few-shot\nimage classification, in which approaches are expected to\ncorrectly identify new classes that are disjoint with the train-\ning classes during the test phase, given only a few ( e.g., one\nor five) labeled images for each of these new classes. The\nchallenges are as follows: 1) Due to the scarcity of labeled\nimages of new classes and the extremely limited number\nof class-relevant entities, it is very difficult for a model to\nidentify which entity determines the class of an image. 2)\nEntities contained in the training images but not covered by\nthe training classes may happen to be the ones expected to\nbe covered by the new classes at test time, which would in-\ntroduce ambiguity. 3) Specific patterns learned during the\ntraining phase may be overemphasized, but they may not\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n18905\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Class-Incremental Grouping Network for Continual Audio-Visual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mo_Class-Incremental_Grouping_Network_for_Continual_Audio-Visual_Learning_ICCV_2023_paper.html",
        "author": "Shentong Mo, Weiguo Pian, Yapeng Tian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mo_Class-Incremental_Grouping_Network_for_Continual_Audio-Visual_Learning_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University; University of Texas at Dallas",
        "project": "",
        "github": "https://github.com/stoneMo/CIGN",
        "arxiv": "2309.05281"
    },
    {
        "title": "Class-incremental Continual Learning for Instance Segmentation with Image-level Weak Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hsieh_Class-incremental_Continual_Learning_for_Instance_Segmentation_with_Image-level_Weak_Supervision_ICCV_2023_paper.html",
        "author": "Yu-Hsing Hsieh, Guan-Sheng Chen, Shun-Xian Cai, Ting-Yun Wei, Huei-Fang Yang, Chu-Song Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hsieh_Class-incremental_Continual_Learning_for_Instance_Segmentation_with_Image-level_Weak_Supervision_ICCV_2023_paper.pdf",
        "aff": "Dept. Information Management, National Sun Yat-sen University, Taiwan; Dept. Computer Science and Information Engineering, National Taiwan University, Taiwan",
        "project": "",
        "github": "https://github.com/AI-Application-and-Integration-Lab/CL4WSIS",
        "arxiv": ""
    },
    {
        "title": "Class-relation Knowledge Distillation for Novel Class Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Class-relation_Knowledge_Distillation_for_Novel_Class_Discovery_ICCV_2023_paper.html",
        "author": "Peiyan Gu, Chuyu Zhang, Ruijie Xu, Xuming He",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Class-relation_Knowledge_Distillation_for_Novel_Class_Discovery_ICCV_2023_paper.pdf",
        "aff": "ShanghaiTech University, Shanghai, China; ShanghaiTech University, Shanghai, China; Lingang Laboratory, Shanghai, China; ShanghaiTech University, Shanghai, China; Shanghai Engineering Research Center of Intelligent Vision and Imaging, Shanghai, China",
        "project": "",
        "github": "https://github.com/here",
        "arxiv": "2307.09158"
    },
    {
        "title": "CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bansal_CleanCLIP_Mitigating_Data_Poisoning_Attacks_in_Multimodal_Contrastive_Learning_ICCV_2023_paper.html",
        "author": "Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bansal_CleanCLIP_Mitigating_Data_Poisoning_Attacks_in_Multimodal_Contrastive_Learning_ICCV_2023_paper.pdf",
        "aff": "UCLA; University of T\u00fcbingen",
        "project": "",
        "github": "https://github.com/nishadsinghi/CleanCLIP",
        "arxiv": "2303.03323"
    },
    {
        "title": "ClimateNeRF: Extreme Weather Synthesis in Neural Radiance Field",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_ClimateNeRF_Extreme_Weather_Synthesis_in_Neural_Radiance_Field_ICCV_2023_paper.html",
        "author": "Yuan Li, Zhi-Hao Lin, David Forsyth, Jia-Bin Huang, Shenlong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_ClimateNeRF_Extreme_Weather_Synthesis_in_Neural_Radiance_Field_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2211.13226"
    },
    {
        "title": "Cloth2Body: Generating 3D Human Body Mesh from 2D Clothing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dai_Cloth2Body_Generating_3D_Human_Body_Mesh_from_2D_Clothing_ICCV_2023_paper.html",
        "author": "Lu Dai, Liqian Ma, Shenhan Qian, Hao Liu, Ziwei Liu, Hui Xiong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_Cloth2Body_Generating_3D_Human_Body_Mesh_from_2D_Clothing_ICCV_2023_paper.pdf",
        "aff": "Cloth2Body: Generating 3D Human Body Mesh from 2D Clothing\nLu Dai1,2\u2217, Liqian Ma2\u2020, Shenhan Qian3, Hao Liu1, Ziwei Liu4\u2020, Hui Xiong1\u2020\n1The Hong Kong University of Science and Technology (Guangzhou)\n2ZMO AI Inc.\n3Technical University of Munich\n4S-Lab, Nanyang Technological University\nldaiae@connect.ust.hk liqianma.scholar.outlook.com shenhan.qian@tum.de\nziwei.liu@ntu.edu.sg {liuh,xionghui }@ust.hk\nFigure 1: In our Cloth2Body problem, our model takes a 2D clothing image as input and produces 3D human body of various poses, which can fit\ninto the cloth pixel-wise when rendered back to the image plane, as shown in (a),(b) and (c). This framework also allows users to manipulate body\nfigure within cloth size constraints. (c\u2032) is a shape variation from (c) but still in the same clothing and pose. (c\u2032\u2032) is an application of our methods\nwhere a stable diffusion module consumes our output and generates human image.\nAbstract\nIn this paper, we define and study a new Cloth2Body\nproblem which has a goal of generating 3d human body\nmeshes from a 2D clothing image. Unlike the existing\nhuman mesh recovery problem, Cloth2Body needs to ad-\ndress new and emerging challenges raised by the partial\nobservation of the input and the high diversity of the out-\nput. Indeed, there are three specific challenges. First, how\nto locate and pose human bodies into the clothes. Sec-\nond, how to effectively estimate body shapes out of vari-\nous clothing types. Finally, how to generate diverse and\nplausible results from a 2D clothing image. To this end,\nwe propose an end-to-end framework that can accurately\nestimate 3D body mesh parameterized by pose and shape\nfrom a 2D clothing image. Along this line, we first utilize\nKinematics-aware Pose Estimation to estimate body pose\nparameters. 3D skeleton is employed as a proxy followed\n*Work partially conducted during an internship at ZMO AI Inc.\n\u2020Corresponding authorby an inverse kinematics module to boost the estimation\naccuracy. We additionally design an adaptive depth trick\nto align the re-projected 3D mesh better with 2D clothing\nimage by disentangling the effects of object size and cam-\nera extrinsic. Next, we propose Physics-informed Shape\nEstimation to estimate body shape parameters. 3D shape\nparameters are predicted based on partial body measure-\nments estimated from RGB image, which not only improves\npixel-wise human-cloth alignment, but also enables flexi-\nble user editing. Finally, we design Evolution-based pose\ngeneration method , a skeleton transplanting method in-\nspired by genetic algorithms to generate diverse reasonable\nposes during inference. As shown by experimental results\non both synthetic and real-world data, the proposed frame-\nwork achieves state-of-the-art performance and can effec-\ntively recover natural and diverse 3D body meshes from 2D\nimages that align well with clothing.\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n15007\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.html",
        "author": "Wenqiang Xu, Wenxin Du, Han Xue, Yutong Li, Ruolin Ye, Yan-Feng Wang, Cewu Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf",
        "aff": "3Cornell University; 1Shanghai Jiao Tong University; 1Shanghai Jiao Tong University, 2Shanghai Qi Zhi institute",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ClothesNet: An Information-Rich 3D Garment Model Repository with Simulated Clothes Environment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_ClothesNet_An_Information-Rich_3D_Garment_Model_Repository_with_Simulated_Clothes_ICCV_2023_paper.html",
        "author": "Bingyang Zhou, Haoyu Zhou, Tianhai Liang, Qiaojun Yu, Siheng Zhao, Yuwei Zeng, Jun Lv, Siyuan Luo, Qiancai Wang, Xinyuan Yu, Haonan Chen, Cewu Lu, Lin Shao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ClothesNet_An_Information-Rich_3D_Garment_Model_Repository_with_Simulated_Clothes_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore; Shanghai Jiao Tong University; Beihang University; Xi\u2019an Jiaotong University; Nanjing University; Harbin Institute of Technology, Shenzhen",
        "project": "https://sites.google.com/view/clothesnet",
        "github": "",
        "arxiv": "2308.09987"
    },
    {
        "title": "ClusT3: Information Invariant Test-Time Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hakim_ClusT3_Information_Invariant_Test-Time_Training_ICCV_2023_paper.html",
        "author": "Gustavo A. Vargas Hakim, David Osowiechi, Mehrdad Noori, Milad Cheraghalikhani, Ali Bahri, Ismail Ben Ayed, Christian Desrosiers",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hakim_ClusT3_Information_Invariant_Test-Time_Training_ICCV_2023_paper.pdf",
        "aff": "ETS Montreal, Canada",
        "project": "",
        "github": "https://github.com/dosowiechi/ClusT3.git",
        "arxiv": ""
    },
    {
        "title": "Clusterformer: Cluster-based Transformer for 3D Object Detection in Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pei_Clusterformer_Cluster-based_Transformer_for_3D_Object_Detection_in_Point_Clouds_ICCV_2023_paper.html",
        "author": "Yu Pei, Xian Zhao, Hao Li, Jingyuan Ma, Jingwei Zhang, Shiliang Pu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pei_Clusterformer_Cluster-based_Transformer_for_3D_Object_Detection_in_Point_Clouds_ICCV_2023_paper.pdf",
        "aff": "HikVision Research Institute",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Clustering based Point Cloud Representation Learning for 3D Analysis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Clustering_based_Point_Cloud_Representation_Learning_for_3D_Analysis_ICCV_2023_paper.html",
        "author": "Tuo Feng, Wenguan Wang, Xiaohan Wang, Yi Yang, Qinghua Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Clustering_based_Point_Cloud_Representation_Learning_for_3D_Analysis_ICCV_2023_paper.pdf",
        "aff": "ReLER, AAII, University of Technology Sydney; ReLER, CCAI, Zhejiang University; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "https://github.com/FengZicai/Cluster3Dseg/",
        "arxiv": "2307.14605"
    },
    {
        "title": "Clutter Detection and Removal in 3D Scenes with View-Consistent Inpainting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Clutter_Detection_and_Removal_in_3D_Scenes_with_View-Consistent_Inpainting_ICCV_2023_paper.html",
        "author": "Fangyin Wei, Thomas Funkhouser, Szymon Rusinkiewicz",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Clutter_Detection_and_Removal_in_3D_Scenes_with_View-Consistent_Inpainting_ICCV_2023_paper.pdf",
        "aff": "Princeton University",
        "project": "https://weify627.github.io/clutter/",
        "github": "",
        "arxiv": "2304.03763"
    },
    {
        "title": "Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/You_Co-Evolution_of_Pose_and_Mesh_for_3D_Human_Body_Estimation_ICCV_2023_paper.html",
        "author": "Yingxuan You, Hong Liu, Ti Wang, Wenhao Li, Runwei Ding, Xia Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/You_Co-Evolution_of_Pose_and_Mesh_for_3D_Human_Body_Estimation_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, ETH Z\u00fcrich; Key Laboratory of Machine Perception, Shenzhen Graduate School, Peking University",
        "project": "",
        "github": "https://github.com/kasvii/PMCE",
        "arxiv": "2308.10305"
    },
    {
        "title": "CoIn: Contrastive Instance Feature Mining for Outdoor 3D Object Detection with Very Limited Annotations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Qiming Xia, Jinhao Deng, Chenglu Wen, Hai Wu, Shaoshuai Shi, Xin Li, Cheng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Texas A&M University; Max-Planck Institute; Xiamen University",
        "project": "",
        "github": "https://github.com/xmuqimingxia/CoIn",
        "arxiv": ""
    },
    {
        "title": "CoSign: Exploring Co-occurrence Signals in Skeleton-based Continuous Sign Language Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiao_CoSign_Exploring_Co-occurrence_Signals_in_Skeleton-based_Continuous_Sign_Language_Recognition_ICCV_2023_paper.html",
        "author": "Peiqi Jiao, Yuecong Min, Yanan Li, Xiaotao Wang, Lei Lei, Xilin Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiao_CoSign_Exploring_Co-occurrence_Signals_in_Skeleton-based_Continuous_Sign_Language_Recognition_ICCV_2023_paper.pdf",
        "aff": "Xiaomi Inc., China; Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, 100190, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_CoTDet_Affordance_Knowledge_Prompting_for_Task_Driven_Object_Detection_ICCV_2023_paper.html",
        "author": "Jiajin Tang, Ge Zheng, Jingyi Yu, Sibei Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_CoTDet_Affordance_Knowledge_Prompting_for_Task_Driven_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "School of Information Science and Technology, ShanghaiTech University",
        "project": "https://toneyaya.github.io/cotdet",
        "github": "",
        "arxiv": "2309.01093"
    },
    {
        "title": "Coarse-to-Fine Amodal Segmentation with Shape Prior",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Coarse-to-Fine_Amodal_Segmentation_with_Shape_Prior_ICCV_2023_paper.html",
        "author": "Jianxiong Gao, Xuelin Qian, Yikai Wang, Tianjun Xiao, Tong He, Zheng Zhang, Yanwei Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Coarse-to-Fine_Amodal_Segmentation_with_Shape_Prior_ICCV_2023_paper.pdf",
        "aff": "Fudan University; Amazon Web Service",
        "project": "https://jianxgao.github.io/C2F-Seg",
        "github": "",
        "arxiv": "2308.16825"
    },
    {
        "title": "Coarse-to-Fine: Learning Compact Discriminative Representation for Single-Stage Image Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Coarse-to-Fine_Learning_Compact_Discriminative_Representation_for_Single-Stage_Image_Retrieval_ICCV_2023_paper.html",
        "author": "Yunquan Zhu, Xinkai Gao, Bo Ke, Ruizhi Qiao, Xing Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Coarse-to-Fine_Learning_Compact_Discriminative_Representation_for_Single-Stage_Image_Retrieval_ICCV_2023_paper.pdf",
        "aff": "YouTu Lab, Tencent, China",
        "project": "",
        "github": "https://github.com/bassyess/CFCD",
        "arxiv": ""
    },
    {
        "title": "Coherent Event Guided Low-Light Video Enhancement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Coherent_Event_Guided_Low-Light_Video_Enhancement_ICCV_2023_paper.html",
        "author": "Jinxiu Liang, Yixin Yang, Boyu Li, Peiqi Duan, Yong Xu, Boxin Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Coherent_Event_Guided_Low-Light_Video_Enhancement_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, South China University of Technology; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University",
        "project": "https://sherrycattt.github.io/EvLowLight",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CoinSeg: Contrast Inter- and Intra- Class Representations for Incremental Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_CoinSeg_Contrast_Inter-_and_Intra-_Class_Representations_for_Incremental_Segmentation_ICCV_2023_paper.html",
        "author": "Zekang Zhang, Guangyu Gao, Jianbo Jiao, Chi Harold Liu, Yunchao Wei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_CoinSeg_Contrast_Inter-_and_Intra-_Class_Representations_for_Incremental_Segmentation_ICCV_2023_paper.pdf",
        "aff": "/0 /1 /2 /3 /4 /5 /6 /7 /0 /1 /3 /8 /9 /10 /11 /8 /12 /3 /8 /5 /9 /13 /10 /3 /14/12 /3 /8 /9 /10 /13 /0 /15 /10 /11 /11 /16 /5 /17 /9 /5 /11 /5 /3 /8 /10 /8 /2 /1 /3 /11\n/18 /1 /9 /12 /3 /19 /9 /5 /20/5 /3 /8 /10 /15 /4 /5 /6 /20/5 /3 /8 /10 /8 /2 /1 /3\n/21 /22 /23 /24 /25 /26 /21 /27 /24 /25 /26/28 /29/30/31 /32 /24 /25 /26 /33 /32/31 /24 /34/28 /35/30/36 /37 /24 /25 /38 /34/36 /37 /24 /34/39/30/40 /27 /37 /41 /24 /42 /34 /43 /44/45 /37 /32/28/30/46 /32 /25 /47 /27 /24 /34/48 /22 /37/49 /50 /51\n/28/52 /47 /27 /34 /34 /43 /34 /53 /40 /34 /54/55 /32 /56 /22 /42 /52 /47 /37 /22 /25 /47 /22 /30 /57 /22 /37 /58 /37 /25 /26/59 /25 /60 /56 /37 /56 /32 /56 /22 /34 /53 /61 /22 /47 /27 /25 /34 /43 /34 /26 /33\n/39/52 /47 /27 /34 /34 /43 /34 /53 /40 /34 /54/55 /32 /56 /22 /42 /52 /47 /37 /22 /25 /47 /22 /30 /62 /25 /37 /63 /22 /42 /60 /37 /56 /33/34 /53 /57 /37 /42 /54/37 /25 /26 /27 /24 /54\n/49/48/64 /59 /45 /24 /38 /30 /59 /25 /60 /56 /37 /56 /32 /56 /22 /34 /53 /59 /25 /53 /34 /42 /54/24 /56 /37 /34 /25/52 /47 /37 /22 /25 /47 /22 /30 /57 /22 /37 /58 /37 /25 /26/36 /37 /24 /34 /56 /34 /25 /26/62 /25 /37 /63 /22 /42 /60 /37 /56 /33\n/51/57 /22 /37 /58 /37 /25 /26/65 /22 /33/45 /24 /38 /34 /42 /24 /56 /34 /42 /33/34 /53 /66 /44 /63 /24 /25 /47 /22 /44/59 /25 /53 /34 /42 /54/24 /56 /37 /34 /25/52 /47 /37 /22 /25 /47 /22 /24 /25 /44/67 /22 /56 /68 /34 /42 /23\n/69 /70 /69 /71 /72 /73 /74 /75 /76 /76 /77 /78 /79 /80 /81 /82 /79 /79 /70 /83 /84 /79 /85\n/86 /87 /11 /8 /9 /10 /19 /8\n/88 /89 /90 /91 /91 /92 /93 /94 /95 /96 /97 /96 /93 /98 /90 /89 /91 /96 /97 /90 /93 /98 /92 /94 /91 /96 /99 /97 /96 /93 /98 /90 /98 /92 /100 /93 /90 /92 /97 /91 /98 /100 /91 /98 /95 /92 /101 /96\n/90/102 /90 /89 /90 /93 /94 /96/102 /96 /98 /103 /96 /96 /93/98 /104 /96/97 /100 /105 /96 /89 /106 /91 /91 /98 /90 /102 /92 /89 /92 /98 /107/90 /93 /105/108 /89 /90 /91 /98 /92 /94 /92 /98 /107/102 /107\n/97 /90 /92 /93 /98 /90 /92 /93 /92 /93 /99 /100 /89 /105/101 /93 /100 /103 /89 /96 /105 /99 /96 /103 /104 /92 /89 /96 /90 /105 /90 /108 /98 /92 /93 /99/98 /100/93 /96 /103/94 /100 /93 /94 /96 /108 /98 /91 /109\n/110 /100 /103 /96 /111 /96 /95 /112 /97 /100 /91 /98 /91 /98 /90 /98 /96 /113 /100 /114 /113 /98 /104 /96 /113 /90 /95 /98 /97 /96 /98 /104 /100 /105 /91 /115 /91 /96 /98 /104 /96 /114 /95 /96 /96 /116 /96 /91 /98 /95 /90 /98 /113\n/96 /99 /107/114 /100 /95 /91 /98 /90 /102 /92 /89 /92 /98 /107 /112 /103 /104 /92 /94 /104/94 /100 /97 /108 /95 /100 /97 /92 /91 /96 /91 /98 /104 /96/97 /100 /105 /96 /89 /106 /91 /108 /89 /90 /91 /98 /92 /94 /113\n/92 /98 /107 /109 /117 /93/94 /100 /93 /98 /95 /90 /91 /98 /112 /95 /96 /89 /96 /90 /91 /92 /93 /99/108 /90 /95 /90 /97 /96 /98 /96 /95 /98 /95 /90 /92 /93 /92 /93 /99/114 /100 /95 /108 /89 /90 /91 /98 /92 /94 /92 /98 /107\n/94 /100 /115 /89 /105/89 /96 /90 /105/98 /100 /98 /104 /96 /102 /96 /91 /98 /108 /96 /95 /114 /100 /95 /97 /90 /93 /94 /96 /114 /100 /95 /90 /89 /89 /94 /90 /98 /96 /99 /100 /95 /92 /96 /91 /112 /102 /115 /98\n/98 /104 /92 /91 /95 /96 /118 /115 /92 /95 /96 /91 /105 /92 /91 /94 /95 /92 /97 /92 /93 /90 /98 /92 /111 /96 /114 /96 /90 /98 /115 /95 /96 /95 /96 /108 /95 /96 /91 /96 /93 /98 /90 /98 /92 /100 /93 /109 /119 /104 /96 /95 /96 /113\n/114 /100 /95 /96 /112 /103 /96/108 /95 /92 /100 /95 /92 /98 /92 /116 /96/98 /104 /96/97 /100 /105 /96 /89 /106 /91 /108 /89 /90 /91 /98 /92 /94 /92 /98 /107/90 /93 /105/108 /95 /100 /108 /100 /91 /96/98 /104 /96\n/120 /121 /93 /98 /95 /90 /91 /98 /122 /123 /98 /96 /95 /113 /90 /93 /105 /122 /123 /98 /95 /90 /113 /94 /89 /90 /91 /91 /95 /96 /108 /95 /96 /91 /96 /93 /98 /90 /98 /92 /100 /93 /91 /114 /100 /95 /117 /93 /94 /95 /96 /97 /96 /93 /113\n/98 /90 /89 /124 /125 /126 /97 /96 /93 /98 /90 /98 /92 /100 /93 /127 /120 /121 /122 /123 /124 /125 /126 /128 /112 /103 /104 /92 /94 /104 /108 /115 /95 /91 /115 /96 /91 /105 /92 /91 /94 /95 /92 /97 /92 /93 /90 /98 /92 /111 /96\n/95 /96 /108 /95 /96 /91 /96 /93 /98 /90 /98 /92 /100 /93 /91 /114 /100 /95 /129 /96 /130 /92 /102 /89 /96 /108 /90 /95 /90 /97 /96 /98 /96 /95 /98 /115 /93 /92 /93 /99 /109 /117 /93 /91 /108 /92 /95 /96 /105 /102 /107 /98 /104 /96\n/131 /90 /115 /91 /91 /92 /90 /93 /97 /92 /130 /98 /115 /95 /96 /97 /100 /105 /96 /89 /98 /104 /90 /98 /91 /90 /97 /108 /89 /96 /91 /114 /95 /100 /97/90 /97 /92 /130 /98 /115 /95 /96 /100 /114 /131 /90 /115 /91 /113\n/91 /92 /90 /93/105 /92 /91 /98 /95 /92 /102 /115 /98 /92 /100 /93 /91 /112 /88 /100 /92 /93 /132 /96 /99/96 /97 /108 /104 /90 /91 /92 /116 /96 /91 /92 /93 /98 /95 /90 /113 /94 /89 /90 /91 /91 /105 /92 /111 /96 /95 /91 /92 /98 /107\n/103 /92 /98 /104 /97 /115 /89 /98 /92 /108 /89 /96 /94 /100 /93 /98 /95 /90 /91 /98 /92 /111 /96 /95 /96 /108 /95 /96 /91 /96 /93 /98 /90 /98 /92 /100 /93 /94 /96 /93 /98 /95 /100 /92 /105 /91 /109 /132 /108 /96 /94 /92 /133 /113\n/94 /90 /89 /89 /107 /112 /103 /96 /115 /91 /96 /97 /90 /91 /101 /108 /95 /100 /108 /100 /91 /90 /89 /91 /98 /100 /92 /105 /96 /93 /98 /92 /114 /107 /95 /96 /99 /92 /100 /93 /91 /103 /92 /98 /104 /91 /98 /95 /100 /93 /99\n/100 /102 /134 /96 /94 /98 /93 /96 /91 /91 /98 /104 /90 /98 /90 /95 /96 /89 /92 /101 /96 /89 /107 /98 /100/102 /96 /105 /92 /111 /96 /95 /91 /96 /92 /93 /91 /98 /90 /93 /94 /96 /91 /135 /94 /96 /93 /98 /95 /100 /92 /105 /91\n/100 /114 /90/94 /90 /98 /96 /99 /100 /95 /107 /109/119 /104 /96 /91 /96/97 /90 /91 /101/108 /95 /100 /108 /100 /91 /90 /89 /91/90 /95 /96/98 /104 /96 /93/115 /91 /96 /105/114 /100 /95\n/94 /100 /93 /98 /95 /90 /91 /98 /92 /111 /96/95 /96 /108 /95 /96 /91 /96 /93 /98 /90 /98 /92 /100 /93 /91/98 /100/95 /96 /92 /93 /114 /100 /95 /94 /96/92 /93 /98 /95 /90 /113 /94 /89 /90 /91 /91/105 /92 /111 /96 /95 /113\n/91 /92 /98 /107 /109 /136/96 /90 /93 /103 /104 /92 /89 /96 /112 /98 /100/90 /111 /100 /92 /105/102 /92 /90 /91 /114 /95 /100 /97/92 /93 /98 /95 /90 /113 /94 /89 /90 /91 /91 /105 /92 /111 /96 /95 /91 /92 /98 /107 /112 /103 /96\n/90 /89 /91 /100 /90 /108 /108 /89 /107 /94 /90 /98 /96 /99 /100 /95 /107 /113 /89 /96 /111 /96 /89 /108 /91 /96 /115 /105 /100 /113 /89 /90 /102 /96 /89 /91 /98 /100 /96 /93 /104 /90 /93 /94 /96 /94 /90 /98 /96 /99 /100 /95 /107 /113\n/89 /96 /111 /96 /89 /94 /100 /93 /91 /92 /91 /98 /96 /93 /94 /107 /90 /93 /105 /92 /93 /98 /96 /95 /113 /94 /90 /98 /96 /99 /100 /95 /107 /105 /92 /111 /96 /95 /91 /92 /98 /107 /109 /137 /105 /105 /92 /98 /92 /100 /93 /90 /89 /89 /107 /112\n/88 /100 /92 /93 /132 /96 /99 /96 /93 /91 /115 /95 /96 /91 /98 /104 /96 /97 /100 /105 /96 /89 /106 /91 /91 /98 /90 /102 /92 /89 /92 /98 /107 /90 /93 /105 /90 /89 /89 /96 /111 /92 /90 /98 /96 /91 /114 /100 /95 /99 /96 /98 /113\n/98 /92 /93 /99 /98 /104 /95 /100 /115 /99 /104 /90 /91 /108 /96 /94 /92 /133 /94 /129 /96 /130 /92 /102 /89 /96 /98 /115 /93 /92 /93 /99 /91 /98 /95 /90 /98 /96 /99 /107 /109 /138 /96 /111 /90 /89 /92 /105 /90 /98 /96\n/88 /100 /92 /93 /132 /96 /99/100 /93/139 /90 /91 /94 /90 /89 /140 /141 /88/142 /143 /144 /142/90 /93 /105/137 /145 /146 /142 /143 /147/105 /90 /98 /90 /91 /96 /98 /91 /103 /92 /98 /104\n/97 /115 /89 /98 /92 /108 /89 /96 /92 /93 /94 /95 /96 /97 /96 /93 /98 /90 /89 /91 /94 /96 /93 /90 /95 /92 /100 /91 /90 /93 /105/90 /94 /104 /92 /96 /111 /96 /91 /115 /108 /96 /95 /92 /100 /95 /95 /96 /91 /115 /89 /98 /91\n/94 /100 /97 /108 /90 /95 /96 /105/98 /100 /108 /95 /96 /111 /92 /100 /115 /91 /91 /98 /90 /98 /96 /113 /100 /114 /113 /98 /104 /96 /113 /90 /95 /98 /97 /96 /98 /104 /100 /105 /91 /112 /96 /91 /108 /96 /94 /92 /90 /89 /89 /107 /92 /93\n/97 /100 /95 /96 /94 /104 /90 /89 /89 /96 /93 /99 /92 /93 /99/90 /93 /105/95 /96 /90 /89 /92 /91 /98 /92 /94 /89 /100 /93 /99 /113 /98 /96 /95 /97/91 /94 /96 /93 /90 /95 /92 /100 /91 /109 /88 /100 /105 /96 /92 /91\n/90 /111 /90 /92 /89 /90 /102 /89 /96 /90 /98 /104 /98 /98 /108 /91 /148 /135 /135 /99 /92 /98 /104 /115 /102 /109 /94 /100 /97 /135 /116 /101 /116 /104 /90 /93 /99 /149 /150 /135 /88 /100 /92 /93 /132 /96 /99 /109\n/29 /48/34 /42 /23 /44 /34 /25 /22 /44 /32 /42 /37 /25 /26 /24 /25 /37 /25 /56 /22 /42 /25 /24 /56 /48/64 /59 /45 /24 /38 /34 /53 /57 /22 /37 /58 /37 /25 /26 /36 /37 /24 /34 /56 /34 /25 /26 /62 /25 /37 /63 /22 /42 /60 /37 /56 /33 /151\n/35/40 /34 /42 /42 /22 /60 /55 /34 /25 /44 /37 /25 /26/24 /32 /56 /27 /34 /42 /151 /99 /115 /90 /93 /99 /107 /115 /99 /90 /100 /152/102 /92 /98 /109 /96 /105 /115 /109 /94 /93 /151\n/153 /154 /155/156 /157 /158 /i255 /156 /160 /161 /162 /161 /162 /163 /156 /158 /i255 /155/161 /164 /158 /157 /154 /165 /166\n/167/168 /157 /162 /154 /156 /157 /158 /i255 /169/154 /170 /162 /160 /154 /171 /168 /162 /154 /161 /165 /i255 /167/161 /164 /158 /157 /154 /165 /166/154 /155/172 /166 /158\n/167/172 /170 /173 /i255 /156 /160 /161 /156 /161 /170 /172 /157/153 /158 /166 /155/158 /165 /162 /i255 /157 /172 /171 /158 /157\n/174 /172 /175\n/174 /171 /175\n/176 /37 /26 /32 /42 /22 /177 /151 /40 /34 /54/55 /24 /42 /37 /60 /34 /25/34 /53 /52 /37 /54/55 /43 /22 /178 /42 /34 /56 /34 /56 /33 /55 /22 /179/34 /44 /22 /43 /37 /25 /26/24 /25 /44/179 /32 /43 /56 /37 /55 /43 /22\n/180 /37 /60 /56 /42 /37 /38 /32 /56 /37 /34 /25/179 /34 /44 /22 /43 /37 /25 /26 /151 /181 /24 /182 /183 /52 /37 /54/55 /43 /22 /55 /42 /34 /56 /34 /56 /33 /55 /22 /54/34 /44 /22 /43 /37 /25 /26/56 /34 /42 /22 /55 /42 /22 /184\n/60 /22 /25 /56 /24 /47 /24 /56 /22 /26 /34 /42 /33/68 /37 /56 /27/26 /43 /34 /38 /24 /43 /24 /63 /22 /42 /24 /26 /22 /55 /34 /34 /43 /37 /25 /26 /185 /181 /38 /182 /183 /179/32 /43 /56 /37 /55 /43 /22 /31 /32 /60 /60 /37 /24 /25\n/44 /37 /60 /56 /42 /37 /38 /32 /56 /37 /34 /25 /54/34 /44 /22 /43 /37 /25 /26 /56 /34 /42 /22 /55 /42 /22 /60 /22 /25 /56 /24 /47 /24 /56 /22 /26 /34 /42 /33 /68 /37 /56 /27 /37 /56 /60 /42 /22 /26 /37 /34 /25 /24 /43 /34 /38 /184\n/58 /22 /47 /56 /25 /22 /60 /60 /30 /68 /27 /37 /47 /27/37 /60 /44 /37 /60 /47 /34 /63 /22 /42 /22 /44/68 /37 /56 /27/56 /27 /22 /26 /32 /37 /44 /24 /25 /47 /22 /34 /53 /54/24 /60 /23/55 /42 /34 /55 /34 /60 /24 /43 /60 /151\n/186 /187 /12 /3 /8 /9 /1 /14 /188 /19 /8 /2 /1 /3\n/59 /25/42 /22 /47 /22 /25 /56/33 /22 /24 /42 /60 /30/44 /22 /22 /55/43 /22 /24 /42 /25 /37 /25 /26/38 /24 /60 /22 /44/54 /22 /56 /27 /34 /44 /60/27 /24 /63 /22\n/24 /47 /27 /37 /22 /63 /22 /44/60 /24 /56 /37 /60 /53 /24 /47 /56 /34 /42 /33/55 /22 /42 /53 /34 /42 /54/24 /25 /47 /22/34 /25/63 /24 /42 /37 /34 /32 /60 /42 /22 /47 /34 /26 /25 /37 /56 /37 /34 /25\n/56 /24 /60 /23 /60 /30 /68 /37 /56 /27/56 /27 /22 /24 /60 /60 /32 /54/55 /56 /37 /34 /25/34 /53 /189 /190 /22 /44/34 /42 /60 /56 /24 /38 /43 /22 /44 /24 /56 /24 /44 /37 /60 /56 /42 /37 /38 /32 /184\n/56 /37 /34 /25/191 /177 /192 /193 /151 /41 /34 /68 /22 /63 /22 /42 /30 /42 /22 /24 /43 /184 /68 /34 /42 /43 /44/44 /24 /56 /24 /37 /60 /56 /33 /55 /37 /47 /24 /43 /43 /33/24 /47 /34 /25 /56 /37 /25 /32 /34 /32 /60\n/60 /56 /42 /22 /24 /54/68 /37 /56 /27 /24 /25 /32 /25 /60 /56 /24 /38 /43 /22 /44 /37 /60 /56 /42 /37 /38 /32 /56 /37 /34 /25 /30 /54/24 /23 /37 /25 /26 /37 /56 /44 /37 /53 /189 /47 /32 /43 /56 /53 /34 /42\n/54/34 /44 /22 /43 /60 /56 /34/42 /22 /56 /24 /37 /25/34 /43 /44/23 /25 /34 /68 /43 /22 /44 /26 /22 /68 /27 /37 /43 /22 /24 /47 /194 /32 /37 /42 /37 /25 /26/25 /22 /68/47 /34 /25 /184\n/47 /22 /55 /56 /60 /30 /23 /25 /34 /68 /25 /24 /60 /94 /90 /98 /90 /91 /98 /95 /100 /108 /104 /92 /94 /114 /100 /95 /99 /96 /98 /98 /92 /93 /99 /191 /195 /30 /196 /197 /30 /195 /198 /193 /151 /61 /34 /56 /24 /47 /23 /43 /22\n/56 /27 /37 /60 /55 /42 /34 /38 /43 /22 /54/30 /92 /93 /94 /95 /96 /97 /96 /93 /98 /90 /89 /89 /96 /90 /95 /93 /92 /93 /99/37 /60 /55 /42 /34 /55 /34 /60 /22 /44/56 /34 /24 /44 /24 /55 /56 /56 /34\n/47 /27 /24 /25 /26 /37 /25 /26 /44 /24 /56 /24 /60 /56 /42 /22 /24 /54/60 /53 /34 /42 /25 /22 /68/47 /34 /25 /47 /22 /55 /56 /60 /30 /38 /32 /56 /24 /43 /60 /34 /24 /63 /34 /37 /44 /53 /34 /42 /184\n/26 /22 /56 /56 /37 /25 /26/34 /43 /44 /23 /25 /34 /68 /43 /22 /44 /26 /22 /30 /22 /60 /55 /22 /47 /37 /24 /43 /43 /33/53 /34 /42 /56 /27 /22 /47 /43 /24 /60 /60 /37 /189 /47 /24 /56 /37 /34 /25 /56 /24 /60 /23 /30\n/92 /109 /96 /151 /30 /40 /43 /24 /60 /60 /184 /59 /25 /47 /42 /22 /54/22 /25 /56 /24 /43 /45 /22 /24 /42 /25 /37 /25 /26/181 /40 /59 /45 /182 /191 /177 /199 /30 /177 /200 /30 /197 /199 /193 /151\n/40 /43 /24 /60 /60 /59 /25 /47 /42 /22 /54/22 /25 /56 /24 /43 /52 /22 /54/24 /25 /56 /37 /47 /52 /22 /26 /54/22 /25 /56 /24 /56 /37 /34 /25 /181 /40 /59 /52 /52 /182 /24 /37 /54/60 /56 /34\n/24 /60 /60 /37 /26 /25/24 /25/37 /54/24 /26 /22 /68 /37 /56 /27/56 /27 /22 /55 /37 /190 /22 /43 /184 /68 /37 /60 /22 /43 /24 /38 /22 /43 /34 /53 /56 /27 /22 /40 /59 /45 /60 /22 /56 /56 /37 /25 /26 /151\n/59 /25/60 /22 /54/24 /25 /56 /37 /47 /60 /22 /26 /54/22 /25 /56 /24 /56 /37 /34 /25/56 /24 /60 /23 /60 /37 /25 /63 /34 /43 /63 /37 /25 /26/44 /22 /25 /60 /22 /55 /42 /22 /44 /37 /47 /56 /37 /34 /25 /60 /30\n/56 /27 /22/55 /42 /34 /38 /43 /22 /54/34 /53 /47 /24 /56 /24 /60 /56 /42 /34 /55 /27 /37 /47/53 /34 /42 /26 /22 /56 /56 /37 /25 /26/56 /33 /55 /37 /47 /24 /43 /43 /33/38 /22 /47 /34 /54/22 /60\n/54/34 /42 /22 /47 /27 /24 /43 /43 /22 /25 /26 /37 /25 /26 /151 /179/34 /60 /56 /42 /22 /47 /22 /25 /56 /68 /34 /42 /23 /60 /191 /197 /30 /201 /30 /177 /196 /193 /27 /24 /63 /22 /60 /56 /42 /32 /26 /184\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n843\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Collaborative Propagation on Multiple Instance Graphs for 3D Instance Segmentation with Single-point Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Collaborative_Propagation_on_Multiple_Instance_Graphs_for_3D_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Shichao Dong, Ruibo Li, Jiacheng Wei, Fayao Liu, Guosheng Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Collaborative_Propagation_on_Multiple_Instance_Graphs_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; S-lab, Nanyang Technological University, Singapore; Institute for Infocomm Research, A*STAR, Singapore",
        "project": "",
        "github": "",
        "arxiv": "2208.05110"
    },
    {
        "title": "Collaborative Tracking Learning for Frame-Rate-Insensitive Multi-Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Collaborative_Tracking_Learning_for_Frame-Rate-Insensitive_Multi-Object_Tracking_ICCV_2023_paper.html",
        "author": "Yiheng Liu, Junta Wu, Yi Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Collaborative_Tracking_Learning_for_Frame-Rate-Insensitive_Multi-Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "ByteDance Inc.",
        "project": "",
        "github": "https://github.com/yolomax/ColTrack",
        "arxiv": "2308.05911"
    },
    {
        "title": "Collecting The Puzzle Pieces: Disentangled Self-Driven Human Pose Transfer by Permuting Textures",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Collecting_The_Puzzle_Pieces_Disentangled_Self-Driven_Human_Pose_Transfer_by_ICCV_2023_paper.html",
        "author": "Nannan Li, Kevin J Shih, Bryan A. Plummer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Collecting_The_Puzzle_Pieces_Disentangled_Self-Driven_Human_Pose_Transfer_by_ICCV_2023_paper.pdf",
        "aff": "Boston University; NVIDIA",
        "project": "",
        "github": "https://github.com/NannanLi999/pt_square",
        "arxiv": "2210.01887"
    },
    {
        "title": "Combating Noisy Labels with Sample Selection by Mining High-Discrepancy Examples",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.html",
        "author": "Xiaobo Xia, Bo Han, Yibing Zhan, Jun Yu, Mingming Gong, Chen Gong, Tongliang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.pdf",
        "aff": "The University of Sydney; Nanjing University of Science and Technology; JD Explore Academy; The University of Melbourne; University of Science and Technology of China; Hong Kong Baptist University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Communication-Efficient Vertical Federated Learning with Limited Overlapping Samples",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Communication-Efficient_Vertical_Federated_Learning_with_Limited_Overlapping_Samples_ICCV_2023_paper.html",
        "author": "Jingwei Sun, Ziyue Xu, Dong Yang, Vishwesh Nath, Wenqi Li, Can Zhao, Daguang Xu, Yiran Chen, Holger R. Roth",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Communication-Efficient_Vertical_Federated_Learning_with_Limited_Overlapping_Samples_ICCV_2023_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, Duke University; NVIDIA",
        "project": "",
        "github": "https://nvidia.github.io/NVFlare/research/one-shot-vfl",
        "arxiv": "2303.16270"
    },
    {
        "title": "Communication-efficient Federated Learning with Single-Step Synthetic Features Compressor for Faster Convergence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Communication-efficient_Federated_Learning_with_Single-Step_Synthetic_Features_Compressor_for_Faster_ICCV_2023_paper.html",
        "author": "Yuhao Zhou, Mingjia Shi, Yuanxi Li, Yanan Sun, Qing Ye, Jiancheng Lv",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Communication-efficient_Federated_Learning_with_Single-Step_Synthetic_Features_Compressor_for_Faster_ICCV_2023_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign; Sichuan University, Engineering Research Center of Machine Learning and Industry Intelligence",
        "project": "",
        "github": "",
        "arxiv": "2302.13562"
    },
    {
        "title": "Compatibility of Fundamental Matrices for Complete Viewing Graphs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bratelund_Compatibility_of_Fundamental_Matrices_for_Complete_Viewing_Graphs_ICCV_2023_paper.html",
        "author": "Martin Br\u00e5telund, Felix Rydell",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bratelund_Compatibility_of_Fundamental_Matrices_for_Complete_Viewing_Graphs_ICCV_2023_paper.pdf",
        "aff": "University of Oslo, Moltke Moes vei 35, 0851 Oslo, Norway; KTH Royal Institute of Technology, Lindstedtsvagen 25, Stockholm, Sweden",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Complementary Domain Adaptation and Generalization for Unsupervised Continual Domain Shift Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Complementary_Domain_Adaptation_and_Generalization_for_Unsupervised_Continual_Domain_Shift_ICCV_2023_paper.html",
        "author": "Wonguk Cho, Jinha Park, Taesup Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Complementary_Domain_Adaptation_and_Generalization_for_Unsupervised_Continual_Domain_Shift_ICCV_2023_paper.pdf",
        "aff": "Graduate School of Data Science, Seoul National University; Department of Electrical and Computer Engineering, Seoul National University",
        "project": "",
        "github": "",
        "arxiv": "2303.15833"
    },
    {
        "title": "Compositional Feature Augmentation for Unbiased Scene Graph Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Compositional_Feature_Augmentation_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.html",
        "author": "Lin Li, Guikun Chen, Jun Xiao, Yi Yang, Chunping Wang, Long Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Compositional_Feature_Augmentation_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology; FinVolution; Zhejiang University",
        "project": "",
        "github": "https://github.com/HKUST-LongGroup/CFA",
        "arxiv": "2308.06712"
    },
    {
        "title": "Computation and Data Efficient Backdoor Attacks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Computation_and_Data_Efficient_Backdoor_Attacks_ICCV_2023_paper.html",
        "author": "Yutong Wu, Xingshuo Han, Han Qiu, Tianwei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Computation_and_Data_Efficient_Backdoor_Attacks_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University, Zhongguancun Laboratory; Nanyang Technological University",
        "project": "",
        "github": "https://github.com/WU-YU-TONG/computational_efficient_backdoor",
        "arxiv": ""
    },
    {
        "title": "Computational 3D Imaging with Position Sensors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Klotz_Computational_3D_Imaging_with_Position_Sensors_ICCV_2023_paper.html",
        "author": "Jeremy Klotz, Mohit Gupta, Aswin C. Sankaranarayanan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Klotz_Computational_3D_Imaging_with_Position_Sensors_ICCV_2023_paper.pdf",
        "aff": "University of Wisconsin-Madison; Carnegie Mellon University; Columbia University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Computationally-Efficient Neural Image Compression with Shallow Decoders",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.html",
        "author": "Yibo Yang, Stephan Mandt",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, University of California, Irvine",
        "project": "",
        "github": "https://github.com/mandt-lab/shallow-ntc",
        "arxiv": ""
    },
    {
        "title": "ConSlide: Asynchronous Hierarchical Interaction Transformer with Breakup-Reorganize Rehearsal for Continual Whole Slide Image Analysis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.html",
        "author": "Yanyan Huang, Weiqin Zhao, Shujun Wang, Yu Fu, Yuming Jiang, Lequan Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.pdf",
        "aff": "Stanford University; The University of Hong Kong; The Hong Kong Polytechnic University; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2308.13324"
    },
    {
        "title": "Concept-wise Fine-tuning Matters in Preventing Negative Transfer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Concept-wise_Fine-tuning_Matters_in_Preventing_Negative_Transfer_ICCV_2023_paper.html",
        "author": "Yunqiao Yang, Long-Kai Huang, Ying Wei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Concept-wise_Fine-tuning_Matters_in_Preventing_Negative_Transfer_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; Tencent AI Lab",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Conceptual and Hierarchical Latent Space Decomposition for Face Editing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ozkan_Conceptual_and_Hierarchical_Latent_Space_Decomposition_for_Face_Editing_ICCV_2023_paper.html",
        "author": "Savas Ozkan, Mete Ozay, Tom Robinson",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ozkan_Conceptual_and_Hierarchical_Latent_Space_Decomposition_for_Face_Editing_ICCV_2023_paper.pdf",
        "aff": "Samsung Research UK",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Conditional 360-degree Image Synthesis for Immersive Indoor Scene Decoration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.html",
        "author": "Ka Chun Shum, Hong-Wing Pang, Binh-Son Hua, Duc Thanh Nguyen, Sai-Kit Yeung",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; Deakin University; Trinity College Dublin, VinAI Research, Vietnam",
        "project": "",
        "github": "https://github.com/kcshum/neural_360_decoration.git",
        "arxiv": "2307.09621"
    },
    {
        "title": "Conditional Cross Attention Network for Multi-Space Embedding without Entanglement in Only a SINGLE Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_Conditional_Cross_Attention_Network_for_Multi-Space_Embedding_without_Entanglement_in_ICCV_2023_paper.html",
        "author": "Chull Hwan Song, Taebaek Hwang, Jooyoung Yoon, Shunghyun Choi, Yeong Hyeon Gu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Conditional_Cross_Attention_Network_for_Multi-Space_Embedding_without_Entanglement_in_ICCV_2023_paper.pdf",
        "aff": "Dealicious Inc.; Sejong University",
        "project": "",
        "github": "",
        "arxiv": "2307.13254"
    },
    {
        "title": "Confidence-aware Pseudo-label Learning for Weakly Supervised Visual Grounding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Confidence-aware_Pseudo-label_Learning_for_Weakly_Supervised_Visual_Grounding_ICCV_2023_paper.html",
        "author": "Yang Liu, Jiahua Zhang, Qingchao Chen, Yuxin Peng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Confidence-aware_Pseudo-label_Learning_for_Weakly_Supervised_Visual_Grounding_ICCV_2023_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University; Wangxuan Institute of Computer Technology, Peking University; National Key Laboratory of General Artificial Intelligence, BIGAI; National Institute of Health Data Science, Peking University",
        "project": "",
        "github": "https://github.com/zjh31/CPL.git",
        "arxiv": ""
    },
    {
        "title": "Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Yizhe Xiong, Hui Chen, Zijia Lin, Sicheng Zhao, Guiguang Ding",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "School of Software, Tsinghua University; Beijing National Research Center for Information Science and Technology (BNRist); School of Software, Tsinghua University; Beijing National Research Center for Information Science and Technology (BNRist); Hangzhou Zhuoxi Institute of Brain and Intelligence; School of Software, Tsinghua University; Beijing National Research Center for Information Science and Technology (BNRist)",
        "project": "",
        "github": "https://github.com/Bostoncake/C-VisDiT",
        "arxiv": ""
    },
    {
        "title": "Consistent Depth Prediction for Transparent Object Reconstruction from RGB-D Camera",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Consistent_Depth_Prediction_for_Transparent_Object_Reconstruction_from_RGB-D_Camera_ICCV_2023_paper.html",
        "author": "Yuxiang Cai, Yifan Zhu, Haiwei Zhang, Bo Ren",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Consistent_Depth_Prediction_for_Transparent_Object_Reconstruction_from_RGB-D_Camera_ICCV_2023_paper.pdf",
        "aff": "Nankai University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Constraining Depth Map Geometry for Multi-View Stereo: A Dual-Depth Approach with Saddle-shaped Depth Cells",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.html",
        "author": "Xinyi Ye, Weiyue Zhao, Tianqi Liu, Zihao Huang, Zhiguo Cao, Xin Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Image Processing and Intelligent Control, Ministry of Education; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan 430074, China; Department of Computer Science, University of Albany, Albany NY 12222",
        "project": "",
        "github": "https://github.com/DIVE128/DMVSNet",
        "arxiv": "2307.09160"
    },
    {
        "title": "ContactGen: Generative Contact Modeling for Grasp Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_ContactGen_Generative_Contact_Modeling_for_Grasp_Generation_ICCV_2023_paper.html",
        "author": "Shaowei Liu, Yang Zhou, Jimei Yang, Saurabh Gupta, Shenlong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_ContactGen_Generative_Contact_Modeling_for_Grasp_Generation_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; University of Illinois Urbana-Champaign",
        "project": "https://stevenlsw.github.io/contactgen/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Contactless Pulse Estimation Leveraging Pseudo Labels and Self-Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Contactless_Pulse_Estimation_Leveraging_Pseudo_Labels_and_Self-Supervision_ICCV_2023_paper.html",
        "author": "Zhihua Li, Lijun Yin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Contactless_Pulse_Estimation_Leveraging_Pseudo_Labels_and_Self-Supervision_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Binghamton University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Content-Aware Local GAN for Photo-Realistic Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_Content-Aware_Local_GAN_for_Photo-Realistic_Super-Resolution_ICCV_2023_paper.html",
        "author": "JoonKyu Park, Sanghyun Son, Kyoung Mu Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Content-Aware_Local_GAN_for_Photo-Realistic_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "Dept. of ECE&ASRI, IPAI, Seoul National University, Korea",
        "project": "",
        "github": "https://github.com/jkpark0825/CAL GAN",
        "arxiv": ""
    },
    {
        "title": "Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.html",
        "author": "Byeonghwi Kim, Jinyeon Kim, Yuyeong Kim, Cheolhong Min, Jonghyun Choi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; Gwangju Institute of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2308.07241"
    },
    {
        "title": "Continual Learning for Personalized Co-speech Gesture Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ahuja_Continual_Learning_for_Personalized_Co-speech_Gesture_Generation_ICCV_2023_paper.html",
        "author": "Chaitanya Ahuja, Pratik Joshi, Ryo Ishii, Louis-Philippe Morency",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ahuja_Continual_Learning_for_Personalized_Co-speech_Gesture_Generation_ICCV_2023_paper.pdf",
        "aff": "NTT Human Informatics Laboratories; Language Technologies Institute, CMU",
        "project": "",
        "github": "https://chahuja.com/cdiffgan",
        "arxiv": ""
    },
    {
        "title": "Continual Segment: Towards a Single, Unified and Non-forgetting Continual Segmentation Model of 143 Whole-body Organs in CT Scans",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Continual_Segment_Towards_a_Single_Unified_and_Non-forgetting_Continual_Segmentation_ICCV_2023_paper.html",
        "author": "Zhanghexuan Ji, Dazhou Guo, Puyang Wang, Ke Yan, Le Lu, Minfeng Xu, Qifeng Wang, Jia Ge, Mingchen Gao, Xianghua Ye, Dakai Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Continual_Segment_Towards_a_Single_Unified_and_Non-forgetting_Continual_Segmentation_ICCV_2023_paper.pdf",
        "aff": "University at Buffalo; DAMO Academy, Alibaba Group; University at Buffalo; DAMO Academy, Alibaba Group; DAMO Academy, Alibaba Group; Hupan Lab, 310023, Hangzhou, China; The First Affiliated Hospital of Zhejiang University; Sichuan Cancer Hospital",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Continual Zero-Shot Learning through Semantically Guided Generative Random Walks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Continual_Zero-Shot_Learning_through_Semantically_Guided_Generative_Random_Walks_ICCV_2023_paper.html",
        "author": "Wenxuan Zhang, Paul Janson, Kai Yi, Ivan Skorokhodov, Mohamed Elhoseiny",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Continual_Zero-Shot_Learning_through_Semantically_Guided_Generative_Random_Walks_ICCV_2023_paper.pdf",
        "aff": "KAUST, University of Moratuwa; KAUST",
        "project": "",
        "github": "https://github.com/wx-zhang/IGCZSL",
        "arxiv": "2308.12366"
    },
    {
        "title": "Continuously Masked Transformer for Image Inpainting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_paper.html",
        "author": "Keunsoo Ko, Chang-Su Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_paper.pdf",
        "aff": "Korea University; The Catholic University of Korea",
        "project": "",
        "github": "https://github.com/keunsoo-ko/CMT",
        "arxiv": ""
    },
    {
        "title": "Contrastive Continuity on Augmentation Stability Rehearsal for Continual Self-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Contrastive_Continuity_on_Augmentation_Stability_Rehearsal_for_Continual_Self-Supervised_Learning_ICCV_2023_paper.html",
        "author": "Haoyang Cheng, Haitao Wen, Xiaoliang Zhang, Heqian Qiu, Lanxiao Wang, Hongliang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Contrastive_Continuity_on_Augmentation_Stability_Rehearsal_for_Continual_Self-Supervised_Learning_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China, Chengdu, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Contrastive Feature Masking Open-Vocabulary Vision Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Contrastive_Feature_Masking_Open-Vocabulary_Vision_Transformer_ICCV_2023_paper.html",
        "author": "Dahun Kim, Anelia Angelova, Weicheng Kuo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Contrastive_Feature_Masking_Open-Vocabulary_Vision_Transformer_ICCV_2023_paper.pdf",
        "aff": "Google DeepMind",
        "project": "",
        "github": "",
        "arxiv": "2309.00775"
    },
    {
        "title": "Contrastive Learning Relies More on Spatial Inductive Bias Than Supervised Learning: An Empirical Study",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_Contrastive_Learning_Relies_More_on_Spatial_Inductive_Bias_Than_Supervised_ICCV_2023_paper.html",
        "author": "Yuanyi Zhong, Haoran Tang, Jun-Kun Chen, Yu-Xiong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_Contrastive_Learning_Relies_More_on_Spatial_Inductive_Bias_Than_Supervised_ICCV_2023_paper.pdf",
        "aff": "University of Pennsylvania; University of Illinois at Urbana-Champaign",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Contrastive Model Adaptation for Cross-Condition Robustness in Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "David Br\u00fcggemann, Christos Sakaridis, Tim Broedermann, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich, Switzerland",
        "project": "",
        "github": "https://github.com/brdav/cma",
        "arxiv": ""
    },
    {
        "title": "Contrastive Pseudo Learning for Open-World DeepFake Attribution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Contrastive_Pseudo_Learning_for_Open-World_DeepFake_Attribution_ICCV_2023_paper.html",
        "author": "Zhimin Sun, Shen Chen, Taiping Yao, Bangjie Yin, Ran Yi, Shouhong Ding, Lizhuang Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Contrastive_Pseudo_Learning_for_Open-World_DeepFake_Attribution_ICCV_2023_paper.pdf",
        "aff": "Shanghai Jiao Tong University/Tencent YouTu Lab/Shanghai Key Laboratory of Computer Software Testing & Evaluating; Tencent YouTu Lab; Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2309.11132"
    },
    {
        "title": "Controllable Guide-Space for Generalizable Face Forgery Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Controllable_Guide-Space_for_Generalizable_Face_Forgery_Detection_ICCV_2023_paper.html",
        "author": "Ying Guo, Cheng Zhen, Pengfei Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Controllable_Guide-Space_for_Generalizable_Face_Forgery_Detection_ICCV_2023_paper.pdf",
        "aff": "Vision AI Department, Meituan",
        "project": "",
        "github": "",
        "arxiv": "2307.14039"
    },
    {
        "title": "Controllable Person Image Synthesis with Pose-Constrained Latent Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.html",
        "author": "Xiao Han, Xiatian Zhu, Jiankang Deng, Yi-Zhe Song, Tao Xiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.pdf",
        "aff": "CVSSP, University of Surrey; iFlyTek-Surrey Joint Research Centre on AI; Imperial College London; CVSSP, University of Surrey; Surrey Institute for People-Centred AI",
        "project": "",
        "github": "https://github.com/BrandonHanx/PoCoLD",
        "arxiv": ""
    },
    {
        "title": "Controllable Visual-Tactile Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Controllable_Visual-Tactile_Synthesis_ICCV_2023_paper.html",
        "author": "Ruihan Gao, Wenzhen Yuan, Jun-Yan Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Controllable_Visual-Tactile_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "https://visual-tactile-synthesis.github.io/",
        "github": "",
        "arxiv": "2305.03051"
    },
    {
        "title": "Convex Decomposition of Indoor Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Vavilala_Convex_Decomposition_of_Indoor_Scenes_ICCV_2023_paper.html",
        "author": "Vaibhav Vavilala, David Forsyth",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Vavilala_Convex_Decomposition_of_Indoor_Scenes_ICCV_2023_paper.pdf",
        "aff": "UIUC",
        "project": "",
        "github": "",
        "arxiv": "2307.04246"
    },
    {
        "title": "Convolutional Networks with Oriented 1D Kernels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kirchmeyer_Convolutional_Networks_with_Oriented_1D_Kernels_ICCV_2023_paper.html",
        "author": "Alexandre Kirchmeyer, Jia Deng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kirchmeyer_Convolutional_Networks_with_Oriented_1D_Kernels_ICCV_2023_paper.pdf",
        "aff": "Princeton University; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/princeton-vl/Oriented1D",
        "arxiv": ""
    },
    {
        "title": "Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Coordinate_Quantized_Neural_Implicit_Representations_for_Multi-view_Reconstruction_ICCV_2023_paper.html",
        "author": "Sijia Jiang, Jing Hua, Zhizhong Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Coordinate_Quantized_Neural_Implicit_Representations_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Wayne State University, Detroit, USA",
        "project": "",
        "github": "https://github.com/MachinePerceptionLab/CQ-NIR",
        "arxiv": "2308.11025"
    },
    {
        "title": "Coordinate Transformer: Achieving Single-stage Multi-person Mesh Recovery from Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Coordinate_Transformer_Achieving_Single-stage_Multi-person_Mesh_Recovery_from_Videos_ICCV_2023_paper.html",
        "author": "Haoyuan Li, Haoye Dong, Hanchao Jia, Dong Huang, Michael C. Kampffmeyer, Liang Lin, Xiaodan Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Coordinate_Transformer_Achieving_Single-stage_Multi-person_Mesh_Recovery_from_Videos_ICCV_2023_paper.pdf",
        "aff": "Shenzhen campus of Sun Yat-sen University; UiT The Arctic University of Norway; Carnegie Mellon University; Sun Yat-sen University; Mohamed bin Zayed University of AI; Samsung Research China \u2013 Beijing (SRC-B)",
        "project": "",
        "github": "https://github.com/Li-Hao-yuan/CoordFormer",
        "arxiv": "2308.10334"
    },
    {
        "title": "CopyRNeRF: Protecting the CopyRight of Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_CopyRNeRF_Protecting_the_CopyRight_of_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Ziyuan Luo, Qing Guo, Ka Chun Cheung, Simon See, Renjie Wan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_CopyRNeRF_Protecting_the_CopyRight_of_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "NVIDIA AI Technology Center, NVIDIA; Department of Computer Science, Hong Kong Baptist University; IHPC and CFAR, Agency for Science, Technology and Research, Singapore",
        "project": "https://luo-ziyuan.github.io/copyrnerf",
        "github": "",
        "arxiv": "2307.11526"
    },
    {
        "title": "Corrupting Neuron Explanations of Deep Visual Features",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Srivastava_Corrupting_Neuron_Explanations_of_Deep_Visual_Features_ICCV_2023_paper.html",
        "author": "Divyansh Srivastava, Tuomas Oikarinen, Tsui-Wei Weng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Srivastava_Corrupting_Neuron_Explanations_of_Deep_Visual_Features_ICCV_2023_paper.pdf",
        "aff": "UCSD HDSI; UCSD CSE",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Counterfactual-based Saliency Map: Towards Visual Contrastive Explanations for Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Counterfactual-based_Saliency_Map_Towards_Visual_Contrastive_Explanations_for_Neural_Networks_ICCV_2023_paper.html",
        "author": "Xue Wang, Zhibo Wang, Haiqin Weng, Hengchang Guo, Zhifei Zhang, Lu Jin, Tao Wei, Kui Ren",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Counterfactual-based_Saliency_Map_Towards_Visual_Contrastive_Explanations_for_Neural_Networks_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; School of Cyber Science and Engineering, Wuhan University, P.R. China; Ant Group; School of Cyber Science and Technology, Zhejiang University, P.R. China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Counting Crowds in Bad Weather",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Counting_Crowds_in_Bad_Weather_ICCV_2023_paper.html",
        "author": "Zhi-Kai Huang, Wei-Ting Chen, Yuan-Chun Chiang, Sy-Yen Kuo, Ming-Hsuan Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Counting_Crowds_in_Bad_Weather_ICCV_2023_paper.pdf",
        "aff": "National Taiwan University; UC Merced, Google Research, Yonsei University; National Taiwan University, Stanford University",
        "project": "URL to project page not provided in text",
        "github": "",
        "arxiv": "2306.01209"
    },
    {
        "title": "Creative Birds: Self-Supervised Single-View 3D Style Transfer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Creative_Birds_Self-Supervised_Single-View_3D_Style_Transfer_ICCV_2023_paper.html",
        "author": "Renke Wang, Guimin Que, Shuo Chen, Xiang Li, Jun Li, Jian Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Creative_Birds_Self-Supervised_Single-View_3D_Style_Transfer_ICCV_2023_paper.pdf",
        "aff": "Nankai University; PCA Lab, Nanjing University of Science and Technology, China; RIKEN",
        "project": "",
        "github": "https://github.com/wrk226/creative_birds",
        "arxiv": "2307.14127"
    },
    {
        "title": "CroCo v2: Improved Cross-view Completion Pre-training for Stereo Matching and Optical Flow",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Weinzaepfel_CroCo_v2_Improved_Cross-view_Completion_Pre-training_for_Stereo_Matching_and_ICCV_2023_paper.html",
        "author": "Philippe Weinzaepfel, Thomas Lucas, Vincent Leroy, Yohann Cabon, Vaibhav Arora, Romain Br\u00e9gier, Gabriela Csurka, Leonid Antsfeld, Boris Chidlovskii, Jerome Revaud",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Weinzaepfel_CroCo_v2_Improved_Cross-view_Completion_Pre-training_for_Stereo_Matching_and_ICCV_2023_paper.pdf",
        "aff": "NAVER LABS Europe",
        "project": "",
        "github": "https://github.com/naver/croco",
        "arxiv": "2211.10408"
    },
    {
        "title": "Cross Contrasting Feature Perturbation for Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Cross_Contrasting_Feature_Perturbation_for_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Chenming Li, Daoan Zhang, Wenjian Huang, Jianguo Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Cross_Contrasting_Feature_Perturbation_for_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "Research Institute of Trustworthy Autonomous Systems and Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Research Institute of Trustworthy Autonomous Systems and Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China",
        "project": "",
        "github": "https://github.com/hackmebroo/CCFP",
        "arxiv": "2307.12502"
    },
    {
        "title": "Cross Modal Transformer: Towards Fast and Robust 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Cross_Modal_Transformer_Towards_Fast_and_Robust_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Junjie Yan, Yingfei Liu, Jianjian Sun, Fan Jia, Shuailin Li, Tiancai Wang, Xiangyu Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Cross_Modal_Transformer_Towards_Fast_and_Robust_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "MEGVII Technology",
        "project": "",
        "github": "https://github.com/junjie18/CMT",
        "arxiv": "2301.01283"
    },
    {
        "title": "Cross-Domain Product Representation Learning for Rich-Content E-Commerce",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bai_Cross-Domain_Product_Representation_Learning_for_Rich-Content_E-Commerce_ICCV_2023_paper.html",
        "author": "Xuehan Bai, Yan Li, Yanhua Cheng, Wenjie Yang, Quan Chen, Han Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Cross-Domain_Product_Representation_Learning_for_Rich-Content_E-Commerce_ICCV_2023_paper.pdf",
        "aff": "Kuaishou Technology; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/adxcreative/COPE",
        "arxiv": ""
    },
    {
        "title": "Cross-Modal Learning with 3D Deformable Attention for Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Cross-Modal_Learning_with_3D_Deformable_Attention_for_Action_Recognition_ICCV_2023_paper.html",
        "author": "Sangwon Kim, Dasom Ahn, Byoung Chul Ko",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Cross-Modal_Learning_with_3D_Deformable_Attention_for_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "Cross-Modal Learning with 3D Deformable Attention for Action Recognition\nSangwon Kim Dasom Ahn Byoung Chul Ko*\nKeimyung University\n{eddiesangwonkim, tommydasomahn }@gmail.com, niceko@kmu.ac.kr\nAbstract\nAn important challenge in vision-based action recogni-\ntion is the embedding of spatiotemporal features with two\nor more heterogeneous modalities into a single feature. In\nthis study, we propose a new 3D deformable transformer\nfor action recognition with adaptive spatiotemporal recep-\ntive fields and a cross-modal learning scheme. The 3D de-\nformable transformer consists of three attention modules:\n3D deformability, local joint stride, and temporal stride at-\ntention. The two cross-modal tokens are input into the 3D\ndeformable attention module to create a cross-attention to-\nken with a reflected spatiotemporal correlation. Local joint\nstride attention is applied to spatially combine attention and\npose tokens. Temporal stride attention temporally reduces\nthe number of input tokens in the attention module and sup-\nports temporal expression learning without the simultane-\nous use of all tokens. The deformable transformer iterates\nL-times and combines the last cross-modal token for clas-\nsification. The proposed 3D deformable transformer was\ntested on the NTU60, NTU120, FineGYM, and PennAction\ndatasets, and showed results better than or similar to pre-\ntrained state-of-the-art methods even without a pre-training\nprocess. In addition, by visualizing important joints and\ncorrelations during action recognition through spatial joint\nand temporal stride attention, the possibility of achieving an\nexplainable potential for action recognition is presented.\n1. Introduction\nSpatiotemporal feature learning is a crucial part of ac-\ntion recognition, which aims to fuse not only the spatial\nfeatures of each frame but also the temporal correlation be-\ntween input sequences. Previous studies on action recog-\nnition [19, 6, 5, 42, 9, 48] investigated the application of\n3D convolutional kernels with an additional temporal space\nbeyond the 2D spatial feature space. Since then, 3D con-\nvolutional neural networks (CNN) have achieved a promis-\ning performance and have eventually become the de facto\n*Corresponding author\n(a) Full Attention (b) 3D Deformable Attention\nandFigure 1: Comparison between (a) Full attention and\n(b) the proposed 3D deformable attention. Full attention\nconsiders all tokens against a specific query in a complete\nsequence. By contrast, 3D deformable attention considers\nonly intense tokens with adaptive receptive fields.\nstandard for various action recognition tasks using sequen-\ntial data. Vision transformers (ViTs) for action recognition,\nwhich have peaked in popularity, have recently been used to\nexplore a 3D token embedding to fuse the temporal space\nwithin a single token. However, ViTs-based action recogni-\ntion methods [1, 34] are limited in that they can only con-\nduct spatiotemporal feature learning within restricted recep-\ntive fields.\nTo avoid this problem, several studies [15, 57, 47] have\nbeen conducted to allow more flexible receptive fields for\ndeep learning models. Deformable CNN leverages dynamic\nkernels to capture the intense object regions. First, they\ndetermine the deformable coordinates using embedded fea-\ntures. The kernel is then applied to the features extracted\nfrom the deformable coordinates. Deformable ViTs [47, 57]\nencourage the use of an existing attention module to learn\ndeformable features. The query tokens are projected onto\nthe coordinates to obtain deformable regions from the key\nandvalue tokens. The deformed value tokens are then ap-\nplied to the attention map, which is generated through a\nscaled dot product of the input query and deformed keyto-\nkens. These methods suggest a new approach that can over-\ncome the limitations of existing standardized feature learn-\ning. However, despite some impressive results, these stud-\nies are still limited in that they are only compatible with\nthe spatial dimensions. Therefore, as a primary challenge,\nthere is a need for the development of novel and deformable\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n10265\n",
        "project": "",
        "github": "",
        "arxiv": "2212.05638"
    },
    {
        "title": "Cross-Modal Orthogonal High-Rank Augmentation for RGB-Event Transformer-Trackers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Cross-Modal_Orthogonal_High-Rank_Augmentation_for_RGB-Event_Transformer-Trackers_ICCV_2023_paper.html",
        "author": "Zhiyu Zhu, Junhui Hou, Dapeng Oliver Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Cross-Modal_Orthogonal_High-Rank_Augmentation_for_RGB-Event_Transformer-Trackers_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, City University of Hong Kong",
        "project": "",
        "github": "https://github.com/ZHU-Zhiyu/High-Rank_RGB-Event_Tracker",
        "arxiv": "2307.04129"
    },
    {
        "title": "Cross-Modal Translation and Alignment for Survival Analysis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Cross-Modal_Translation_and_Alignment_for_Survival_Analysis_ICCV_2023_paper.html",
        "author": "Fengtao Zhou, Hao Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Cross-Modal_Translation_and_Alignment_for_Survival_Analysis_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, Department of Chemical and Biological Engineering, The Hong Kong University of Science and Technology; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology",
        "project": "",
        "github": "https://github.com/FT-ZHOU-ZZZ/CMTA",
        "arxiv": "2309.12855"
    },
    {
        "title": "Cross-Ray Neural Radiance Fields for Novel-View Synthesis from Unconstrained Image Collections",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.html",
        "author": "Yifan Yang, Shuhai Zhang, Zixiong Huang, Yubing Zhang, Mingkui Tan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology; South China University of Technology, Pazhou Lab, Key Laboratory of Big Data and Intelligent Robot, Ministry of Education; Guangzhou Shiyuan Electronics Co., Ltd; South China University of Technology, Pazhou Lab",
        "project": "",
        "github": "https://github.com/YifYang993/CR-NeRF-PyTorch.git",
        "arxiv": "2307.08093"
    },
    {
        "title": "Cross-modal Latent Space Alignment for Image to Avatar Translation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/de_Guevara_Cross-modal_Latent_Space_Alignment_for_Image_to_Avatar_Translation_ICCV_2023_paper.html",
        "author": "Manuel Ladron de Guevara, Jose Echevarria, Yijun Li, Yannick Hold-Geoffroy, Cameron Smith, Daichi Ito",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/de_Guevara_Cross-modal_Latent_Space_Alignment_for_Image_to_Avatar_Translation_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Cross-modal Scalable Hyperbolic Hierarchical Clustering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Long_Cross-modal_Scalable_Hierarchical_Clustering_in_Hyperbolic_space_ICCV_2023_paper.html",
        "author": "Teng Long, Nanne van Noord",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Long_Cross-modal_Scalable_Hierarchical_Clustering_in_Hyperbolic_space_ICCV_2023_paper.pdf",
        "aff": "University of Amsterdam",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Cross-view Semantic Alignment for Livestreaming Product Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Cross-view_Semantic_Alignment_for_Livestreaming_Product_Recognition_ICCV_2023_paper.html",
        "author": "Wenjie Yang, Yiyi Chen, Yan Li, Yanhua Cheng, Xudong Liu, Quan Chen, Han Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-view_Semantic_Alignment_for_Livestreaming_Product_Recognition_ICCV_2023_paper.pdf",
        "aff": "Kuaishou Technology",
        "project": "",
        "github": "https://github.com/adxcreative/RICE",
        "arxiv": "2308.04912"
    },
    {
        "title": "Cross-view Topology Based Consistent and Complementary Information for Deep Multi-view Clustering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Cross-view_Topology_Based_Consistent_and_Complementary_Information_for_Deep_Multi-view_ICCV_2023_paper.html",
        "author": "Zhibin Dong, Siwei Wang, Jiaqi Jin, Xinwang Liu, En Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Cross-view_Topology_Based_Consistent_and_Complementary_Information_for_Deep_Multi-view_ICCV_2023_paper.pdf",
        "aff": "Intelligent Game and Decision Lab, Beijing, China; School of Computer, National University of Defense Technology, Changsha, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CrossLoc3D: Aerial-Ground Cross-Source 3D Place Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guan_CrossLoc3D_Aerial-Ground_Cross-Source_3D_Place_Recognition_ICCV_2023_paper.html",
        "author": "Tianrui Guan, Aswath Muthuselvam, Montana Hoover, Xijun Wang, Jing Liang, Adarsh Jagan Sathyamoorthy, Damon Conover, Dinesh Manocha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_CrossLoc3D_Aerial-Ground_Cross-Source_3D_Place_Recognition_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; DEVCOM Army Research Laboratory",
        "project": "",
        "github": "github.com/rayguan97/crossloc3d",
        "arxiv": "2303.17778"
    },
    {
        "title": "CrossMatch: Source-Free Domain Adaptive Semantic Segmentation via Cross-Modal Consistency Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yin_CrossMatch_Source-Free_Domain_Adaptive_Semantic_Segmentation_via_Cross-Modal_Consistency_Training_ICCV_2023_paper.html",
        "author": "Yifang Yin, Wenmiao Hu, Zhenguang Liu, Guanfeng Wang, Shili Xiang, Roger Zimmermann",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_CrossMatch_Source-Free_Domain_Adaptive_Semantic_Segmentation_via_Cross-Modal_Consistency_Training_ICCV_2023_paper.pdf",
        "aff": "Grabtaxi Holdings Pte. Ltd.; Zhejiang Gongshang University; National University of Singapore; Institute for Infocomm Research, A*STAR",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CuNeRF: Cube-Based Neural Radiance Field for Zero-Shot Medical Image Arbitrary-Scale Super Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.html",
        "author": "Zixuan Chen, Lingxiao Yang, Jian-Huang Lai, Xiaohua Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Guangdong Province Key Laboratory of Information Security Technology, Guangzhou, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
        "project": "NarcissusEx.github.io/CuNeRF",
        "github": "NarcissusEx.github.io/CuNeRF",
        "arxiv": "2303.16242"
    },
    {
        "title": "Cumulative Spatial Knowledge Distillation for Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Cumulative_Spatial_Knowledge_Distillation_for_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Borui Zhao, Renjie Song, Jiajun Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Cumulative_Spatial_Knowledge_Distillation_for_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "MEGVII Technology",
        "project": "",
        "github": "https://github.com/Zzzzz1/CSKD",
        "arxiv": "2307.08500"
    },
    {
        "title": "Curvature-Aware Training for Coordinate Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Saratchandran_Curvature-Aware_Training_for_Coordinate_Networks_ICCV_2023_paper.html",
        "author": "Hemanth Saratchandran, Shin-Fang Chng, Sameera Ramasinghe, Lachlan MacDonald, Simon Lucey",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Saratchandran_Curvature-Aware_Training_for_Coordinate_Networks_ICCV_2023_paper.pdf",
        "aff": "Amazon, Australia; Australian Institute of Machine Learning, University of Adelaide",
        "project": "",
        "github": "https://github.com/sfchng/curvature-aware-INRs",
        "arxiv": "2305.08552"
    },
    {
        "title": "Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nam_Cyclic_Test-Time_Adaptation_on_Monocular_Video_for_3D_Human_Mesh_ICCV_2023_paper.html",
        "author": "Hyeongjin Nam, Daniel Sungho Jung, Yeonguk Oh, Kyoung Mu Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nam_Cyclic_Test-Time_Adaptation_on_Monocular_Video_for_3D_Human_Mesh_ICCV_2023_paper.pdf",
        "aff": "IPAI, Seoul National University, Korea; SNU-LG AI Research Center; Dept. of ECE&ASRI, Seoul National University, Korea; SNU-LG AI Research Center; Dept. of ECE&ASRI, IPAI, Seoul National University, Korea; SNU-LG AI Research Center",
        "project": "",
        "github": "https://github.com/{namhjsnu28,dqj5182,namepllet,kyoungmu }",
        "arxiv": "2308.06554"
    },
    {
        "title": "Cyclic-Bootstrap Labeling for Weakly Supervised Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.html",
        "author": "Yufei Yin, Jiajun Deng, Wengang Zhou, Li Li, Houqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "CAS Key Laboratory of Technology in GIPAS, EEIS Department, University of Science and Technology of China; The University of Sydney",
        "project": "",
        "github": "https://github.com/Yinyf0804/WSOD-CBL",
        "arxiv": "2308.05991"
    },
    {
        "title": "D-IF: Uncertainty-aware Human Digitization via Implicit Distribution Field",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.html",
        "author": "Xueting Yang, Yihao Luo, Yuliang Xiu, Wei Wang, Hao Xu, Zhaoxin Fan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.pdf",
        "aff": "Imperial College London; Hong Kong University of Science and Technology; Max Planck Institute for Intelligent Systems; Psyche AI Inc.",
        "project": "",
        "github": "github.com/psyai-net/D-IF",
        "arxiv": ""
    },
    {
        "title": "D3G: Exploring Gaussian Prior for Temporal Sentence Grounding with Glance Annotation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_D3G_Exploring_Gaussian_Prior_for_Temporal_Sentence_Grounding_with_Glance_ICCV_2023_paper.html",
        "author": "Hanjun Li, Xiujun Shu, Sunan He, Ruizhi Qiao, Wei Wen, Taian Guo, Bei Gan, Xing Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_D3G_Exploring_Gaussian_Prior_for_Temporal_Sentence_Grounding_with_Glance_ICCV_2023_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; Youtu Lab, Tencent",
        "project": "",
        "github": "https://github.com/solicucu/D3G",
        "arxiv": "2308.04197"
    },
    {
        "title": "DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generation Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cho_DALL-Eval_Probing_the_Reasoning_Skills_and_Social_Biases_of_Text-to-Image_ICCV_2023_paper.html",
        "author": "Jaemin Cho, Abhay Zala, Mohit Bansal",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_DALL-Eval_Probing_the_Reasoning_Skills_and_Social_Biases_of_Text-to-Image_ICCV_2023_paper.pdf",
        "aff": "UNC Chapel Hill",
        "project": "",
        "github": "https://github.com/j-min/DallEval",
        "arxiv": ""
    },
    {
        "title": "DARTH: Holistic Test-time Adaptation for Multiple Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Segu_DARTH_Holistic_Test-time_Adaptation_for_Multiple_Object_Tracking_ICCV_2023_paper.html",
        "author": "Mattia Segu, Bernt Schiele, Fisher Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Segu_DARTH_Holistic_Test-time_Adaptation_for_Multiple_Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; Max Planck Institute for Informatics, Saarland Informatics Campus",
        "project": "https://www.vis.xyz/pub/darth",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DCPB: Deformable Convolution Based on the Poincare Ball for Top-view Fisheye Cameras",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_DCPB_Deformable_Convolution_Based_on_the_Poincare_Ball_for_Top-view_ICCV_2023_paper.html",
        "author": "Xuan Wei, Zhidan Ran, Xiaobo Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_DCPB_Deformable_Convolution_Based_on_the_Poincare_Ball_for_Top-view_ICCV_2023_paper.pdf",
        "aff": "School of Automation, Southeast University, Nanjing 210096, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kang_DDColor_Towards_Photo-Realistic_Image_Colorization_via_Dual_Decoders_ICCV_2023_paper.html",
        "author": "Xiaoyang Kang, Tao Yang, Wenqi Ouyang, Peiran Ren, Lingzhi Li, Xuansong Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_DDColor_Towards_Photo-Realistic_Image_Colorization_via_Dual_Decoders_ICCV_2023_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/piddnad/DDColor",
        "arxiv": "2212.11613"
    },
    {
        "title": "DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.html",
        "author": "Zixiang Zhao, Haowen Bai, Yuanzhi Zhu, Jiangshe Zhang, Shuang Xu, Yulun Zhang, Kai Zhang, Deyu Meng, Radu Timofte, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Lab, ETH Z\u00fcrich; Northwestern Polytechnical University; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "https://github.com/Zhaozixiang1228/MMIF-DDFM",
        "arxiv": "2303.06840"
    },
    {
        "title": "DDG-Net: Discriminability-Driven Graph Network for Weakly-supervised Temporal Action Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_DDG-Net_Discriminability-Driven_Graph_Network_for_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.html",
        "author": "Xiaojun Tang, Junsong Fan, Chuanchen Luo, Zhaoxiang Zhang, Man Zhang, Zongyuan Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_DDG-Net_Discriminability-Driven_Graph_Network_for_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf",
        "aff": "Institute of Automation, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, UCAS, China; Beijing University of Posts and Telecommunications, China",
        "project": "",
        "github": "https://github.com/XiaojunTang22/ICCV2023-DDGNet",
        "arxiv": ""
    },
    {
        "title": "DDIT: Semantic Scene Completion via Deformable Deep Implicit Templates",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_DDIT_Semantic_Scene_Completion_via_Deformable_Deep_Implicit_Templates_ICCV_2023_paper.html",
        "author": "Haoang Li, Jinhu Dong, Binghui Wen, Ming Gao, Tianyu Huang, Yun-Hui Liu, Daniel Cremers",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DDIT_Semantic_Scene_Completion_via_Deformable_Deep_Implicit_Templates_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich; Munich Center for Machine Learning (MCML); Technical University of Munich; Munich Center for Machine Learning (MCML); University of Oxford; Technical University of Munich; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DDP: Diffusion Model for Dense Visual Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ji_DDP_Diffusion_Model_for_Dense_Visual_Prediction_ICCV_2023_paper.html",
        "author": "Yuanfeng Ji, Zhe Chen, Enze Xie, Lanqing Hong, Xihui Liu, Zhaoqiang Liu, Tong Lu, Zhenguo Li, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_DDP_Diffusion_Model_for_Dense_Visual_Prediction_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; The University of Hong Kong; Nanjing University; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/JiYuanFeng/DDP",
        "arxiv": "2303.17559"
    },
    {
        "title": "DDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for Hyperspectral Image Restoration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Miao_DDS2M_Self-Supervised_Denoising_Diffusion_Spatio-Spectral_Model_for_Hyperspectral_Image_Restoration_ICCV_2023_paper.html",
        "author": "Yuchun Miao, Lefei Zhang, Liangpei Zhang, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_DDS2M_Self-Supervised_Denoising_Diffusion_Spatio-Spectral_Model_for_Hyperspectral_Image_Restoration_ICCV_2023_paper.pdf",
        "aff": "Sydney AI Centre, School of Computer Science, The University of Sydney; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University; State Key Lab. of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University",
        "project": "",
        "github": "https://github.com/miaoyuchun/DDS2M",
        "arxiv": "2303.06682"
    },
    {
        "title": "DECO: Dense Estimation of 3D Human-Scene Contact In The Wild",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tripathi_DECO_Dense_Estimation_of_3D_Human-Scene_Contact_In_The_Wild_ICCV_2023_paper.html",
        "author": "Shashank Tripathi, Agniv Chatterjee, Jean-Claude Passy, Hongwei Yi, Dimitrios Tzionas, Michael J. Black",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tripathi_DECO_Dense_Estimation_of_3D_Human-Scene_Contact_In_The_Wild_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; University of Amsterdam, the Netherlands",
        "project": "",
        "github": "https://deco.is.tue.mpg.de",
        "arxiv": ""
    },
    {
        "title": "DEDRIFT: Robust Similarity Search under Content Drift",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Baranchuk_DEDRIFT_Robust_Similarity_Search_under_Content_Drift_ICCV_2023_paper.html",
        "author": "Dmitry Baranchuk, Matthijs Douze, Yash Upadhyay, I. Zeki Yalniz",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Baranchuk_DEDRIFT_Robust_Similarity_Search_under_Content_Drift_ICCV_2023_paper.pdf",
        "aff": "Meta AI; Yandex Research",
        "project": "",
        "github": "",
        "arxiv": "2308.02752"
    },
    {
        "title": "DELFlow: Dense Efficient Learning of Scene Flow for Large-Scale Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Peng_DELFlow_Dense_Efficient_Learning_of_Scene_Flow_for_Large-Scale_Point_ICCV_2023_paper.html",
        "author": "Chensheng Peng, Guangming Wang, Xian Wan Lo, Xinrui Wu, Chenfeng Xu, Masayoshi Tomizuka, Wei Zhan, Hesheng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_DELFlow_Dense_Efficient_Learning_of_Scene_Flow_for_Large-Scale_Point_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Shanghai Jiao Tong University; Mechanical Systems Control Laboratory, University of California, Berkeley",
        "project": "",
        "github": "https://github.com/IRMVLab/DELFlow",
        "arxiv": "2308.04383"
    },
    {
        "title": "DETA: Denoised Task Adaptation for Few-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.html",
        "author": "Ji Zhang, Lianli Gao, Xu Luo, Hengtao Shen, Jingkuan Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.pdf",
        "aff": "Shenzhen Institute for Advanced Study, UESTC; University of Electronic Science and Technology of China (UESTC)",
        "project": "",
        "github": "https://github.com/JimZAI/DETA",
        "arxiv": "2303.06315"
    },
    {
        "title": "DETR Does Not Need Multi-Scale or Locality Design",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_DETR_Does_Not_Need_Multi-Scale_or_Locality_Design_ICCV_2023_paper.html",
        "author": "Yutong Lin, Yuhui Yuan, Zheng Zhang, Chen Li, Nanning Zheng, Han Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_DETR_Does_Not_Need_Multi-Scale_or_Locality_Design_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Applications, and Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University",
        "project": "",
        "github": "https://github.com/impiga/Plain-DETR",
        "arxiv": ""
    },
    {
        "title": "DETRDistill: A Universal Knowledge Distillation Framework for DETR-families",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chang_DETRDistill_A_Universal_Knowledge_Distillation_Framework_for_DETR-families_ICCV_2023_paper.html",
        "author": "Jiahao Chang, Shuo Wang, Hai-Ming Xu, Zehui Chen, Chenhongyi Yang, Feng Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_DETRDistill_A_Universal_Knowledge_Distillation_Framework_for_DETR-families_ICCV_2023_paper.pdf",
        "aff": "University of Adelaide; University of Edinburgh; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2211.10156"
    },
    {
        "title": "DETRs with Collaborative Hybrid Assignments Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.html",
        "author": "Zhuofan Zong, Guanglu Song, Yu Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.pdf",
        "aff": "SenseTime Research",
        "project": "",
        "github": "https://github.com/Sense-X/Co-DETR",
        "arxiv": "2211.12860"
    },
    {
        "title": "DFA3D: 3D Deformable Attention For 2D-to-3D Feature Lifting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_DFA3D_3D_Deformable_Attention_For_2D-to-3D_Feature_Lifting_ICCV_2023_paper.html",
        "author": "Hongyang Li, Hao Zhang, Zhaoyang Zeng, Shilong Liu, Feng Li, Tianhe Ren, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DFA3D_3D_Deformable_Attention_For_2D-to-3D_Feature_Lifting_ICCV_2023_paper.pdf",
        "aff": "DFA3D: 3D Deformable Attention For 2D-to-3D Feature Lifting\nHongyang Li1,3*\u2020Hao Zhang2,3*\u2020Zhaoyang Zeng3Shilong Liu4,3\nFeng Li2,3Tianhe Ren3Lei Zhang1,3\u2021\n1South China University of Technology.\n2The Hong Kong University of Science and Technology.\n3International Digital Economy Academy (IDEA).\n4Dept. of CST., BNRist Center, Institute for AI, Tsinghua University.\nAbstract\nIn this paper, we propose a new operator, called 3D\nDeFormable Attention (DFA3D), for 2D-to-3D feature lift-\ning, which transforms multi-view 2D image features into\na uni\ufb01ed 3D space for 3D object detection. Existing fea-\nture lifting approaches, such as Lift-Splat-based and 2D\nattention-based, either use estimated depth to get pseudo\nLiDAR features and then splat them to a 3D space, which is\na one-pass operation without feature re\ufb01nement, or ignore\ndepth and lift features by 2D attention mechanisms, which\nachieve \ufb01ner semantics while suffering from a depth ambi-\nguity problem. In contrast, our DFA3D-based method \ufb01rst\nleverages the estimated depth to expand each view\u2019s 2D fea-\nture map to 3D and then utilizes DFA3D to aggregate fea-\ntures from the expanded 3D feature maps. With the help\nof DFA3D, the depth ambiguity problem can be effectively\nalleviated from the root, and the lifted features can be pro-\ngressively re\ufb01ned layer by layer, thanks to the Transformer-\nlike architecture. In addition, we propose a mathemati-\ncally equivalent implementation of DFA3D which can sig-\nni\ufb01cantly improve its memory ef\ufb01ciency and computational\nspeed. We integrate DFA3D into several methods that use\n2D attention-based feature lifting with only a few modi\ufb01ca-\ntions in code and evaluate on the nuScenes dataset. The ex-\nperiment results show a consistent improvement of +1.41%\nmAP on average, and up to +15.1% mAP improvement\nwhen high-quality depth information is available, demon-\nstrating the superiority, applicability, and huge potential of\nDFA3D. The code is available at https://github.com/IDEA-\nResearch/3D-deformable-attention.git .\n*This work was done during the internship at IDEA.\n\u2020Equal contribution.\n\u2021Corresponding author.1. Introduction\n3D object detection is a fundamental task in many real-\nworld applications such as robotics and autonomous driv-\ning. Although LiDAR-based methods [ 37,40,23,33] have\nachieved impressive results with the help of accurate 3D\nperception from LiDAR, multi-view camera-based meth-\nods have recently received extensive attention because of\ntheir low cost for deployment and distinctive capability\nof long-range and color perception. Classical multi-view\ncamera-based 3D object detection approaches mostly fol-\nlow monocular frameworks which \ufb01rst perform 2D/3D ob-\nject detection in each individual view and then conduct\ncross-view post-processing to obtain the \ufb01nal result. While\nremarkable progress has been made [ 30,31,24,26,1], such\na framework cannot fully utilize cross-view information and\nusually leads to low performance.\nTo eliminate the ineffective cross-view post-processing,\nseveral end-to-end approaches [ 25,13,10,14,32,20,21]\nhave been developed. These approaches normally contain\nthree important modules: a backbone for 2D image feature\nextraction, a feature lifting module for transforming multi-\nview 2D image features into a uni\ufb01ed 3D space (e.g. BEV\nspace in an ego coordinate system) to obtain lifted features,\nand a detection head for performing object detection by tak-\ning as input the lifted features. Among these modules, the\nfeature lifting module serves as an important component to\nbridge the 2D backbone and the 3D detection head, whose\nquality will greatly affect the \ufb01nal detection performance.\nTo perform feature lifting, recent methods usually pre-\nde\ufb01ne a set of 3D anchors in the ego coordinate sys-\ntem sparsely or uniformly, with randomly initialized con-\ntent features. After that, they lift 2D image features into\nthe 3D anchors to obtain the lifted features. Some meth-\nods [ 13,10,9,34,12] utilize a straightforward lift and\nsplat mechanism [ 25] by \ufb01rst lifting 2D image features into\npseudo LiDAR features in an ego coordinate system using\nestimated depth and then assigning the pseudo LiDAR fea-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n6684\n",
        "project": "",
        "github": "",
        "arxiv": "2307.12972"
    },
    {
        "title": "DG-Recon: Depth-Guided Neural 3D Scene Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.html",
        "author": "Jihong Ju, Ching Wei Tseng, Oleksandr Bailo, Georgi Dikov, Mohsen Ghafoorian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "XR Labs, Qualcomm Technologies, Inc.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DG3D: Generating High Quality 3D Textured Shapes by Learning to Discriminate Multi-Modal Diffusion-Renderings",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zuo_DG3D_Generating_High_Quality_3D_Textured_Shapes_by_Learning_to_ICCV_2023_paper.html",
        "author": "Qi Zuo, Yafei Song, Jianfang Li, Lin Liu, Liefeng Bo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zuo_DG3D_Generating_High_Quality_3D_Textured_Shapes_by_Learning_to_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group",
        "project": "",
        "github": "https://github.com/seakforzq/DG3D",
        "arxiv": ""
    },
    {
        "title": "DIFFGUARD: Semantic Mismatch-Guided Out-of-Distribution Detection Using Pre-Trained Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_DIFFGUARD_Semantic_Mismatch-Guided_Out-of-Distribution_Detection_Using_Pre-Trained_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Ruiyuan Gao, Chenchen Zhao, Lanqing Hong, Qiang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_DIFFGUARD_Semantic_Mismatch-Guided_Out-of-Distribution_Detection_Using_Pre-Trained_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/cure-lab/DiffGuard",
        "arxiv": "2308.07687"
    },
    {
        "title": "DIME-FM : DIstilling Multimodal and Efficient Foundation Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_DIME-FM__DIstilling_Multimodal_and_Efficient_Foundation_Models_ICCV_2023_paper.html",
        "author": "Ximeng Sun, Pengchuan Zhang, Peizhao Zhang, Hardik Shah, Kate Saenko, Xide Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_DIME-FM__DIstilling_Multimodal_and_Efficient_Foundation_Models_ICCV_2023_paper.pdf",
        "aff": "Boston University; Meta AI; Boston University, Meta AI",
        "project": "http://www.cs.bu.edu/~ximengsun/distill-vit/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human Avatars",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Svitov_DINAR_Diffusion_Inpainting_of_Neural_Textures_for_One-Shot_Human_Avatars_ICCV_2023_paper.html",
        "author": "David Svitov, Dmitrii Gudkov, Renat Bashirov, Victor Lempitsky",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Svitov_DINAR_Diffusion_Inpainting_of_Neural_Textures_for_One-Shot_Human_Avatars_ICCV_2023_paper.pdf",
        "aff": "Cinemersive Labs; Samsung AI Center",
        "project": "",
        "github": "",
        "arxiv": "2303.09375"
    },
    {
        "title": "DIRE for Diffusion-Generated Image Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DIRE_for_Diffusion-Generated_Image_Detection_ICCV_2023_paper.html",
        "author": "Zhendong Wang, Jianmin Bao, Wengang Zhou, Weilun Wang, Hezhen Hu, Hong Chen, Houqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DIRE_for_Diffusion-Generated_Image_Detection_ICCV_2023_paper.pdf",
        "aff": "CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China; Microsoft Research Asia; Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; Merchants Union Consumer Finance Company",
        "project": "",
        "github": "https://github.com/ZhendongWang6/DIRE",
        "arxiv": "2303.09295"
    },
    {
        "title": "DISeR: Designing Imaging Systems with Reinforcement Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.html",
        "author": "Tzofi Klinghoffer, Kushagra Tiwary, Nikhil Behari, Bhavya Agrawalla, Ramesh Raskar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.pdf",
        "aff": "Massachusetts Institute of Technology",
        "project": "https://tzofi.github.io/diser",
        "github": "https://github.com/tzofi/diser",
        "arxiv": "2309.13851"
    },
    {
        "title": "DLGSANet: Lightweight Dynamic Local and Global Self-Attention Networks for Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.html",
        "author": "Xiang Li, Jiangxin Dong, Jinhui Tang, Jinshan Pan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology",
        "project": "https://neonleexiang.github.io/DLGSANet/",
        "github": "",
        "arxiv": "2301.02031"
    },
    {
        "title": "DLT: Conditioned layout generation with Joint Discrete-Continuous Diffusion Layout Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Levi_DLT_Conditioned_layout_generation_with_Joint_Discrete-Continuous_Diffusion_Layout_Transformer_ICCV_2023_paper.html",
        "author": "Elad Levi, Eli Brosh, Mykola Mykhailych, Meir Perez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Levi_DLT_Conditioned_layout_generation_with_Joint_Discrete-Continuous_Diffusion_Layout_Transformer_ICCV_2023_paper.pdf",
        "aff": "Wix.com",
        "project": "https://wix-incubator.github.io/DLT",
        "github": "",
        "arxiv": "2303.03755"
    },
    {
        "title": "DMNet: Delaunay Meshing Network for 3D Shape Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DMNet_Delaunay_Meshing_Network_for_3D_Shape_Representation_ICCV_2023_paper.html",
        "author": "Chen Zhang, Ganzhangqin Yuan, Wenbing Tao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DMNet_Delaunay_Meshing_Network_for_3D_Shape_Representation_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artifical Intelligence and Automation, Huazhong University of Science and Technology, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artifical Intelligence and Automation, Huazhong University of Science and Technology, China; TuKe Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-Centric Rendering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_DNA-Rendering_A_Diverse_Neural_Actor_Repository_for_High-Fidelity_Human-Centric_Rendering_ICCV_2023_paper.html",
        "author": "Wei Cheng, Ruixiang Chen, Siming Fan, Wanqi Yin, Keyu Chen, Zhongang Cai, Jingbo Wang, Yang Gao, Zhengming Yu, Zhengyu Lin, Daxuan Ren, Lei Yang, Ziwei Liu, Chen Change Loy, Chen Qian, Wayne Wu, Dahua Lin, Bo Dai, Kwan-Yee Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_DNA-Rendering_A_Diverse_Neural_Actor_Repository_for_High-Fidelity_Human-Centric_Rendering_ICCV_2023_paper.pdf",
        "aff": "Shanghai AI Laboratory; Shanghai AI Laboratory, CUHK; S-Lab, NTU; CUHK; Shanghai AI Laboratory, SenseTime Research; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DOLCE: A Model-Based Probabilistic Diffusion Framework for Limited-Angle CT Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DOLCE_A_Model-Based_Probabilistic_Diffusion_Framework_for_Limited-Angle_CT_Reconstruction_ICCV_2023_paper.html",
        "author": "Jiaming Liu, Rushil Anirudh, Jayaraman J. Thiagarajan, Stewart He, K Aditya Mohan, Ulugbek S. Kamilov, Hyojin Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DOLCE_A_Model-Based_Probabilistic_Diffusion_Framework_for_Limited-Angle_CT_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Washington University in St. Louis; Lawrence Livermore National Laboratory",
        "project": "",
        "github": "",
        "arxiv": "2211.12340"
    },
    {
        "title": "DOT: A Distillation-Oriented Trainer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_DOT_A_Distillation-Oriented_Trainer_ICCV_2023_paper.html",
        "author": "Borui Zhao, Quan Cui, Renjie Song, Jiajun Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DOT_A_Distillation-Oriented_Trainer_ICCV_2023_paper.pdf",
        "aff": "MEGVII Technology; Waseda University",
        "project": "",
        "github": "https://github.com/megvii-research/mdistiller",
        "arxiv": "2307.08436"
    },
    {
        "title": "DPF-Net: Combining Explicit Shape Priors in Deformable Primitive Field for Unsupervised Structural Reconstruction of 3D Objects",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shuai_DPF-Net_Combining_Explicit_Shape_Priors_in_Deformable_Primitive_Field_for_ICCV_2023_paper.html",
        "author": "Qingyao Shuai, Chi Zhang, Kaizhi Yang, Xuejin Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shuai_DPF-Net_Combining_Explicit_Shape_Priors_in_Deformable_Primitive_Field_for_ICCV_2023_paper.pdf",
        "aff": "National Engineering Laboratory for Brain-inspired Intelligence Technology and Application, University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DPM-OT: A New Diffusion Probabilistic Model Based on Optimal Transport",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_DPM-OT_A_New_Diffusion_Probabilistic_Model_Based_on_Optimal_Transport_ICCV_2023_paper.html",
        "author": "Zezeng Li, Shenghao Li, Zhanpeng Wang, Na Lei, Zhongxuan Luo, David Xianfeng Gu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DPM-OT_A_New_Diffusion_Probabilistic_Model_Based_on_Optimal_Transport_ICCV_2023_paper.pdf",
        "aff": "School of Mathematical Sciences, University of the Chinese Academy of Sciences, China; Computer Science and Applied Mathematics, State University of New York at Stony Brook, USA; School of Software, Dalian University of Technology, China",
        "project": "",
        "github": "https://github.com/cognaclee/DPM-OT",
        "arxiv": ""
    },
    {
        "title": "DPS-Net: Deep Polarimetric Stereo Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tian_DPS-Net_Deep_Polarimetric_Stereo_Depth_Estimation_ICCV_2023_paper.html",
        "author": "Chaoran Tian, Weihong Pan, Zimo Wang, Mao Mao, Guofeng Zhang, Hujun Bao, Ping Tan, Zhaopeng Cui",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_DPS-Net_Deep_Polarimetric_Stereo_Depth_Estimation_ICCV_2023_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; State Key Lab of CAD&CG, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DQS3D: Densely-matched Quantization-aware Semi-supervised 3D Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_DQS3D_Densely-matched_Quantization-aware_Semi-supervised_3D_Detection_ICCV_2023_paper.html",
        "author": "Huan-ang Gao, Beiwen Tian, Pengfei Li, Hao Zhao, Guyue Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_DQS3D_Densely-matched_Quantization-aware_Semi-supervised_3D_Detection_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Technology, THU; Institute for AI Industry Research (AIR), THU",
        "project": "",
        "github": "https://github.com/AIR-DISCOVER/DQS3D",
        "arxiv": "2304.13031"
    },
    {
        "title": "DR-Tune: Improving Fine-tuning of Pretrained Visual Models by Distribution Regularization with Semantic Calibration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_DR-Tune_Improving_Fine-tuning_of_Pretrained_Visual_Models_by_Distribution_Regularization_ICCV_2023_paper.html",
        "author": "Nan Zhou, Jiaxin Chen, Di Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_DR-Tune_Improving_Fine-tuning_of_Pretrained_Visual_Models_by_Distribution_Regularization_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Beihang University, Beijing, China; Hangzhou Innovation Institute, Beihang University, Hangzhou, China; State Key Laboratory of Software Development Environment, Beihang University, Beijing, China",
        "project": "",
        "github": "https://github.com/weeknan/DR-Tune",
        "arxiv": ""
    },
    {
        "title": "DRAW: Defending Camera-shooted RAW Against Image Manipulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.html",
        "author": "Xiaoxiao Hu, Qichao Ying, Zhenxing Qian, Sheng Li, Xinpeng Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Fudan University; Key Laboratory of Culture & Tourism Intelligent Computing, Fudan University",
        "project": "",
        "github": "",
        "arxiv": "2307.16418"
    },
    {
        "title": "DREAM: Efficient Dataset Distillation by Representative Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DREAM_Efficient_Dataset_Distillation_by_Representative_Matching_ICCV_2023_paper.html",
        "author": "Yanqing Liu, Jianyang Gu, Kai Wang, Zheng Zhu, Wei Jiang, Yang You",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DREAM_Efficient_Dataset_Distillation_by_Representative_Matching_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Zhejiang University; National University of Singapore, Zhejiang University; National University of Singapore",
        "project": "",
        "github": "https://github.com/lyq312318224/DREAM",
        "arxiv": "2302.14416"
    },
    {
        "title": "DREAMWALKER: Mental Planning for Continuous Vision-Language Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DREAMWALKER_Mental_Planning_for_Continuous_Vision-Language_Navigation_ICCV_2023_paper.html",
        "author": "Hanqing Wang, Wei Liang, Luc Van Gool, Wenguan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DREAMWALKER_Mental_Planning_for_Continuous_Vision-Language_Navigation_ICCV_2023_paper.pdf",
        "aff": "DREAMW ALKER : Mental Planning for Continuous Vision-Language Navigation\nHanqing Wang1, 2Wei Liang1,4\u2217Luc Van Gool2Wenguan Wang3*\n1Beijing Institute of Technology2Computer Vision Lab, ETH Zurich3ReLER, CCAI, Zhejiang University\n4Yangtze Delta Region Academy of Beijing Institute of Technology, Jiaxing\nhttps://github.com/hanqingwangai/Dreamwalker\nAbstract\nVLN-CE is a recently released embodied task, where AI\nagents need to navigate a freely traversable environment toreach a distant target location, given language instructions.It poses great challenges due to the huge space of possible\nstrategies. Driven by the belief that the ability to anticipate\nthe consequences of future actions is crucial for the emer-gence of intelligent and interpretable planning behavior , wepropose D\nREAMWALKER \u2014a world model based VLN-CE\nagent. The world model is built to summarize the visual, to-\npological, and dynamic properties of the complicated conti-\nnuous environment into a discrete, structured, and compactrepresentation. D\nREAMWALKER can simulate and evaluate\npossible plans entirely in such internal abstract world, be-fore executing costly actions. As opposed to existing model-free VLN-CE agents simply making greedy decisions in thereal world, which easily results in shortsighted behaviors,\nD\nREAMWALKER is able to make strategic planning through\nlarge amounts of \u201cmental experiments. \u201d Moreover , the ima-gined future scenarios re\ufb02ect our agent\u2019s intention, makingits decision-making process more transparent. Extensive ex-periments and ablation studies on VLN-CE dataset con\ufb01rmthe effectiveness of the proposed approach and outline fruit-ful directions for future work.\n1. Introduction\nFor decades, the AI community has strived to develop in-\ntelligent robots that can understand human instructions andcarry them out. As a small step towards this long-held goal,\nvision-language navigation (VLN) [ 6] \u2014 the task of entail-\ning autonomous agents to navigate in never-before-seen 3D\nenvironments with language instructions \u2014 gained growingattention. In the standard VLN setting, agent\u2019s movementis constrained to a small set of pre-de\ufb01ned sparse locations.As pointed out by [ 45], such over-simpli\ufb01ed, discrete task\nsetup involves many unrealistic assumptions such as known\n*Corresponding authors.\ncontinuous environment\ntable\nsofa\na\n9al]K\u0003!aKM]\np@H]MmaR@\nU^@SU_S\nvUmUpMK\u0003\nw@yiaU_p\nU^@SU_MK\u0003w@yiaU_p\nInstruction: Head out and turn left. Pass a fireplace and continue \ntowards the sofa. Enter the room and stop when seeing a table . \nFigure 1: In partially observable, continuous VLN environments,\nDREAMWALKER maps its surrounding into a discrete and structured\nabstraction.In this internal world, it is able to conduct mental plan-ning (\n) by imagining future scenarios, before taking real action.\ntopology, perfect localization, and deterministic transition.\nTo better re\ufb02ect the challenges of real world navigation,\nKrantz et al.[45]updatethediscreteVLNtoacontinuousver-\nsion \u2013 VLN-CE (VLN in continuous environments), wherethe agent is free to traverse any unobstructed location with\nlow-level actions. VLN-CE proved much more challenging\nthan its discrete counterpart: the performance gap betweenthe state-of-the-arts in the two settings is more than 20%, interms of episode success rate. The main challenge posed byVLN-CE lies in the demand of strategic planning in conti-\nnuous environments with low-level actions.\nAs a direct response, we developed a world model based\nVLN-CE agent, called D\nREAMWALKER . Previous studies in\ncognitive science [ 17,34,35] suggest that humans build a\nmental model of the local surrounding, based on our limited\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n10873\n",
        "project": "",
        "github": "",
        "arxiv": "2308.07498"
    },
    {
        "title": "DReg-NeRF: Deep Registration for Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DReg-NeRF_Deep_Registration_for_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Yu Chen, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DReg-NeRF_Deep_Registration_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, National University of Singapore",
        "project": "",
        "github": "https://github.com/AIBluefisher/DReg-NeRF",
        "arxiv": ""
    },
    {
        "title": "DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tanveer_DS-Fusion_Artistic_Typography_via_Discriminated_and_Stylized_Diffusion_ICCV_2023_paper.html",
        "author": "Maham Tanveer, Yizhi Wang, Ali Mahdavi-Amiri, Hao Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tanveer_DS-Fusion_Artistic_Typography_via_Discriminated_and_Stylized_Diffusion_ICCV_2023_paper.pdf",
        "aff": "Simon Fraser University",
        "project": "",
        "github": "https://ds-fusion.github.io/",
        "arxiv": ""
    },
    {
        "title": "DVGaze: Dual-View Gaze Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_DVGaze_Dual-View_Gaze_Estimation_ICCV_2023_paper.html",
        "author": "Yihua Cheng, Feng Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_DVGaze_Dual-View_Gaze_Estimation_ICCV_2023_paper.pdf",
        "aff": "Beihang University, Beijing, China",
        "project": "",
        "github": "https://github.com/yihuacheng/DVGaze",
        "arxiv": "2308.10310"
    },
    {
        "title": "DVIS: Decoupled Video Instance Segmentation Framework",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DVIS_Decoupled_Video_Instance_Segmentation_Framework_ICCV_2023_paper.html",
        "author": "Tao Zhang, Xingye Tian, Yu Wu, Shunping Ji, Xuebo Wang, Yuan Zhang, Pengfei Wan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DVIS_Decoupled_Video_Instance_Segmentation_Framework_ICCV_2023_paper.pdf",
        "aff": "Y-tech, Kuaishou Technology; Wuhan University",
        "project": "",
        "github": "https://github.com/zhang-tao-whu/DVIS",
        "arxiv": "2306.03413"
    },
    {
        "title": "Dancing in the Dark: A Benchmark towards General Low-light Video Enhancement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fu_Dancing_in_the_Dark_A_Benchmark_towards_General_Low-light_Video_ICCV_2023_paper.html",
        "author": "Huiyuan Fu, Wenkai Zheng, Xicong Wang, Jiaxuan Wang, Heng Zhang, Huadong Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Dancing_in_the_Dark_A_Benchmark_towards_General_Low-light_Video_ICCV_2023_paper.pdf",
        "aff": "Beijing University of Posts and Telecommunications; Xiaomi",
        "project": "",
        "github": "https://github.com/ciki000/DID",
        "arxiv": ""
    },
    {
        "title": "DandelionNet: Domain Composition with Instance Adaptive Classification for Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_DandelionNet_Domain_Composition_with_Instance_Adaptive_Classification_for_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Lanqing Hu, Meina Kan, Shiguang Shan, Xilin Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DandelionNet_Domain_Composition_with_Instance_Adaptive_Classification_for_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100090, China; University of Chinese Academy of Sciences, Beijing, 100090, China; Peng Cheng Laboratory, Shenzhen, 518055, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100090, China; University of Chinese Academy of Sciences, Beijing, 100090, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DarSwin: Distortion Aware Radial Swin Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Athwale_DarSwin_Distortion_Aware_Radial_Swin_Transformer_ICCV_2023_paper.html",
        "author": "Akshaya Athwale, Arman Afrasiyabi, Justin Lag\u00fce, Ichrak Shili, Ola Ahmad, Jean-Fran\u00e7ois Lalonde",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Athwale_DarSwin_Distortion_Aware_Radial_Swin_Transformer_ICCV_2023_paper.pdf",
        "aff": "Universit\u00e8 Laval, Thales Digital Solutions; Yale University; Universit\u00e8 Laval",
        "project": "https://lvsn.github.io/darswin/",
        "github": "https://github.com/lvsn/darswin",
        "arxiv": ""
    },
    {
        "title": "Dark Side Augmentation: Generating Diverse Night Examples for Metric Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mohwald_Dark_Side_Augmentation_Generating_Diverse_Night_Examples_for_Metric_Learning_ICCV_2023_paper.html",
        "author": "Albert Mohwald, Tomas Jenicek, Ond\u0159ej Chum",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mohwald_Dark_Side_Augmentation_Generating_Diverse_Night_Examples_for_Metric_Learning_ICCV_2023_paper.pdf",
        "aff": "VRG, Faculty of Electrical Engineering, Czech Technical University in Prague",
        "project": "",
        "github": "https://github.com/mohwald/gandtr",
        "arxiv": ""
    },
    {
        "title": "Data Augmented Flatness-aware Gradient Projection for Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Data_Augmented_Flatness-aware_Gradient_Projection_for_Continual_Learning_ICCV_2023_paper.html",
        "author": "Enneng Yang, Li Shen, Zhenyi Wang, Shiwei Liu, Guibing Guo, Xingwei Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Data_Augmented_Flatness-aware_Gradient_Projection_for_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "Data Augmented Flatness-aware Gradient Projection for Continual Learning\nEnneng Yang1Li Shen2*Zhenyi Wang3*Shiwei Liu4Guibing Guo1*Xingwei Wang1\n1Northeastern University, China2JD Explore Academy, China\n3University of Maryland, USA4The University of Texas at Austin, USA\nennengyang@stumail.neu.edu.cn ,{mathshenli,wangzhenyineu }@gmail.com ,\nshiwei.liu@austin.utexas.edu ,{guogb,wangxw }@swc.neu.edu.cn\nAbstract\nThe goal of continual learning (CL) is to continuously\nlearn new tasks without forgetting previously learned old\ntasks. To alleviate catastrophic forgetting, gradient projec-\ntion based CL methods require that the gradient updates of\nnew tasks are orthogonal to the subspace spanned by oldtasks. This limits the learning process and leads to poor\nperformance on the new task due to the projection constraint\nbeing too strong. In this paper , we \ufb01rst revisit the gradientprojection method from the perspective of \ufb02atness of losssurface, and \ufb01nd that un\ufb02atness of the loss surface leadsto catastrophic forgetting of the old tasks when the projec-tion constraint is reduced to improve the performance ofnew tasks. Based on our \ufb01ndings, we propose a Data Aug-\nmented Flatness-aware Gradient Projection (DFGP) method\nto solve the problem, which consists of three modules: data\nand weight perturbation, \ufb02atness-aware optimization, and\ngradient projection. Speci\ufb01cally, we \ufb01rst perform a \ufb02atness-\naware perturbation on the task data and current weights to\n\ufb01nd the case that makes the task loss worst. Next, \ufb02atness-\naware optimization optimizes both the loss and the \ufb02atness\nof the loss surface on raw and worst-case perturbed data to\nobtain a \ufb02atness-aware gradient. Finally, gradient projec-\ntion updates the network with the \ufb02atness-aware gradient\nalong directions orthogonal to the subspace of the old tasks.\nExtensive experiments on four datasets show that our method\nimproves the \ufb02atness of loss surface and the performance of\nnew tasks, and achieves state-of-the-art (SOTA) performance\nin the average accuracy of all tasks.\n1. Introduction\nHumans can learn a series of continuously encountered\ntasks without forgetting previously learned knowledge. In\nrecent years, many researches target for making the neu-\nral network achieve continual learning (CL) ability like hu-\n*Corresponding author.Figure 1: New tasks\u2019 accuracy (Higher Better) of GPM,\nSGD, and MTL on CIFAR-100 dataset, where a signi\ufb01cant\nperformance gap exists between GPM and SGD/MTL.\nmans [ 38,47]. One of the main challenge of CL is to mitigate\nthe catastrophic forgetting [ 40,17,53] of the knowledge of\nprevious tasks when learning new tasks [ 51].\nTo alleviate catastrophic forgetting of old tasks, several\nworks [ 57,15,8,27,43] propose to constrain the gradient\nupdate direction of the new tasks. The new tasks only update\nthe network along the orthogonal direction to the gradientsubspaces deemed for the old tasks. Compared to other\nmethods, the recently proposed Gradient Projection Memory\n(GPM) [ 43] shows better performance in CL. However, we\nobserve poor performance for the new tasks in GPM. As\nshown in Fig. 1, by comparing vanilla SGD (which learns\nnew tasks without any gradient constraints) or MTL (which\nlearns all tasks simultaneously and can be seen as an upper\nbound for CL) with GPM, we \ufb01nd that the performance of\nnew tasks with GPM has a large gap compared with SGD and\nMTL. When learning the 10-th task T10, MTL and SGD can\nachieve 85.40% and 83.00% accuracy, respectively, while\nGPM can only achieve 74.50%. This vast gap has prompted\nus to explore the reasons behind it and devise effective ways\nto address this issue.\nIn this paper, we \ufb01rst revisit the \u2018stability-plasticity\u2019\ndilemma [ 33] in GPM from the perspective of the \ufb02atness\nof loss surface (we provide the formal de\ufb01nition of \ufb02atness\nin the appendix). We \ufb01nd that the projection threshold inGPM is a key factor in improving the performance of new\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n5630\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Data-Free Class-Incremental Hand Gesture Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Aich_Data-Free_Class-Incremental_Hand_Gesture_Recognition_ICCV_2023_paper.html",
        "author": "Shubhra Aich, Jesus Ruiz-Santaquiteria, Zhenyu Lu, Prachi Garg, K J Joseph, Alvaro Fernandez Garcia, Vineeth N Balasubramanian, Kenrick Kin, Chengde Wan, Necati Cihan Camgoz, Shugao Ma, Fernando De la Torre",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Data-Free_Class-Incremental_Hand_Gesture_Recognition_ICCV_2023_paper.pdf",
        "aff": "Meta Reality Labs; Carnegie Mellon University; Indian Institute of Technology Hyderabad",
        "project": "",
        "github": "https://github.com/humansensinglab/dfcil-hgr",
        "arxiv": ""
    },
    {
        "title": "Data-free Knowledge Distillation for Fine-grained Visual Categorization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Data-free_Knowledge_Distillation_for_Fine-grained_Visual_Categorization_ICCV_2023_paper.html",
        "author": "Renrong Shao, Wei Zhang, Jianhua Yin, Jun Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Data-free_Knowledge_Distillation_for_Fine-grained_Visual_Categorization_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Technology, Shandong University; School of Computer Science and Technology, East China Normal University",
        "project": "",
        "github": "https://github.com/RoryShao/DFKD-FGVC.git",
        "arxiv": ""
    },
    {
        "title": "DataDAM: Efficient Dataset Distillation with Attention Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sajedi_DataDAM_Efficient_Dataset_Distillation_with_Attention_Matching_ICCV_2023_paper.html",
        "author": "Ahmad Sajedi, Samir Khaki, Ehsan Amjadian, Lucy Z. Liu, Yuri A. Lawryshyn, Konstantinos N. Plataniotis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sajedi_DataDAM_Efficient_Dataset_Distillation_with_Attention_Matching_ICCV_2023_paper.pdf",
        "aff": "University of Toronto; Royal Bank of Canada (RBC)",
        "project": "",
        "github": "https://github.com/DataDistillation/DataDAM",
        "arxiv": ""
    },
    {
        "title": "Dataset Quantization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Dataset_Quantization_ICCV_2023_paper.html",
        "author": "Daquan Zhou, Kai Wang, Jianyang Gu, Xiangyu Peng, Dongze Lian, Yifan Zhang, Yang You, Jiashi Feng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Dataset_Quantization_ICCV_2023_paper.pdf",
        "aff": "Bytedance Inc.; National University of Singapore",
        "project": "",
        "github": "https://github.com/magic-research/Dataset_Quantization",
        "arxiv": "2308.10524"
    },
    {
        "title": "DeFormer: Integrating Transformers with Deformable Models for 3D Shape Abstraction from a Single Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DeFormer_Integrating_Transformers_with_Deformable_Models_for_3D_Shape_Abstraction_ICCV_2023_paper.html",
        "author": "Di Liu, Xiang Yu, Meng Ye, Qilong Zhangli, Zhuowei Li, Zhixing Zhang, Dimitris N. Metaxas",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DeFormer_Integrating_Transformers_with_Deformable_Models_for_3D_Shape_Abstraction_ICCV_2023_paper.pdf",
        "aff": "Rutgers University; Amazon Prime Video",
        "project": "",
        "github": "",
        "arxiv": "2309.12594"
    },
    {
        "title": "DeLiRa: Self-Supervised Depth, Light, and Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guizilini_DeLiRa_Self-Supervised_Depth_Light_and_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Vitor Guizilini, Igor Vasiljevic, Jiading Fang, Rares Ambrus, Sergey Zakharov, Vincent Sitzmann, Adrien Gaidon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_DeLiRa_Self-Supervised_Depth_Light_and_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "Toyota Research Institute (TRI), Los Altos, CA; Massachusetts Institute of Technology (MIT), Cambridge, MA; Toyota Technological Institute of Chicago (TTIC), Chicago, IL",
        "project": "https://sites.google.com/view/tri-delira",
        "github": "",
        "arxiv": "2304.02797"
    },
    {
        "title": "Dec-Adapter: Exploring Efficient Decoder-Side Adapter for Bridging Screen Content and Natural Image Compression",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Dec-Adapter_Exploring_Efficient_Decoder-Side_Adapter_for_Bridging_Screen_Content_and_ICCV_2023_paper.html",
        "author": "Sheng Shen, Huanjing Yue, Jingyu Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Dec-Adapter_Exploring_Efficient_Decoder-Side_Adapter_for_Bridging_Screen_Content_and_ICCV_2023_paper.pdf",
        "aff": "Tianjin University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Decomposition-Based Variational Network for Multi-Contrast MRI Super-Resolution and Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.html",
        "author": "Pengcheng Lei, Faming Fang, Guixu Zhang, Tieyong Zeng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Technology, East China Normal University; KLATASDS-MOE; Department of Mathematics, Chinese University of Hong Kong; School of Computer Science and Technology, East China Normal University",
        "project": "",
        "github": "https://github.com/lpcccc-cv/MC-VarNet",
        "arxiv": ""
    },
    {
        "title": "Decouple Before Interact: Multi-Modal Prompt Learning for Continual Visual Question Answering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Decouple_Before_Interact_Multi-Modal_Prompt_Learning_for_Continual_Visual_Question_ICCV_2023_paper.html",
        "author": "Zi Qian, Xin Wang, Xuguang Duan, Pengda Qin, Yuhong Li, Wenwu Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Decouple_Before_Interact_Multi-Modal_Prompt_Learning_for_Continual_Visual_Question_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group; Department of Computer Science and Technology, BNRist, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Decoupled DETR: Spatially Disentangling Localization and Classification for Improved End-to-End Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Decoupled_DETR_Spatially_Disentangling_Localization_and_Classification_for_Improved_End-to-End_ICCV_2023_paper.html",
        "author": "Manyuan Zhang, Guanglu Song, Yu Liu, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Decoupled_DETR_Spatially_Disentangling_Localization_and_Classification_for_Improved_End-to-End_ICCV_2023_paper.pdf",
        "aff": "Multimedia Laboratory, The Chinese University of HongKong; Centre for Perceptual and Interactive Intelligence Limited; Shanghai AI Laboratory; SenseTime Research; Multimedia Laboratory, The Chinese University of HongKong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Decoupled Iterative Refinement Framework for Interacting Hands Reconstruction from a Single RGB Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Decoupled_Iterative_Refinement_Framework_for_Interacting_Hands_Reconstruction_from_a_ICCV_2023_paper.html",
        "author": "Pengfei Ren, Chao Wen, Xiaozheng Zheng, Zhou Xue, Haifeng Sun, Qi Qi, Jingyu Wang, Jianxin Liao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Decoupled_Iterative_Refinement_Framework_for_Interacting_Hands_Reconstruction_from_a_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications; PICO IDL, ByteDance, Beijing",
        "project": "",
        "github": "",
        "arxiv": "2302.02410"
    },
    {
        "title": "DeePoint: Visual Pointing Recognition and Direction Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nakamura_DeePoint_Visual_Pointing_Recognition_and_Direction_Estimation_ICCV_2023_paper.html",
        "author": "Shu Nakamura, Yasutomo Kawanishi, Shohei Nobuhara, Ko Nishino",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_DeePoint_Visual_Pointing_Recognition_and_Direction_Estimation_ICCV_2023_paper.pdf",
        "aff": "Graduate School of Informatics, Kyoto University and RIKEN; RIKEN; Graduate School of Informatics, Kyoto University",
        "project": "https://vision.ist.i.kyoto-u.ac.jp/ https://grp.riken.jp/",
        "github": "",
        "arxiv": "2304.06977"
    },
    {
        "title": "Deep Active Contours for Real-time 6-DoF Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Active_Contours_for_Real-time_6-DoF_Object_Tracking_ICCV_2023_paper.html",
        "author": "Long Wang, Shen Yan, Jianan Zhen, Yu Liu, Maojun Zhang, Guofeng Zhang, Xiaowei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Active_Contours_for_Real-time_6-DoF_Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "National University of Defense Technology; Zhejiang University; SenseTime Research",
        "project": "https://zju3dv.github.io/deep_ac/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Deep Directly-Trained Spiking Neural Networks for Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.html",
        "author": "Qiaoyi Su, Yuhong Chou, Yifan Hu, Jianing Li, Shijie Mei, Ziyang Zhang, Guoqi Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences; Department of Precision Instrument, Tsinghua University; College of Artificial Intelligence, Xi\u2019an Jiaotong University; Institute of Automation, Chinese Academy of Sciences; School of Computer Science, Peking University; Advanced Computing and Storage Lab, Huawei Technologies Co. Ltd.; School of Vehicle and Mobility, Tsinghua University",
        "project": "",
        "github": "https://github.com/BICLab/EMS-YOLO",
        "arxiv": "2307.11411"
    },
    {
        "title": "Deep Equilibrium Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Equilibrium_Object_Detection_ICCV_2023_paper.html",
        "author": "Shuai Wang, Yao Teng, Limin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Equilibrium_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "(IIT )UYMPMFVMYQ 3FNIGX(IXIGXMSR\n7LYEM ;ERK\u0015=ES 8IRK\u00150MQMR;ERK\u0015\u0010\u0016\u0010\n\u00157XEXI /I]0EFSVEXSV] JSV 2SZIP 7SJX[EVI8IGLRSPSK]\u0010 2ERNMRK9RMZIVWMX]\u00167LERKLEM%-0EF\nLXXTW\u001e\u0013\u0013KMXLYF\u0012GSQ\u00131'+\u00112.9\u0013()5(IX\n%FWXVEGX\n5YIV]\u0011FEWIHSFNIGX HIXIGXSVWHMVIGXP]HIGSHI MQEKI JIE\u0011\nERI[UYIV]\u0011FEWIHSFNIGXHIXIGXSV\f()5(IX\rF] HIWMKRMRK\nMQ\u0011\nX[S\u0011WXITYRVSPPIHIUYMPMFVMYQIUYEXMSRXSI\\TPMGMXP]GETXYVI\nXSWXEFMPM^IXLIXVEMRMRKSJSYV ()5(IXERHMQTVSZIMXW KIR\u0011\nTIVXYVFEXMSR\f6%4\r\u0012 3YV I\\TIVMQIRXW HIQSRWXVEXI ()5(IX\n\u0018\u001d\u001e\u0019 \u0017\u0017\u001e\u0014W\n'3'3FIRGLQEVOYRHIV \u0016XVEMRMRK WGLIQI \f\u0016\u0018 ITSGLW\r\u0012\n\u0015\u0012-RXVSHYGXMSR\n3FNIGX HIXIGXMSR ? \u0017\u0017\u0010\u0016\u0018\u0010\u001a\u0010\u0017\u0019\u0010\u0015\u0018A MWE JYRHEQIRXEPXEWO\nPSGEXMSRWERHGEXIKSVMIWSJEPPSFNIGX MRWXERGIWMR ERMQEKI\u0012\n\u0016\u001b\u0017\u0017\u0019 \u0015\u0015\u0018\u0018\u0016\u0014\nXLIWI QSHIPW\u0010SRI\u0011WXEKISFNIGX HIXIGXSVW? \u0016\u001b\u0010\u0017\u001c\u0010\u0016\u0018\u0010\u0018\u0019AHM\u0011\n\u001e 'SVVIWTSRHMRK EYXLSV \fPQ[ERK$RNY\u0012IHY\u0012GR\r\u0012\u0014VW\u0010\n'HFRGHU\u0003/D\\HU\n^\u019a\u0102\u0150\u011e\u0190\n0XOWL\u0010VFDOH\u0003IHDWXUHV\nWK\u0010\n'HFRGHU\u0003/D\\HU\u0015UG\u0010\n'HFRGHU\u0003/D\\HU\u0358\u0358\u0358&RQWHQW\u00039HFWRUV\n3RVLWLRQDO\u00039HFWRUV&RQWHQW\u00039HFWRUV\n3RVLWLRQDO\u00039HFWRUV\n\fE\r **2 ZMI[ SR UYIV]\u0011FEWIH SFNIGX HIXIGXSV\u0012\n,QLWLDOL]DWLRQ\u0003\n/D\\HU\n^\u019a\u0102\u0150\u011e\u0190\n0XOWL\u0010VFDOH\u0003IHDWXUHV\n'HFRGHU\u0003/D\\HU&RQWHQW\u00039HFWRUV\n3RVLWLRQDO\u00039HFWRUV&RQWHQW\u00039HFWRUV\n3RVLWLRQDO\u00039HFWRUV&RQWHQW\u00039HFWRUV\n3RVLWLRQDO\u00039HFWRUV\n\fF\r 622 ZMI[ SR UYIV]\u0011FEWIH SFNIGX HIXIGXSV\u0012\n,QLWLDOL]DWLRQ\u0003\n/D\\HU\n0XOWL\u0010VFDOH\u0003IHDWXUHV\n&RQWHQW\u00039HFWRUV\n3RVLWLRQDO\u00039HFWRUV&RQWHQW\u00039HFWRUV\n3RVLWLRQDO\u00039HFWRUV^\u019a\u0102\u0150\u011e\u0190\n,PSOLFLW\u0003/D\\HU\n^\u017d\u016f\u01c0\u015d\u0176\u0150\u0357\u0003&RQWHQW\u00039HFWRUV\n3RVLWLRQDO\u00039HFWRUV'HFRGHU\u0003/D\\HU\n\fG\r 3YV()5(IX ZMI[ SRUYIV]\u0011FEWIH SFNIGX HIXIGXSV\u0012\nWLEVIHHIGSHIVPE]IVW I\u0012K\u0012%H E1M\\ IV? \u0015\u0018A\fF \r-R622ZMI [ \u0010\n\u0017\u0017\u0015\u001a\n\u001a\u0017\u0019\u0015\u0018\nUYIVMIWERHWIZIVEPWXEGOIHRSR\u0011WLEVIHHIGSHIV PE]IVW\fI\u0012K\u0012\n\u001a \u0017\u0019\n\u0015\u0018\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n6296\n",
        "project": "",
        "github": "",
        "arxiv": "2308.09564"
    },
    {
        "title": "Deep Feature Deblurring Diffusion for Detecting Out-of-Distribution Objects",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Deep_Feature_Deblurring_Diffusion_for_Detecting_Out-of-Distribution_Objects_ICCV_2023_paper.html",
        "author": "Aming Wu, Da Chen, Cheng Deng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Deep_Feature_Deblurring_Diffusion_for_Detecting_Out-of-Distribution_Objects_ICCV_2023_paper.pdf",
        "aff": "University of Bath; School of Electronic Engineering, Xidian University, Xi'an, China",
        "project": "",
        "github": "https://github.com/AmingWu/DFDD-OOD",
        "arxiv": ""
    },
    {
        "title": "Deep Fusion Transformer Network with Weighted Vector-Wise Keypoints Voting for Robust 6D Object Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Deep_Fusion_Transformer_Network_with_Weighted_Vector-Wise_Keypoints_Voting_for_ICCV_2023_paper.html",
        "author": "Jun Zhou, Kai Chen, Linlin Xu, Qi Dou, Jing Qin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Deep_Fusion_Transformer_Network_with_Weighted_Vector-Wise_Keypoints_Voting_for_ICCV_2023_paper.pdf",
        "aff": "University of Waterloo; The Hong Kong Polytechnic University; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/junzastar/DFTr Voting",
        "arxiv": "2308.05438"
    },
    {
        "title": "Deep Geometrized Cartoon Line Inbetweening",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.html",
        "author": "Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf",
        "aff": "Lexica; S-Lab, Nanyang Technological University; Southeast University",
        "project": "",
        "github": "https://github.com/lisiyao21/AnimeInbet",
        "arxiv": ""
    },
    {
        "title": "Deep Geometry-Aware Camera Self-Calibration from Video",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hagemann_Deep_Geometry-Aware_Camera_Self-Calibration_from_Video_ICCV_2023_paper.html",
        "author": "Annika Hagemann, Moritz Knorr, Christoph Stiller",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hagemann_Deep_Geometry-Aware_Camera_Self-Calibration_from_Video_ICCV_2023_paper.pdf",
        "aff": "Karlsruhe Institute of Technology; Bosch Research, Germany",
        "project": "",
        "github": "https://github.com/boschresearch/droidcalib",
        "arxiv": ""
    },
    {
        "title": "Deep Homography Mixture for Single Image Rolling Shutter Correction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.html",
        "author": "Weilong Yan, Robby T. Tan, Bing Zeng, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; National University of Singapore",
        "project": "",
        "github": "https://github.com/DavidYan2001/Deep_HM",
        "arxiv": ""
    },
    {
        "title": "Deep Image Harmonization with Globally Guided Feature Transformation and Relation Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.html",
        "author": "Li Niu, Linfeng Tan, Xinhao Tao, Junyan Cao, Fengjun Guo, Teng Long, Liqing Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.pdf",
        "aff": "INTSIG; Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/bcmi/Image-Harmonization-Dataset-ccHarmony",
        "arxiv": "2308.00356"
    },
    {
        "title": "Deep Image Harmonization with Learnable Augmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.html",
        "author": "Li Niu, Junyan Cao, Wenyan Cong, Liqing Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.pdf",
        "aff": "University of Texas at Austin; Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/bcmi/SycoNet-Adaptive-Image-Harmonization",
        "arxiv": "2308.00376"
    },
    {
        "title": "Deep Incubation: Training Large Models by Divide-and-Conquering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ni_Deep_Incubation_Training_Large_Models_by_Divide-and-Conquering_ICCV_2023_paper.html",
        "author": "Zanlin Ni, Yulin Wang, Jiangwei Yu, Haojun Jiang, Yue Cao, Gao Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Deep_Incubation_Training_Large_Models_by_Divide-and-Conquering_ICCV_2023_paper.pdf",
        "aff": "Beijing Academy of Artificial Intelligence, Beijing, China; Department of Automation, BNRist, Tsinghua University, Beijing, China; Beijing Academy of Artificial Intelligence, Beijing, China; Department of Automation, BNRist, Tsinghua University, Beijing, China",
        "project": "",
        "github": "https://github.com/LeapLabTHU/Deep-Incubation",
        "arxiv": "2212.04129"
    },
    {
        "title": "Deep Multitask Learning with Progressive Parameter Sharing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.html",
        "author": "Haosen Shi, Shen Ren, Tianwei Zhang, Sinno Jialin Pan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.pdf",
        "aff": "Continental Automotive Singapore; Nanyang Technological University; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Deep Multiview Clustering by Contrasting Cluster Assignments",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Deep_Multiview_Clustering_by_Contrasting_Cluster_Assignments_ICCV_2023_paper.html",
        "author": "Jie Chen, Hua Mao, Wai Lok Woo, Xi Peng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Deep_Multiview_Clustering_by_Contrasting_Cluster_Assignments_ICCV_2023_paper.pdf",
        "aff": "College of Computer Science, Sichuan University, China; Department of Computer and Information Sciences, Northumbria University",
        "project": "",
        "github": "",
        "arxiv": "2304.10769"
    },
    {
        "title": "Deep Optics for Video Snapshot Compressive Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Optics_for_Video_Snapshot_Compressive_Imaging_ICCV_2023_paper.html",
        "author": "Ping Wang, Lishun Wang, Xin Yuan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Optics_for_Video_Snapshot_Compressive_Imaging_ICCV_2023_paper.pdf",
        "aff": "School of Engineering, Westlake University; Zhejiang University, School of Engineering, Westlake University",
        "project": "",
        "github": "https://github.com/pwangcs/DeepOpticsSCI",
        "arxiv": ""
    },
    {
        "title": "Deep Video Demoireing via Compact Invertible Dyadic Decomposition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Deep_Video_Demoireing_via_Compact_Invertible_Dyadic_Decomposition_ICCV_2023_paper.html",
        "author": "Yuhui Quan, Haoran Huang, Shengfeng He, Ruotao Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Deep_Video_Demoireing_via_Compact_Invertible_Dyadic_Decomposition_ICCV_2023_paper.pdf",
        "aff": "; the final published version of the proceedings is available on IEEE Xplore.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DeepChange: A Long-Term Person Re-Identification Benchmark with Clothes Change",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_DeepChange_A_Long-Term_Person_Re-Identification_Benchmark_with_Clothes_Change_ICCV_2023_paper.html",
        "author": "Peng Xu, Xiatian Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_DeepChange_A_Long-Term_Person_Re-Identification_Benchmark_with_Clothes_Change_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; University of Surrey",
        "project": "",
        "github": "https://github.com/PengBoXiangShang/deepchange",
        "arxiv": ""
    },
    {
        "title": "DeformToon3D: Deformable Neural Radiance Fields for 3D Toonification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DeformToon3D_Deformable_Neural_Radiance_Fields_for_3D_Toonification_ICCV_2023_paper.html",
        "author": "Junzhe Zhang, Yushi Lan, Shuai Yang, Fangzhou Hong, Quan Wang, Chai Kiat Yeo, Ziwei Liu, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DeformToon3D_Deformable_Neural_Radiance_Fields_for_3D_Toonification_ICCV_2023_paper.pdf",
        "aff": "SenseTime Research; Nanyang Technological University; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/junzhezhang/DeformToon3D",
        "arxiv": ""
    },
    {
        "title": "Deformable Model-Driven Neural Rendering for High-Fidelity 3D Reconstruction of Human Heads Under Low-View Settings",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Deformable_Model-Driven_Neural_Rendering_for_High-Fidelity_3D_Reconstruction_of_Human_ICCV_2023_paper.html",
        "author": "Baixin Xu, Jiarui Zhang, Kwan-Yee Lin, Chen Qian, Ying He",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Deformable_Model-Driven_Neural_Rendering_for_High-Fidelity_3D_Reconstruction_of_Human_ICCV_2023_paper.pdf",
        "aff": "Peking University; The Chinese University of Hong Kong; SenseTime Research; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/xubaixinxbx/3dheads",
        "arxiv": "2303.13855"
    },
    {
        "title": "Deformable Neural Radiance Fields using RGB and Event Cameras",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Deformable_Neural_Radiance_Fields_using_RGB_and_Event_Cameras_ICCV_2023_paper.html",
        "author": "Qi Ma, Danda Pani Paudel, Ajad Chhatkuli, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Deformable_Neural_Radiance_Fields_using_RGB_and_Event_Cameras_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Lab, ETH Zurich and INSAIT, Sofia University; Computer Vision Lab, ETH Zurich; Computer Vision Lab, ETH Zurich and VISICS, ESAT/PSI, KU Leuven and INSAIT, Sofia University",
        "project": "",
        "github": "https://qimaqi.github.io/DE-NeRF",
        "arxiv": "2309.08416"
    },
    {
        "title": "Deformer: Dynamic Fusion Transformer for Robust Hand Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fu_Deformer_Dynamic_Fusion_Transformer_for_Robust_Hand_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Qichen Fu, Xingyu Liu, Ran Xu, Juan Carlos Niebles, Kris M. Kitani",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Deformer_Dynamic_Fusion_Transformer_for_Robust_Hand_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "Deformer: Dynamic Fusion Transformer for Robust Hand Pose Estimation\nQichen Fu1Xingyu Liu1Ran Xu2Juan Carlos Niebles2Kris M. Kitani1\n1Carnegie Mellon University2Salesforce Research\nAbstract\nAccurately estimating 3D hand pose is crucial for under-\nstanding how humans interact with the world. Despite re-\nmarkable progress, existing methods often struggle to gen-\nerate plausible hand poses when the hand is heavily oc-\ncluded or blurred. In videos, the movements of the hand al-\nlow us to observe various parts of the hand that may be oc-\ncluded or blurred in a single frame. To adaptively leverage\nthe visual clue before and after the occlusion or blurring for\nrobust hand pose estimation, we propose the Deformer: a\nframework that implicitly reasons about the relationship be-\ntween hand parts within the same image (spatial dimension)\nand different timesteps (temporal dimension). We show that\na naive application of the transformer self-attention mech-\nanism is not sufficient because motion blur or occlusions\nin certain frames can lead to heavily distorted hand fea-\ntures and generate imprecise keys and queries. To address\nthis challenge, we incorporate a Dynamic Fusion Module\ninto Deformer, which predicts the deformation of the hand\nand warps the hand mesh predictions from nearby frames\nto explicitly support the current frame estimation. Further-\nmore, we have observed that errors are unevenly distributed\nacross different hand parts, with vertices around fingertips\nhaving disproportionately higher errors than those around\nthe palm. We mitigate this issue by introducing a new\nloss function called maxMSE that automatically adjusts the\nweight of every vertex to focus the model on critical hand\nparts. Extensive experiments show that our method signifi-\ncantly outperforms state-of-the-art methods by 10%, and is\nmore robust to occlusions (over 14%).\n1. Introduction\nAccurately estimating hand poses in the wild is a chal-\nlenging task that is affected by various factors, including ob-\nject occlusion, self-occlusion, motion blur, and low camera\nexposure. To address these challenges, temporal informa-\ntion can be leveraged using a self-attention mechanism [52]\nthat reasons the feature correlation between adjacent frames\nto generate better hand pose estimations. However, as the\ngeneration of key and query vectors depends on per-frame\nVertex ErrorOurs\nTCMR\nInput Frames\nTimeFigure 1: Given a video where in some frames ( left) the\nhand is heavily occluded or blurred, the existing state-of-\nthe-art video-based method TCMR [10] ( middle ) fails to\npredict accurate hand poses. Our method ( right ) is able\nto capture the hand dynamics and leverage neighborhood\nframes to robustly produce plausible hand pose estimations.\nfeatures, heavy occlusion or blurring can significantly con-\ntaminate them, resulting in inaccurate output. Another chal-\nlenge of hand pose estimation is that the fingertips, located\nat the periphery of the hand, are more prone to occlusion\nand have more complex motion patterns, making them par-\nticularly challenging for the model to estimate accurately.\nTo tackle the aforementioned challenges, we propose\nDeformer: a dynamic fusion transformer that leverages\nnearby frames to learn hand deformations and assemble\nmultiple wrapped hand poses from nearby frames for a ro-\nbust hand pose estimation in the current frame. Deformer\nimplicitly models the temporal correlations between adja-\ncent frames and automatically selects frames to focus on.\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n23600\n",
        "project": "",
        "github": "",
        "arxiv": "2303.04991"
    },
    {
        "title": "Degradation-Resistant Unfolding Network for Heterogeneous Image Fusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Degradation-Resistant_Unfolding_Network_for_Heterogeneous_Image_Fusion_ICCV_2023_paper.html",
        "author": "Chunming He, Kai Li, Guoxia Xu, Yulun Zhang, Runze Hu, Zhenhua Guo, Xiu Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Degradation-Resistant_Unfolding_Network_for_Heterogeneous_Image_Fusion_ICCV_2023_paper.pdf",
        "aff": "Tianyi Traffic Technology; Beijing Institute of Technology; Smart Vision; ETH Z\u00fcrich; NEC Laboratories America; Shenzhen International Graduate School, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Delicate Textured Mesh Recovery from NeRF via Adaptive Surface Refinement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Delicate_Textured_Mesh_Recovery_from_NeRF_via_Adaptive_Surface_Refinement_ICCV_2023_paper.html",
        "author": "Jiaxiang Tang, Hang Zhou, Xiaokang Chen, Tianshu Hu, Errui Ding, Jingdong Wang, Gang Zeng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Delicate_Textured_Mesh_Recovery_from_NeRF_via_Adaptive_Surface_Refinement_ICCV_2023_paper.pdf",
        "aff": "Baidu Inc.; Key Lab. of Machine Perception (MoE), School of IST, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2303.02091"
    },
    {
        "title": "Delta Denoising Score",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hertz_Delta_Denoising_Score_ICCV_2023_paper.html",
        "author": "Amir Hertz, Kfir Aberman, Daniel Cohen-Or,",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hertz_Delta_Denoising_Score_ICCV_2023_paper.pdf",
        "aff": "Google Research, Tel Aviv University; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2304.07090"
    },
    {
        "title": "Delving into Motion-Aware Matching for Monocular 3D Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_paper.html",
        "author": "Kuan-Chih Huang, Ming-Hsuan Yang, Yi-Hsuan Tsai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "University of California, Merced, Google, Yonsei University; University of California, Merced; Google",
        "project": "",
        "github": "https://github.com/kuanchihhuang/MoMA-M3T",
        "arxiv": "2308.11607"
    },
    {
        "title": "Democratising 2D Sketch to 3D Shape Retrieval Through Pivoting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.html",
        "author": "Pinaki Nath Chowdhury, Ayan Kumar Bhunia, Aneeshan Sain, Subhadeep Koley, Tao Xiang, Yi-Zhe Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.pdf",
        "aff": "SketchX, CVSSP, University of Surrey, United Kingdom; iFlyTek-Surrey Joint Research Centre on Artificial Intelligence.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Denoising Diffusion Autoencoders are Unified Self-supervised Learners",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Denoising_Diffusion_Autoencoders_are_Unified_Self-supervised_Learners_ICCV_2023_paper.html",
        "author": "Weilai Xiang, Hongyu Yang, Di Huang, Yunhong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Denoising_Diffusion_Autoencoders_are_Unified_Self-supervised_Learners_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Beihang University, Beijing, China; Institute of Artificial Intelligence, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China",
        "project": "",
        "github": "github.com/FutureXiang/ddae",
        "arxiv": "2303.09769"
    },
    {
        "title": "Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yun_Dense_2D-3D_Indoor_Prediction_with_Sound_via_Aligned_Cross-Modal_Distillation_ICCV_2023_paper.html",
        "author": "Heeseung Yun, Joonil Na, Gunhee Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Dense_2D-3D_Indoor_Prediction_with_Sound_via_Aligned_Cross-Modal_Distillation_ICCV_2023_paper.pdf",
        "aff": "Seoul National University",
        "project": "",
        "github": "https://github.com/hs-yn/DAPS",
        "arxiv": "2309.11081"
    },
    {
        "title": "Dense Text-to-Image Generation with Attention Modulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.html",
        "author": "Yunji Kim, Jiyoung Lee, Jin-Hwa Kim, Jung-Woo Ha, Jun-Yan Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.pdf",
        "aff": "NAVER AI Lab; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/naver-ai/DenseDiffusion",
        "arxiv": "2308.12964"
    },
    {
        "title": "DenseShift: Towards Accurate and Efficient Low-Bit Power-of-Two Quantization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_DenseShift_Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization_ICCV_2023_paper.html",
        "author": "Xinlin Li, Bang Liu, Rui Heng Yang, Vanessa Courville, Chao Xing, Vahid Partovi Nia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DenseShift_Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization_ICCV_2023_paper.pdf",
        "aff": "University of Montreal & Mila - Quebec AI Institute; Noah\u2019s Ark Lab, Huawei Technologies.",
        "project": "",
        "github": "https://github.com/...",
        "arxiv": "2208.09708"
    },
    {
        "title": "Density-invariant Features for Distant Point Cloud Registration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Density-invariant_Features_for_Distant_Point_Cloud_Registration_ICCV_2023_paper.html",
        "author": "Quan Liu, Hongzi Zhu, Yunsong Zhou, Hongyang Li, Shan Chang, Minyi Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Density-invariant_Features_for_Distant_Point_Cloud_Registration_ICCV_2023_paper.pdf",
        "aff": "Shanghai AI Lab; Donghua University; Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/liuQuan98/GCL",
        "arxiv": "2307.09788"
    },
    {
        "title": "Designing Phase Masks for Under-Display Cameras",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Designing_Phase_Masks_for_Under-Display_Cameras_ICCV_2023_paper.html",
        "author": "Anqi Yang, Eunhee Kang, Hyong-Euk Lee, Aswin C. Sankaranarayanan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Designing_Phase_Masks_for_Under-Display_Cameras_ICCV_2023_paper.pdf",
        "aff": "Samsung Advanced Institute of Technology, Suwon-si, South Korea; Carnegie Mellon University, Pittsburgh, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DetZero: Rethinking Offboard 3D Object Detection with Long-term Sequential Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_DetZero_Rethinking_Offboard_3D_Object_Detection_with_Long-term_Sequential_Point_ICCV_2023_paper.html",
        "author": "Tao Ma, Xuemeng Yang, Hongbin Zhou, Xin Li, Botian Shi, Junjie Liu, Yuchen Yang, Zhizheng Liu, Liang He, Yu Qiao, Yikang Li, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_DetZero_Rethinking_Offboard_3D_Object_Detection_with_Long-term_Sequential_Point_ICCV_2023_paper.pdf",
        "aff": "DetZero: Rethinking Offboard 3D Object Detection with Long-term Sequential\nPoint Clouds\nTao Ma1,2* Xuemeng Yang2Hongbin Zhou2Xin Li3,2\u2217Botian Shi2Junjie Liu4\u2217\nYuchen Yang5,2\u2217Zhizheng Liu6\u2217Liang He3Yu Qiao2Yikang Li2B\nHongsheng Li1,2,7B\n1Multimedia Laboratory, The Chinese University of Hong Kong\n2Shanghai Artificial Intelligence Laboratory3East China Normal University\n4South China University of Technology5Fudan University6ETH Zurich7CPII\nBCorresponding author\nhttps://github.com/PJLab-ADG/DetZero\nAbstract\nExisting offboard 3D detectors always follow a modular\npipeline design to take advantage of unlimited sequential\npoint clouds. We have found that the full potential of off-\nboard 3D detectors is not explored mainly due to two rea-\nsons: (1) the onboard multi-object tracker cannot gener-\nate sufficient complete object trajectories, and (2) the mo-\ntion state of objects poses an inevitable challenge for the\nobject-centric refining stage in leveraging the long-term\ntemporal context representation. To tackle these problems,\nwe propose a novel paradigm of offboard 3D object detec-\ntion, named DetZero. Concretely, an offline tracker cou-\npled with a multi-frame detector is proposed to focus on\nthe completeness of generated object tracks. An attention-\nmechanism refining module is proposed to strengthen con-\ntextual information interaction across long-term sequential\npoint clouds for object refining with decomposed regression\nmethods. Extensive experiments on Waymo Open Dataset\nshow our DetZero outperforms all state-of-the-art onboard\nand offboard 3D detection methods. Notably, DetZero ranks\n1st place on Waymo 3D object detection leaderboard1with\n85.15 mAPH (L2) detection performance. Further experi-\nments validate the application of taking the place of human\nlabels with such high-quality results. Our empirical study\nleads to rethinking conventions and interesting findings that\ncan guide future research on offboard 3D object detection.\n*Work performed during internship at Shanghai Artificial Intelligence\nLaboratory.\n1https://waymo.com/open/challenges/2020/3d-detection/.\n#)#'#&!$#%!##(#*#\"#!\n!'\"&%!&\")&#)\")*!#\"!+#)\"&+#)\"&(#)\"+'#(\"+(#)\"!&!&\"#+#'\"&*\nDetZero (LiDAR only)\nLiDAR only methodsLiDAR-Camera methodsVehicle  APH (L2)!!!\"!\"##$!%$!&##$!&'$!($!)$!*$!\"##$\n!*$!($!*$TimelineFigure 1. We compare several SOTA methods proposed along the\ntimeline on the Waymo 3D detection leaderboard. Our DetZero\nobtains the best performance with a remarkable margin on Vehi-\ncle. We mark the number of input point cloud frames below each\nmethod. Please refer to Table 1 for a detailed comparison.\n1. Introduction\nAutonomous driving has rapidly advanced with promis-\ning progress in both industry and academia. A crucial com-\nponent of this development is offboard 3D object detec-\ntion, which can utilize entire sequence data from sensors\n(video or sequential point cloud) with few constraints on\nmodel capacity and inference speed. Therefore, some ap-\nproaches [33, 50] are dedicated to developing high-quality\n\u201cauto labels\u201d, aiming to reduce manual labor in point cloud\nannotation.\nSubsequently, many online detectors [54, 8, 56] are in-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n6736\n",
        "project": "",
        "github": "",
        "arxiv": "2306.06023"
    },
    {
        "title": "Detecting Objects with Context-Likelihood Graphs and Graph Refinement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bhowmik_Detecting_Objects_with_Context-Likelihood_Graphs_and_Graph_Refinement_ICCV_2023_paper.html",
        "author": "Aritra Bhowmik, Yu Wang, Nora Baka, Martin R. Oswald, Cees G. M. Snoek",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bhowmik_Detecting_Objects_with_Context-Likelihood_Graphs_and_Graph_Refinement_ICCV_2023_paper.pdf",
        "aff": "Atlas Lab - University of Amsterdam; TomTom",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Detection Transformer with Stable Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Detection_Transformer_with_Stable_Matching_ICCV_2023_paper.html",
        "author": "Shilong Liu, Tianhe Ren, Jiayu Chen, Zhaoyang Zeng, Hao Zhang, Feng Li, Hongyang Li, Jun Huang, Hang Su, Jun Zhu, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Detection_Transformer_with_Stable_Matching_ICCV_2023_paper.pdf",
        "aff": "Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., Institute for AI, Tsinghua-Bosch Joint Center for ML, Tsinghua University; The Hong Kong University of Science and Technology; Platform of AI (PAI), Alibaba Group; South China University of Technology; International Digital Economy Academy (IDEA)",
        "project": "",
        "github": "https://github.com/IDEA-Research/Stable-DINO",
        "arxiv": "2304.04742"
    },
    {
        "title": "DetermiNet: A Large-Scale Diagnostic Dataset for Complex Visually-Grounded Referencing using Determiners",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_DetermiNet_A_Large-Scale_Diagnostic_Dataset_for_Complex_Visually-Grounded_Referencing_using_ICCV_2023_paper.html",
        "author": "Clarence Lee, M Ganesh Kumar, Cheston Tan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_DetermiNet_A_Large-Scale_Diagnostic_Dataset_for_Complex_Visually-Grounded_Referencing_using_ICCV_2023_paper.pdf",
        "aff": "Design and Artificial Intelligence, SUTD; Centre for Frontier AI Research, A*STAR",
        "project": "",
        "github": "https://github.com/clarence-lee-sheng/DetermiNet",
        "arxiv": "2309.03483"
    },
    {
        "title": "DiFaReli: Diffusion Face Relighting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ponglertnapakorn_DiFaReli_Diffusion_Face_Relighting_ICCV_2023_paper.html",
        "author": "Puntawat Ponglertnapakorn, Nontawat Tritrong, Supasorn Suwajanakorn",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ponglertnapakorn_DiFaReli_Diffusion_Face_Relighting_ICCV_2023_paper.pdf",
        "aff": "VISTEC, Thailand",
        "project": "https://diffusion-face-relighting.github.io",
        "github": "https://github.com/diffusion-face-relighting",
        "arxiv": "2304.09479"
    },
    {
        "title": "DiLiGenT-Pi: Photometric Stereo for Planar Surfaces with Rich Details - Benchmark Dataset and Beyond",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DiLiGenT-Pi_Photometric_Stereo_for_Planar_Surfaces_with_Rich_Details_-_ICCV_2023_paper.html",
        "author": "Feishi Wang, Jieji Ren, Heng Guo, Mingjun Ren, Boxin Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DiLiGenT-Pi_Photometric_Stereo_for_Planar_Surfaces_with_Rich_Details_-_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence, Beijing University of Posts and Telecommunications; Osaka University; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University; National Engineering Research Center of Visual Technology, School of Computer Science, Peking University; AI Innovation Center, School of Computer Science, Peking University; School of Mechanical Engineering, Shanghai Jiao Tong University",
        "project": "https://photometricstereo.github.io/diligentpi.html",
        "github": "https://github.com/photometricstereo/diligentpi",
        "arxiv": ""
    },
    {
        "title": "Diff-Retinex: Rethinking Low-light Image Enhancement with A Generative Diffusion Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Diff-Retinex_Rethinking_Low-light_Image_Enhancement_with_A_Generative_Diffusion_Model_ICCV_2023_paper.html",
        "author": "Xunpeng Yi, Han Xu, Hao Zhang, Linfeng Tang, Jiayi Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Diff-Retinex_Rethinking_Low-light_Image_Enhancement_with_A_Generative_Diffusion_Model_ICCV_2023_paper.pdf",
        "aff": "Electronic Information School, Wuhan University, Wuhan 430072, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DiffCloth: Diffusion Based Garment Synthesis and Manipulation via Structural Cross-modal Semantic Alignment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DiffCloth_Diffusion_Based_Garment_Synthesis_and_Manipulation_via_Structural_Cross-modal_ICCV_2023_paper.html",
        "author": "Xujie Zhang, Binbin Yang, Michael C. Kampffmeyer, Wenqing Zhang, Shiyue Zhang, Guansong Lu, Liang Lin, Hang Xu, Xiaodan Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DiffCloth_Diffusion_Based_Garment_Synthesis_and_Manipulation_via_Structural_Cross-modal_ICCV_2023_paper.pdf",
        "aff": "Shenzhen Campus of Sun Yat-Sen University; Sun Yat-Sen University; UiT The Arctic University of Norway; Huawei Noah\u2019s Ark Lab",
        "project": "",
        "github": "",
        "arxiv": "2308.11206"
    },
    {
        "title": "DiffDis: Empowering Generative Diffusion Model with Cross-Modal Discrimination Capability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_DiffDis_Empowering_Generative_Diffusion_Model_with_Cross-Modal_Discrimination_Capability_ICCV_2023_paper.html",
        "author": "Runhui Huang, Jianhua Han, Guansong Lu, Xiaodan Liang, Yihan Zeng, Wei Zhang, Hang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_DiffDis_Empowering_Generative_Diffusion_Model_with_Cross-Modal_Discrimination_Capability_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; Shenzhen Campus of Sun Yat-sen University",
        "project": "",
        "github": "",
        "arxiv": "2308.09306"
    },
    {
        "title": "DiffDreamer: Towards Consistent Unsupervised Single-view Scene Extrapolation with Conditional Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_DiffDreamer_Towards_Consistent_Unsupervised_Single-view_Scene_Extrapolation_with_Conditional_Diffusion_ICCV_2023_paper.html",
        "author": "Shengqu Cai, Eric Ryan Chan, Songyou Peng, Mohamad Shahbazi, Anton Obukhov, Luc Van Gool, Gordon Wetzstein",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_DiffDreamer_Towards_Consistent_Unsupervised_Single-view_Scene_Extrapolation_with_Conditional_Diffusion_ICCV_2023_paper.pdf",
        "aff": "ETH Z\u00fcrich/KU Leuven; Stanford University; ETH Z\u00fcrich",
        "project": "https://primecai.github.io/diffdreamer",
        "github": "",
        "arxiv": "2211.12131"
    },
    {
        "title": "DiffFacto: Controllable Part-Based 3D Point Cloud Generation with Cross Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nakayama_DiffFacto_Controllable_Part-Based_3D_Point_Cloud_Generation_with_Cross_Diffusion_ICCV_2023_paper.html",
        "author": "George Kiyohiro Nakayama, Mikaela Angelina Uy, Jiahui Huang, Shi-Min Hu, Ke Li, Leonidas Guibas",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nakayama_DiffFacto_Controllable_Part-Based_3D_Point_Cloud_Generation_with_Cross_Diffusion_ICCV_2023_paper.pdf",
        "aff": "Simon Fraser University; Stanford University; Tsinghua University",
        "project": "https://difffacto.github.io/",
        "github": "https://github.com/DiffFacto",
        "arxiv": "2305.01921"
    },
    {
        "title": "DiffFit: Unlocking Transferability of Large Diffusion Models via Simple Parameter-efficient Fine-Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_DiffFit_Unlocking_Transferability_of_Large_Diffusion_Models_via_Simple_Parameter-efficient_ICCV_2023_paper.html",
        "author": "Enze Xie, Lewei Yao, Han Shi, Zhili Liu, Daquan Zhou, Zhaoqiang Liu, Jiawei Li, Zhenguo Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_DiffFit_Unlocking_Transferability_of_Large_Diffusion_Models_via_Simple_Parameter-efficient_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah's Ark Lab; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": "2304.06648"
    },
    {
        "title": "DiffIR: Efficient Diffusion Model for Image Restoration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_DiffIR_Efficient_Diffusion_Model_for_Image_Restoration_ICCV_2023_paper.html",
        "author": "Bin Xia, Yulun Zhang, Shiyin Wang, Yitong Wang, Xinglong Wu, Yapeng Tian, Wenming Yang, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_DiffIR_Efficient_Diffusion_Model_for_Image_Restoration_ICCV_2023_paper.pdf",
        "aff": "ByteDance Inc; ETH Z\u00fcrich; Tsinghua University; University of Texas at Dallas",
        "project": "",
        "github": "https://github.com/Zj-BinXia/DiffIR",
        "arxiv": "2303.09472"
    },
    {
        "title": "DiffPose: Multi-hypothesis Human Pose Estimation using Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Holmquist_DiffPose_Multi-hypothesis_Human_Pose_Estimation_using_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Karl Holmquist, Bastian Wandt",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Holmquist_DiffPose_Multi-hypothesis_Human_Pose_Estimation_using_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Link\u00f6ping University",
        "project": "",
        "github": "https://github.com/bastianwandt/DiffPose/",
        "arxiv": "2211.16487"
    },
    {
        "title": "DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_DiffPose_SpatioTemporal_Diffusion_Model_for_Video-Based_Human_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Runyang Feng, Yixing Gao, Tze Ho Elden Tse, Xueqing Ma, Hyung Jin Chang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_DiffPose_SpatioTemporal_Diffusion_Model_for_Video-Based_Human_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "DiffPose: SpatioTemporal Diffusion Model for Video-Based\nHuman Pose Estimation\nRunyang Feng1,2, Yixing Gao1,2*, Tze Ho Elden Tse3, Xueqing Ma1,2, Hyung Jin Chang3\n1School of Artificial Intelligence, Jilin University,\n2Engineering Research Center of Knowledge-Driven Human-Machine Intelligence,\nMinistry of Education, China,3School of Computer Science, University of Birmingham\n{fengry22, maxq21 }@mails.jlu.edu.cn, gaoyixing@jlu.edu.cn,\ntxt994@student.bham.ac.uk, h.j.chang@bham.ac.uk\nAbstract\nDenoising diffusion probabilistic models that were ini-\ntially proposed for realistic image generation have recently\nshown success in various perception tasks (e.g., object de-\ntection and image segmentation) and are increasingly gain-\ning attention in computer vision. However, extending such\nmodels to multi-frame human pose estimation is non-trivial\ndue to the presence of the additional temporal dimension\nin videos. More importantly, learning representations that\nfocus on keypoint regions is crucial for accurate localiza-\ntion of human joints. Nevertheless, the adaptation of the\ndiffusion-based methods remains unclear on how to achieve\nsuch objective. In this paper, we present DiffPose, a novel\ndiffusion architecture that formulates video-based human\npose estimation as a conditional heatmap generation prob-\nlem. First, to better leverage temporal information, we pro-\npose SpatioTemporal Representation Learner which aggre-\ngates visual evidences across frames and uses the resulting\nfeatures in each denoising step as a condition. In addi-\ntion, we present a mechanism called Lookup-based Multi-\nScale Feature Interaction that determines the correlations\nbetween local joints and global contexts across multiple\nscales. This mechanism generates delicate representations\nthat focus on keypoint regions. Altogether, by extending\ndiffusion models, we show two unique characteristics from\nDiffPose on pose estimation task: (i) the ability to combine\nmultiple sets of pose estimates to improve prediction accu-\nracy, particularly for challenging joints, and (ii) the ability\nto adjust the number of iterative steps for feature refinement\nwithout retraining the model. DiffPose sets new state-of-\nthe-art results on three benchmarks: PoseTrack2017, Pose-\nTrack2018, and PoseTrack21.\n1. Introduction\nHuman pose estimation has been extensively studied in\ncomputer vision, with the aim of detecting all instances of\n*Corresponding Author\nFigure 1. (a)Illustration of the original diffusion model where q\nandp\u03b8refer to the diffusion and denoising process, respectively.\n(b)In this work, we propose a novel framework named DiffPose\nwhich formulates video-based human pose estimation as a gener-\native process of keypoint heatmaps.\npeople from images and localizing anatomical keypoints for\neach individual [20, 57, 63, 68]. It finds numerous appli-\ncations ranging from human-computer interaction and aug-\nmented reality [21, 22] to behavior analysis and surveil-\nlance tracking [36, 40, 56, 64, 65, 66]. Conventional\napproaches [55, 69, 82] mainly employ the probabilistic\ngraphical model or the pictorial structure model. Fueled by\nthe explosion of deep learning, Convolutional Neural Net-\nworks [8, 39, 40, 63] and Vision Transformers [38, 75, 80]\nhave witnessed significant progress in this task.\nUntil recently, denoising diffusion probabilistic models\n[30, 58], which are a type of generative models, have re-\nceived much research attention for surpassing other meth-\nods such as GANs and achieving state-of-the-art generative\nresults [6, 14]. The superior performance of the diffusion\nmodel has facilitated its expansion in diverse applications,\nsuch as super-resolution [54], inpainting [42], and image\ndeblurring [52]. Following the demonstration of the effec-\ntiveness of diffusion models as representation learners for\ndiscriminative computer vision problems [6], several con-\ntemporary approaches have successfully employed the dif-\nfusion model for perception tasks, including object detec-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n14861\n",
        "project": "",
        "github": "",
        "arxiv": "2307.16687"
    },
    {
        "title": "DiffRate : Differentiable Compression Rate for Efficient Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DiffRate__Differentiable_Compression_Rate_for_Efficient_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Mengzhao Chen, Wenqi Shao, Peng Xu, Mingbao Lin, Kaipeng Zhang, Fei Chao, Rongrong Ji, Yu Qiao, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffRate__Differentiable_Compression_Rate_for_Efficient_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "1. Key Laboratory of Multimedia Trusted Perception and Ef\ufb01cient Computing, Ministry of Education of China, School of Informatics, Xiamen University; 1. Key Laboratory of Multimedia Trusted Perception and Ef\ufb01cient Computing, Ministry of Education of China, School of Informatics, Xiamen University; 2. OpenGVLab, Shanghai AI Laboratory; 2. OpenGVLab, Shanghai AI Laboratory; 2. OpenGVLab, Shanghai AI Laboratory; 3. The University of Hong Kong; 4. Tencent Holdings Ltd",
        "project": "",
        "github": "https://github.com/OpenGVLab/DiffRate",
        "arxiv": "2305.17997"
    },
    {
        "title": "DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.html",
        "author": "Sauradip Nag, Xiatian Zhu, Jiankang Deng, Yi-Zhe Song, Tao Xiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.pdf",
        "aff": "Imperial College London, UK; CVSSP, University of Surrey, UK; iFlyTek-Surrey Joint Research Center on Artificial Intelligence, UK; CVSSP, University of Surrey, UK; Surrey Institute for People-Centred Artificial Intelligence, UK",
        "project": "",
        "github": "https://github.com/sauradip/DiffusionTAD",
        "arxiv": "2303.14863"
    },
    {
        "title": "DiffV2S: Diffusion-Based Video-to-Speech Synthesis with Vision-Guided Speaker Embedding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Choi_DiffV2S_Diffusion-Based_Video-to-Speech_Synthesis_with_Vision-Guided_Speaker_Embedding_ICCV_2023_paper.html",
        "author": "Jeongsoo Choi, Joanna Hong, Yong Man Ro",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_DiffV2S_Diffusion-Based_Video-to-Speech_Synthesis_with_Vision-Guided_Speaker_Embedding_ICCV_2023_paper.pdf",
        "aff": "School of Electrical Engineering, KAIST",
        "project": "",
        "github": "",
        "arxiv": "2308.07787"
    },
    {
        "title": "Differentiable Transportation Pruning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Differentiable_Transportation_Pruning_ICCV_2023_paper.html",
        "author": "Yunqiang Li, Jan C. van Gemert, Torsten Hoefler, Bert Moons, Evangelos Eleftheriou, Bram-Ernst Verhoef",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Differentiable_Transportation_Pruning_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; Axelera AI; TU Delft",
        "project": "",
        "github": "",
        "arxiv": "2307.08483"
    },
    {
        "title": "DiffuMask: Synthesizing Images with Pixel-level Annotations for Semantic Segmentation Using Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_DiffuMask_Synthesizing_Images_with_Pixel-level_Annotations_for_Semantic_Segmentation_Using_ICCV_2023_paper.html",
        "author": "Weijia Wu, Yuzhong Zhao, Mike Zheng Shou, Hong Zhou, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_DiffuMask_Synthesizing_Images_with_Pixel-level_Annotations_for_Semantic_Segmentation_Using_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University, Ant Group; National University of Singapore; Zhejiang University; University of Chinese Academy of Sciences",
        "project": "http://DiffuMask",
        "github": "",
        "arxiv": "2303.11681"
    },
    {
        "title": "Diffuse3D: Wide-Angle 3D Photography via Bilateral Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Diffuse3D_Wide-Angle_3D_Photography_via_Bilateral_Diffusion_ICCV_2023_paper.html",
        "author": "Yutao Jiang, Yang Zhou, Yuan Liang, Wenxi Liu, Jianbo Jiao, Yuhui Quan, Shengfeng He",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Diffuse3D_Wide-Angle_3D_Photography_via_Bilateral_Diffusion_ICCV_2023_paper.pdf",
        "aff": "College of Computer and Data Science, Fuzhou University; School of Computer Science, University of Birmingham; School of Computer Science and Engineering, South China University of Technology; School of Computing and Information Systems, Singapore Management University",
        "project": "",
        "github": "https://github.com/yutaojiang1/Diffuse3D",
        "arxiv": ""
    },
    {
        "title": "Diffusion Action Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.html",
        "author": "Daochang Liu, Qiyue Li, Anh-Dung Dinh, Tingting Jiang, Mubarak Shah, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.pdf",
        "aff": "NERCVT, NKLMIP, School of Computer Science, School of Mathematical Sciences, Peking University; School of Computer Science, Faculty of Engineering, The University of Sydney; Center for Research in Computer Vision, University of Central Florida",
        "project": "",
        "github": "https://tinyurl.com/DiffAct",
        "arxiv": "2303.17959"
    },
    {
        "title": "Diffusion Model as Representation Learner",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Diffusion_Model_as_Representation_Learner_ICCV_2023_paper.html",
        "author": "Xingyi Yang, Xinchao Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Diffusion_Model_as_Representation_Learner_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore",
        "project": "",
        "github": "https://github.com/Adamdad/Repfusion",
        "arxiv": "2308.10916"
    },
    {
        "title": "Diffusion Models as Masked Autoencoders",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Diffusion_Models_as_Masked_Autoencoders_ICCV_2023_paper.html",
        "author": "Chen Wei, Karttikeya Mangalam, Po-Yao Huang, Yanghao Li, Haoqi Fan, Hu Xu, Huiyu Wang, Cihang Xie, Alan Yuille, Christoph Feichtenhofer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Diffusion_Models_as_Masked_Autoencoders_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; UC Santa Cruz; FAIR, Meta AI",
        "project": "Project page",
        "github": "",
        "arxiv": "2304.03283"
    },
    {
        "title": "Diffusion in Style",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Everaert_Diffusion_in_Style_ICCV_2023_paper.html",
        "author": "Martin Nicolas Everaert, Marco Bocchio, Sami Arpa, Sabine S\u00fcsstrunk, Radhakrishna Achanta",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Everaert_Diffusion_in_Style_ICCV_2023_paper.pdf",
        "aff": "Largo.ai, Lausanne, Switzerland; School of Computer and Communication Sciences, EPFL, Switzerland",
        "project": "https://ivrl.github.io/diffusion-in-style/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis Aggregation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shan_Diffusion-Based_3D_Human_Pose_Estimation_with_Multi-Hypothesis_Aggregation_ICCV_2023_paper.html",
        "author": "Wenkang Shan, Zhenhua Liu, Xinfeng Zhang, Zhao Wang, Kai Han, Shanshe Wang, Siwei Ma, Wen Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shan_Diffusion-Based_3D_Human_Pose_Estimation_with_Multi-Hypothesis_Aggregation_ICCV_2023_paper.pdf",
        "aff": "National Engineering Research Center of Visual Technology, Peking University and Peng Cheng Laboratory; Huawei Noah\u2019s Ark Lab; National Engineering Research Center of Visual Technology, Peking University; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/paTRICK-swk/D3DP",
        "arxiv": "2303.11579"
    },
    {
        "title": "Diffusion-Guided Reconstruction of Everyday Hand-Object Interaction Clips",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Diffusion-Guided_Reconstruction_of_Everyday_Hand-Object_Interaction_Clips_ICCV_2023_paper.html",
        "author": "Yufei Ye, Poorvi Hebbar, Abhinav Gupta, Shubham Tulsiani",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Diffusion-Guided_Reconstruction_of_Everyday_Hand-Object_Interaction_Clips_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "https://judyye.github.io/diffhoi",
        "github": "",
        "arxiv": "2309.05663"
    },
    {
        "title": "Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chou_Diffusion-SDF_Conditional_Generative_Modeling_of_Signed_Distance_Functions_ICCV_2023_paper.html",
        "author": "Gene Chou, Yuval Bahat, Felix Heide",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chou_Diffusion-SDF_Conditional_Generative_Modeling_of_Signed_Distance_Functions_ICCV_2023_paper.pdf",
        "aff": "Princeton University",
        "project": "",
        "github": "https://github.com/princeton-computational-imaging/Diffusion-SDF",
        "arxiv": ""
    },
    {
        "title": "Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.html",
        "author": "Duo Peng, Ping Hu, Qiuhong Ke, Jun Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf",
        "aff": "Boston University; Singapore University of Technology and Design; Monash University",
        "project": "",
        "github": "",
        "arxiv": "2308.12350"
    },
    {
        "title": "DiffusionDet: Diffusion Model for Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DiffusionDet_Diffusion_Model_for_Object_Detection_ICCV_2023_paper.html",
        "author": "Shoufa Chen, Peize Sun, Yibing Song, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffusionDet_Diffusion_Model_for_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Tencent AI Lab, AI3Institute, Fudan University; The University of Hong Kong, Shanghai AI Laboratory; The University of Hong Kong",
        "project": "",
        "github": "https://github.com/ShoufaChen/DiffusionDet",
        "arxiv": "2211.09788"
    },
    {
        "title": "DiffusionRet: Generative Text-Video Retrieval with Diffusion Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jin_DiffusionRet_Generative_Text-Video_Retrieval_with_Diffusion_Model_ICCV_2023_paper.html",
        "author": "Peng Jin, Hao Li, Zesen Cheng, Kehan Li, Xiangyang Ji, Chang Liu, Li Yuan, Jie Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_DiffusionRet_Generative_Text-Video_Retrieval_with_Diffusion_Model_ICCV_2023_paper.pdf",
        "aff": "DiffusionRet: Generative Text-Video Retrieval with Diffusion Model\nPeng Jin1,3*Hao Li1,3*Zesen Cheng1,3Kehan Li1,3Xiangyang Ji4\nChang Liu4Li Yuan1,2,3\u2020Jie Chen1,2,3\u2020\n1School of Electronic and Computer Engineering, Peking University, Shenzhen, China2Peng Cheng Laboratory, Shenzhen, China\n3AI for Science (AI4S)-Preferred Program, Peking University Shenzhen Graduate School, Shenzhen, China\n4Department of Automation and BNRist, Tsinghua University, Beijing, China\n{jp21, cyanlaser, kehanli }@stu.pku.edu.cn {lihao1984, yuanli-ece }@pku.edu.cn {liuchang2022, xyji }@tsinghua.edu.cn chenj@pcl.ac.cn\nAbstract\nExisting text-video retrieval solutions are, in essence, dis-\ncriminant models focused on maximizing the conditional\nlikelihood, i.e., p(candidates |query ). While straightforward,\nthis de facto paradigm overlooks the underlying data distri-\nbution p(query ), which makes it challenging to identify out-\nof-distribution data. To address this limitation, we creatively\ntackle this task from a generative viewpoint and model the\ncorrelation between the text and the video as their joint prob-\nability p(candidates ,query ). This is accomplished through\na diffusion -based text-video ret rieval framework (Diffusion-\nRet), which models the retrieval task as a process of gradu-\nally generating joint distribution from noise. During training,\nDiffusionRet is optimized from both the generation and dis-\ncrimination perspectives, with the generator being optimized\nby generation loss and the feature extractor trained with\ncontrastive loss. In this way, DiffusionRet cleverly lever-\nages the strengths of both generative and discriminative\nmethods. Extensive experiments on five commonly used text-\nvideo retrieval benchmarks, including MSRVTT, LSMDC,\nMSVD, ActivityNet Captions, and DiDeMo, with superior\nperformances, justify the efficacy of our method. More en-\ncouragingly, without any modification, DiffusionRet even\nperforms well in out-domain retrieval settings. We believe\nthis work brings fundamental insights into the related fields.\nCode is available at https://github.com/jpthu17/DiffusionRet.\n1. Introduction\nIn recent years, text-video retrieval has made significant\nprogress, allowing humans to associate textual concepts with\nvideo entities and vice versa [ 67,66]. Existing methods for\nvideo-text retrieval typically model the cross-modal interac-\n*Equal contribution.\n\u2020Corresponding author: Li Yuan, Jie Chen.\n\ud835\udc65\ud835\udc3e \ud835\udc65\ud835\udc58 \ud835\udc65\ud835\udc58\u22121 \ud835\udc650\ud835\udc5d\ud835\udf11 \u0201\ud835\udc65\ud835\udc58\u22121\ud835\udc65\ud835\udc58\n\ud835\udc5e\u0201\ud835\udc65\ud835\udc58\ud835\udc65\ud835\udc58\u22121Query:  A man speaks to a camera for an interview.\n(b) Diffusion model for generating joint distribution\n(a) The joint distribution of query and candidates\n\ud835\udc65\ud835\udc3e \ud835\udc65\ud835\udc58 \ud835\udc65\ud835\udc58\u22121 \ud835\udc650Figure 1: Diffusion model for text-video retrieval. (a) We\npropose to model the correlation between the query and the\ncandidates as their joint probability. (b) The diffusion model\nhas demonstrated remarkable generative power in various\nfields, and due to its coarse-to-fine nature, we utilize the\ndiffusion model for joint probability generation.\ntion as discriminant models [ 24,51]. Under the discriminant\nparadigm based on contrastive learning [ 53], the primary\nfocus of mainstream methods is to improve the dense fea-\nture extractor to learn better representation. This has led\nto the emergence of a large number of discriminative so-\nlutions [ 31,4,50,22], and recent advances in large-scale\nvision-language pre-training models [ 56,41] have pushed\ntheir state-of-the-art performance even further.\nHowever, from a probabilistic perspective, discriminant\nmodels only learn the conditional probability distribution,\ni.e.,p(candidates |query ). This leads to a limitation of dis-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n2470\n",
        "project": "",
        "github": "",
        "arxiv": "2303.09867"
    },
    {
        "title": "Discovering Spatio-Temporal Rationales for Video Question Answering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Discovering_Spatio-Temporal_Rationales_for_Video_Question_Answering_ICCV_2023_paper.html",
        "author": "Yicong Li, Junbin Xiao, Chun Feng, Xiang Wang, Tat-Seng Chua",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Discovering_Spatio-Temporal_Rationales_for_Video_Question_Answering_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/yl3800/TranSTR",
        "arxiv": "2307.12058"
    },
    {
        "title": "Discrepant and Multi-Instance Proxies for Unsupervised Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.html",
        "author": "Chang Zou, Zeqi Chen, Zhichao Cui, Yuehu Liu, Chi Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.pdf",
        "aff": "Chang\u2019an University; School of Software Engineering, Xi\u2019an Jiaotong University; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Discriminative Class Tokens for Text-to-Image Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Idan Schwartz, V\u00e9steinn Sn\u00e6bjarnarson, Hila Chefer, Serge Belongie, Lior Wolf, Sagie Benaim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Tel Aviv University; University of Copenhagen",
        "project": "",
        "github": "https://github.com/idansc/discriminative_class_tokens",
        "arxiv": ""
    },
    {
        "title": "Disentangle then Parse: Night-time Semantic Segmentation with Illumination Disentanglement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Disentangle_then_Parse_Night-time_Semantic_Segmentation_with_Illumination_Disentanglement_ICCV_2023_paper.html",
        "author": "Zhixiang Wei, Lin Chen, Tao Tu, Pengyang Ling, Huaian Chen, Yi Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Disentangle_then_Parse_Night-time_Semantic_Segmentation_with_Illumination_Disentanglement_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Shanghai AI Laboratory; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/w1oves/DTP.git",
        "arxiv": "2307.09362"
    },
    {
        "title": "Disentangling Spatial and Temporal Learning for Efficient Image-to-Video Transfer Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qing_Disentangling_Spatial_and_Temporal_Learning_for_Efficient_Image-to-Video_Transfer_Learning_ICCV_2023_paper.html",
        "author": "Zhiwu Qing, Shiwei Zhang, Ziyuan Huang, Yingya Zhang, Changxin Gao, Deli Zhao, Nong Sang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qing_Disentangling_Spatial_and_Temporal_Learning_for_Efficient_Image-to-Video_Transfer_Learning_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Image Processing and Intelligent Control, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology; Alibaba Group; ARC, National University of Singapore",
        "project": "",
        "github": "https://github.com/alibaba-mmai-research/DiST",
        "arxiv": "2309.07911"
    },
    {
        "title": "Disposable Transfer Learning for Selective Source Task Unlearning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Koh_Disposable_Transfer_Learning_for_Selective_Source_Task_Unlearning_ICCV_2023_paper.html",
        "author": "Seunghee Koh, Hyounguk Shon, Janghyeon Lee, Hyeong Gwon Hong, Junmo Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Koh_Disposable_Transfer_Learning_for_Selective_Source_Task_Unlearning_ICCV_2023_paper.pdf",
        "aff": "LG AI Research, South Korea; Korea Advanced Institute of Science and Technology, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2308.09971"
    },
    {
        "title": "DistillBEV: Boosting Multi-Camera 3D Object Detection with Cross-Modal Knowledge Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DistillBEV_Boosting_Multi-Camera_3D_Object_Detection_with_Cross-Modal_Knowledge_Distillation_ICCV_2023_paper.html",
        "author": "Zeyu Wang, Dingwen Li, Chenxu Luo, Cihang Xie, Xiaodong Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DistillBEV_Boosting_Multi-Camera_3D_Object_Detection_with_Cross-Modal_Knowledge_Distillation_ICCV_2023_paper.pdf",
        "aff": "2UC Santa Cruz; 1QCraft, 2UC Santa Cruz; 1QCraft",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Distilled Reverse Attention Network for Open-world Compositional Zero-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilled_Reverse_Attention_Network_for_Open-world_Compositional_Zero-Shot_Learning_ICCV_2023_paper.html",
        "author": "Yun Li, Zhe Liu, Saurav Jha, Lina Yao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilled_Reverse_Attention_Network_for_Open-world_Compositional_Zero-Shot_Learning_ICCV_2023_paper.pdf",
        "aff": "University of New South Wales; CSIRO Data61, University of New South Wales",
        "project": "",
        "github": "",
        "arxiv": "2303.00404"
    },
    {
        "title": "Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly Supervised 3D Visual Grounding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Distilling_Coarse-to-Fine_Semantic_Matching_Knowledge_for_Weakly_Supervised_3D_Visual_ICCV_2023_paper.html",
        "author": "Zehan Wang, Haifeng Huang, Yang Zhao, Linjun Li, Xize Cheng, Yichen Zhu, Aoxiong Yin, Zhou Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distilling_Coarse-to-Fine_Semantic_Matching_Knowledge_for_Weakly_Supervised_3D_Visual_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2307.09267"
    },
    {
        "title": "Distilling DETR with Visual-Linguistic Knowledge for Open-Vocabulary Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilling_DETR_with_Visual-Linguistic_Knowledge_for_Open-Vocabulary_Object_Detection_ICCV_2023_paper.html",
        "author": "Liangqi Li, Jiaxu Miao, Dahu Shi, Wenming Tan, Ye Ren, Yi Yang, Shiliang Pu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilling_DETR_with_Visual-Linguistic_Knowledge_for_Open-Vocabulary_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Hikvision Research Institute, Zhejiang University, Key Laboratory of Peace-building Big Data of Zhejiang Province; Zhejiang University; Hikvision Research Institute",
        "project": "",
        "github": "https://github.com/hikvision-research/opera",
        "arxiv": ""
    },
    {
        "title": "Distilling Large Vision-Language Model with Out-of-Distribution Generalizability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilling_Large_Vision-Language_Model_with_Out-of-Distribution_Generalizability_ICCV_2023_paper.html",
        "author": "Xuanlin Li, Yunhao Fang, Minghua Liu, Zhan Ling, Zhuowen Tu, Hao Su",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilling_Large_Vision-Language_Model_with_Out-of-Distribution_Generalizability_ICCV_2023_paper.pdf",
        "aff": "UC San Diego",
        "project": "",
        "github": "Code released at this link (\u5177\u4f53\u7684\u94fe\u63a5\u6ca1\u6709\u63d0\u4f9b)",
        "arxiv": "2307.03135"
    },
    {
        "title": "Distilling from Similar Tasks for Transfer Learning on a Budget",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Borup_Distilling_from_Similar_Tasks_for_Transfer_Learning_on_a_Budget_ICCV_2023_paper.html",
        "author": "Kenneth Borup, Cheng Perng Phoo, Bharath Hariharan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Borup_Distilling_from_Similar_Tasks_for_Transfer_Learning_on_a_Budget_ICCV_2023_paper.pdf",
        "aff": "Cornell University; Aarhus University",
        "project": "",
        "github": "github.com/Kennethborup/DistillWeighted",
        "arxiv": "2304.12314"
    },
    {
        "title": "Distracting Downpour: Adversarial Weather Attacks for Motion Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Schmalfuss_Distracting_Downpour_Adversarial_Weather_Attacks_for_Motion_Estimation_ICCV_2023_paper.html",
        "author": "Jenny Schmalfuss, Lukas Mehl, Andr\u00e9s Bruhn",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Schmalfuss_Distracting_Downpour_Adversarial_Weather_Attacks_for_Motion_Estimation_ICCV_2023_paper.pdf",
        "aff": "Institute for Visualization and Interactive Systems, University of Stuttgart",
        "project": "",
        "github": "https://github.com/cv-stuttgart/DistractingDownpour",
        "arxiv": "2305.06716"
    },
    {
        "title": "Distributed Bundle Adjustment with Block-Based Sparse Matrix Compression for Super Large Scale Datasets",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.html",
        "author": "Maoteng Zheng, Nengcheng Chen, Junfeng Zhu, Xiaoru Zeng, Huanbin Qiu, Yuyao Jiang, Xingyue Lu, Hao Qu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.pdf",
        "aff": "China University of Geosciences(Wuhan); Jiantong Surveying; Mirauge3D Technology Inc.; Mirauge3D Technology",
        "project": "",
        "github": "",
        "arxiv": "2307.08383"
    },
    {
        "title": "Distribution Shift Matters for Knowledge Distillation with Webly Collected Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Distribution_Shift_Matters_for_Knowledge_Distillation_with_Webly_Collected_Images_ICCV_2023_paper.html",
        "author": "Jialiang Tang, Shuo Chen, Gang Niu, Masashi Sugiyama, Chen Gong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Distribution_Shift_Matters_for_Knowledge_Distillation_with_Webly_Collected_Images_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology, China; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, China; Jiangsu Key Laboratory of Image and Video Understanding for Social Security, China; Center for Advanced Intelligence Project, RIKEN, Japan; Center for Advanced Intelligence Project, RIKEN, Japan; The Graduate School of Frontier Sciences, The University of Tokyo, Japan",
        "project": "",
        "github": "",
        "arxiv": "2307.11469"
    },
    {
        "title": "Distribution-Aligned Diffusion for Human Mesh Recovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Foo_Distribution-Aligned_Diffusion_for_Human_Mesh_Recovery_ICCV_2023_paper.html",
        "author": "Lin Geng Foo, Jia Gong, Hossein Rahmani, Jun Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Foo_Distribution-Aligned_Diffusion_for_Human_Mesh_Recovery_ICCV_2023_paper.pdf",
        "aff": "Lancaster University; Singapore University of Technology and Design",
        "project": "https://gongjia0208.github.io/HMDiff/",
        "github": "",
        "arxiv": "2308.13369"
    },
    {
        "title": "Distribution-Aware Prompt Tuning for Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Distribution-Aware_Prompt_Tuning_for_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Eulrang Cho, Jooyeon Kim, Hyunwoo J Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Distribution-Aware_Prompt_Tuning_for_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, Korea University",
        "project": "",
        "github": "https://github.com/mlvlab/DAPT",
        "arxiv": "2309.03406"
    },
    {
        "title": "Distribution-Consistent Modal Recovering for Incomplete Multimodal Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Distribution-Consistent_Modal_Recovering_for_Incomplete_Multimodal_Learning_ICCV_2023_paper.html",
        "author": "Yuanzhi Wang, Zhen Cui, Yong Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distribution-Consistent_Modal_Recovering_for_Incomplete_Multimodal_Learning_ICCV_2023_paper.pdf",
        "aff": "PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China.",
        "project": "",
        "github": "https://github.com/mdswyz/DiCMoR",
        "arxiv": ""
    },
    {
        "title": "Diverse Cotraining Makes Strong Semi-Supervised Segmentor",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Diverse_Cotraining_Makes_Strong_Semi-Supervised_Segmentor_ICCV_2023_paper.html",
        "author": "Yijiang Li, Xinjiang Wang, Lihe Yang, Litong Feng, Wayne Zhang, Ying Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Diverse_Cotraining_Makes_Strong_Semi-Supervised_Segmentor_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n16055\n",
        "project": "",
        "github": "",
        "arxiv": "2308.09281"
    },
    {
        "title": "Diverse Data Augmentation with Diffusions for Effective Test-time Prompt Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Diverse_Data_Augmentation_with_Diffusions_for_Effective_Test-time_Prompt_Tuning_ICCV_2023_paper.html",
        "author": "Chun-Mei Feng, Kai Yu, Yong Liu, Salman Khan, Wangmeng Zuo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Diverse_Data_Augmentation_with_Diffusions_for_Effective_Test-time_Prompt_Tuning_ICCV_2023_paper.pdf",
        "aff": "Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR), Singapore; Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), UAE; Harbin Institute of Technology, Harbin, China",
        "project": "",
        "github": "https://github.com/chunmeifeng/DiffTPT",
        "arxiv": "2308.06038"
    },
    {
        "title": "Diverse Inpainting and Editing with GAN Inversion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yildirim_Diverse_Inpainting_and_Editing_with_GAN_Inversion_ICCV_2023_paper.html",
        "author": "Ahmet Burak Yildirim, Hamza Pehlivan, Bahri Batuhan Bilecen, Aysegul Dundar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yildirim_Diverse_Inpainting_and_Editing_with_GAN_Inversion_ICCV_2023_paper.pdf",
        "aff": "Bilkent University",
        "project": "",
        "github": "",
        "arxiv": "2307.15033"
    },
    {
        "title": "Divide and Conquer: 3D Point Cloud Instance Segmentation With Point-Wise Binarization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Divide_and_Conquer_3D_Point_Cloud_Instance_Segmentation_With_Point-Wise_ICCV_2023_paper.html",
        "author": "Weiguang Zhao, Yuyao Yan, Chaolong Yang, Jianan Ye, Xi Yang, Kaizhu Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Divide_and_Conquer_3D_Point_Cloud_Instance_Segmentation_With_Point-Wise_ICCV_2023_paper.pdf",
        "aff": "Duke Kunshan University; Xi\u2019an Jiaotong-Liverpool University",
        "project": "",
        "github": "https://github.com/weiguangzhao/PBNet",
        "arxiv": "2207.11209"
    },
    {
        "title": "Divide and Conquer: a Two-Step Method for High Quality Face De-identification with Model Explainability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Divide_and_Conquer_a_Two-Step_Method_for_High_Quality_Face_ICCV_2023_paper.html",
        "author": "Yunqian Wen, Bo Liu, Jingyi Cao, Rong Xie, Li Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Divide_and_Conquer_a_Two-Step_Method_for_High_Quality_Face_ICCV_2023_paper.pdf",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University; School of Computer Science University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Divide&Classify: Fine-Grained Classification for City-Wide Visual Geo-Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Trivigno_DivideClassify_Fine-Grained_Classification_for_City-Wide_Visual_Geo-Localization_ICCV_2023_paper.html",
        "author": "Gabriele Trivigno, Gabriele Berton, Juan Aragon, Barbara Caputo, Carlo Masone",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Trivigno_DivideClassify_Fine-Grained_Classification_for_City-Wide_Visual_Geo-Localization_ICCV_2023_paper.pdf",
        "aff": "Politecnico di Torino",
        "project": "",
        "github": "https://github.com/ga1i13o/Divide-and-Classify",
        "arxiv": ""
    },
    {
        "title": "Do DALL-E and Flamingo Understand Each Other?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Do_DALL-E_and_Flamingo_Understand_Each_Other_ICCV_2023_paper.html",
        "author": "Hang Li, Jindong Gu, Rajat Koner, Sahand Sharifzadeh, Volker Tresp",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Do_DALL-E_and_Flamingo_Understand_Each_Other_ICCV_2023_paper.pdf",
        "aff": "University of Oxford, UK; LMU Munich, Germany; Siemens AG, Germany; LMU Munich, Germany",
        "project": "https://dalleflamingo.github.io",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DocTr: Document Transformer for Structured Information Extraction in Documents",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liao_DocTr_Document_Transformer_for_Structured_Information_Extraction_in_Documents_ICCV_2023_paper.html",
        "author": "Haofu Liao, Aruni RoyChowdhury, Weijian Li, Ankan Bansal, Yuting Zhang, Zhuowen Tu, Ravi Kumar Satzoda, R. Manmatha, Vijay Mahadevan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_DocTr_Document_Transformer_for_Structured_Information_Extraction_in_Documents_ICCV_2023_paper.pdf",
        "aff": "MathWorks; AWS AI Labs; Amazon Physical Stores",
        "project": "",
        "github": "",
        "arxiv": "2307.07929"
    },
    {
        "title": "Document Understanding Dataset and Evaluation (DUDE)",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Van_Landeghem_Document_Understanding_Dataset_and_Evaluation_DUDE_ICCV_2023_paper.html",
        "author": "Jordy Van Landeghem, Rub\u00e8n Tito, \u0141ukasz Borchmann, Micha\u0142 Pietruszka, Pawel Joziak, Rafal Powalski, Dawid Jurkiewicz, Mickael Coustaty, Bertrand Anckaert, Ernest Valveny, Matthew Blaschko, Sien Moens, Tomasz Stanislawek",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Landeghem_Document_Understanding_Dataset_and_Evaluation_DUDE_ICCV_2023_paper.pdf",
        "aff": "University of La Rochelle; KU Leuven; Instabase; Computer Vision Center, Universitat Aut\u00f2noma de Barcelona; Contract.fit; Snowflake; Adam Mickiewicz University",
        "project": "",
        "github": "https://huggingface.co/datasets/jordyvl/DUDE_loader",
        "arxiv": "2305.08455"
    },
    {
        "title": "Does Physical Adversarial Example Really Matter to Autonomous Driving? Towards System-Level Effect of Adversarial Object Evasion Attack",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Does_Physical_Adversarial_Example_Really_Matter_to_Autonomous_Driving_Towards_ICCV_2023_paper.html",
        "author": "Ningfei Wang, Yunpeng Luo, Takami Sato, Kaidi Xu, Qi Alfred Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Does_Physical_Adversarial_Example_Really_Matter_to_Autonomous_Driving_Towards_ICCV_2023_paper.pdf",
        "aff": "University of California, Irvine; Drexel University",
        "project": "",
        "github": "",
        "arxiv": "2308.11894"
    },
    {
        "title": "Domain Adaptive Few-Shot Open-Set Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pal_Domain_Adaptive_Few-Shot_Open-Set_Learning_ICCV_2023_paper.html",
        "author": "Debabrata Pal, Deeptej More, Sai Bhargav, Dipesh Tamboli, Vaneet Aggarwal, Biplab Banerjee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_Domain_Adaptive_Few-Shot_Open-Set_Learning_ICCV_2023_paper.pdf",
        "aff": "Manipal Institute of Technology, India; Indian Institute of Technology, Bombay; Purdue University",
        "project": "",
        "github": "https://github.com/DebabrataPal7/DAFOSNET",
        "arxiv": "2309.12814"
    },
    {
        "title": "Domain Generalization Guided by Gradient Signal to Noise Ratio of Parameters",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Michalkiewicz_Domain_Generalization_Guided_by_Gradient_Signal_to_Noise_Ratio_of_ICCV_2023_paper.html",
        "author": "Mateusz Michalkiewicz, Masoud Faraki, Xiang Yu, Manmohan Chandraker, Mahsa Baktashmotlagh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Michalkiewicz_Domain_Generalization_Guided_by_Gradient_Signal_to_Noise_Ratio_of_ICCV_2023_paper.pdf",
        "aff": "NEC Labs America, University of California, San Diego; NEC Labs America; Amazon*; University of Queensland",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Domain Generalization of 3D Semantic Segmentation in Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sanchez_Domain_Generalization_of_3D_Semantic_Segmentation_in_Autonomous_Driving_ICCV_2023_paper.html",
        "author": "Jules Sanchez, Jean-Emmanuel Deschaud, Fran\u00e7ois Goulette",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sanchez_Domain_Generalization_of_3D_Semantic_Segmentation_in_Autonomous_Driving_ICCV_2023_paper.pdf",
        "aff": "U2IS, ENSTA Paris, Institut Polytechnique de Paris, 91120 Palaiseau, France; Centre for Robotics, Mines Paris - PSL, PSL University, 75006 Paris, France",
        "project": "",
        "github": "https://github.com/JulesSanchez/3DLabelProp",
        "arxiv": "2212.04245"
    },
    {
        "title": "Domain Generalization via Balancing Training Difficulty and Model Capability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.html",
        "author": "Xueying Jiang, Jiaxing Huang, Sheng Jin, Shijian Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.pdf",
        "aff": "S-lab, Nanyang Technological University",
        "project": "",
        "github": "",
        "arxiv": "2309.00844"
    },
    {
        "title": "Domain Generalization via Rationale Invariance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Domain_Generalization_via_Rationale_Invariance_ICCV_2023_paper.html",
        "author": "Liang Chen, Yong Zhang, Yibing Song, Anton van den Hengel, Lingqiao Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Domain_Generalization_via_Rationale_Invariance_ICCV_2023_paper.pdf",
        "aff": "AI3Institute, Fudan University; The University of Adelaide; Tencent AI Lab",
        "project": "",
        "github": "https://github.com/liangchen527/RIDG",
        "arxiv": "2308.11158"
    },
    {
        "title": "Domain Specified Optimization for Deployment Authorization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Domain_Specified_Optimization_for_Deployment_Authorization_ICCV_2023_paper.html",
        "author": "Haotian Wang, Haoang Chi, Wenjing Yang, Zhipeng Lin, Mingyang Geng, Long Lan, Jing Zhang, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Domain_Specified_Optimization_for_Deployment_Authorization_ICCV_2023_paper.pdf",
        "aff": "National University of Defense Technology; The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sanyal_Domain-Specificity_Inducing_Transformers_for_Source-Free_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Sunandini Sanyal, Ashish Ramayee Asokan, Suvaansh Bhambri, Akshay Kulkarni, Jogendra Nath Kundu, R Venkatesh Babu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sanyal_Domain-Specificity_Inducing_Transformers_for_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Vision and AI Lab, Indian Institute of Science, Bengaluru",
        "project": "http://val.cds.iisc.ac.in/DSiT-SFDA/",
        "github": "",
        "arxiv": "2308.14023"
    },
    {
        "title": "DomainAdaptor: A Novel Approach to Test-time Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DomainAdaptor_A_Novel_Approach_to_Test-time_Adaptation_ICCV_2023_paper.html",
        "author": "Jian Zhang, Lei Qi, Yinghuan Shi, Yang Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DomainAdaptor_A_Novel_Approach_to_Test-time_Adaptation_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; National Institute of Healthcare Data Science, Nanjing University; School of Computer Science and Engineering, Southeast University",
        "project": "",
        "github": "https://github.com/koncle/DomainAdaptor",
        "arxiv": "2308.10297"
    },
    {
        "title": "DomainDrop: Suppressing Domain-Sensitive Channels for Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_DomainDrop_Suppressing_Domain-Sensitive_Channels_for_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Jintao Guo, Lei Qi, Yinghuan Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_DomainDrop_Suppressing_Domain-Sensitive_Channels_for_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Southeast University; State Key Laboratory for Novel Software Technology, Nanjing University and National Institute of Healthcare Data Science, Nanjing University",
        "project": "",
        "github": "https://github.com/lingeringlight/DomainDrop",
        "arxiv": "2308.10285"
    },
    {
        "title": "Doppelgangers: Learning to Disambiguate Images of Similar Structures",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Doppelgangers_Learning_to_Disambiguate_Images_of_Similar_Structures_ICCV_2023_paper.html",
        "author": "Ruojin Cai, Joseph Tung, Qianqian Wang, Hadar Averbuch-Elor, Bharath Hariharan, Noah Snavely",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Doppelgangers_Learning_to_Disambiguate_Images_of_Similar_Structures_ICCV_2023_paper.pdf",
        "aff": "Cornell University; Tel Aviv University",
        "project": "doppelgangers-3d.github.io",
        "github": "https://github.com/doppelgangers-3d",
        "arxiv": "2309.02420"
    },
    {
        "title": "Downscaled Representation Matters: Improving Image Rescaling with Collaborative Downscaled Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.html",
        "author": "Bingna Xu, Yong Guo, Luoqian Jiang, Mianjie Yu, Jian Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology",
        "project": "",
        "github": "https://github.com/xubingna/HCD",
        "arxiv": "2211.10643"
    },
    {
        "title": "Downstream-agnostic Adversarial Examples",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Downstream-agnostic_Adversarial_Examples_ICCV_2023_paper.html",
        "author": "Ziqi Zhou, Shengshan Hu, Ruizhi Zhao, Qian Wang, Leo Yu Zhang, Junhui Hou, Hai Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Downstream-agnostic_Adversarial_Examples_ICCV_2023_paper.pdf",
        "aff": "School of Cyber Science and Engineering, Huazhong University of Science and Technology; School of Cyber Science and Engineering, Wuhan University; School of Information and Communication Technology, Griffith University; Department of Computer Science, City University of Hong Kong; School of Computer Science and Technology, Huazhong University of Science and Technology",
        "project": "",
        "github": "https://github.com/CGCL-codes/AdvEncoder",
        "arxiv": "2307.12280"
    },
    {
        "title": "DreamBooth3D: Subject-Driven Text-to-3D Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.html",
        "author": "Amit Raj, Srinivas Kaza, Ben Poole, Michael Niemeyer, Nataniel Ruiz, Ben Mildenhall, Shiran Zada, Kfir Aberman, Michael Rubinstein, Jonathan Barron, Yuanzhen Li, Varun Jampani",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.pdf",
        "aff": "Google",
        "project": "https://dreambooth3d.github.io",
        "github": "",
        "arxiv": "2303.13508"
    },
    {
        "title": "DreamPose: Fashion Video Synthesis with Stable Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Karras_DreamPose_Fashion_Video_Synthesis_with_Stable_Diffusion_ICCV_2023_paper.html",
        "author": "Johanna Karras, Aleksander Holynski, Ting-Chun Wang, Ira Kemelmacher-Shlizerman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Karras_DreamPose_Fashion_Video_Synthesis_with_Stable_Diffusion_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley, Google Research; NVIDIA; University of Washington",
        "project": "https://grail.cs.washington.edu/projects/dreampose",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DreamTeacher: Pretraining Image Backbones with Deep Generative Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.html",
        "author": "Daiqing Li, Huan Ling, Amlan Kar, David Acuna, Seung Wook Kim, Karsten Kreis, Antonio Torralba, Sanja Fidler",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.pdf",
        "aff": "NVIDIA, University of Toronto, Vector Institute; NVIDIA; MIT",
        "project": "https://research.nvidia.com/labs/toronto-ai/DreamTeacher/",
        "github": "",
        "arxiv": "2307.07487"
    },
    {
        "title": "DriveAdapter: Breaking the Coupling Barrier of Perception and Planning in End-to-End Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jia_DriveAdapter_Breaking_the_Coupling_Barrier_of_Perception_and_Planning_in_ICCV_2023_paper.html",
        "author": "Xiaosong Jia, Yulu Gao, Li Chen, Junchi Yan, Patrick Langechuan Liu, Hongyang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jia_DriveAdapter_Breaking_the_Coupling_Barrier_of_Perception_and_Planning_in_ICCV_2023_paper.pdf",
        "aff": "DriveAdapter: Breaking the Coupling Barrier of\nPerception and Planning in End-to-End Autonomous Driving\nXiaosong Jia1,2, Yulu Gao2,3, Li Chen2, Junchi Yan1,2\u2020, Patrick Langechuan Liu4, Hongyang Li2,1\u2020\n1MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University\n2OpenDriveLab, Shanghai AI Lab3Beihang University4Anker Innovations\n\u2020Correspondence authors\nhttps://github.com/OpenDriveLab/DriveAdapter\nModelRaw Sensor Input \nReinforcement \nLearning\nPrivileged Input \nTeacher \nModel\nReinforcement \nLearningStage 1\nStudent \nModelRaw Sensor Input \nBehavior CloningSupervisions\nStage 2Privileged Input \nTeacher \nModel\nReinforcement \nLearningStage 1\nStudent \nModelRaw Sensor Input \nPerception\nLearningFrozen Teacher Model \nwith Adapters Masked Feature \nAlignmentAction \nGuided\nFeature \nLearning\nStage 2(a) Direct Reinforcement Learning\n(b) Teacher -Student Paradigm c) DriveAdapter ParadigmEfficiency\nCausal\nEfficiency\nCausal\nEfficiency\nCausal\nFigure 1: Comparison of different paradigms for end-to-end autonomous driving. (a) Though directly conducting rein-\nforcement learning (RL) with raw sensor inputs [35] enables the inference model to learn the causal relationship of driving\nthrough rewards, it requires tens of days of training with the simulator rendering raw sensor inputs, which is of low efficiency.\n(b) State-of-the-art works [4, 3, 40, 32, 14] usually adopt the teacher-student paradigm to enable efficient policy learning by\nproviding privileged inputs (perception ground-truth) to the RL model. However, their student model suffers from the causal\nconfusion issues [37] due to behavior cloning. (c) In the proposed DriveAdapter paradigm, the model still enjoys high RL\ntraining efficiency while the usage of the frozen teacher model empowers the inference process with its driving knowledge.\nThe student model could focus on perception learning, and the proposed adapter module with its masked feature alignment\nobjective functions deals with the distribution gap between the perception results and the privileged inputs.\nAbstract\nEnd-to-end autonomous driving aims to build a fully dif-\nferentiable system that takes raw sensor data as inputs and\ndirectly outputs the planned trajectory or control signals\nof the ego vehicle. State-of-the-art methods usually followthe \u2018Teacher-Student\u2019 paradigm. The Teacher model uses\nprivileged information (ground-truth states of surrounding\nagents and map elements) to learn the driving strategy. The\nstudent model only has access to raw sensor data and con-\nducts behavior cloning on the data collected by the teacher\nmodel. By eliminating the noise of the perception part dur-\n1\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n7953\n",
        "project": "",
        "github": "",
        "arxiv": "2308.00398"
    },
    {
        "title": "Dual Aggregation Transformer for Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.html",
        "author": "Zheng Chen, Yulun Zhang, Jinjin Gu, Linghe Kong, Xiaokang Yang, Fisher Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "ETH Z\u00fcrich; Shanghai Jiao Tong University; The University of Sydney",
        "project": "",
        "github": "https://github.com/zhengchen1999/DAT",
        "arxiv": "2308.03364"
    },
    {
        "title": "Dual Learning with Dynamic Knowledge Distillation for Partially Relevant Video Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Dual_Learning_with_Dynamic_Knowledge_Distillation_for_Partially_Relevant_Video_ICCV_2023_paper.html",
        "author": "Jianfeng Dong, Minsong Zhang, Zheng Zhang, Xianke Chen, Daizong Liu, Xiaoye Qu, Xun Wang, Baolong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Dual_Learning_with_Dynamic_Knowledge_Distillation_for_Partially_Relevant_Video_ICCV_2023_paper.pdf",
        "aff": "Peking University; Zhejiang Gongshang University; Huazhong University of Science and Technology; Zhejiang Gongshang University, Zhejiang Key Lab of E-Commerce",
        "project": "",
        "github": "https://github.com/HuiGuanLab/DL-DKD",
        "arxiv": ""
    },
    {
        "title": "Dual Meta-Learning with Longitudinally Consistent Regularization for One-Shot Brain Tissue Segmentation Across the Human Lifespan",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Dual_Meta-Learning_with_Longitudinally_Consistent_Regularization_for_One-Shot_Brain_Tissue_ICCV_2023_paper.html",
        "author": "Yongheng Sun, Fan Wang, Jun Shu, Haifeng Wang, Li Wang, Deyu Meng, Chunfeng Lian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Dual_Meta-Learning_with_Longitudinally_Consistent_Regularization_for_One-Shot_Brain_Tissue_ICCV_2023_paper.pdf",
        "aff": "School of Mathematics and Statistics, Xi\u2019an Jiaotong University, Xi\u2019an 710049, China; UNC Chapel Hill, Chapel Hill, NC 27599, United States; The Key Laboratory of Biomedical Information Engineering of Ministry of Education, School of Life Science and Technology, Xi\u2019an Jiaotong University, Xi\u2019an 710049, China",
        "project": "",
        "github": "https://github.com/ladderlab-xjtu/DuMeta",
        "arxiv": ""
    },
    {
        "title": "Dual Pseudo-Labels Interactive Self-Training for Semi-Supervised Visible-Infrared Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Dual_Pseudo-Labels_Interactive_Self-Training_for_Semi-Supervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.html",
        "author": "Jiangming Shi, Yachao Zhang, Xiangbo Yin, Yuan Xie, Zhizhong Zhang, Jianping Fan, Zhongchao Shi, Yanyun Qu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Dual_Pseudo-Labels_Interactive_Self-Training_for_Semi-Supervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf",
        "aff": "Institute of Artificial Intelligence, Xiamen University; East China Normal University; Tsinghua Shenzhen International Graduate School, Tsinghua University; School of Informatics, Xiamen University; East China Normal University, Chongqing Institute of East China Normal University; Institute of Artificial Intelligence, School of Informatics, Xiamen University; Lenovo",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DyGait: Exploiting Dynamic Representations for High-performance Gait Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DyGait_Exploiting_Dynamic_Representations_for_High-performance_Gait_Recognition_ICCV_2023_paper.html",
        "author": "Ming Wang, Xianda Guo, Beibei Lin, Tian Yang, Zheng Zhu, Lincheng Li, Shunli Zhang, Xin Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DyGait_Exploiting_Dynamic_Representations_for_High-performance_Gait_Recognition_ICCV_2023_paper.pdf",
        "aff": "Unknown Affiliation",
        "project": "",
        "github": "",
        "arxiv": "2303.14953"
    },
    {
        "title": "DynaMITe: Dynamic Query Bootstrapping for Multi-object Interactive Segmentation Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rana_DynaMITe_Dynamic_Query_Bootstrapping_for_Multi-object_Interactive_Segmentation_Transformer_ICCV_2023_paper.html",
        "author": "Amit Kumar Rana, Sabarinath Mahadevan, Alexander Hermans, Bastian Leibe",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rana_DynaMITe_Dynamic_Query_Bootstrapping_for_Multi-object_Interactive_Segmentation_Transformer_ICCV_2023_paper.pdf",
        "aff": "RWTH Aachen University, Germany",
        "project": "https://vision.rwth-aachen.de/dynamite",
        "github": "",
        "arxiv": "2304.06668"
    },
    {
        "title": "Dynamic Hyperbolic Attention Network for Fine Hand-object Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Leng_Dynamic_Hyperbolic_Attention_Network_for_Fine_Hand-object_Reconstruction_ICCV_2023_paper.html",
        "author": "Zhiying Leng, Shun-Cheng Wu, Mahdi Saleh, Antonio Montanaro, Hao Yu, Yin Wang, Nassir Navab, Xiaohui Liang, Federico Tombari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Leng_Dynamic_Hyperbolic_Attention_Network_for_Fine_Hand-object_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, China; Politecnico di Torino, Italy; Computer Aided Medical Procedures, Technical University of Munich, Germany",
        "project": "",
        "github": "",
        "arxiv": "2309.02965"
    },
    {
        "title": "Dynamic Mesh Recovery from Partial Point Cloud Sequence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Dynamic_Mesh_Recovery_from_Partial_Point_Cloud_Sequence_ICCV_2023_paper.html",
        "author": "Hojun Jang, Minkwan Kim, Jinseok Bae, Young Min Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Dynamic_Mesh_Recovery_from_Partial_Point_Cloud_Sequence_ICCV_2023_paper.pdf",
        "aff": "Dept. of Electrical and Computer Engineering, Seoul National University and Interdisciplinary Program in Artificial Intelligence and INMC, Seoul National University; Dept. of Electrical and Computer Engineering, Seoul National University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Dynamic Mesh-Aware Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_Dynamic_Mesh-Aware_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Yi-Ling Qiao, Alexander Gao, Yiran Xu, Yue Feng, Jia-Bin Huang, Ming C. Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_Dynamic_Mesh-Aware_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "University of Maryland College Park",
        "project": "https://mesh-aware-rf.github.io",
        "github": "",
        "arxiv": "2309.04581"
    },
    {
        "title": "Dynamic Perceiver for Efficient Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_Dynamic_Perceiver_for_Efficient_Visual_Recognition_ICCV_2023_paper.html",
        "author": "Yizeng Han, Dongchen Han, Zeyu Liu, Yulin Wang, Xuran Pan, Yifan Pu, Chao Deng, Junlan Feng, Shiji Song, Gao Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Dynamic_Perceiver_for_Efficient_Visual_Recognition_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, BNRist, Tsinghua University; China Mobile Research Institute; Department of Computer Science and Technology, BNRist, Tsinghua University; Department of Automation, BNRist, Tsinghua University and Beijing Academy of Artificial Intelligence",
        "project": "",
        "github": "https://www.github.com/LeapLabTHU/Dynamic_Perceiver",
        "arxiv": "2306.11248"
    },
    {
        "title": "Dynamic PlenOctree for Adaptive Sampling Refinement in Explicit NeRF",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bai_Dynamic_PlenOctree_for_Adaptive_Sampling_Refinement_in_Explicit_NeRF_ICCV_2023_paper.html",
        "author": "Haotian Bai, Yiqi Lin, Yize Chen, Lin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Dynamic_PlenOctree_for_Adaptive_Sampling_Refinement_in_Explicit_NeRF_ICCV_2023_paper.pdf",
        "aff": "VLIS LAB, AI Thrust, HKUST(GZ); Dept. of CSE, HKUST",
        "project": "https://vlislab22.github.io/DOT/",
        "github": "",
        "arxiv": "2307.15333"
    },
    {
        "title": "Dynamic Point Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Prokudin_Dynamic_Point_Fields_ICCV_2023_paper.html",
        "author": "Sergey Prokudin, Qianli Ma, Maxime Raafat, Julien Valentin, Siyu Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Prokudin_Dynamic_Point_Fields_ICCV_2023_paper.pdf",
        "aff": "ETH Z\u00fcrich; ETH Z\u00fcrich, Max Planck Institute for Intelligent Systems; Microsoft",
        "project": "",
        "github": "https://sergeyprokudin.github.io/dpf",
        "arxiv": "2304.02626"
    },
    {
        "title": "Dynamic Residual Classifier for Class Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Dynamic_Residual_Classifier_for_Class_Incremental_Learning_ICCV_2023_paper.html",
        "author": "Xiuwei Chen, Xiaobin Chang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dynamic_Residual_Classifier_for_Class_Incremental_Learning_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence, Sun Yat-sen University, China; Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou 510006, P.R.China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China",
        "project": "",
        "github": "https://github.com/chen-xw/DRC-CIL",
        "arxiv": "2308.13305"
    },
    {
        "title": "Dynamic Snake Convolution Based on Topological Geometric Constraints for Tubular Structure Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qi_Dynamic_Snake_Convolution_Based_on_Topological_Geometric_Constraints_for_Tubular_ICCV_2023_paper.html",
        "author": "Yaolei Qi, Yuting He, Xiaoming Qi, Yuan Zhang, Guanyu Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_Dynamic_Snake_Convolution_Based_on_Topological_Geometric_Constraints_for_Tubular_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications (Southeast University), Ministry of Education, Nanjing 210096, China; Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications (Southeast University), Ministry of Education, Nanjing 210096, China; Jiangsu Province Joint International Research Laboratory of Medical Information Processing, Southeast University, Nanjing, China; Centre de Recherche en Information Biom\u00e9dicale Sino-Fran\u00e7ais (CRIBs), Strasbourg, France",
        "project": "",
        "github": "https://github.com/YaoleiQi/DSCNet",
        "arxiv": "2307.08388"
    },
    {
        "title": "Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Quan Tang, Bowen Zhang, Jiajun Liu, Fagui Liu, Yifan Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology; The University of Adelaide; CSIRO",
        "project": "",
        "github": "https://github.com/zbwxp/Dynamic-Token-Pruning",
        "arxiv": "2308.01045"
    },
    {
        "title": "DynamicISP: Dynamically Controlled Image Signal Processor for Image Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yoshimura_DynamicISP_Dynamically_Controlled_Image_Signal_Processor_for_Image_Recognition_ICCV_2023_paper.html",
        "author": "Masakazu Yoshimura, Junji Otsuka, Atsushi Irie, Takeshi Ohashi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yoshimura_DynamicISP_Dynamically_Controlled_Image_Signal_Processor_for_Image_Recognition_ICCV_2023_paper.pdf",
        "aff": "Sony Group Corporation",
        "project": "",
        "github": "",
        "arxiv": "2211.01146"
    },
    {
        "title": "E2E-LOAD: End-to-End Long-form Online Action Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_E2E-LOAD_End-to-End_Long-form_Online_Action_Detection_ICCV_2023_paper.html",
        "author": "Shuqiang Cao, Weixin Luo, Bairui Wang, Wei Zhang, Lin Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_E2E-LOAD_End-to-End_Long-form_Online_Action_Detection_ICCV_2023_paper.pdf",
        "aff": "Meituan; School of Control Science and Engineering, Shandong University",
        "project": "",
        "github": "https://github.com/sqiangcao99/E2E-LOAD",
        "arxiv": ""
    },
    {
        "title": "E2NeRF: Event Enhanced Neural Radiance Fields from Blurry Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qi_E2NeRF_Event_Enhanced_Neural_Radiance_Fields_from_Blurry_Images_ICCV_2023_paper.html",
        "author": "Yunshan Qi, Lin Zhu, Yu Zhang, Jia Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_E2NeRF_Event_Enhanced_Neural_Radiance_Fields_from_Blurry_Images_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of Technology; SenseTime and Tetras.AI; State Key Laboratory of Virtual Reality Technology and Systems, SCSE, Beihang University; State Key Laboratory of Virtual Reality Technology and Systems, SCSE, Beihang University; Peng Cheng Laboratory",
        "project": "",
        "github": "https://github.com/iCVTEAM/E2NeRF",
        "arxiv": ""
    },
    {
        "title": "E3Sym: Leveraging E(3) Invariance for Unsupervised 3D Planar Reflective Symmetry Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_E3Sym_Leveraging_E3_Invariance_for_Unsupervised_3D_Planar_Reflective_Symmetry_ICCV_2023_paper.html",
        "author": "Ren-Wu Li, Ling-Xiao Zhang, Chunpeng Li, Yu-Kun Lai, Lin Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_E3Sym_Leveraging_E3_Invariance_for_Unsupervised_3D_Planar_Reflective_Symmetry_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Informatics, Cardiff University; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "EDAPS: Enhanced Domain-Adaptive Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Saha_EDAPS_Enhanced_Domain-Adaptive_Panoptic_Segmentation_ICCV_2023_paper.html",
        "author": "Suman Saha, Lukas Hoyer, Anton Obukhov, Dengxin Dai, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_EDAPS_Enhanced_Domain-Adaptive_Panoptic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; Huawei Zurich Research Center; ETH Zurich, KU Leuven",
        "project": "",
        "github": "https://github.com/susaha/edaps",
        "arxiv": "2304.14291"
    },
    {
        "title": "EGC: Image Generation and Classification via a Diffusion Energy-Based Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.html",
        "author": "Qiushan Guo, Chuofan Ma, Yi Jiang, Zehuan Yuan, Yizhou Yu, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.pdf",
        "aff": "The University of Hong Kong, Shanghai AI Laboratory; The University of Hong Kong; ByteDance Inc.",
        "project": "",
        "github": "https://github.com/GuoQiushan/EGC",
        "arxiv": "2304.02012"
    },
    {
        "title": "EGformer: Equirectangular Geometry-biased Transformer for 360 Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yun_EGformer_Equirectangular_Geometry-biased_Transformer_for_360_Depth_Estimation_ICCV_2023_paper.html",
        "author": "Ilwi Yun, Chanyong Shin, Hyunku Lee, Hyuk-Jae Lee, Chae Eun Rhee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_EGformer_Equirectangular_Geometry-biased_Transformer_for_360_Depth_Estimation_ICCV_2023_paper.pdf",
        "aff": "Inha University, Incheon, Republic of Korea; Seoul National University, Seoul, Republic of Korea",
        "project": "",
        "github": "",
        "arxiv": "2304.07803"
    },
    {
        "title": "ELFNet: Evidential Local-global Fusion for Stereo Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lou_ELFNet_Evidential_Local-global_Fusion_for_Stereo_Matching_ICCV_2023_paper.html",
        "author": "Jieming Lou, Weide Liu, Zhuo Chen, Fayao Liu, Jun Cheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lou_ELFNet_Evidential_Local-global_Fusion_for_Stereo_Matching_ICCV_2023_paper.pdf",
        "aff": "Institute for Infocomm Research, A*STAR; Institute for Infocomm Research, A*STAR and National University of Singapore",
        "project": "",
        "github": "https://github.com/jimmy19991222/ELFNet",
        "arxiv": "2308.00728"
    },
    {
        "title": "ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.html",
        "author": "Yuxiang Wei, Yabo Zhang, Zhilong Ji, Jinfeng Bai, Lei Zhang, Wangmeng Zuo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong Polytechnic University; Harbin Institute of Technology, Peng Cheng Lab; Harbin Institute of Technology; Tomorrow Advancing Life",
        "project": "",
        "github": "https://github.com/csyxwei/ELITE",
        "arxiv": "2302.13848"
    },
    {
        "title": "EMDB: The Electromagnetic Database of Global 3D Human Pose and Shape in the Wild",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kaufmann_EMDB_The_Electromagnetic_Database_of_Global_3D_Human_Pose_and_ICCV_2023_paper.html",
        "author": "Manuel Kaufmann, Jie Song, Chen Guo, Kaiyue Shen, Tianjian Jiang, Chengcheng Tang, Juan Jos\u00e9 Z\u00e1rate, Otmar Hilliges",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kaufmann_EMDB_The_Electromagnetic_Database_of_Global_3D_Human_Pose_and_ICCV_2023_paper.pdf",
        "aff": "Meta Reality Labs; ETH Z\u00fcrich, Department of Computer Science",
        "project": "https://ait.ethz.ch/emdb",
        "github": "",
        "arxiv": "2308.16894"
    },
    {
        "title": "EMMN: Emotional Motion Memory Network for Audio-driven Emotional Talking Face Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.html",
        "author": "Shuai Tan, Bin Ji, Ye Pan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.pdf",
        "aff": "Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "EMQ: Evolving Training-free Proxies for Automated Mixed Precision Quantization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_EMQ_Evolving_Training-free_Proxies_for_Automated_Mixed_Precision_Quantization_ICCV_2023_paper.html",
        "author": "Peijie Dong, Lujun Li, Zimian Wei, Xin Niu, Zhiliang Tian, Hengyue Pan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_EMQ_Evolving_Training-free_Proxies_for_Automated_Mixed_Precision_Quantization_ICCV_2023_paper.pdf",
        "aff": "HKUST; National University of Defense Technology",
        "project": "",
        "github": "",
        "arxiv": "2307.10554"
    },
    {
        "title": "EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting Ego-Motion Rigidity",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_EMR-MSF_Self-Supervised_Recurrent_Monocular_Scene_Flow_Exploiting_Ego-Motion_Rigidity_ICCV_2023_paper.html",
        "author": "Zijie Jiang, Masatoshi Okutomi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_EMR-MSF_Self-Supervised_Recurrent_Monocular_Scene_Flow_Exploiting_Ego-Motion_Rigidity_ICCV_2023_paper.pdf",
        "aff": "Tokyo Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ENTL: Embodied Navigation Trajectory Learner",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kotar_ENTL_Embodied_Navigation_Trajectory_Learner_ICCV_2023_paper.html",
        "author": "Klemen Kotar, Aaron Walsman, Roozbeh Mottaghi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kotar_ENTL_Embodied_Navigation_Trajectory_Learner_ICCV_2023_paper.pdf",
        "aff": "Stanford University; Meta AI; University of Washington",
        "project": "",
        "github": "https://github.com/klemenkotar/ENTL",
        "arxiv": "2304.02639"
    },
    {
        "title": "ENVIDR: Implicit Differentiable Renderer with Neural Environment Lighting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_ENVIDR_Implicit_Differentiable_Renderer_with_Neural_Environment_Lighting_ICCV_2023_paper.html",
        "author": "Ruofan Liang, Huiting Chen, Chunlin Li, Fan Chen, Selvakumar Panneer, Nandita Vijaykumar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_ENVIDR_Implicit_Differentiable_Renderer_with_Neural_Environment_Lighting_ICCV_2023_paper.pdf",
        "aff": "Intel Labs; University of Toronto; University of Toronto, Vector Institute",
        "project": "nexuslrf.github.io/ENVIDR",
        "github": "",
        "arxiv": "2303.13022"
    },
    {
        "title": "EP2P-Loc: End-to-End 3D Point to 2D Pixel Localization for Large-Scale Visual Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_EP2P-Loc_End-to-End_3D_Point_to_2D_Pixel_Localization_for_Large-Scale_ICCV_2023_paper.html",
        "author": "Minjung Kim, Junseo Koo, Gunhee Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_EP2P-Loc_End-to-End_3D_Point_to_2D_Pixel_Localization_for_Large-Scale_ICCV_2023_paper.pdf",
        "aff": "Seoul National University",
        "project": "",
        "github": "https://github.com/minnjung/EP2P-Loc",
        "arxiv": ""
    },
    {
        "title": "EPiC: Ensemble of Partial Point Clouds for Robust Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Levi_EPiC_Ensemble_of_Partial_Point_Clouds_for_Robust_Classification_ICCV_2023_paper.html",
        "author": "Meir Yossef Levi, Guy Gilboa",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Levi_EPiC_Ensemble_of_Partial_Point_Clouds_for_Robust_Classification_ICCV_2023_paper.pdf",
        "aff": "Viterbi Faculty of Electrical and Computer Engineering, Technion - Israel Institute of Technology, Haifa, Israel",
        "project": "",
        "github": "https://github.com/yossilevii100/EPiC",
        "arxiv": "2303.11419"
    },
    {
        "title": "EQ-Net: Elastic Quantization Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_EQ-Net_Elastic_Quantization_Neural_Networks_ICCV_2023_paper.html",
        "author": "Ke Xu, Lei Han, Ye Tian, Shangshang Yang, Xingyi Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_EQ-Net_Elastic_Quantization_Neural_Networks_ICCV_2023_paper.pdf",
        "aff": "Institutes of Physical Science and Information Technology, Anhui University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China; School of Artificial Intelligence, Anhui University, Hefei, China",
        "project": "",
        "github": "https://github.com/xuke225/EQ-Net",
        "arxiv": ""
    },
    {
        "title": "ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.html",
        "author": "Mingjin Zhang, Chi Zhang, Qiming Zhang, Jie Guo, Xinbo Gao, Jing Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.pdf",
        "aff": "Chongqing University of Posts and Telecommunications, China; Xidian University, China; The University of Sydney, Australia",
        "project": "",
        "github": "ESSAformer",
        "arxiv": "2307.14010"
    },
    {
        "title": "ESTextSpotter: Towards Better Scene Text Spotting with Explicit Synergy in Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_ESTextSpotter_Towards_Better_Scene_Text_Spotting_with_Explicit_Synergy_in_ICCV_2023_paper.html",
        "author": "Mingxin Huang, Jiaxin Zhang, Dezhi Peng, Hao Lu, Can Huang, Yuliang Liu, Xiang Bai, Lianwen Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ESTextSpotter_Towards_Better_Scene_Text_Spotting_with_Explicit_Synergy_in_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology; Huazhong University of Science and Technology; ByteDance",
        "project": "",
        "github": "https://github.com/mxin262/ESTextSpotter",
        "arxiv": "2308.10147"
    },
    {
        "title": "ETran: Energy-Based Transferability Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gholami_ETran_Energy-Based_Transferability_Estimation_ICCV_2023_paper.html",
        "author": "Mohsen Gholami, Mohammad Akbari, Xinglu Wang, Behnam Kamranian, Yong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gholami_ETran_Energy-Based_Transferability_Estimation_ICCV_2023_paper.pdf",
        "aff": "Huawei Technologies Canada Co., Ltd., University of British Columbia; Huawei Technologies Canada Co., Ltd.",
        "project": "https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=56e6645a-8133-49f6-a7ef-d877ef608fa5",
        "github": "",
        "arxiv": "2308.02027"
    },
    {
        "title": "E^2VPT: An Effective and Efficient Approach for Visual Prompt Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_E2VPT_An_Effective_and_Efficient_Approach_for_Visual_Prompt_Tuning_ICCV_2023_paper.html",
        "author": "Cheng Han, Qifan Wang, Yiming Cui, Zhiwen Cao, Wenguan Wang, Siyuan Qi, Dongfang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_E2VPT_An_Effective_and_Efficient_Approach_for_Visual_Prompt_Tuning_ICCV_2023_paper.pdf",
        "aff": "...\n......\n...\n......\n(d) Ours\n (c) Prompt tuning\n...\n(a) Partial tuning\n...\n(b) Extra module\nAccuracy (%)\nPrompt T.\n O\nFull F. T.\nPartial T.\nExtra M.\nTunable Parameters (%)100 101 102 4050607080\n10-1 \nVTAB-1k Natural\nVTAB-1k StructuredVTAB-1k SpecializedLN\nL2\nL1LN\nL2\nL1LN\nL2\nL1LN\nL2\nL1\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n17491\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_EdaDet_Open-Vocabulary_Object_Detection_Using_Early_Dense_Alignment_ICCV_2023_paper.html",
        "author": "Cheng Shi, Sibei Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_EdaDet_Open-Vocabulary_Object_Detection_Using_Early_Dense_Alignment_ICCV_2023_paper.pdf",
        "aff": "School of Information Science and Technology, ShanghaiTech University",
        "project": "https://chengshiest.github.io/edadet",
        "github": "",
        "arxiv": "2309.01151"
    },
    {
        "title": "Editable Image Geometric Abstraction via Neural Primitive Assembly",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.html",
        "author": "Ye Chen, Bingbing Ni, Xuanhong Chen, Zhangli Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.pdf",
        "aff": "Shanghai Jiao Tong University, Shanghai 200240, China; Shanghai Jiao Tong University, Shanghai 200240, China; USC-SJTU Institute of Cultural and Creative Industry",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Editing Implicit Assumptions in Text-to-Image Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Hadas Orgad, Bahjat Kawar, Yonatan Belinkov",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Computer Science Faculty, Technion, Israel",
        "project": "https://time-diffusion.github.io/",
        "github": "",
        "arxiv": "2303.08084"
    },
    {
        "title": "Effective Real Image Editing with Accelerated Iterative Diffusion Inversion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.html",
        "author": "Zhihong Pan, Riccardo Gherardi, Xiufeng Xie, Stephen Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf",
        "aff": "Oppo Mobile Telecommunications Corp., 2479 E Bayshore Rd, Palo Alto, CA, USA",
        "project": "",
        "github": "",
        "arxiv": "2309.04907"
    },
    {
        "title": "Efficient 3D Semantic Segmentation with Superpoint Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Robert_Efficient_3D_Semantic_Segmentation_with_Superpoint_Transformer_ICCV_2023_paper.html",
        "author": "Damien Robert, Hugo Raguet, Loic Landrieu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Robert_Efficient_3D_Semantic_Segmentation_with_Superpoint_Transformer_ICCV_2023_paper.pdf",
        "aff": "INSA Centre Val-de-Loire Univ de Tours, LIFAT, France; LASTIG, IGN, ENSG, Univ Gustave Eiffel, France; LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS, France; CSAI, ENGIE Lab CRIGEN, France; LASTIG, IGN, ENSG, Univ Gustave Eiffel, France",
        "project": "",
        "github": "github.com/drprojects/superpoint_transformer",
        "arxiv": "2306.08045"
    },
    {
        "title": "Efficient Adaptive Human-Object Interaction Detection with Concept-guided Memory",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lei_Efficient_Adaptive_Human-Object_Interaction_Detection_with_Concept-guided_Memory_ICCV_2023_paper.html",
        "author": "Ting Lei, Fabian Caba, Qingchao Chen, Hailin Jin, Yuxin Peng, Yang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Efficient_Adaptive_Human-Object_Interaction_Detection_with_Concept-guided_Memory_ICCV_2023_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University; Adobe Research; National Institute of Health Data Science, Peking University",
        "project": "",
        "github": "https://github.com/ltttpku/ADA-CM",
        "arxiv": "2309.03696"
    },
    {
        "title": "Efficient Computation Sharing for Multi-Task Visual Scene Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shoouri_Efficient_Computation_Sharing_for_Multi-Task_Visual_Scene_Understanding_ICCV_2023_paper.html",
        "author": "Sara Shoouri, Mingyu Yang, Zichen Fan, Hun-Seok Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shoouri_Efficient_Computation_Sharing_for_Multi-Task_Visual_Scene_Understanding_ICCV_2023_paper.pdf",
        "aff": "University of Michigan",
        "project": "",
        "github": "https://github.com/sarashoouri/EfficientMTL",
        "arxiv": "2303.09663"
    },
    {
        "title": "Efficient Controllable Multi-Task Architectures",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Aich_Efficient_Controllable_Multi-Task_Architectures_ICCV_2023_paper.html",
        "author": "Abhishek Aich, Samuel Schulter, Amit K. Roy-Chowdhury, Manmohan Chandraker, Yumin Suh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Efficient_Controllable_Multi-Task_Architectures_ICCV_2023_paper.pdf",
        "aff": "University of California, San Diego; University of California, Riverside; NEC Labs America",
        "project": "",
        "github": "",
        "arxiv": "2308.11744"
    },
    {
        "title": "Efficient Converted Spiking Neural Network for 3D and 2D Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lan_Efficient_Converted_Spiking_Neural_Network_for_3D_and_2D_Classification_ICCV_2023_paper.html",
        "author": "Yuxiang Lan, Yachao Zhang, Xu Ma, Yanyun Qu, Yun Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lan_Efficient_Converted_Spiking_Neural_Network_for_3D_and_2D_Classification_ICCV_2023_paper.pdf",
        "aff": "School of Informatics, Xiamen University; Department of ECE, Northeastern University; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Efficient Decision-based Black-box Patch Attacks on Video Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Efficient_Decision-based_Black-box_Patch_Attacks_on_Video_Recognition_ICCV_2023_paper.html",
        "author": "Kaixun Jiang, Zhaoyu Chen, Hao Huang, Jiafeng Wang, Dingkang Yang, Bo Li, Yan Wang, Wenqiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Efficient_Decision-based_Black-box_Patch_Attacks_on_Video_Recognition_ICCV_2023_paper.pdf",
        "aff": "vivo Mobile Communication Co., Ltd.; School of Computer Science, Fudan University; Academy for Engineering and Technology, Fudan University",
        "project": "",
        "github": "",
        "arxiv": "2303.11917"
    },
    {
        "title": "Efficient Deep Space Filling Curve",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Efficient_Deep_Space_Filling_Curve_ICCV_2023_paper.html",
        "author": "Wanli Chen, Xufeng Yao, Xinyun Zhang, Bei Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Deep_Space_Filling_Curve_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Efficient Diffusion Training via Min-SNR Weighting Strategy",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hang_Efficient_Diffusion_Training_via_Min-SNR_Weighting_Strategy_ICCV_2023_paper.html",
        "author": "Tiankai Hang, Shuyang Gu, Chen Li, Jianmin Bao, Dong Chen, Han Hu, Xin Geng, Baining Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hang_Efficient_Diffusion_Training_via_Min-SNR_Weighting_Strategy_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; Southeast University; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Applications, and Institute of Arti\ufb01cial Intelligence and Robotics, Xi\u2019an Jiaotong University",
        "project": "",
        "github": "https://github.com/TiankaiHang/Min-SNR-Diffusion-Training",
        "arxiv": "2303.09556"
    },
    {
        "title": "Efficient Discovery and Effective Evaluation of Visual Perceptual Similarity: A Benchmark and Beyond",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Barkan_Efficient_Discovery_and_Effective_Evaluation_of_Visual_Perceptual_Similarity_A_ICCV_2023_paper.html",
        "author": "Oren Barkan, Tal Reiss, Jonathan Weill, Ori Katz, Roy Hirsch, Itzik Malkiel, Noam Koenigstein",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Barkan_Efficient_Discovery_and_Effective_Evaluation_of_Visual_Perceptual_Similarity_A_ICCV_2023_paper.pdf",
        "aff": "The Hebrew University of Jerusalem; The Open University; Technion; Tel Aviv University",
        "project": "https://vsd-benchmark.github.io/vsd",
        "github": "",
        "arxiv": "2308.14753"
    },
    {
        "title": "Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gan_Efficient_Emotional_Adaptation_for_Audio-Driven_Talking-Head_Generation_ICCV_2023_paper.html",
        "author": "Yuan Gan, Zongxin Yang, Xihang Yue, Lingyun Sun, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Efficient_Emotional_Adaptation_for_Audio-Driven_Talking-Head_Generation_ICCV_2023_paper.pdf",
        "aff": "College of Computer Science and Technology, Zhejiang University, China; ReLER, CCAI, Zhejiang University, China; College of Computer Science and Technology, Zhejiang University, China",
        "project": "https://yuangan.github.io/eat/",
        "github": "",
        "arxiv": "2309.04946"
    },
    {
        "title": "Efficient Joint Optimization of Layer-Adaptive Weight Pruning in Deep Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Efficient_Joint_Optimization_of_Layer-Adaptive_Weight_Pruning_in_Deep_Neural_ICCV_2023_paper.html",
        "author": "Kaixin Xu, Zhe Wang, Xue Geng, Min Wu, Xiaoli Li, Weisi Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Efficient_Joint_Optimization_of_Layer-Adaptive_Weight_Pruning_in_Deep_Neural_ICCV_2023_paper.pdf",
        "aff": "Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR); Nanyang Technological University, Singapore; Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR); Nanyang Technological University, Singapore",
        "project": "",
        "github": "https://github.com/Akimoto-Cris/RD_VIT_PRUNE",
        "arxiv": "2308.10438"
    },
    {
        "title": "Efficient LiDAR Point Cloud Oversegmentation Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hui_Efficient_LiDAR_Point_Cloud_Oversegmentation_Network_ICCV_2023_paper.html",
        "author": "Le Hui, Linghua Tang, Yuchao Dai, Jin Xie, Jian Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hui_Efficient_LiDAR_Point_Cloud_Oversegmentation_Network_ICCV_2023_paper.pdf",
        "aff": "Northwestern Polytechnical University; Nanjing University of Science and Technology",
        "project": "",
        "github": "https://github.com/fpthink/SuperLiDAR",
        "arxiv": ""
    },
    {
        "title": "Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Efficient_Model_Personalization_in_Federated_Learning_via_Client-Specific_Prompt_Generation_ICCV_2023_paper.html",
        "author": "Fu-En Yang, Chien-Yi Wang, Yu-Chiang Frank Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Efficient_Model_Personalization_in_Federated_Learning_via_Client-Specific_Prompt_Generation_ICCV_2023_paper.pdf",
        "aff": "NVIDIA; National Taiwan University",
        "project": "",
        "github": "",
        "arxiv": "2308.15367"
    },
    {
        "title": "Efficient Neural Supersampling on a Novel Gaming Dataset",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mercier_Efficient_Neural_Supersampling_on_a_Novel_Gaming_Dataset_ICCV_2023_paper.html",
        "author": "Antoine Mercier, Ruan Erasmus, Yashesh Savani, Manik Dhingra, Fatih Porikli, Guillaume Berger",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mercier_Efficient_Neural_Supersampling_on_a_Novel_Gaming_Dataset_ICCV_2023_paper.pdf",
        "aff": "Qualcomm AI Research",
        "project": "",
        "github": "",
        "arxiv": "2308.01483"
    },
    {
        "title": "Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.html",
        "author": "Jiahe Li, Jiawei Zhang, Xiao Bai, Jun Zhou, Lin Gu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, State Key Laboratory of Software Development Environment, Jiangxi Research Institute, Beihang University; School of Information and Communication Technology, Griffith University; RIKEN AIP, The University of Tokyo",
        "project": "",
        "github": "https://github.com/Fictionarry/ER-NeRF",
        "arxiv": "2307.09323"
    },
    {
        "title": "Efficient Transformer-based 3D Object Detection with Dynamic Token Halting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Efficient_Transformer-based_3D_Object_Detection_with_Dynamic_Token_Halting_ICCV_2023_paper.html",
        "author": "Mao Ye, Gregory P. Meyer, Yuning Chai, Qiang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Efficient_Transformer-based_3D_Object_Detection_with_Dynamic_Token_Halting_ICCV_2023_paper.pdf",
        "aff": "The University of Texas at Austin; Cruise LLC",
        "project": "",
        "github": "",
        "arxiv": "2303.05078"
    },
    {
        "title": "Efficient Unified Demosaicing for Bayer and Non-Bayer Patterned Image Sensors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Efficient_Unified_Demosaicing_for_Bayer_and_Non-Bayer_Patterned_Image_Sensors_ICCV_2023_paper.html",
        "author": "Haechang Lee, Dongwon Park, Wongi Jeong, Kijeong Kim, Hyunwoo Je, Dongil Ryu, Se Young Chun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Efficient_Unified_Demosaicing_for_Bayer_and_Non-Bayer_Patterned_Image_Sensors_ICCV_2023_paper.pdf",
        "aff": "Dept. of ECE, Seoul National University, Republic of Korea; SK hynix, Republic of Korea; INMC, Seoul National University, Republic of Korea; SK hynix, Republic of Korea; Dept. of ECE, Seoul National University, Republic of Korea; SK hynix, Republic of Korea; INMC, IPAI, Seoul National University, Republic of Korea",
        "project": "",
        "github": "",
        "arxiv": "2307.10667"
    },
    {
        "title": "Efficient Video Action Detection with Token Dropout and Context Refinement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Efficient_Video_Action_Detection_with_Token_Dropout_and_Context_Refinement_ICCV_2023_paper.html",
        "author": "Lei Chen, Zhan Tong, Yibing Song, Gangshan Wu, Limin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Video_Action_Detection_with_Token_Dropout_and_Context_Refinement_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University, Shanghai AI Lab; AI3Institute, Fudan University; Ant Group",
        "project": "",
        "github": "https://github.com/MCG-NJU/EVAD",
        "arxiv": "2304.08451"
    },
    {
        "title": "Efficient Video Prediction via Sparsely Conditioned Flow Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Davtyan_Efficient_Video_Prediction_via_Sparsely_Conditioned_Flow_Matching_ICCV_2023_paper.html",
        "author": "Aram Davtyan, Sepehr Sameni, Paolo Favaro",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Davtyan_Efficient_Video_Prediction_via_Sparsely_Conditioned_Flow_Matching_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Group, Institute of Computer Science, University of Bern, Switzerland",
        "project": "https://araachie.github.io/river",
        "github": "",
        "arxiv": "2211.14575"
    },
    {
        "title": "Efficient View Synthesis with Neural Radiance Distribution Field",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Efficient_View_Synthesis_with_Neural_Radiance_Distribution_Field_ICCV_2023_paper.html",
        "author": "Yushuang Wu, Xiao Li, Jinglu Wang, Xiaoguang Han, Shuguang Cui, Yan Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Efficient_View_Synthesis_with_Neural_Radiance_Distribution_Field_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; FNii, CUHKSZ and SSE, CUHKSZ",
        "project": "http://yushuang-wu.github.io/NeRDF",
        "github": "https://github.com/yushuang-wu/NeRDF",
        "arxiv": "2308.11130"
    },
    {
        "title": "Efficient-VQGAN: Towards High-Resolution Image Generation with Efficient Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Shiyue Cao, Yueqin Yin, Lianghua Huang, Yu Liu, Xin Zhao, Deli Zhao, Kaigi Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences; CAS Center for Excellence in Brain Science and Intelligence Technology, China; Machine Intelligence Technology Lab, Alibaba Group, China; School of Artificial Intelligence, University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "EfficientTrain: Exploring Generalized Curriculum Learning for Training Visual Backbones",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_EfficientTrain_Exploring_Generalized_Curriculum_Learning_for_Training_Visual_Backbones_ICCV_2023_paper.html",
        "author": "Yulin Wang, Yang Yue, Rui Lu, Tianjiao Liu, Zhao Zhong, Shiji Song, Gao Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_EfficientTrain_Exploring_Generalized_Curriculum_Learning_for_Training_Visual_Backbones_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, BNRist, Tsinghua University; BAAI; Department of Automation, BNRist, Tsinghua University; Huawei Technologies Ltd.",
        "project": "",
        "github": "https://github.com/LeapLabTHU/EfficientTrain",
        "arxiv": "2211.09703"
    },
    {
        "title": "EfficientViT: Lightweight Multi-Scale Attention for High-Resolution Dense Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.html",
        "author": "Han Cai, Junyan Li, Muyan Hu, Chuang Gan, Song Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; MIT-IBM Watson AI Lab; Zhejiang University; MIT",
        "project": "",
        "github": "https://github.com/mit-han-lab/efficientvit",
        "arxiv": ""
    },
    {
        "title": "Efficiently Robustify Pre-Trained Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jain_Efficiently_Robustify_Pre-Trained_Models_ICCV_2023_paper.html",
        "author": "Nishant Jain, Harkirat Behl, Yogesh Singh Rawat, Vibhav Vineet",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_Efficiently_Robustify_Pre-Trained_Models_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; CRCV, UCF; IIT Roorkee",
        "project": "",
        "github": "",
        "arxiv": "2309.07499"
    },
    {
        "title": "Ego-Humans: An Ego-Centric 3D Multi-Human Benchmark",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Khirodkar_Ego-Humans_An_Ego-Centric_3D_Multi-Human_Benchmark_ICCV_2023_paper.html",
        "author": "Rawal Khirodkar, Aayush Bansal, Lingni Ma, Richard Newcombe, Minh Vo, Kris Kitani",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Khirodkar_Ego-Humans_An_Ego-Centric_3D_Multi-Human_Benchmark_ICCV_2023_paper.pdf",
        "aff": "Not provided",
        "project": "https://rawalkhirodkar.github.io/egohumans",
        "github": "https://github.com/rawalkhirodkar/egohumans",
        "arxiv": ""
    },
    {
        "title": "Ego-Only: Egocentric Action Detection without Exocentric Transferring",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Ego-Only_Egocentric_Action_Detection_without_Exocentric_Transferring_ICCV_2023_paper.html",
        "author": "Huiyu Wang, Mitesh Kumar Singh, Lorenzo Torresani",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Ego-Only_Egocentric_Action_Detection_without_Exocentric_Transferring_ICCV_2023_paper.pdf",
        "aff": "Meta AI",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "EgoLoc: Revisiting 3D Object Localization from Egocentric Videos with Visual Queries",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.html",
        "author": "Jinjie Mai, Abdullah Hamdi, Silvio Giancola, Chen Zhao, Bernard Ghanem",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.pdf",
        "aff": "Visual Geometry Group, University of Oxford; King Abdullah University of Science and Technology (KAUST)",
        "project": "",
        "github": "https://github.com/Wayne-Mai/EgoLoc",
        "arxiv": "2212.06969"
    },
    {
        "title": "EgoObjects: A Large-Scale Egocentric Dataset for Fine-Grained Object Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_EgoObjects_A_Large-Scale_Egocentric_Dataset_for_Fine-Grained_Object_Understanding_ICCV_2023_paper.html",
        "author": "Chenchen Zhu, Fanyi Xiao, Andres Alvarado, Yasmine Babaei, Jiabo Hu, Hichem El-Mohri, Sean Culatana, Roshan Sumbaly, Zhicheng Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_EgoObjects_A_Large-Scale_Egocentric_Dataset_for_Fine-Grained_Object_Understanding_ICCV_2023_paper.pdf",
        "aff": "Meta AI",
        "project": "",
        "github": "https://github.com/facebookresearch/EgoObjects",
        "arxiv": "2309.08816"
    },
    {
        "title": "EgoPCA: A New Framework for Egocentric Hand-Object Interaction Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_EgoPCA_A_New_Framework_for_Egocentric_Hand-Object_Interaction_Understanding_ICCV_2023_paper.html",
        "author": "Yue Xu, Yong-Lu Li, Zhemin Huang, Michael Xu Liu, Cewu Lu, Yu-Wing Tai, Chi-Keung Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_EgoPCA_A_New_Framework_for_Egocentric_Hand-Object_Interaction_Understanding_ICCV_2023_paper.pdf",
        "aff": "HKUST; Dartmouth College; Shanghai Jiao Tong University; Shanghai Jiao Tong University, HKUST; New Hope Investment Group",
        "project": "https://mvig-rhos.com/ego_pca",
        "github": "",
        "arxiv": "2309.02423"
    },
    {
        "title": "EgoTV: Egocentric Task Verification from Natural Language Task Descriptions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hazra_EgoTV_Egocentric_Task_Verification_from_Natural_Language_Task_Descriptions_ICCV_2023_paper.html",
        "author": "Rishi Hazra, Brian Chen, Akshara Rai, Nitin Kamra, Ruta Desai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hazra_EgoTV_Egocentric_Task_Verification_from_Natural_Language_Task_Descriptions_ICCV_2023_paper.pdf",
        "aff": "Meta; Orebro University",
        "project": "https://rishihazra.github.io/EgoTV",
        "github": "https://github.com/rishihazra/EgoTV",
        "arxiv": "2303.16975"
    },
    {
        "title": "EgoVLPv2: Egocentric Video-Language Pre-training with Fusion in the Backbone",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pramanick_EgoVLPv2_Egocentric_Video-Language_Pre-training_with_Fusion_in_the_Backbone_ICCV_2023_paper.html",
        "author": "Shraman Pramanick, Yale Song, Sayan Nag, Kevin Qinghong Lin, Hardik Shah, Mike Zheng Shou, Rama Chellappa, Pengchuan Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pramanick_EgoVLPv2_Egocentric_Video-Language_Pre-training_with_Fusion_in_the_Backbone_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; University of Toronto; Meta AI; National University of Singapore",
        "project": "https://shramanpramanick.github.io/EgoVLPv2/",
        "github": "https://github.com/shramanpramanick/EgoVLPv2",
        "arxiv": "2307.05463"
    },
    {
        "title": "EigenPlaces: Training Viewpoint Robust Models for Visual Place Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Berton_EigenPlaces_Training_Viewpoint_Robust_Models_for_Visual_Place_Recognition_ICCV_2023_paper.html",
        "author": "Gabriele Berton, Gabriele Trivigno, Barbara Caputo, Carlo Masone",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Berton_EigenPlaces_Training_Viewpoint_Robust_Models_for_Visual_Place_Recognition_ICCV_2023_paper.pdf",
        "aff": "Politecnico di Torino",
        "project": "https://github.com/gmberton/auto_VPR",
        "github": "https://github.com/gmberton/EigenPlaces",
        "arxiv": "2308.10832"
    },
    {
        "title": "EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory Forecasting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bae_EigenTrajectory_Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting_ICCV_2023_paper.html",
        "author": "Inhwan Bae, Jean Oh, Hae-Gon Jeon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_EigenTrajectory_Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting_ICCV_2023_paper.pdf",
        "aff": "GIST AI Graduate School; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/inhwanbae/EigenTrajectory",
        "arxiv": "2307.09306"
    },
    {
        "title": "ElasticViT: Conflict-aware Supernet Training for Deploying Fast Vision Transformer on Diverse Mobile Devices",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_ElasticViT_Conflict-aware_Supernet_Training_for_Deploying_Fast_Vision_Transformer_on_ICCV_2023_paper.html",
        "author": "Chen Tang, Li Lyna Zhang, Huiqiang Jiang, Jiahang Xu, Ting Cao, Quanlu Zhang, Yuqing Yang, Zhi Wang, Mao Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_ElasticViT_Conflict-aware_Supernet_Training_for_Deploying_Fast_Vision_Transformer_on_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; Tsinghua University",
        "project": "",
        "github": "https://github.com/microsoft/Moonlit/tree/main/ElasticViT",
        "arxiv": "2303.09730"
    },
    {
        "title": "EmoSet: A Large-scale Visual Emotion Dataset with Rich Attributes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_EmoSet_A_Large-scale_Visual_Emotion_Dataset_with_Rich_Attributes_ICCV_2023_paper.html",
        "author": "Jingyuan Yang, Qirui Huang, Tingting Ding, Dani Lischinski, Danny Cohen-Or, Hui Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_EmoSet_A_Large-scale_Visual_Emotion_Dataset_with_Rich_Attributes_ICCV_2023_paper.pdf",
        "aff": "The Hebrew University of Jerusalem; Tel Aviv University; Shenzhen University",
        "project": "https://vcc.tech/EmoSet",
        "github": "",
        "arxiv": "2307.07961"
    },
    {
        "title": "EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Peng_EmoTalk_Speech-Driven_Emotional_Disentanglement_for_3D_Face_Animation_ICCV_2023_paper.html",
        "author": "Ziqiao Peng, Haoyu Wu, Zhenbo Song, Hao Xu, Xiangyu Zhu, Jun He, Hongyan Liu, Zhaoxin Fan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_EmoTalk_Speech-Driven_Emotional_Disentanglement_for_3D_Face_Animation_ICCV_2023_paper.pdf",
        "aff": "Renmin University of China; Nanjing University of Science and Technology; The Hong Kong University of Science and Technology; Tsinghua University; Chinese Academy of Sciences",
        "project": "",
        "github": "https://ziqiaopeng.github.io/emotalk",
        "arxiv": "2303.11089"
    },
    {
        "title": "Emotional Listener Portrait: Neural Listener Head Generation with Emotion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_Emotional_Listener_Portrait_Neural_Listener_Head_Generation_with_Emotion_ICCV_2023_paper.html",
        "author": "Luchuan Song, Guojun Yin, Zhenchao Jin, Xiaoyi Dong, Chenliang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Emotional_Listener_Portrait_Neural_Listener_Head_Generation_with_Emotion_ICCV_2023_paper.pdf",
        "aff": "University of Hong Kong; University of Rochester; Shanghai AI Laboratory; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Empowering Low-Light Image Enhancer through Customized Learnable Priors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Empowering_Low-Light_Image_Enhancer_through_Customized_Learnable_Priors_ICCV_2023_paper.html",
        "author": "Naishan Zheng, Man Zhou, Yanmeng Dong, Xiangyu Rui, Jie Huang, Chongyi Li, Feng Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Empowering_Low-Light_Image_Enhancer_through_Customized_Learnable_Priors_ICCV_2023_paper.pdf",
        "aff": "Nankai University; Xi\u2019an Jiaotong University; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/zheng980629/CUE",
        "arxiv": "2309.01958"
    },
    {
        "title": "Encyclopedic VQA: Visual Questions About Detailed Properties of Fine-Grained Categories",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mensink_Encyclopedic_VQA_Visual_Questions_About_Detailed_Properties_of_Fine-Grained_Categories_ICCV_2023_paper.html",
        "author": "Thomas Mensink, Jasper Uijlings, Lluis Castrejon, Arushi Goel, Felipe Cadar, Howard Zhou, Fei Sha, Andr\u00e9 Araujo, Vittorio Ferrari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mensink_Encyclopedic_VQA_Visual_Questions_About_Detailed_Properties_of_Fine-Grained_Categories_ICCV_2023_paper.pdf",
        "aff": "Universidade Federal de Minas Gerais; Google (Work done during internship); Google Research",
        "project": "",
        "github": "https://github.com/google-research/google-research/tree/master/encyclopedic_vqa",
        "arxiv": "2306.09224"
    },
    {
        "title": "End-to-End Diffusion Latent Optimization Improves Classifier Guidance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wallace_End-to-End_Diffusion_Latent_Optimization_Improves_Classifier_Guidance_ICCV_2023_paper.html",
        "author": "Bram Wallace, Akash Gokul, Stefano Ermon, Nikhil Naik",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wallace_End-to-End_Diffusion_Latent_Optimization_Improves_Classifier_Guidance_ICCV_2023_paper.pdf",
        "aff": "Salesforce AI; Stanford University",
        "project": "",
        "github": "",
        "arxiv": "2303.13703"
    },
    {
        "title": "End-to-end 3D Tracking with Decoupled Queries",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_End-to-end_3D_Tracking_with_Decoupled_Queries_ICCV_2023_paper.html",
        "author": "Yanwei Li, Zhiding Yu, Jonah Philion, Anima Anandkumar, Sanja Fidler, Jiaya Jia, Jose Alvarez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_End-to-end_3D_Tracking_with_Decoupled_Queries_ICCV_2023_paper.pdf",
        "aff": "CUHK and SmartMore; NVIDIA and University of Toronto and Vector Institute; NVIDIA; CUHK; NVIDIA and Caltech; NVIDIA and University of Toronto",
        "project": "https://sites.google.com/view/dqtrack",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "End2End Multi-View Feature Matching with Differentiable Pose Optimization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Roessle_End2End_Multi-View_Feature_Matching_with_Differentiable_Pose_Optimization_ICCV_2023_paper.html",
        "author": "Barbara Roessle, Matthias Nie\u00dfner",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Roessle_End2End_Multi-View_Feature_Matching_with_Differentiable_Pose_Optimization_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Energy-based Self-Training and Normalization for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Herath_Energy-based_Self-Training_and_Normalization_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Samitha Herath, Basura Fernando, Ehsan Abbasnejad, Munawar Hayat, Shahram Khadivi, Mehrtash Harandi, Hamid Rezatofighi, Gholamreza Haffari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Herath_Energy-based_Self-Training_and_Normalization_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Monash University, Australia; eBay Inc.; A*STAR, Singapore; The University of Adelaide, Australia",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Enhanced Meta Label Correction for Coping with Label Corruption",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Taraday_Enhanced_Meta_Label_Correction_for_Coping_with_Label_Corruption_ICCV_2023_paper.html",
        "author": "Mitchell Keren Taraday, Chaim Baskin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Taraday_Enhanced_Meta_Label_Correction_for_Coping_with_Label_Corruption_ICCV_2023_paper.pdf",
        "aff": "Technion \u2013 Israel Institute of Technology",
        "project": "https://sites.google.com/view/emlc-paper",
        "github": "",
        "arxiv": "2305.12961"
    },
    {
        "title": "Enhanced Soft Label for Semi-Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Enhanced_Soft_Label_for_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Jie Ma, Chuan Wang, Yang Liu, Liang Lin, Guanbin Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Enhanced_Soft_Label_for_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Research Institute, Sun Yat-sen University, Shenzhen, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Enhancing_Adversarial_Robustness_in_Low-Label_Regime_via_Adaptively_Weighted_Regularization_ICCV_2023_paper.html",
        "author": "Dongyoon Yang, Insung Kong, Yongdai Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Enhancing_Adversarial_Robustness_in_Low-Label_Regime_via_Adaptively_Weighted_Regularization_ICCV_2023_paper.pdf",
        "aff": "Seoul National University, Department of Statistics",
        "project": "",
        "github": "",
        "arxiv": "2308.04061"
    },
    {
        "title": "Enhancing Fine-Tuning Based Backdoor Defense with Sharpness-Aware Minimization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Enhancing_Fine-Tuning_Based_Backdoor_Defense_with_Sharpness-Aware_Minimization_ICCV_2023_paper.html",
        "author": "Mingli Zhu, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Enhancing_Fine-Tuning_Based_Backdoor_Defense_with_Sharpness-Aware_Minimization_ICCV_2023_paper.pdf",
        "aff": "School of Data Science, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; Tencent AI Lab; JD Explore Academy",
        "project": "",
        "github": "https://github.com/SCLBD/BackdoorBench",
        "arxiv": "2304.11823"
    },
    {
        "title": "Enhancing Generalization of Universal Adversarial Perturbation through Gradient Aggregation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Enhancing_Generalization_of_Universal_Adversarial_Perturbation_through_Gradient_Aggregation_ICCV_2023_paper.html",
        "author": "Xuannan Liu, Yaoyao Zhong, Yuhang Zhang, Lixiong Qin, Weihong Deng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Enhancing_Generalization_of_Universal_Adversarial_Perturbation_through_Gradient_Aggregation_ICCV_2023_paper.pdf",
        "aff": "Beijing University of Posts and Telecommunications",
        "project": "",
        "github": "https://github.com/liuxuannan/Stochastic-Gradient-Aggregation",
        "arxiv": "2308.06015"
    },
    {
        "title": "Enhancing Modality-Agnostic Representations via Meta-Learning for Brain Tumor Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Konwer_Enhancing_Modality-Agnostic_Representations_via_Meta-Learning_for_Brain_Tumor_Segmentation_ICCV_2023_paper.html",
        "author": "Aishik Konwer, Xiaoling Hu, Joseph Bae, Xuan Xu, Chao Chen, Prateek Prasanna",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Konwer_Enhancing_Modality-Agnostic_Representations_via_Meta-Learning_for_Brain_Tumor_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Department of Biomedical Informatics, Stony Brook University; Department of Computer Science, Stony Brook University",
        "project": "",
        "github": "",
        "arxiv": "2302.04308"
    },
    {
        "title": "Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer with Mixture-of-View-Experts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cong_Enhancing_NeRF_akin_to_Enhancing_LLMs_Generalizable_NeRF_Transformer_with_ICCV_2023_paper.html",
        "author": "Wenyan Cong, Hanxue Liang, Peihao Wang, Zhiwen Fan, Tianlong Chen, Mukund Varma, Yi Wang, Zhangyang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cong_Enhancing_NeRF_akin_to_Enhancing_LLMs_Generalizable_NeRF_Transformer_with_ICCV_2023_paper.pdf",
        "aff": "Indian Institute of Technology Madras; University of Cambridge; University of Texas at Austin",
        "project": "",
        "github": "https://github.com/VITA-Group/GNT-MOVE",
        "arxiv": "2308.11793"
    },
    {
        "title": "Enhancing Non-line-of-sight Imaging via Learnable Inverse Kernel and Attention Mechanisms",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Enhancing_Non-line-of-sight_Imaging_via_Learnable_Inverse_Kernel_and_Attention_Mechanisms_ICCV_2023_paper.html",
        "author": "Yanhua Yu, Siyuan Shen, Zi Wang, Binbin Huang, Yuehan Wang, Xingyue Peng, Suan Xia, Ping Liu, Ruiqian Li, Shiying Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Enhancing_Non-line-of-sight_Imaging_via_Learnable_Inverse_Kernel_and_Attention_Mechanisms_ICCV_2023_paper.pdf",
        "aff": "Shanghai Engineering Research Center of Intelligent Vision and Imaging, School of Information Science and Technology, ShanghaiTech University, Shanghai, China",
        "project": "",
        "github": "https://sci2020.github.io",
        "arxiv": ""
    },
    {
        "title": "Enhancing Privacy Preservation in Federated Learning via Learning Rate Perturbation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wan_Enhancing_Privacy_Preservation_in_Federated_Learning_via_Learning_Rate_Perturbation_ICCV_2023_paper.html",
        "author": "Guangnian Wan, Haitao Du, Xuejing Yuan, Jun Yang, Meiling Chen, Jie Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_Enhancing_Privacy_Preservation_in_Federated_Learning_via_Learning_Rate_Perturbation_ICCV_2023_paper.pdf",
        "aff": "Beijing University of Posts and Telecommunications; China Mobile Research Institute",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Enhancing Sample Utilization through Sample Adaptive Augmentation in Semi-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gui_Enhancing_Sample_Utilization_through_Sample_Adaptive_Augmentation_in_Semi-Supervised_Learning_ICCV_2023_paper.html",
        "author": "Guan Gui, Zhen Zhao, Lei Qi, Luping Zhou, Lei Wang, Yinghuan Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gui_Enhancing_Sample_Utilization_through_Sample_Adaptive_Augmentation_in_Semi-Supervised_Learning_ICCV_2023_paper.pdf",
        "aff": "University of Sydney; Southeast University; Nanjing University; University of Wollongong",
        "project": "",
        "github": "https://github.com/GuanGui-nju/SAA",
        "arxiv": "2309.03598"
    },
    {
        "title": "Environment Agnostic Representation for Visual Reinforcement Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Choi_Environment_Agnostic_Representation_for_Visual_Reinforcement_Learning_ICCV_2023_paper.html",
        "author": "Hyesong Choi, Hunsang Lee, Seongwon Jeong, Dongbo Min",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_Environment_Agnostic_Representation_for_Visual_Reinforcement_Learning_ICCV_2023_paper.pdf",
        "aff": "Hyundai Motor Company; Ewha W. University",
        "project": "",
        "github": "https://github.com/doihye/EAR",
        "arxiv": ""
    },
    {
        "title": "Environment-Invariant Curriculum Relation Learning for Fine-Grained Scene Graph Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Min_Environment-Invariant_Curriculum_Relation_Learning_for_Fine-Grained_Scene_Graph_Generation_ICCV_2023_paper.html",
        "author": "Yukuan Min, Aming Wu, Cheng Deng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Environment-Invariant_Curriculum_Relation_Learning_for_Fine-Grained_Scene_Graph_Generation_ICCV_2023_paper.pdf",
        "aff": "Xidian University",
        "project": "",
        "github": "https://github.com/myukzzz/EICR",
        "arxiv": "2308.03282"
    },
    {
        "title": "Equivariant Similarity for Vision-Language Foundation Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Equivariant_Similarity_for_Vision-Language_Foundation_Models_ICCV_2023_paper.html",
        "author": "Tan Wang, Kevin Lin, Linjie Li, Chung-Ching Lin, Zhengyuan Yang, Hanwang Zhang, Zicheng Liu, Lijuan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Equivariant_Similarity_for_Vision-Language_Foundation_Models_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; Microsoft",
        "project": "",
        "github": "https://github.com/Wangt-CN/EqBen",
        "arxiv": "2303.14465"
    },
    {
        "title": "Erasing Concepts from Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Rohit Gandikota, Joanna Materzynska, Jaden Fiotto-Kaufman, David Bau",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Northeastern University; Massachusetts Institute of Technology",
        "project": "erasing.baulab.info",
        "github": "",
        "arxiv": "2303.07345"
    },
    {
        "title": "Essential Matrix Estimation using Convex Relaxations in Orthogonal Space",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Karimian_Essential_Matrix_Estimation_using_Convex_Relaxations_in_Orthogonal_Space_ICCV_2023_paper.html",
        "author": "Arman Karimian, Roberto Tron",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Karimian_Essential_Matrix_Estimation_using_Convex_Relaxations_in_Orthogonal_Space_ICCV_2023_paper.pdf",
        "aff": "Boston University",
        "project": "",
        "github": "https://github.com/armandok/QMEsolvers",
        "arxiv": ""
    },
    {
        "title": "Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.html",
        "author": "Xiao-Ming Wu, Dian Zheng, Zuhao Liu, Wei-Shi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Pengcheng Lab, China; Guangdong Province Key Laboratory of Information Security Technology, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China; School of Computer Science and Engineering, Sun Yat-sen University, China",
        "project": "",
        "github": "",
        "arxiv": "2308.06689"
    },
    {
        "title": "Eulerian Single-Photon Vision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_Eulerian_Single-Photon_Vision_ICCV_2023_paper.html",
        "author": "Shantanu Gupta, Mohit Gupta",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_Eulerian_Single-Photon_Vision_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Sciences, University of Wisconsin-Madison",
        "project": "https://wisionlab.com/project/eulerian-single-photon-vision/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Evaluating Data Attribution for Text-to-Image Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.html",
        "author": "Sheng-Yu Wang, Alexei A. Efros, Jun-Yan Zhu, Richard Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; Adobe Research; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2306.09345"
    },
    {
        "title": "Evaluation and Improvement of Interpretability for Self-Explainable Part-Prototype Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.html",
        "author": "Qihan Huang, Mengqi Xue, Wenqi Huang, Haofei Zhang, Jie Song, Yongcheng Jing, Mingli Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University - China Southern Power Grid Joint Research Centre on AI; Digital Grid Research Institute, China Southern Power Grid; Zhejiang University; The University of Sydney",
        "project": "",
        "github": "https://github.com/hqhQAQ/EvalProtoPNet",
        "arxiv": "2212.05946"
    },
    {
        "title": "Event Camera Data Pre-training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Event_Camera_Data_Pre-training_ICCV_2023_paper.html",
        "author": "Yan Yang, Liyuan Pan, Liu Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Event_Camera_Data_Pre-training_ICCV_2023_paper.pdf",
        "aff": "Cyberverse Dept., Huawei; BITSZ & School of CSAT, BIT; BDSI, ANU",
        "project": "",
        "github": "https://github.com/Yan98/Event-Camera-Data-Pre-training",
        "arxiv": "2301.01928"
    },
    {
        "title": "Event-Guided Procedure Planning from Instructional Videos with Text Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Event-Guided_Procedure_Planning_from_Instructional_Videos_with_Text_Supervision_ICCV_2023_paper.html",
        "author": "An-Lan Wang, Kun-Yu Lin, Jia-Run Du, Jingke Meng, Wei-Shi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Event-Guided_Procedure_Planning_from_Instructional_Videos_with_Text_Supervision_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China",
        "project": "",
        "github": "",
        "arxiv": "2308.08885"
    },
    {
        "title": "Event-based Temporally Dense Optical Flow Estimation with Sequential Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ponghiran_Event-based_Temporally_Dense_Optical_Flow_Estimation_with_Sequential_Learning_ICCV_2023_paper.html",
        "author": "Wachirawit Ponghiran, Chamika Mihiranga Liyanagedera, Kaushik Roy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ponghiran_Event-based_Temporally_Dense_Optical_Flow_Estimation_with_Sequential_Learning_ICCV_2023_paper.pdf",
        "aff": "Purdue University, West Lafayette, IN 47907, USA",
        "project": "",
        "github": "https://github.com/wponghiran/temporally_dense_flow",
        "arxiv": ""
    },
    {
        "title": "Eventful Transformers: Leveraging Temporal Redundancy in Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dutson_Eventful_Transformers_Leveraging_Temporal_Redundancy_in_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Matthew Dutson, Yin Li, Mohit Gupta",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dutson_Eventful_Transformers_Leveraging_Temporal_Redundancy_in_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "University of Wisconsin\u2013Madison",
        "project": "",
        "github": "",
        "arxiv": "2308.13494"
    },
    {
        "title": "EverLight: Indoor-Outdoor Editable HDR Lighting Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dastjerdi_EverLight_Indoor-Outdoor_Editable_HDR_Lighting_Estimation_ICCV_2023_paper.html",
        "author": "Mohammad Reza Karimi Dastjerdi, Jonathan Eisenmann, Yannick Hold-Geoffroy, Jean-Fran\u00e7ois Lalonde",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dastjerdi_EverLight_Indoor-Outdoor_Editable_HDR_Lighting_Estimation_ICCV_2023_paper.pdf",
        "aff": "Adobe; Universit\u00e8 Laval",
        "project": "https://lvsn.github.io/everlight/",
        "github": "",
        "arxiv": "2304.13207"
    },
    {
        "title": "ExBluRF: Efficient Radiance Fields for Extreme Motion Blurred Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_ExBluRF_Efficient_Radiance_Fields_for_Extreme_Motion_Blurred_Images_ICCV_2023_paper.html",
        "author": "Dongwoo Lee, Jeongtaek Oh, Jaesung Rim, Sunghyun Cho, Kyoung Mu Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ExBluRF_Efficient_Radiance_Fields_for_Extreme_Motion_Blurred_Images_ICCV_2023_paper.pdf",
        "aff": "GSAI, POSTECH, Korea; IPAI, Seoul National University, Korea; Dept. of ECE&ASRI, IPAI, Seoul National University, Korea; Dept. of ECE&ASRI, Seoul National University, Korea; Dept. of CSE, POSTECH, Korea",
        "project": "",
        "github": "",
        "arxiv": "2309.08957"
    },
    {
        "title": "Examining Autoexposure for Challenging Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tedla_Examining_Autoexposure_for_Challenging_Scenes_ICCV_2023_paper.html",
        "author": "SaiKiran Tedla, Beixuan Yang, Michael S. Brown",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tedla_Examining_Autoexposure_for_Challenging_Scenes_ICCV_2023_paper.pdf",
        "aff": "York University",
        "project": "",
        "github": "",
        "arxiv": "2309.04542"
    },
    {
        "title": "Exemplar-Free Continual Transformer with Convolutions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Roy_Exemplar-Free_Continual_Transformer_with_Convolutions_ICCV_2023_paper.html",
        "author": "Anurag Roy, Vinay K. Verma, Sravan Voonna, Kripabandhu Ghosh, Saptarshi Ghosh, Abir Das",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Roy_Exemplar-Free_Continual_Transformer_with_Convolutions_ICCV_2023_paper.pdf",
        "aff": "IIT Kharagpur; IML Amazon India; IISER Kolkata",
        "project": "https://cvir.github.io/projects/contracon",
        "github": "",
        "arxiv": "2308.11357"
    },
    {
        "title": "Explaining Adversarial Robustness of Neural Networks from Clustering Effect Perspective",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Explaining_Adversarial_Robustness_of_Neural_Networks_from_Clustering_Effect_Perspective_ICCV_2023_paper.html",
        "author": "Yulin Jin, Xiaoyu Zhang, Jian Lou, Xu Ma, Zilong Wang, Xiaofeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Explaining_Adversarial_Robustness_of_Neural_Networks_from_Clustering_Effect_Perspective_ICCV_2023_paper.pdf",
        "aff": "School of Cyber Science and Engineering, Qufu Normal University; ZJU-Hangzhou Global Scientific and Technological Innovation Center, Zhejiang University; State Key Laboratory of Integrated Service Networks (ISN), Xidian University",
        "project": "",
        "github": "https://github.com/clustering-effect/SAT",
        "arxiv": ""
    },
    {
        "title": "Explicit Motion Disentangling for Efficient Optical Flow Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Explicit_Motion_Disentangling_for_Efficient_Optical_Flow_Estimation_ICCV_2023_paper.html",
        "author": "Changxing Deng, Ao Luo, Haibin Huang, Shaodan Ma, Jiangyu Liu, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Explicit_Motion_Disentangling_for_Efficient_Optical_Flow_Estimation_ICCV_2023_paper.pdf",
        "aff": "Explicit Motion Disentangling for Efficient Optical Flow Estimation\nChangxing Deng1\u2217, Ao Luo2\u2217, Haibin Huang3, Shaodan Ma1, Jiangyu Liu2, Shuaicheng Liu4,2\u2020\n1University of Macau2Megvii Technology3Kuaishou Technology\n4University of Electronic Science and Technology of China\nAbstract\nIn this paper, we propose a novel framework for opti-\ncal flow estimation that achieves a good balance between\nperformance and efficiency. Our approach involves disen-\ntangling global motion learning from local flow estimation,\ntreating global matching and local refinement as separate\nstages. We offer two key insights: First, the multi-scale\n4D cost-volume based recurrent flow decoder is computa-\ntionally expensive and unnecessary for handling small dis-\nplacement. With the separation, we can utilize lightweight\nmethods for both parts and maintain similar performance.\nSecond, a dense and robust global matching is essential\nfor both flow initialization as well as stable and fast con-\nvergence for the refinement stage. Towards this end, we\nintroduce EMD-Flow, a framework that explicitly sepa-\nrates global motion estimation from the recurrent refine-\nment stage. We propose two novel modules: Multi-scale\nMotion Aggregation (MMA) and Confidence-induced Flow\nPropagation (CFP). These modules leverage cross-scale\nmatching prior and self-contained confidence maps to han-\ndle the ambiguities of dense matching in a global manner,\ngenerating a dense initial flow. Additionally, a lightweight\ndecoding module is followed to handle small displacements,\nresulting in an efficient yet robust flow estimation frame-\nwork. We further conduct comprehensive experiments on\nstandard optical flow benchmarks with the proposed frame-\nwork, and the experimental results demonstrate its superior\nbalance between performance and runtime. Code is avail-\nable at https://github.com/gddcx/EMD-Flow .\n1. Introduction\nOptical flow represents the 2D motion field between suc-\ncessive video frames. It is a fundamental computer vi-\nsion task and has various downstream applications, e.g.\nvideo frame interpolation [13], video super-resolution [8],\nvisual tracking [33] and motion detection [26]. Different\nfrom traditional energy-based or matching-based optimiza-\n\u2217Equal contribution.\u2020Corresponding Author.\nFigure 1: Comparison with state-of-the-art methods in\nterms of inference accuracy (F1-all), runtime (s) and\nmodel size (M). All models are trained on \u201cC + T\u201d, and\nevaluated on KITTI-15 [25] (image size 375 \u00d71242) with\na single NVIDIA A100 card. Our EMD-Flow models not\nonly demonstrate substantial performance enhancements\ncompared to state-of-the-art methods but also achieve sig-\nnificant reductions in computational overhead.\ntions, deep learning based methods [30, 15] have made\ngreat progress by introducing the cost-volume based re-\ngression paradigm in a pyramid structure. Recently, the\nrecurrent regression framework [32] has become a main-\nstream approach for optical flow, and advanced methods\nlike attention-based operations [18, 21, 38], graph mod-\nels [23], and latent cost-volume augmentation [12] have\nbeen developed to improve its performance. However, these\nmethods often require extra computational resources and\nconsume significant inference time, limiting their applica-\ntion in real-world scenarios. Therefore, a critical question\narises: can we improve the accuracy of flow estimation\nwhile maintaining high runtime efficiency?\nTo understand the trade-off between accuracy and run-\ntime efficiency, we empirically analyze the recurrent pre-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n9521\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Exploiting Proximity-Aware Tasks for Embodied Social Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cancelli_Exploiting_Proximity-Aware_Tasks_for_Embodied_Social_Navigation_ICCV_2023_paper.html",
        "author": "Enrico Cancelli, Tommaso Campari, Luciano Serafini, Angel X. Chang, Lamberto Ballan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cancelli_Exploiting_Proximity-Aware_Tasks_for_Embodied_Social_Navigation_ICCV_2023_paper.pdf",
        "aff": "Simon Fraser University; Fondazione Bruno Kessler (FBK); University of Padova",
        "project": "",
        "github": "https://github.com/EnricoCancelli/ProximitySocialNav",
        "arxiv": "2212.00767"
    },
    {
        "title": "Explore and Tell: Embodied Visual Captioning in 3D Environments",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Explore_and_Tell_Embodied_Visual_Captioning_in_3D_Environments_ICCV_2023_paper.html",
        "author": "Anwen Hu, Shizhe Chen, Liang Zhang, Qin Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Explore_and_Tell_Embodied_Visual_Captioning_in_3D_Environments_ICCV_2023_paper.pdf",
        "aff": "INRIA; School of Information, Renmin University of China",
        "project": "https://aim3-ruc.github.io/ExploreAndTell",
        "github": "https://github.com/aim3-ruc/ExploreAndTell",
        "arxiv": "2308.10447"
    },
    {
        "title": "Exploring Group Video Captioning with Efficient Relational Approximation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Exploring_Group_Video_Captioning_with_Efficient_Relational_Approximation_ICCV_2023_paper.html",
        "author": "Wang Lin, Tao Jin, Ye Wang, Wenwen Pan, Linjun Li, Xize Cheng, Zhou Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Exploring_Group_Video_Captioning_with_Efficient_Relational_Approximation_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University, Hangzhou, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.html",
        "author": "Ben Kang, Xin Chen, Dong Wang, Houwen Peng, Huchuan Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; School of Information and Communication Engineering, Dalian University of Technology",
        "project": "",
        "github": "https://github.com/kangben258/HiT",
        "arxiv": "2308.06904"
    },
    {
        "title": "Exploring Model Transferability through the Lens of Potential Energy",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Exploring_Model_Transferability_through_the_Lens_of_Potential_Energy_ICCV_2023_paper.html",
        "author": "Xiaotong Li, Zixuan Hu, Yixiao Ge, Ying Shan, Ling-Yu Duan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Exploring_Model_Transferability_through_the_Lens_of_Potential_Energy_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Peking University, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; School of Computer Science, Peking University, Beijing, China; ARC Lab, Tencent PCG, Beijing, China",
        "project": "",
        "github": "https://github.com/lixiaotong97/PED",
        "arxiv": "2308.15074"
    },
    {
        "title": "Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Exploring_Object-Centric_Temporal_Modeling_for_Efficient_Multi-View_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Shihao Wang, Yingfei Liu, Tiancai Wang, Ying Li, Xiangyu Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Exploring_Object-Centric_Temporal_Modeling_for_Efficient_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "MEGVII Technology; Beijing Institute of Technology",
        "project": "",
        "github": "https://github.com/exiawsh/StreamPETR.git",
        "arxiv": "2303.11926"
    },
    {
        "title": "Exploring Open-Vocabulary Semantic Segmentation from CLIP Vision Encoder Distillation Only",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Exploring_Open-Vocabulary_Semantic_Segmentation_from_CLIP_Vision_Encoder_Distillation_Only_ICCV_2023_paper.html",
        "author": "Jun Chen, Deyao Zhu, Guocheng Qian, Bernard Ghanem, Zhicheng Yan, Chenchen Zhu, Fanyi Xiao, Sean Chang Culatana, Mohamed Elhoseiny",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Exploring_Open-Vocabulary_Semantic_Segmentation_from_CLIP_Vision_Encoder_Distillation_Only_ICCV_2023_paper.pdf",
        "aff": "Meta AI Research; King Abdullah University of Science and Technology (KAUST)",
        "project": "",
        "github": "https://github.com/facebookresearch/ZeroSeg",
        "arxiv": ""
    },
    {
        "title": "Exploring Positional Characteristics of Dual-Pixel Data for Camera Autofocus",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Choi_Exploring_Positional_Characteristics_of_Dual-Pixel_Data_for_Camera_Autofocus_ICCV_2023_paper.html",
        "author": "Myungsub Choi, Hana Lee, Hyong-euk Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_Exploring_Positional_Characteristics_of_Dual-Pixel_Data_for_Camera_Autofocus_ICCV_2023_paper.pdf",
        "aff": "Samsung Advanced Institute of Technology (SAIT)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Exploring Predicate Visual Context in Detecting of Human-Object Interactions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Exploring_Predicate_Visual_Context_in_Detecting_of_Human-Object_Interactions_ICCV_2023_paper.html",
        "author": "Frederic Z Zhang, Yuhui Yuan, Dylan Campbell, Zhuoyao Zhong, Stephen Gould",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Exploring_Predicate_Visual_Context_in_Detecting_of_Human-Object_Interactions_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; The Australian National University",
        "project": "",
        "github": "https://github.com/fredzzhang/pvic",
        "arxiv": "2308.06202"
    },
    {
        "title": "Exploring Temporal Concurrency for Video-Language Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Exploring_Temporal_Concurrency_for_Video-Language_Representation_Learning_ICCV_2023_paper.html",
        "author": "Heng Zhang, Daqing Liu, Zezhong Lv, Bing Su, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Exploring_Temporal_Concurrency_for_Video-Language_Representation_Learning_ICCV_2023_paper.pdf",
        "aff": "Gaoling School of Artiificial Intelligence, Renmin University of China; JD Explore Academy, JD.com; The University of Sydney",
        "project": "",
        "github": "https://github.com/hengRUC/TCP",
        "arxiv": ""
    },
    {
        "title": "Exploring Temporal Frequency Spectrum in Deep Video Deblurring",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Exploring_Temporal_Frequency_Spectrum_in_Deep_Video_Deblurring_ICCV_2023_paper.html",
        "author": "Qi Zhu, Man Zhou, Naishan Zheng, Chongyi Li, Jie Huang, Feng Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Exploring_Temporal_Frequency_Spectrum_in_Deep_Video_Deblurring_ICCV_2023_paper.pdf",
        "aff": "Nankai University; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Exploring Transformers for Open-world Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Exploring_Transformers_for_Open-world_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Jiannan Wu, Yi Jiang, Bin Yan, Huchuan Lu, Zehuan Yuan, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Transformers_for_Open-world_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Dalian University of Technology; The University of Hong Kong; Shanghai AI Laboratory; ByteDance",
        "project": "",
        "github": "",
        "arxiv": "2308.04206"
    },
    {
        "title": "Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.html",
        "author": "Haoning Wu, Erli Zhang, Liang Liao, Chaofeng Chen, Jingwen Hou, Annan Wang, Wenxiu Sun, Qiong Yan, Weisi Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.pdf",
        "aff": "Sensetime Research and Tetras AI; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/VQAssessment/DOVER",
        "arxiv": "2211.04894"
    },
    {
        "title": "Exploring the Benefits of Visual Prompting in Differential Privacy",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Exploring_the_Benefits_of_Visual_Prompting_in_Differential_Privacy_ICCV_2023_paper.html",
        "author": "Yizhe Li, Yu-Lin Tsai, Chia-Mu Yu, Pin-Yu Chen, Xuebin Ren",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Exploring_the_Benefits_of_Visual_Prompting_in_Differential_Privacy_ICCV_2023_paper.pdf",
        "aff": "National Yang Ming Chiao Tung University; IBM Research; School of Computer Science and Technology, Xi'an Jiaotong University",
        "project": "",
        "github": "https://github.com/EzzzLi/Prompt-PATE",
        "arxiv": "2303.12247"
    },
    {
        "title": "Exploring the Sim2Real Gap Using Digital Twins",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sudhakar_Exploring_the_Sim2Real_Gap_Using_Digital_Twins_ICCV_2023_paper.html",
        "author": "Sruthi Sudhakar, Jon Hanzelka, Josh Bobillot, Tanmay Randhavane, Neel Joshi, Vibhav Vineet",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakar_Exploring_the_Sim2Real_Gap_Using_Digital_Twins_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; Columbia University",
        "project": "",
        "github": "https://github.com/SruthiSudhakar/Exploring-the-Sim2Real-Gap-using-Digital-Twins-Dataset.git",
        "arxiv": ""
    },
    {
        "title": "ExposureDiffusion: Learning to Expose for Low-light Image Enhancement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ExposureDiffusion_Learning_to_Expose_for_Low-light_Image_Enhancement_ICCV_2023_paper.html",
        "author": "Yufei Wang, Yi Yu, Wenhan Yang, Lanqing Guo, Lap-Pui Chau, Alex C. Kot, Bihan Wen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ExposureDiffusion_Learning_to_Expose_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; The Hong Kong Polytechnic University; Peng Cheng Laboratory",
        "project": "",
        "github": "https://github.com/wyf0912/ExposureDiffusion",
        "arxiv": "2307.07710"
    },
    {
        "title": "Expressive Text-to-Image Generation with Rich Text",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.html",
        "author": "Songwei Ge, Taesung Park, Jun-Yan Zhu, Jia-Bin Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; Adobe Research; Carnegie Mellon University",
        "project": "https://rich-text-to-image.github.io/",
        "github": "",
        "arxiv": "2304.06720"
    },
    {
        "title": "Extensible and Efficient Proxy for Neural Architecture Search",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Extensible_and_Efficient_Proxy_for_Neural_Architecture_Search_ICCV_2023_paper.html",
        "author": "Yuhong Li, Jiajie Li, Cong Hao, Pan Li, Jinjun Xiong, Deming Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Extensible_and_Efficient_Proxy_for_Neural_Architecture_Search_ICCV_2023_paper.pdf",
        "aff": "University at Buffalo; Georgia Institute of Technology; University of Illinois at Urbana-Champaign",
        "project": "",
        "github": "https://github.com/leeyeehoo/GenNAS-Zero",
        "arxiv": ""
    },
    {
        "title": "F&F Attack: Adversarial Attack against Multiple Object Trackers by Inducing False Negatives and False Positives",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_FF_Attack_Adversarial_Attack_against_Multiple_Object_Trackers_by_Inducing_ICCV_2023_paper.html",
        "author": "Tao Zhou, Qi Ye, Wenhan Luo, Kaihao Zhang, Zhiguo Shi, Jiming Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_FF_Attack_Adversarial_Attack_against_Multiple_Object_Trackers_by_Inducing_ICCV_2023_paper.pdf",
        "aff": "Sun Yat-sen University; Australian National University; Zhejiang University",
        "project": "https://infzhou.github.io/FnFAttack/index.html",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FACET: Fairness in Computer Vision Evaluation Benchmark",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gustafson_FACET_Fairness_in_Computer_Vision_Evaluation_Benchmark_ICCV_2023_paper.html",
        "author": "Laura Gustafson, Chloe Rolland, Nikhila Ravi, Quentin Duval, Aaron Adcock, Cheng-Yang Fu, Melissa Hall, Candace Ross",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gustafson_FACET_Fairness_in_Computer_Vision_Evaluation_Benchmark_ICCV_2023_paper.pdf",
        "aff": "Meta AI Research, FAIR",
        "project": "https://facet.metademolab.com",
        "github": "",
        "arxiv": "2309.00035"
    },
    {
        "title": "FACTS: First Amplify Correlations and Then Slice to Discover Bias",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.html",
        "author": "Sriram Yenamandra, Pratik Ramesh, Viraj Prabhu, Judy Hoffman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.pdf",
        "aff": "Georgia Institute of Technology",
        "project": "",
        "github": "https://github.com/yvsriram/FACTS",
        "arxiv": ""
    },
    {
        "title": "FB-BEV: BEV Representation from Forward-Backward View Transformations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_FB-BEV_BEV_Representation_from_Forward-Backward_View_Transformations_ICCV_2023_paper.html",
        "author": "Zhiqi Li, Zhiding Yu, Wenhai Wang, Anima Anandkumar, Tong Lu, Jose M. Alvarez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FB-BEV_BEV_Representation_from_Forward-Backward_View_Transformations_ICCV_2023_paper.pdf",
        "aff": "NVIDIA; National Key Lab for Novel Software Technology, Nanjing University; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/NVlabs/FB-BEV",
        "arxiv": ""
    },
    {
        "title": "FBLNet: FeedBack Loop Network for Driver Attention Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FBLNet_FeedBack_Loop_Network_for_Driver_Attention_Prediction_ICCV_2023_paper.html",
        "author": "Yilong Chen, Zhixiong Nan, Tao Xiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FBLNet_FeedBack_Loop_Network_for_Driver_Attention_Prediction_ICCV_2023_paper.pdf",
        "aff": "Chongqing University, Chongqing, China",
        "project": "",
        "github": "",
        "arxiv": "2212.02096"
    },
    {
        "title": "FCCNs: Fully Complex-valued Convolutional Networks using Complex-valued Color Model and Loss Function",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yadav_FCCNs_Fully_Complex-valued_Convolutional_Networks_using_Complex-valued_Color_Model_and_ICCV_2023_paper.html",
        "author": "Saurabh Yadav, Koteswar Rao Jerripothula",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yadav_FCCNs_Fully_Complex-valued_Convolutional_Networks_using_Complex-valued_Color_Model_and_ICCV_2023_paper.pdf",
        "aff": "Indraprastha Institute of Information Technology Delhi (IIIT-Delhi), New Delhi, India",
        "project": "",
        "github": "https://github.com/saurabhya/FCCNs",
        "arxiv": ""
    },
    {
        "title": "FDViT: Improve the Hierarchical Architecture of Vision Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_FDViT_Improve_the_Hierarchical_Architecture_of_Vision_Transformer_ICCV_2023_paper.html",
        "author": "Yixing Xu, Chao Li, Dong Li, Xiao Sheng, Fan Jiang, Lu Tian, Ashish Sirasao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_FDViT_Improve_the_Hierarchical_Architecture_of_Vision_Transformer_ICCV_2023_paper.pdf",
        "aff": "Advanced Micro Devices, Inc., Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FLIP: Cross-domain Face Anti-spoofing with Language Guidance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Srivatsan_FLIP_Cross-domain_Face_Anti-spoofing_with_Language_Guidance_ICCV_2023_paper.html",
        "author": "Koushik Srivatsan, Muzammal Naseer, Karthik Nandakumar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Srivatsan_FLIP_Cross-domain_Face_Anti-spoofing_with_Language_Guidance_ICCV_2023_paper.pdf",
        "aff": "Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), Abu Dhabi, United Arab Emirates",
        "project": "",
        "github": "https://github.com/koushiksrivats/FLIP",
        "arxiv": ""
    },
    {
        "title": "FLatten Transformer: Vision Transformer using Focused Linear Attention",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_FLatten_Transformer_Vision_Transformer_using_Focused_Linear_Attention_ICCV_2023_paper.html",
        "author": "Dongchen Han, Xuran Pan, Yizeng Han, Shiji Song, Gao Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_FLatten_Transformer_Vision_Transformer_using_Focused_Linear_Attention_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, BNRist, Tsinghua University",
        "project": "",
        "github": "https://github.com/LeapLabTHU/FLatten-Transformer",
        "arxiv": "2308.00442"
    },
    {
        "title": "FPR: False Positive Rectification for Weakly Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FPR_False_Positive_Rectification_for_Weakly_Supervised_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Liyi Chen, Chenyang Lei, Ruihuang Li, Shuai Li, Zhaoxiang Zhang, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FPR_False_Positive_Rectification_for_Weakly_Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Multimodal Arti\ufb01cial Intelligence Systems, CASIA; The Hong Kong Polytechnic University; Center for Arti\ufb01cial Intelligence and Robotics, HKISI, CAS",
        "project": "",
        "github": "https://github.com/mt-cly/FPR",
        "arxiv": ""
    },
    {
        "title": "FRAug: Tackling Federated Learning with Non-IID Features via Representation Augmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FRAug_Tackling_Federated_Learning_with_Non-IID_Features_via_Representation_Augmentation_ICCV_2023_paper.html",
        "author": "Haokun Chen, Ahmed Frikha, Denis Krompass, Jindong Gu, Volker Tresp",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FRAug_Tackling_Federated_Learning_with_Non-IID_Features_via_Representation_Augmentation_ICCV_2023_paper.pdf",
        "aff": "Siemens Technology; Ludwig Maximilian University of Munich, Munich Center for Machine Learning; Ludwig Maximilian University of Munich, Siemens Technology; University of Oxford; Ludwig Maximilian University of Munich, Siemens Technology, Munich Center for Machine Learning",
        "project": "",
        "github": "",
        "arxiv": "2205.14900"
    },
    {
        "title": "FS-DETR: Few-Shot DEtection TRansformer with Prompting and without Re-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.html",
        "author": "Adrian Bulat, Ricardo Guerrero, Brais Martinez, Georgios Tzimiropoulos",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.pdf",
        "aff": "Technical University of Iasi; Queen Mary University of London; Samsung AI Cambridge",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FSAR: Federated Skeleton-based Action Recognition with Adaptive Topology Structure and Knowledge Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_FSAR_Federated_Skeleton-based_Action_Recognition_with_Adaptive_Topology_Structure_and_ICCV_2023_paper.html",
        "author": "Jingwen Guo, Hong Liu, Shitong Sun, Tianyu Guo, Min Zhang, Chenyang Si",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_FSAR_Federated_Skeleton-based_Action_Recognition_with_Adaptive_Topology_Structure_and_ICCV_2023_paper.pdf",
        "aff": "Singapore Nanyang Technological University; Peking University Shenzhen Graduate School; Harbin Institute of Technology Shenzhen Graduate School; Queen Mary University of London",
        "project": "",
        "github": "",
        "arxiv": "2306.11046"
    },
    {
        "title": "FSI: Frequency and Spatial Interactive Learning for Image Restoration in Under-Display Cameras",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_paper.html",
        "author": "Chengxu Liu, Xuan Wang, Shuai Li, Yuzhi Wang, Xueming Qian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_paper.pdf",
        "aff": "Xi\u2019an Jiaotong University, Shaanxi Yulan Jiuzhou Intelligent Optoelectronic Technology Co., Ltd; MEGVII Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FULLER: Unified Multi-modality Multi-task 3D Perception via Multi-level Gradient Calibration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_FULLER_Unified_Multi-modality_Multi-task_3D_Perception_via_Multi-level_Gradient_Calibration_ICCV_2023_paper.html",
        "author": "Zhijian Huang, Sihao Lin, Guiyu Liu, Mukun Luo, Chaoqiang Ye, Hang Xu, Xiaojun Chang, Xiaodan Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_FULLER_Unified_Multi-modality_Multi-task_3D_Perception_via_Multi-level_Gradient_Calibration_ICCV_2023_paper.pdf",
        "aff": "RMIT University; Shenzhen Campus of Sun Yat-sen University; University of Technology Sydney; Huawei Noah\u2019s Ark Lab; Shanghai Jiao Tong University; MBZUAI",
        "project": "",
        "github": "",
        "arxiv": "2307.16617"
    },
    {
        "title": "Face Clustering via Graph Convolutional Networks with Confidence Edges",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Face_Clustering_via_Graph_Convolutional_Networks_with_Confidence_Edges_ICCV_2023_paper.html",
        "author": "Yang Wu, Zhiwei Ge, Yuhao Luo, Lin Liu, Sulong Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Face_Clustering_via_Graph_Convolutional_Networks_with_Confidence_Edges_ICCV_2023_paper.pdf",
        "aff": "Institute of Automation, Chinese Academy of Sciences; JD.COM; SKLCS, Institute of Software, Chinese Academy of Sciences; University of Chinese Academy of Sciences, Beijing, China; JD.COM",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FaceCLIPNeRF: Text-driven 3D Face Manipulation using Deformable Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hwang_FaceCLIPNeRF_Text-driven_3D_Face_Manipulation_using_Deformable_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Sungwon Hwang, Junha Hyung, Daejin Kim, Min-Jung Kim, Jaegul Choo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_FaceCLIPNeRF_Text-driven_3D_Face_Manipulation_using_Deformable_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "KAIST; Scatter Lab",
        "project": "",
        "github": "",
        "arxiv": "2307.11418"
    },
    {
        "title": "Factorized Inverse Path Tracing for Efficient and Accurate Material-Lighting Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Factorized_Inverse_Path_Tracing_for_Efficient_and_Accurate_Material-Lighting_Estimation_ICCV_2023_paper.html",
        "author": "Liwen Wu, Rui Zhu, Mustafa B. Yaldiz, Yinhao Zhu, Hong Cai, Janarbek Matai, Fatih Porikli, Tzu-Mao Li, Manmohan Chandraker, Ravi Ramamoorthi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Factorized_Inverse_Path_Tracing_for_Efficient_and_Accurate_Material-Lighting_Estimation_ICCV_2023_paper.pdf",
        "aff": "UC San Diego; Qualcomm AI Research",
        "project": "",
        "github": "https://github.com/lwwu2/fipt",
        "arxiv": "2304.05669"
    },
    {
        "title": "Fan-Beam Binarization Difference Projection (FB-BDP): A Novel Local Object Descriptor for Fine-Grained Leaf Image Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Fan-Beam_Binarization_Difference_Projection_FB-BDP_A_Novel_Local_Object_Descriptor_ICCV_2023_paper.html",
        "author": "Xin Chen, Bin Wang, Yongsheng Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Fan-Beam_Binarization_Difference_Projection_FB-BDP_A_Novel_Local_Object_Descriptor_ICCV_2023_paper.pdf",
        "aff": "Griffith University, Brisbane, Australia; Nanjing University of Finance and Economics, Nanjing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Fantasia3D_Disentangling_Geometry_and_Appearance_for_High-quality_Text-to-3D_Content_Creation_ICCV_2023_paper.html",
        "author": "Rui Chen, Yongwei Chen, Ningxin Jiao, Kui Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Fantasia3D_Disentangling_Geometry_and_Appearance_for_High-quality_Text-to-3D_Content_Creation_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology",
        "project": "https://fantasia3d.github.io/",
        "github": "https://github.com/fantasia3d",
        "arxiv": "2303.13873"
    },
    {
        "title": "FashionNTM: Multi-turn Fashion Image Retrieval via Cascaded Memory",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pal_FashionNTM_Multi-turn_Fashion_Image_Retrieval_via_Cascaded_Memory_ICCV_2023_paper.html",
        "author": "Anwesan Pal, Sahil Wadhwa, Ayush Jaiswal, Xu Zhang, Yue Wu, Rakesh Chada, Pradeep Natarajan, Henrik I. Christensen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_FashionNTM_Multi-turn_Fashion_Image_Retrieval_via_Cascaded_Memory_ICCV_2023_paper.pdf",
        "aff": "UC San Diego; Amazon Alexa Natural Understanding",
        "project": "https://sites.google.com/eng.ucsd.edu/fashionntm",
        "github": "",
        "arxiv": "2308.10170"
    },
    {
        "title": "Fast Adversarial Training with Smooth Convergence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Fast_Adversarial_Training_with_Smooth_Convergence_ICCV_2023_paper.html",
        "author": "Mengnan Zhao, Lihe Zhang, Yuqiu Kong, Baocai Yin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Adversarial_Training_with_Smooth_Convergence_ICCV_2023_paper.pdf",
        "aff": "Dalian University of Technology, China",
        "project": "",
        "github": "https://github.com/FAT-CS/ConvergeSmooth",
        "arxiv": "2308.12857"
    },
    {
        "title": "Fast Full-frame Video Stabilization with Iterative Optimization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Fast_Full-frame_Video_Stabilization_with_Iterative_Optimization_ICCV_2023_paper.html",
        "author": "Weiyue Zhao, Xin Li, Zhan Peng, Xianrui Luo, Xinyi Ye, Hao Lu, Zhiguo Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Full-frame_Video_Stabilization_with_Iterative_Optimization_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Image Processing and Intelligent Control, Ministry of Education; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan 430074, China; Department of Computer Science, University of Albany, Albany NY 12222",
        "project": "",
        "github": "https://github.com/zwyking/Fast-Stab",
        "arxiv": "2307.12774"
    },
    {
        "title": "Fast Globally Optimal Surface Normal Estimation from an Affine Correspondence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hajder_Fast_Globally_Optimal_Surface_Normal_Estimation_from_an_Affine_Correspondence_ICCV_2023_paper.html",
        "author": "Levente Hajder, Lajos L\u00f3czi, Daniel Barath",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hajder_Fast_Globally_Optimal_Surface_Normal_Estimation_from_an_Affine_Correspondence_ICCV_2023_paper.pdf",
        "aff": "Geometric Computer Vision Group, Eotvos Lorand University, Budapest, Hungary; Computer Vision and Geometry Group, ETH Zurich, Switzerland",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Fast Inference and Update of Probabilistic Density Estimation on Trajectory Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Maeda_Fast_Inference_and_Update_of_Probabilistic_Density_Estimation_on_Trajectory_ICCV_2023_paper.html",
        "author": "Takahiro Maeda, Norimichi Ukita",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Maeda_Fast_Inference_and_Update_of_Probabilistic_Density_Estimation_on_Trajectory_ICCV_2023_paper.pdf",
        "aff": "Toyota Technological Institute, Japan",
        "project": "",
        "github": "https://github.com/meaten/FlowChain-ICCV2023",
        "arxiv": "2308.08824"
    },
    {
        "title": "Fast Neural Scene Flow",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Fast_Neural_Scene_Flow_ICCV_2023_paper.html",
        "author": "Xueqian Li, Jianqiao Zheng, Francesco Ferroni, Jhony Kaesemodel Pontes, Simon Lucey",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Fast_Neural_Scene_Flow_ICCV_2023_paper.pdf",
        "aff": "The University of Adelaide; NVIDIA; Latitude AI",
        "project": "",
        "github": "https://github.com/Lilac-Lee/FastNSF.git",
        "arxiv": "2304.09121"
    },
    {
        "title": "Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature Variance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Fast_and_Accurate_Transferability_Measurement_by_Evaluating_Intra-class_Feature_Variance_ICCV_2023_paper.html",
        "author": "Huiwen Xu, U Kang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Fast_and_Accurate_Transferability_Measurement_by_Evaluating_Intra-class_Feature_Variance_ICCV_2023_paper.pdf",
        "aff": "Seoul National University, Seoul, Republic of Korea",
        "project": "",
        "github": "",
        "arxiv": "2308.05986"
    },
    {
        "title": "FastRecon: Few-shot Industrial Anomaly Detection via Fast Feature Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fang_FastRecon_Few-shot_Industrial_Anomaly_Detection_via_Fast_Feature_Reconstruction_ICCV_2023_paper.html",
        "author": "Zheng Fang, Xiaoyang Wang, Haocheng Li, Jiejie Liu, Qiugui Hu, Jimin Xiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_FastRecon_Few-shot_Industrial_Anomaly_Detection_via_Fast_Feature_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "1XJTLU2Metavisioncn; 1XJTLU3Dinnar Automation Technology; 1XJTLU; 3Dinnar Automation Technology",
        "project": "",
        "github": "https://github.com/FzJun26th/FastRecon",
        "arxiv": ""
    },
    {
        "title": "FastViT: A Fast Hybrid Vision Transformer Using Structural Reparameterization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Vasu_FastViT_A_Fast_Hybrid_Vision_Transformer_Using_Structural_Reparameterization_ICCV_2023_paper.html",
        "author": "Pavan Kumar Anasosalu Vasu, James Gabriel, Jeff Zhu, Oncel Tuzel, Anurag Ranjan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Vasu_FastViT_A_Fast_Hybrid_Vision_Transformer_Using_Structural_Reparameterization_ICCV_2023_paper.pdf",
        "aff": "Apple",
        "project": "",
        "github": "https://github.com/apple/ml-fastvit",
        "arxiv": "2303.14189"
    },
    {
        "title": "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/QI_FateZero_Fusing_Attentions_for_Zero-shot_Text-based_Video_Editing_ICCV_2023_paper.html",
        "author": "Chenyang QI, Xiaodong Cun, Yong Zhang, Chenyang Lei, Xintao Wang, Ying Shan, Qifeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/QI_FateZero_Fusing_Attentions_for_Zero-shot_Text-based_Video_Editing_ICCV_2023_paper.pdf",
        "aff": "HKUST; Tencent AI Lab; CAIR, HKISI-CAS",
        "project": "",
        "github": "https://fate-zero-edit.github.io",
        "arxiv": "2303.09535"
    },
    {
        "title": "Fcaformer: Forward Cross Attention in Hybrid Vision Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Fcaformer_Forward_Cross_Attention_in_Hybrid_Vision_Transformer_ICCV_2023_paper.html",
        "author": "Haokui Zhang, Wenze Hu, Xiaoyu Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Fcaformer_Forward_Cross_Attention_in_Hybrid_Vision_Transformer_ICCV_2023_paper.pdf",
        "aff": "Intellifusion; The Hong Kong University of Science and Technology (Guangzhou); Intellifusion, Yan'an University",
        "project": "",
        "github": "https://github.com/hkzhang-git/FcaFormer",
        "arxiv": "2211.07198"
    },
    {
        "title": "FeatEnHancer: Enhancing Hierarchical Features for Object Detection and Beyond Under Low-Light Vision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hashmi_FeatEnHancer_Enhancing_Hierarchical_Features_for_Object_Detection_and_Beyond_Under_ICCV_2023_paper.html",
        "author": "Khurram Azeem Hashmi, Goutham Kallempudi, Didier Stricker, Muhammad Zeshan Afzal",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hashmi_FeatEnHancer_Enhancing_Hierarchical_Features_for_Object_Detection_and_Beyond_Under_ICCV_2023_paper.pdf",
        "aff": "DFKI - German Research Center for Artificial Intelligence, RPTU Kaiserslautern; RPTU Kaiserslautern",
        "project": "",
        "github": "",
        "arxiv": "2308.03594"
    },
    {
        "title": "Feature Modulation Transformer: Cross-Refinement of Global Representation via High-Frequency Prior for Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.html",
        "author": "Ao Li, Le Zhang, Yun Liu, Ce Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; I2R, A*STAR",
        "project": "",
        "github": "https://github.com/AVC2-UESTC/CRAFT-SR.git",
        "arxiv": "2308.05022"
    },
    {
        "title": "Feature Prediction Diffusion Model for Video Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.html",
        "author": "Cheng Yan, Shiyu Zhang, Yang Liu, Guansong Pang, Wenjun Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.pdf",
        "aff": "Tianjin University; Singapore Management University; Zhejiang University",
        "project": "",
        "github": "FPDM",
        "arxiv": ""
    },
    {
        "title": "Feature Proliferation -- the \"Cancer\" in StyleGAN and its Treatments",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_Feature_Proliferation_--_the_Cancer_in_StyleGAN_and_its_Treatments_ICCV_2023_paper.html",
        "author": "Shuang Song, Yuanbang Liang, Jing Wu, Yu-Kun Lai, Yipeng Qin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Feature_Proliferation_--_the_Cancer_in_StyleGAN_and_its_Treatments_ICCV_2023_paper.pdf",
        "aff": "Cardiff University",
        "project": "",
        "github": "https://github.com/songc42/Feature-proliferation",
        "arxiv": ""
    },
    {
        "title": "FeatureNeRF: Learning Generalizable NeRFs by Distilling Foundation Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_FeatureNeRF_Learning_Generalizable_NeRFs_by_Distilling_Foundation_Models_ICCV_2023_paper.html",
        "author": "Jianglong Ye, Naiyan Wang, Xiaolong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_FeatureNeRF_Learning_Generalizable_NeRFs_by_Distilling_Foundation_Models_ICCV_2023_paper.pdf",
        "aff": "UC San Diego; TuSimple",
        "project": "https://jianglongye.com/featurenerf/",
        "github": "",
        "arxiv": "2303.12786"
    },
    {
        "title": "FedPD: Federated Open Set Recognition with Parameter Disentanglement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_FedPD_Federated_Open_Set_Recognition_with_Parameter_Disentanglement_ICCV_2023_paper.html",
        "author": "Chen Yang, Meilu Zhu, Yifan Liu, Yixuan Yuan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_FedPD_Federated_Open_Set_Recognition_with_Parameter_Disentanglement_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; City University of Hong Kong, The Chinese University of Hong Kong; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_FedPerfix_Towards_Partial_Model_Personalization_of_Vision_Transformers_in_Federated_ICCV_2023_paper.html",
        "author": "Guangyu Sun, Matias Mendieta, Jun Luo, Shandong Wu, Chen Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_FedPerfix_Towards_Partial_Model_Personalization_of_Vision_Transformers_in_Federated_ICCV_2023_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida, USA; Department of Radiology, Biomedical Informatics, and Bioengineering, University of Pittsburgh, USA; Intelligent Systems Program, University of Pittsburgh, USA",
        "project": "",
        "github": "https://github.com/imguangyu/FedPerfix",
        "arxiv": "2308.09160"
    },
    {
        "title": "Federated Learning Over Images: Vertical Decompositions and Pre-Trained Backbones Are Difficult to Beat",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Federated_Learning_Over_Images_Vertical_Decompositions_and_Pre-Trained_Backbones_Are_ICCV_2023_paper.html",
        "author": "Erdong Hu, Yuxin Tang, Anastasios Kyrillidis, Chris Jermaine",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Federated_Learning_Over_Images_Vertical_Decompositions_and_Pre-Trained_Backbones_Are_ICCV_2023_paper.pdf",
        "aff": "Rice University",
        "project": "",
        "github": "",
        "arxiv": "2309.03237"
    },
    {
        "title": "FemtoDet: An Object Detection Baseline for Energy Versus Performance Tradeoffs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tu_FemtoDet_An_Object_Detection_Baseline_for_Energy_Versus_Performance_Tradeoffs_ICCV_2023_paper.html",
        "author": "Peng Tu, Xu Xie, Guo Ai, Yuexiang Li, Yawen Huang, Yefeng Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_FemtoDet_An_Object_Detection_Baseline_for_Energy_Versus_Performance_Tradeoffs_ICCV_2023_paper.pdf",
        "aff": "Jarvis Lab, Tencent; MicroBT Inc.",
        "project": "",
        "github": "",
        "arxiv": "2301.06719"
    },
    {
        "title": "FerKD: Surgical Label Adaptation for Efficient Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shen_FerKD_Surgical_Label_Adaptation_for_Efficient_Distillation_ICCV_2023_paper.html",
        "author": "Zhiqiang Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_FerKD_Surgical_Label_Adaptation_for_Efficient_Distillation_ICCV_2023_paper.pdf",
        "aff": "Mohamed bin Zayed University of AI",
        "project": "",
        "github": "https://github.com/szq0214/FKD/tree/main/FerKD",
        "arxiv": ""
    },
    {
        "title": "Few Shot Font Generation Via Transferring Similarity Guided Global Style and Quantization Local Style",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Few_Shot_Font_Generation_Via_Transferring_Similarity_Guided_Global_Style_ICCV_2023_paper.html",
        "author": "Wei Pan, Anna Zhu, Xinyu Zhou, Brian Kenji Iwana, Shilin Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Few_Shot_Font_Generation_Via_Transferring_Similarity_Guided_Global_Style_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Artificial Intelligence, Wuhan University of Technology; Human Interface Laboratory, Kyushu University",
        "project": "",
        "github": "https://github.com/awei669/VQ-Font",
        "arxiv": "2309.00827"
    },
    {
        "title": "Few-Shot Common Action Localization via Cross-Attentional Fusion of Context and Temporal Dynamics",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Few-Shot_Common_Action_Localization_via_Cross-Attentional_Fusion_of_Context_and_ICCV_2023_paper.html",
        "author": "Juntae Lee, Mihir Jain, Sungrack Yun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Few-Shot_Common_Action_Localization_via_Cross-Attentional_Fusion_of_Context_and_ICCV_2023_paper.pdf",
        "aff": "Qualcomm Technologies, Inc.; Qualcomm AI Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Few-Shot Dataset Distillation via Translative Pre-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Few-Shot_Dataset_Distillation_via_Translative_Pre-Training_ICCV_2023_paper.html",
        "author": "Songhua Liu, Xinchao Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Few-Shot_Dataset_Distillation_via_Translative_Pre-Training_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Few-Shot_Physically-Aware_Articulated_Mesh_Generation_via_Hierarchical_Deformation_ICCV_2023_paper.html",
        "author": "Xueyi Liu, Bin Wang, He Wang, Li Yi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Few-Shot_Physically-Aware_Articulated_Mesh_Generation_via_Hierarchical_Deformation_ICCV_2023_paper.pdf",
        "aff": "Shanghai Qi Zhi Institute; Tsinghua University; Shanghai Artificial Intelligence Laboratory; Beijing Institute for General Artificial Intelligence; Peking University",
        "project": "https://meowuu7.github.io/few-arti-obj-gen",
        "github": "https://github.com/meowuu7/few-arti-obj-gen",
        "arxiv": "2308.10898"
    },
    {
        "title": "Few-Shot Video Classification via Representation Fusion and Promotion Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Few-Shot_Video_Classification_via_Representation_Fusion_and_Promotion_Learning_ICCV_2023_paper.html",
        "author": "Haifeng Xia, Kai Li, Martin Renqiang Min, Zhengming Ding",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Few-Shot_Video_Classification_via_Representation_Fusion_and_Promotion_Learning_ICCV_2023_paper.pdf",
        "aff": "NEC Labs, America; Department of Computer Science, Tulane University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Few-shot Continual Infomax Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Few-shot_Continual_Infomax_Learning_ICCV_2023_paper.html",
        "author": "Ziqi Gu, Chunyan Xu, Jian Yang, Zhen Cui",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Few-shot_Continual_Infomax_Learning_ICCV_2023_paper.pdf",
        "aff": "PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Fg-T2M: Fine-Grained Text-Driven Human Motion Generation via Diffusion Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Fg-T2M_Fine-Grained_Text-Driven_Human_Motion_Generation_via_Diffusion_Model_ICCV_2023_paper.html",
        "author": "Yin Wang, Zhiying Leng, Frederick W. B. Li, Shun-Cheng Wu, Xiaohui Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Fg-T2M_Fine-Grained_Text-Driven_Human_Motion_Generation_via_Diffusion_Model_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich, Germany; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Department of Computer Science, University of Durham, U.K.; Zhongguancun Laboratory, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Fine-grained Unsupervised Domain Adaptation for Gait Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Fine-grained_Unsupervised_Domain_Adaptation_for_Gait_Recognition_ICCV_2023_paper.html",
        "author": "Kang Ma, Ying Fu, Dezhi Zheng, Yunjie Peng, Chunshui Cao, Yongzhen Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Fine-grained_Unsupervised_Domain_Adaptation_for_Gait_Recognition_ICCV_2023_paper.pdf",
        "aff": "WATRIX.AI; Beijing Institute of Technology; Beihang University; Beijing Normal University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Fine-grained Visible Watermark Removal",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Fine-grained_Visible_Watermark_Removal_ICCV_2023_paper.html",
        "author": "Li Niu, Xing Zhao, Bo Zhang, Liqing Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Fine-grained_Visible_Watermark_Removal_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FineDance: A Fine-grained Choreography Dataset for 3D Full Body Dance Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.html",
        "author": "Ronghui Li, Junfan Zhao, Yachao Zhang, Mingyang Su, Zeping Ren, Han Zhang, Yansong Tang, Xiu Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.pdf",
        "aff": "Northwestern Polytechnical University; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "project": "website (not specified in the provided content)",
        "github": "",
        "arxiv": "2212.03741"
    },
    {
        "title": "FineRecon: Depth-aware Feed-forward Network for Detailed 3D Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Stier_FineRecon_Depth-aware_Feed-forward_Network_for_Detailed_3D_Reconstruction_ICCV_2023_paper.html",
        "author": "Noah Stier, Anurag Ranjan, Alex Colburn, Yajie Yan, Liang Yang, Fangchang Ma, Baptiste Angles",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_FineRecon_Depth-aware_Feed-forward_Network_for_Detailed_3D_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Apple, University of California, Santa Barbara; Apple",
        "project": "",
        "github": "https://github.com/apple/ml-finerecon",
        "arxiv": "2304.01480"
    },
    {
        "title": "Fingerprinting Deep Image Restoration Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Fingerprinting_Deep_Image_Restoration_Models_ICCV_2023_paper.html",
        "author": "Yuhui Quan, Huan Teng, Ruotao Xu, Jun Huang, Hui Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Fingerprinting_Deep_Image_Restoration_Models_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China; Pazhou Lab, Guangzhou 510335, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China; Platform of AI, Alibaba Group, Hangzhou 311121, China; Department of Mathematics, National University of Singapore, Singapore 119076; Platform of AI, Alibaba Group, Hangzhou 311121, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "First Session Adaptation: A Strong Replay-Free Baseline for Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Panos_First_Session_Adaptation_A_Strong_Replay-Free_Baseline_for_Class-Incremental_Learning_ICCV_2023_paper.html",
        "author": "Aristeidis Panos, Yuriko Kobe, Daniel Olmeda Reino, Rahaf Aljundi, Richard E. Turner",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Panos_First_Session_Adaptation_A_Strong_Replay-Free_Baseline_for_Class-Incremental_Learning_ICCV_2023_paper.pdf",
        "aff": "University of Cambridge; Toyota Motor Europe",
        "project": "",
        "github": "",
        "arxiv": "2303.13199"
    },
    {
        "title": "FishNet: A Large-scale Dataset and Benchmark for Fish Recognition, Detection, and Functional Trait Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Khan_FishNet_A_Large-scale_Dataset_and_Benchmark_for_Fish_Recognition_Detection_ICCV_2023_paper.html",
        "author": "Faizan Farooq Khan, Xiang Li, Andrew J. Temple, Mohamed Elhoseiny",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_FishNet_A_Large-scale_Dataset_and_Benchmark_for_Fish_Recognition_Detection_ICCV_2023_paper.pdf",
        "aff": "King Abdullah University of Science and Technology (KAUST)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Flatness-Aware Minimization for Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Flatness-Aware_Minimization_for_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Xingxuan Zhang, Renzhe Xu, Han Yu, Yancheng Dong, Pengfei Tian, Peng Cui",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Flatness-Aware_Minimization_for_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2307.11108"
    },
    {
        "title": "Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.html",
        "author": "Lei Fan, Bo Liu, Haoxiang Li, Ying Wu, Gang Hua",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.pdf",
        "aff": "Northwestern University; Wormpex AI Research",
        "project": "",
        "github": "",
        "arxiv": "2309.07403"
    },
    {
        "title": "FlipNeRF: Flipped Reflection Rays for Few-shot Novel View Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Seo_FlipNeRF_Flipped_Reflection_Rays_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.html",
        "author": "Seunghyeon Seo, Yeonjin Chang, Nojun Kwak",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_FlipNeRF_Flipped_Reflection_Rays_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Seoul National University",
        "project": "",
        "github": "",
        "arxiv": "2306.17723"
    },
    {
        "title": "Focal Network for Image Restoration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Focal_Network_for_Image_Restoration_ICCV_2023_paper.html",
        "author": "Yuning Cui, Wenqi Ren, Xiaochun Cao, Alois Knoll",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Focal_Network_for_Image_Restoration_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich; Shenzhen Campus of Sun Yat-sen University",
        "project": "",
        "github": "https://github.com/c-yn/FocalNet",
        "arxiv": ""
    },
    {
        "title": "FocalFormer3D: Focusing on Hard Instance for 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FocalFormer3D_Focusing_on_Hard_Instance_for_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Yilun Chen, Zhiding Yu, Yukang Chen, Shiyi Lan, Anima Anandkumar, Jiaya Jia, Jose M. Alvarez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FocalFormer3D_Focusing_on_Hard_Instance_for_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Caltech; NVIDIA; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/NVlabs/FocalFormer3D",
        "arxiv": "2308.04556"
    },
    {
        "title": "Focus on Your Target: A Dual Teacher-Student Framework for Domain-Adaptive Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huo_Focus_on_Your_Target_A_Dual_Teacher-Student_Framework_for_Domain-Adaptive_ICCV_2023_paper.html",
        "author": "Xinyue Huo, Lingxi Xie, Wengang Zhou, Houqiang Li, Qi Tian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huo_Focus_on_Your_Target_A_Dual_Teacher-Student_Framework_for_Domain-Adaptive_ICCV_2023_paper.pdf",
        "aff": "Huawei Inc.; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/xinyuehuo/DTS",
        "arxiv": "2303.09083"
    },
    {
        "title": "Focus the Discrepancy: Intra- and Inter-Correlation Learning for Image Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.html",
        "author": "Xincheng Yao, Ruoqi Li, Zefeng Qian, Yan Luo, Chongyang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.pdf",
        "aff": "School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/xcyao00/FOD",
        "arxiv": ""
    },
    {
        "title": "Forecast-MAE: Self-supervised Pre-training for Motion Forecasting with Masked Autoencoders",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Forecast-MAE_Self-supervised_Pre-training_for_Motion_Forecasting_with_Masked_Autoencoders_ICCV_2023_paper.html",
        "author": "Jie Cheng, Xiaodong Mei, Ming Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Forecast-MAE_Self-supervised_Pre-training_for_Motion_Forecasting_with_Masked_Autoencoders_ICCV_2023_paper.pdf",
        "aff": "HKUST; HKUST, HKUST(GZ)",
        "project": "",
        "github": "https://github.com/jchengai/forecast-mae",
        "arxiv": ""
    },
    {
        "title": "Foreground Object Search by Distilling Composite Image Feature",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.html",
        "author": "Bo Zhang, Jiacheng Sui, Li Niu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.pdf",
        "aff": "Xian Jiao Tong University; Center for Machine Cognitive Computing of Artificial Intelligence Institute, Artificial Intelligence Institute, Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/bcmi/Foreground-Object-Search-Dataset-FOSD",
        "arxiv": "2308.04990"
    },
    {
        "title": "Foreground and Text-lines Aware Document Image Rectification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.html",
        "author": "Heng Li, Xiangping Wu, Qingcai Chen, Qianjin Xiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.pdf",
        "aff": "Harbin Institute of Technology Shenzhen, China; Harbin Institute of Technology Shenzhen, China, PengCheng Laboratory, Shenzhen China; Harbin Institute of Technology Shenzhen, China, The Hong Kong Polytechnic University, Hung Hom Kowloon, Hong Kong",
        "project": "",
        "github": "https://github.com/xiaomore/Document-Image-Dewarping",
        "arxiv": ""
    },
    {
        "title": "Foreground-Background Distribution Modeling Transformer for Visual Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.html",
        "author": "Dawei Yang, Jianfeng He, Yinchao Ma, Qianjin Yu, Tianzhu Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Foreground-Background Separation through Concept Distillation from Generative Image Foundation Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dombrowski_Foreground-Background_Separation_through_Concept_Distillation_from_Generative_Image_Foundation_Models_ICCV_2023_paper.html",
        "author": "Mischa Dombrowski, Hadrien Reynaud, Matthew Baugh, Bernhard Kainz",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dombrowski_Foreground-Background_Separation_through_Concept_Distillation_from_Generative_Image_Foundation_Models_ICCV_2023_paper.pdf",
        "aff": "Friedrich\u2013Alexander\u2013Universit \u00a8at Erlangen\u2013N \u00a8urnberg; Imperial College London",
        "project": "",
        "github": "https://github.com/MischaD/fobadiffusion",
        "arxiv": "2212.14306"
    },
    {
        "title": "Forward Flow for Novel View Synthesis of Dynamic Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Forward_Flow_for_Novel_View_Synthesis_of_Dynamic_Scenes_ICCV_2023_paper.html",
        "author": "Xiang Guo, Jiadai Sun, Yuchao Dai, Guanying Chen, Xiaoqing Ye, Xiao Tan, Errui Ding, Yumeng Zhang, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Forward_Flow_for_Novel_View_Synthesis_of_Dynamic_Scenes_ICCV_2023_paper.pdf",
        "aff": "Northwestern Polytechnical University; Baidu Inc.; FNii and SSE, CUHK-Shenzhen",
        "project": "https://npucvr.github.io/ForwardFlowDNeRF/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FreeCOS: Self-Supervised Learning from Fractals and Unlabeled Images for Curvilinear Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_FreeCOS_Self-Supervised_Learning_from_Fractals_and_Unlabeled_Images_for_Curvilinear_ICCV_2023_paper.html",
        "author": "Tianyi Shi, Xiaohuan Ding, Liang Zhang, Xin Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_FreeCOS_Self-Supervised_Learning_from_Fractals_and_Unlabeled_Images_for_Curvilinear_ICCV_2023_paper.pdf",
        "aff": "School of EIC, Huazhong University of Science & Technology",
        "project": "",
        "github": "https://github.com/TY-Shi/FreeCOS",
        "arxiv": "2307.07245"
    },
    {
        "title": "FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_FreeDoM_Training-Free_Energy-Guided_Conditional_Diffusion_Model_ICCV_2023_paper.html",
        "author": "Jiwen Yu, Yinhuai Wang, Chen Zhao, Bernard Ghanem, Jian Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_FreeDoM_Training-Free_Energy-Guided_Conditional_Diffusion_Model_ICCV_2023_paper.pdf",
        "aff": "Peking University Shenzhen Graduate School; King Abdullah University of Science and Technology (KAUST)",
        "project": "",
        "github": "",
        "arxiv": "2303.09833"
    },
    {
        "title": "Frequency Guidance Matters in Few-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Frequency_Guidance_Matters_in_Few-Shot_Learning_ICCV_2023_paper.html",
        "author": "Hao Cheng, Siyuan Yang, Joey Tianyi Zhou, Lanqing Guo, Bihan Wen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Frequency_Guidance_Matters_in_Few-Shot_Learning_ICCV_2023_paper.pdf",
        "aff": "Centre for Frontier AI Research (CFAR), A*STAR, Singapore; Nanyang Technological University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Frequency-aware GAN for Adversarial Manipulation Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Frequency-aware_GAN_for_Adversarial_Manipulation_Generation_ICCV_2023_paper.html",
        "author": "Peifei Zhu, Genki Osada, Hirokatsu Kataoka, Tsubasa Takahashi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Frequency-aware_GAN_for_Adversarial_Manipulation_Generation_ICCV_2023_paper.pdf",
        "aff": "LINE Corporation",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "From Chaos Comes Order: Ordering Event Representations for Object Recognition and Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zubic_From_Chaos_Comes_Order_Ordering_Event_Representations_for_Object_Recognition_ICCV_2023_paper.html",
        "author": "Nikola Zubi\u0107, Daniel Gehrig, Mathias Gehrig, Davide Scaramuzza",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zubic_From_Chaos_Comes_Order_Ordering_Event_Representations_for_Object_Recognition_ICCV_2023_paper.pdf",
        "aff": "Robotics and Perception Group, University of Zurich, Switzerland",
        "project": "",
        "github": "https://github.com/uzh-rpg/event_representation_study",
        "arxiv": ""
    },
    {
        "title": "From Knowledge Distillation to Self-Knowledge Distillation: A Unified Approach with Normalized Loss and Customized Soft Labels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_From_Knowledge_Distillation_to_Self-Knowledge_Distillation_A_Unified_Approach_with_ICCV_2023_paper.html",
        "author": "Zhendong Yang, Ailing Zeng, Zhe Li, Tianke Zhang, Chun Yuan, Yu Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_From_Knowledge_Distillation_to_Self-Knowledge_Distillation_A_Unified_Approach_with_ICCV_2023_paper.pdf",
        "aff": "International Digital Economy Academy (IDEA); Tsinghua Shenzhen International Graduate School; Institute of Automation, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/yzd-v/cls_KD",
        "arxiv": "2303.13005"
    },
    {
        "title": "From Sky to the Ground: A Large-scale Benchmark and Simple Baseline Towards Real Rain Removal",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_From_Sky_to_the_Ground_A_Large-scale_Benchmark_and_Simple_ICCV_2023_paper.html",
        "author": "Yun Guo, Xueyao Xiao, Yi Chang, Shumin Deng, Luxin Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_From_Sky_to_the_Ground_A_Large-scale_Benchmark_and_Simple_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China",
        "project": "",
        "github": "https://github.com/yunguo224/LHP-Rain",
        "arxiv": "2308.03867"
    },
    {
        "title": "FrozenRecon: Pose-free 3D Scene Reconstruction with Frozen Depth Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_FrozenRecon_Pose-free_3D_Scene_Reconstruction_with_Frozen_Depth_Models_ICCV_2023_paper.html",
        "author": "Guangkai Xu, Wei Yin, Hao Chen, Chunhua Shen, Kai Cheng, Feng Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_FrozenRecon_Pose-free_3D_Scene_Reconstruction_with_Frozen_Depth_Models_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n9310\n",
        "project": "",
        "github": "",
        "arxiv": "2308.05733"
    },
    {
        "title": "Full-Body Articulated Human-Object Interaction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Full-Body_Articulated_Human-Object_Interaction_ICCV_2023_paper.html",
        "author": "Nan Jiang, Tengyu Liu, Zhexuan Cao, Jieming Cui, Zhiyuan Zhang, Yixin Chen, He Wang, Yixin Zhu, Siyuan Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Full-Body_Articulated_Human-Object_Interaction_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of General Arti\ufb01cial Intelligence (BIGAI); Department of Automation, Tsinghua University; School of Intelligence Science and Technology, Peking University; Beijing Institute of General Arti\ufb01cial Intelligence (BIGAI); Department of Automation, Tsinghua University; Institute for Arti\ufb01cial Intelligence, Peking University; Center on Frontiers of Computing Studies, Peking University; Beijing Institute of General Arti\ufb01cial Intelligence (BIGAI)",
        "project": "https://jnnan.github.io/project/chairs/",
        "github": "",
        "arxiv": "2212.10621"
    },
    {
        "title": "Fully Attentional Networks with Self-emerging Token Labeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Fully_Attentional_Networks_with_Self-emerging_Token_Labeling_ICCV_2023_paper.html",
        "author": "Bingyin Zhao, Zhiding Yu, Shiyi Lan, Yutao Cheng, Anima Anandkumar, Yingjie Lao, Jose M. Alvarez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fully_Attentional_Networks_with_Self-emerging_Token_Labeling_ICCV_2023_paper.pdf",
        "aff": "Fudan University; Caltech; NVIDIA; Clemson University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.html",
        "author": "Robin Hesse, Simone Schaub-Meyer, Stefan Roth",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, TU Darmstadt; hessian.AI; Department of Computer Science, TU Darmstadt",
        "project": "",
        "github": "github.com/visinf/funnybirds/",
        "arxiv": "2308.06248"
    },
    {
        "title": "G2L: Semantically Aligned and Uniform Video Grounding via Geodesic and Game Theory",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_G2L_Semantically_Aligned_and_Uniform_Video_Grounding_via_Geodesic_and_ICCV_2023_paper.html",
        "author": "Hongxiang Li, Meng Cao, Xuxin Cheng, Yaowei Li, Zhihong Zhu, Yuexian Zou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_G2L_Semantically_Aligned_and_Uniform_Video_Grounding_via_Geodesic_and_ICCV_2023_paper.pdf",
        "aff": "School of Electronic and Computer Engineering, Peking University; International Digital Economy Academy (IDEA)",
        "project": "",
        "github": "",
        "arxiv": "2307.14277"
    },
    {
        "title": "GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object Detectors on LiDAR-Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Schinagl_GACE_Geometry_Aware_Confidence_Enhancement_for_Black-Box_3D_Object_Detectors_ICCV_2023_paper.html",
        "author": "David Schinagl, Georg Krispel, Christian Fruhwirth-Reisinger, Horst Possegger, Horst Bischof",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Schinagl_GACE_Geometry_Aware_Confidence_Enhancement_for_Black-Box_3D_Object_Detectors_ICCV_2023_paper.pdf",
        "aff": "Graz University of Technology; Graz University of Technology, Christian Doppler Laboratory for Embedded Machine Learning",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GAFlow: Incorporating Gaussian Attention into Optical Flow",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.html",
        "author": "Ao Luo, Fan Yang, Xin Li, Lang Nie, Chunyu Lin, Haoqiang Fan, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.pdf",
        "aff": "GAFlow: Incorporating Gaussian Attention into Optical Flow\nAo Luo1, Fan Yang2, Xin Li2, Lang Nie3, Chunyu Lin3, Haoqiang Fan1, and Shuaicheng Liu4,1*\n1Megvii Technology2Group 423Beijing Jiaotong University\n4University of Electronic Science and Technology of China\nAbstract\nOptical flow, or the estimation of motion fields from\nimage sequences, is one of the fundamental problems in\ncomputer vision. Unlike most pixel-wise tasks that aim at\nachieving consistent representations of the same category,\noptical flow raises extra demands for obtaining local dis-\ncrimination and smoothness, which yet is not fully explored\nby existing approaches. In this paper, we push Gaussian\nAttention (GA) into the optical flow models to accentuate\nlocal properties during representation learning and enforce\nthe motion affinity during matching. Specifically, we in-\ntroduce a novel Gaussian-Constrained Layer (GCL) which\ncan be easily plugged into existing Transformer blocks to\nhighlight the local neighborhood that contains fine-grained\nstructural information. Moreover, for reliable motion anal-\nysis, we provide a new Gaussian-Guided Attention Mod-\nule (GGAM) which not only inherits properties from Gaus-\nsian distribution to instinctively revolve around the neigh-\nbor fields of each point but also is empowered to put the\nemphasis on contextually related regions during match-\ning. Our fully-equipped model, namely Gaussian Attention\nFlow network (GAFlow), naturally incorporates a series of\nnovel Gaussian-based modules into the conventional opti-\ncal flow framework for reliable motion analysis. Extensive\nexperiments on standard optical flow datasets consistently\ndemonstrate the exceptional performance of the proposed\napproach in terms of both generalization ability evalua-\ntion and online benchmark testing. Code is available at\nhttps://github.com/LA30/GAFlow .\n1. Introduction\nOptical flow aims to establish pixel-wise correspon-\ndences across images, playing a crucial role in video un-\nderstanding. It unifies representation learning and fea-\nture matching as a problem of pixel-wise motion inference.\nModern optical flow models typically focus on either im-\nproving representation learning techniques ( e.g., alternative\n*Corresponding author\nFrame T\nDiscrimination SmoothnessFrame T+1\nGMA\nGGAM\ud835\udc77\u2032\ud835\udc77\nGCL\nBaselineFigure 1: Visualization of feature discrimination (left) and\nsmoothness constraint (right). For a random point Pin\nframe t, our GCL enhances feature discrimination by em-\nphasizing fine-grained structural details. Concurrently, our\nGGAM effectively captures smoothness constraints, center-\ning on pertinent local regions.\nlearning [40, 20, 54] and reinforcement learning [1]) or re-\nfining feature similarity measurement methodologies ( e.g.,\n4D correlation volumes [42] or 4D Transformer [16]). De-\nspite these significant advancements, a glaring limitation\npersists: these models largely neglect the exploration of\nlocal structural information. This oversight hinders their\nperformance, particularly in challenging scenarios involv-\ning large motions, occlusions, blurring effects, and shifts in\nappearance. Such situations demand an elevated focus on\nlocal discrimination and flow consistency. This brings us\nto an intriguing inquiry: Is it feasible to architect optical\nflow models that intrinsically focus on local structural in-\nformation during both representation learning and feature\nmatching?\nIn response to the aforementioned challenge, we present\nthe Gaussian Attention Flow network (GAFlow), a pioneer-\ning framework that leverages Gaussian Attention (GA) to\ninform both the feature encoder and the matching mod-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n9642\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GAIT: Generating Aesthetic Indoor Tours with Deep Reinforcement Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_GAIT_Generating_Aesthetic_Indoor_Tours_with_Deep_Reinforcement_Learning_ICCV_2023_paper.html",
        "author": "Desai Xie, Ping Hu, Xin Sun, Soren Pirk, Jianming Zhang, Radomir Mech, Arie E. Kaufman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_GAIT_Generating_Aesthetic_Indoor_Tours_with_Deep_Reinforcement_Learning_ICCV_2023_paper.pdf",
        "aff": "Stony Brook University; Adobe Research",
        "project": "https://desaixie.github.io/gait-rl",
        "github": "https://github.com/desaixie/gait-rl",
        "arxiv": ""
    },
    {
        "title": "GECCO: Geometrically-Conditioned Point Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tyszkiewicz_GECCO_Geometrically-Conditioned_Point_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Micha\u0142 J Tyszkiewicz, Pascal Fua, Eduard Trulls",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tyszkiewicz_GECCO_Geometrically-Conditioned_Point_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL); Google Research, Zurich",
        "project": "",
        "github": "",
        "arxiv": "2303.05916"
    },
    {
        "title": "GEDepth: Ground Embedding for Monocular Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_GEDepth_Ground_Embedding_for_Monocular_Depth_Estimation_ICCV_2023_paper.html",
        "author": "Xiaodong Yang, Zhuang Ma, Zhiyu Ji, Zhe Ren",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_GEDepth_Ground_Embedding_for_Monocular_Depth_Estimation_ICCV_2023_paper.pdf",
        "aff": "QCraft",
        "project": "",
        "github": "",
        "arxiv": "2309.09975"
    },
    {
        "title": "GET: Group Event Transformer for Event-Based Vision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Peng_GET_Group_Event_Transformer_for_Event-Based_Vision_ICCV_2023_paper.html",
        "author": "Yansong Peng, Yueyi Zhang, Zhiwei Xiong, Xiaoyan Sun, Feng Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_GET_Group_Event_Transformer_for_Event-Based_Vision_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/Peterande/GET-Group-Event-Transformer",
        "arxiv": ""
    },
    {
        "title": "GETAvatar: Generative Textured Meshes for Animatable Human Avatars",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GETAvatar_Generative_Textured_Meshes_for_Animatable_Human_Avatars_ICCV_2023_paper.html",
        "author": "Xuanmeng Zhang, Jianfeng Zhang, Rohan Chacko, Hongyi Xu, Guoxian Song, Yi Yang, Jiashi Feng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GETAvatar_Generative_Textured_Meshes_for_Animatable_Human_Avatars_ICCV_2023_paper.pdf",
        "aff": "ReLER, AAII, University of Technology Sydney; ReLER, CCAI, Zhejiang University; ByteDance",
        "project": "",
        "github": "https://getavatar.github.io/",
        "arxiv": ""
    },
    {
        "title": "GIFD: A Generative Gradient Inversion Method with Feature Domain Optimization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fang_GIFD_A_Generative_Gradient_Inversion_Method_with_Feature_Domain_Optimization_ICCV_2023_paper.html",
        "author": "Hao Fang, Bin Chen, Xuan Wang, Zhi Wang, Shu-Tao Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_GIFD_A_Generative_Gradient_Inversion_Method_with_Feature_Domain_Optimization_ICCV_2023_paper.pdf",
        "aff": "Peng Cheng Laboratory; Tsinghua Shenzhen International Graduate School, Tsinghua University; Harbin Institute of Technology, Shenzhen",
        "project": "",
        "github": "",
        "arxiv": "2308.04699"
    },
    {
        "title": "GLA-GCN: Global-local Adaptive Graph Convolutional Network for 3D Human Pose Estimation from Monocular Video",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_GLA-GCN_Global-local_Adaptive_Graph_Convolutional_Network_for_3D_Human_Pose_ICCV_2023_paper.html",
        "author": "Bruce X.B. Yu, Zhi Zhang, Yongxu Liu, Sheng-hua Zhong, Yan Liu, Chang Wen Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_GLA-GCN_Global-local_Adaptive_Graph_Convolutional_Network_for_3D_Human_Pose_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong Polytechnic University; Shenzhen University",
        "project": "",
        "github": "https://github.com/bruceyo/GLA-GCN",
        "arxiv": ""
    },
    {
        "title": "GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GO-SLAM_Global_Optimization_for_Consistent_3D_Instant_Reconstruction_ICCV_2023_paper.html",
        "author": "Youmin Zhang, Fabio Tosi, Stefano Mattoccia, Matteo Poggi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GO-SLAM_Global_Optimization_for_Consistent_3D_Instant_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering (DISI), University of Bologna, Italy",
        "project": "https://youmi-zym.github.io/projects/GO-SLAM/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GPA-3D: Geometry-aware Prototype Alignment for Unsupervised Domain Adaptive 3D Object Detection from Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_GPA-3D_Geometry-aware_Prototype_Alignment_for_Unsupervised_Domain_Adaptive_3D_Object_ICCV_2023_paper.html",
        "author": "Ziyu Li, Jingming Guo, Tongtong Cao, Liu Bingbing, Wankou Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_GPA-3D_Geometry-aware_Prototype_Alignment_for_Unsupervised_Domain_Adaptive_3D_Object_ICCV_2023_paper.pdf",
        "aff": "School of Automation, Southeast University; Huawei Noah\u2019s Ark Lab",
        "project": "",
        "github": "https://github.com/Liz66666/GPA3D",
        "arxiv": ""
    },
    {
        "title": "GPFL: Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GPFL_Simultaneously_Learning_Global_and_Personalized_Feature_Information_for_Personalized_ICCV_2023_paper.html",
        "author": "Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Jian Cao, Haibing Guan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GPFL_Simultaneously_Learning_Global_and_Personalized_Feature_Information_for_Personalized_ICCV_2023_paper.pdf",
        "aff": "Queen\u2019s University Belfast; Louisiana State University; Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2308.10279"
    },
    {
        "title": "GPGait: Generalized Pose-based Gait Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fu_GPGait_Generalized_Pose-based_Gait_Recognition_ICCV_2023_paper.html",
        "author": "Yang Fu, Shibei Meng, Saihui Hou, Xuecai Hu, Yongzhen Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_GPGait_Generalized_Pose-based_Gait_Recognition_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence, Beijing Normal University; School of Artificial Intelligence, Beijing Normal University; WATRIX.AI",
        "project": "",
        "github": "https://github.com/BNU-IVC/FastPoseGait",
        "arxiv": "2303.05234"
    },
    {
        "title": "GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.html",
        "author": "Jianfeng Xiang, Jiaolong Yang, Yu Deng, Xin Tong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; Tsinghua University, Microsoft Research Asia",
        "project": "https://jeffreyxiang.github.io/GRAM-HD/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GaPro: Box-Supervised 3D Point Cloud Instance Segmentation Using Gaussian Processes as Pseudo Labelers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ngo_GaPro_Box-Supervised_3D_Point_Cloud_Instance_Segmentation_Using_Gaussian_Processes_ICCV_2023_paper.html",
        "author": "Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_GaPro_Box-Supervised_3D_Point_Cloud_Instance_Segmentation_Using_Gaussian_Processes_ICCV_2023_paper.pdf",
        "aff": "VinAI Research, Hanoi, Vietnam",
        "project": "",
        "github": "https://github.com/VinAIResearch/GaPro",
        "arxiv": "2307.13251"
    },
    {
        "title": "GameFormer: Game-theoretic Modeling and Learning of Transformer-based Interactive Prediction and Planning for Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_GameFormer_Game-theoretic_Modeling_and_Learning_of_Transformer-based_Interactive_Prediction_and_ICCV_2023_paper.html",
        "author": "Zhiyu Huang, Haochen Liu, Chen Lv",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_GameFormer_Game-theoretic_Modeling_and_Learning_of_Transformer-based_Interactive_Prediction_and_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University, Singapore",
        "project": "https://mczhi.github.io/GameFormer/",
        "github": "",
        "arxiv": "2303.05760"
    },
    {
        "title": "GasMono: Geometry-Aided Self-Supervised Monocular Depth Estimation for Indoor Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_GasMono_Geometry-Aided_Self-Supervised_Monocular_Depth_Estimation_for_Indoor_Scenes_ICCV_2023_paper.html",
        "author": "Chaoqiang Zhao, Matteo Poggi, Fabio Tosi, Lei Zhou, Qiyu Sun, Yang Tang, Stefano Mattoccia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_GasMono_Geometry-Aided_Self-Supervised_Monocular_Depth_Estimation_for_Indoor_Scenes_ICCV_2023_paper.pdf",
        "aff": "University of Bologna; East China University of Science and Technology",
        "project": "",
        "github": "https://github.com/zxcqlf/GasMono",
        "arxiv": ""
    },
    {
        "title": "GePSAn: Generative Procedure Step Anticipation in Cooking Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Abdelsalam_GePSAn_Generative_Procedure_Step_Anticipation_in_Cooking_Videos_ICCV_2023_paper.html",
        "author": "Mohamed A. Abdelsalam, Samrudhdhi B. Rangrej, Isma Hadji, Nikita Dvornik, Konstantinos G. Derpanis, Afsaneh Fazly",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelsalam_GePSAn_Generative_Procedure_Step_Anticipation_in_Cooking_Videos_ICCV_2023_paper.pdf",
        "aff": "Waabi; Samsung AI Centre; Samsung AI Centre, York University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GeT: Generative Target Structure Debiasing for Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GeT_Generative_Target_Structure_Debiasing_for_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Can Zhang, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GeT_Generative_Target_Structure_Debiasing_for_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, National University of Singapore",
        "project": "",
        "github": "https://lulusindazc.github.io/getproject/",
        "arxiv": "2308.10205"
    },
    {
        "title": "Gender Artifacts in Visual Datasets",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Meister_Gender_Artifacts_in_Visual_Datasets_ICCV_2023_paper.html",
        "author": "Nicole Meister, Dora Zhao, Angelina Wang, Vikram V. Ramaswamy, Ruth Fong, Olga Russakovsky",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Meister_Gender_Artifacts_in_Visual_Datasets_ICCV_2023_paper.pdf",
        "aff": "Sony AI; Stanford University; Princeton University",
        "project": "",
        "github": "",
        "arxiv": "2206.09191"
    },
    {
        "title": "General Image-to-Image Translation with One-Shot Image Guidance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.html",
        "author": "Bin Cheng, Zuhao Liu, Yunbo Peng, Yue Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.pdf",
        "aff": "NetEase Games AI Lab",
        "project": "",
        "github": "https://github.com/CrystalNeuro/visual-concept-translator",
        "arxiv": "2307.14352"
    },
    {
        "title": "General Planar Motion from a Pair of 3D Correspondences",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dibene_General_Planar_Motion_from_a_Pair_of_3D_Correspondences_ICCV_2023_paper.html",
        "author": "Juan Carlos Dibene, Zhixiang Min, Enrique Dunn",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dibene_General_Planar_Motion_from_a_Pair_of_3D_Correspondences_ICCV_2023_paper.pdf",
        "aff": "Stevens Institute of Technology",
        "project": "",
        "github": "https://github.com/jdibenes/gpm",
        "arxiv": ""
    },
    {
        "title": "Generalizable Decision Boundaries: Dualistic Meta-Learning for Open Set Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Generalizable_Decision_Boundaries_Dualistic_Meta-Learning_for_Open_Set_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Xiran Wang, Jian Zhang, Lei Qi, Yinghuan Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Generalizable_Decision_Boundaries_Dualistic_Meta-Learning_for_Open_Set_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "Southeast University; Nanjing University",
        "project": "",
        "github": "https://github.com/zzwdx/MEDIC",
        "arxiv": "2308.09391"
    },
    {
        "title": "Generalizable Neural Fields as Partially Observed Neural Processes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Generalizable_Neural_Fields_as_Partially_Observed_Neural_Processes_ICCV_2023_paper.html",
        "author": "Jeffrey Gu, Kuan-Chieh Wang, Serena Yeung",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Generalizable_Neural_Fields_as_Partially_Observed_Neural_Processes_ICCV_2023_paper.pdf",
        "aff": "ICME, Stanford, CA; Department of Computer Science, Stanford, CA",
        "project": "",
        "github": "",
        "arxiv": "2309.06660"
    },
    {
        "title": "Generalized Differentiable RANSAC",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Generalized_Differentiable_RANSAC_ICCV_2023_paper.html",
        "author": "Tong Wei, Yash Patel, Alexander Shekhovtsov, Jiri Matas, Daniel Barath",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Generalized_Differentiable_RANSAC_ICCV_2023_paper.pdf",
        "aff": "Computer Vision and Geometry Group, ETH Zurich; Visual Recognition Group, FEE, Czech Technical University in Prague",
        "project": "",
        "github": "https://github.com/weitong8591/differentiable_ransac",
        "arxiv": "2212.13185"
    },
    {
        "title": "Generalized Few-Shot Point Cloud Segmentation via Geometric Words",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Generalized_Few-Shot_Point_Cloud_Segmentation_via_Geometric_Words_ICCV_2023_paper.html",
        "author": "Yating Xu, Conghui Hu, Na Zhao, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Generalized_Few-Shot_Point_Cloud_Segmentation_via_Geometric_Words_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, National University of Singapore; Singapore University of Technology and Design",
        "project": "",
        "github": "https://github.com/Pixie8888/GFS-3DSeg_GWs",
        "arxiv": "2309.11222"
    },
    {
        "title": "Generalized Lightness Adaptation with Channel Selective Normalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Generalized_Lightness_Adaptation_with_Channel_Selective_Normalization_ICCV_2023_paper.html",
        "author": "Mingde Yao, Jie Huang, Xin Jin, Ruikang Xu, Shenglong Zhou, Man Zhou, Zhiwei Xiong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Generalized_Lightness_Adaptation_with_Channel_Selective_Normalization_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; Eastern Institute of Technology; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/mdyao/CSNorm",
        "arxiv": "2308.13783"
    },
    {
        "title": "Generalized Sum Pooling for Metric Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gurbuz_Generalized_Sum_Pooling_for_Metric_Learning_ICCV_2023_paper.html",
        "author": "Yeti Z. G\u00fcrb\u00fcz, Ozan Sener, A. Aydin Alatan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gurbuz_Generalized_Sum_Pooling_for_Metric_Learning_ICCV_2023_paper.pdf",
        "aff": "Intel Labs; RSiM, TU Berlin; OGAM and METU",
        "project": "",
        "github": "GSP-DML Framework",
        "arxiv": ""
    },
    {
        "title": "Generalizing Event-Based Motion Deblurring in Real-World Scenarios",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Generalizing_Event-Based_Motion_Deblurring_in_Real-World_Scenarios_ICCV_2023_paper.html",
        "author": "Xiang Zhang, Lei Yu, Wen Yang, Jianzhuang Liu, Gui-Song Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Generalizing_Event-Based_Motion_Deblurring_in_Real-World_Scenarios_ICCV_2023_paper.pdf",
        "aff": "Wuhan University; Shenzhen Institute of Advanced Technology",
        "project": "",
        "github": "https://github.com/XiangZ-0/GEM",
        "arxiv": "2308.05932"
    },
    {
        "title": "Generalizing Neural Human Fitting to Unseen Poses With Articulated SE(3) Equivariance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Generalizing_Neural_Human_Fitting_to_Unseen_Poses_With_Articulated_SE3_ICCV_2023_paper.html",
        "author": "Haiwen Feng, Peter Kulits, Shichen Liu, Michael J. Black, Victoria Fernandez Abrevaya",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Generalizing_Neural_Human_Fitting_to_Unseen_Poses_With_Articulated_SE3_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; University of Southern California",
        "project": "https://arteq.is.tue.mpg.de",
        "github": "",
        "arxiv": "2304.10528"
    },
    {
        "title": "Generating Dynamic Kernels via Transformers for Lane Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Generating_Dynamic_Kernels_via_Transformers_for_Lane_Detection_ICCV_2023_paper.html",
        "author": "Ziye Chen, Yu Liu, Mingming Gong, Bo Du, Guoqi Qian, Kate Smith-Miles",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Generating_Dynamic_Kernels_via_Transformers_for_Lane_Detection_ICCV_2023_paper.pdf",
        "aff": "School of Mathematics and Statistics, University of Melbourne, Australia; Mach Drive, China; School of Computer Science, Wuhan University, Wuhan, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Generating Instance-level Prompts for Rehearsal-free Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jung_Generating_Instance-level_Prompts_for_Rehearsal-free_Continual_Learning_ICCV_2023_paper.html",
        "author": "Dahuin Jung, Dongyoon Han, Jihwan Bang, Hwanjun Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_Generating_Instance-level_Prompts_for_Rehearsal-free_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "NAVER Cloud; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea; AWS AI Labs; NAVER AI Lab",
        "project": "",
        "github": "https://github.com/naver-ai/dap-cl",
        "arxiv": ""
    },
    {
        "title": "Generating Realistic Images from In-the-wild Sounds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Generating_Realistic_Images_from_In-the-wild_Sounds_ICCV_2023_paper.html",
        "author": "Taegyeong Lee, Jeonghun Kang, Hyeonyu Kim, Taehwan Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Generating_Realistic_Images_from_In-the-wild_Sounds_ICCV_2023_paper.pdf",
        "aff": "Artificial Intelligence Graduate School, UNIST",
        "project": "",
        "github": "",
        "arxiv": "2309.02405"
    },
    {
        "title": "Generating Visual Scenes from Touch",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Generating_Visual_Scenes_from_Touch_ICCV_2023_paper.html",
        "author": "Fengyu Yang, Jiacheng Zhang, Andrew Owens",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Generating_Visual_Scenes_from_Touch_ICCV_2023_paper.pdf",
        "aff": "University of Michigan",
        "project": "https://fredfyyang.github.io/vision-from-touch/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Generative Action Description Prompts for Skeleton-based Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Generative_Action_Description_Prompts_for_Skeleton-based_Action_Recognition_ICCV_2023_paper.html",
        "author": "Wangmeng Xiang, Chao Li, Yuxuan Zhou, Biao Wang, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Generative_Action_Description_Prompts_for_Skeleton-based_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "Mannheim University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University*; DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/MartinXM/GAP",
        "arxiv": "2208.05318"
    },
    {
        "title": "Generative Gradient Inversion via Over-Parameterized Networks in Federated Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Generative_Gradient_Inversion_via_Over-Parameterized_Networks_in_Federated_Learning_ICCV_2023_paper.html",
        "author": "Chi Zhang, Zhang Xiaoman, Ekanut Sotthiwat, Yanyu Xu, Ping Liu, Liangli Zhen, Yong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Generative_Gradient_Inversion_via_Over-Parameterized_Networks_in_Federated_Learning_ICCV_2023_paper.pdf",
        "aff": "Institute of High Performance Computing, A*STAR, Singapore",
        "project": "",
        "github": "https://github.com/czhang024/CI-Net",
        "arxiv": ""
    },
    {
        "title": "Generative Multiplane Neural Radiance for 3D-Aware Image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.html",
        "author": "Amandeep Kumar, Ankan Kumar Bhunia, Sanath Narayan, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.pdf",
        "aff": "Technology Innovation Institute; University of California, Merced; Mohamed bin Zayed University of AI; Link\u00f6ping University",
        "project": "",
        "github": "https://github.com/VIROBO-15/GMNR",
        "arxiv": "2304.01172"
    },
    {
        "title": "Generative Novel View Synthesis with 3D-Aware Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chan_Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Eric R. Chan, Koki Nagano, Matthew A. Chan, Alexander W. Bergman, Jeong Joon Park, Axel Levy, Miika Aittala, Shalini De Mello, Tero Karras, Gordon Wetzstein",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Stanford University; NVIDIA",
        "project": "",
        "github": "",
        "arxiv": "2304.02602"
    },
    {
        "title": "Generative Prompt Model for Weakly Supervised Object Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Generative_Prompt_Model_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html",
        "author": "Yuzhong Zhao, Qixiang Ye, Weijia Wu, Chunhua Shen, Fang Wan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Generative_Prompt_Model_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/callsys/GenPromp",
        "arxiv": "2307.09756"
    },
    {
        "title": "GeoMIM: Towards Better 3D Knowledge Transfer via Masked Image Modeling for Multi-view 3D Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.html",
        "author": "Jihao Liu, Tai Wang, Boxiao Liu, Qihang Zhang, Yu Liu, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.pdf",
        "aff": "2SenseTime Research; 1CUHK MMLab; 1CUHK MMLab, 2SenseTime Research; 1CUHK MMLab, 3Shanghai AI Laboratory, 4CPII under InnoHK",
        "project": "",
        "github": "",
        "arxiv": "2303.11325"
    },
    {
        "title": "GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided Distance Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ren_GeoUDF_Surface_Reconstruction_from_3D_Point_Clouds_via_Geometry-guided_Distance_ICCV_2023_paper.html",
        "author": "Siyu Ren, Junhui Hou, Xiaodong Chen, Ying He, Wenping Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_GeoUDF_Surface_Reconstruction_from_3D_Point_Clouds_via_Geometry-guided_Distance_ICCV_2023_paper.pdf",
        "aff": "3. Nanyang Technological University; 1. City University of Hong Kong; 4. Texas A&M University; 2. Tianjin University",
        "project": "",
        "github": "https://github.com/rsy6318/GeoUDF",
        "arxiv": "2211.16762"
    },
    {
        "title": "Geometric Viewpoint Learning with Hyper-Rays and Harmonics Encoding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Min_Geometric_Viewpoint_Learning_with_Hyper-Rays_and_Harmonics_Encoding_ICCV_2023_paper.html",
        "author": "Zhixiang Min, Juan Carlos Dibene, Enrique Dunn",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Geometric_Viewpoint_Learning_with_Hyper-Rays_and_Harmonics_Encoding_ICCV_2023_paper.pdf",
        "aff": "Stevens Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Geometrized Transformer for Self-Supervised Homography Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Geometrized_Transformer_for_Self-Supervised_Homography_Estimation_ICCV_2023_paper.html",
        "author": "Jiazhen Liu, Xirong Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Geometrized_Transformer_for_Self-Supervised_Homography_Estimation_ICCV_2023_paper.pdf",
        "aff": "Key Lab of DEKE, Renmin University of China",
        "project": "",
        "github": "https://github.com/ruc-aimc-lab/GeoFormer",
        "arxiv": ""
    },
    {
        "title": "Geometry-guided Feature Learning and Fusion for Indoor Scene Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_paper.html",
        "author": "Ruihong Yin, Sezer Karaoglu, Theo Gevers",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "University of Amsterdam, Amsterdam, The Netherlands; University of Amsterdam, Amsterdam, The Netherlands; 3DUniversum, Amsterdam, The Netherlands",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Get the Best of Both Worlds: Improving Accuracy and Transferability by Grassmann Class Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Get_the_Best_of_Both_Worlds_Improving_Accuracy_and_Transferability_ICCV_2023_paper.html",
        "author": "Haoqi Wang, Zhizhong Li, Wayne Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Get_the_Best_of_Both_Worlds_Improving_Accuracy_and_Transferability_ICCV_2023_paper.pdf",
        "aff": "EPFL, Lausanne, Switzerland; Guangdong Provincial Key Laboratory of Digital Grid Technology; SenseTime Research",
        "project": "",
        "github": "https://github.com/innerlee/GCR",
        "arxiv": "2308.01547"
    },
    {
        "title": "Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model Using Pixel-Aligned Reconstruction Priors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_Get3DHuman_Lifting_StyleGAN-Human_into_a_3D_Generative_Model_Using_Pixel-Aligned_ICCV_2023_paper.html",
        "author": "Zhangyang Xiong, Di Kang, Derong Jin, Weikai Chen, Linchao Bao, Shuguang Cui, Xiaoguang Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Get3DHuman_Lifting_StyleGAN-Human_into_a_3D_Generative_Model_Using_Pixel-Aligned_ICCV_2023_paper.pdf",
        "aff": "Tencent America; 2SSE, CUHKSZ; Tencent AI Lab; 1FNii, CUHKSZ; 2SSE, CUHKSZ",
        "project": "",
        "github": "",
        "arxiv": "2302.01162"
    },
    {
        "title": "Global Adaptation Meets Local Generalization: Unsupervised Domain Adaptation for 3D Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chai_Global_Adaptation_Meets_Local_Generalization_Unsupervised_Domain_Adaptation_for_3D_ICCV_2023_paper.html",
        "author": "Wenhao Chai, Zhongyu Jiang, Jenq-Neng Hwang, Gaoang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_Global_Adaptation_Meets_Local_Generalization_Unsupervised_Domain_Adaptation_for_3D_ICCV_2023_paper.pdf",
        "aff": "University of Washington; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2303.16456"
    },
    {
        "title": "Global Balanced Experts for Federated Long-Tailed Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zeng_Global_Balanced_Experts_for_Federated_Long-Tailed_Learning_ICCV_2023_paper.html",
        "author": "Yaopei Zeng, Lei Liu, Li Liu, Li Shen, Shaoguo Liu, Baoyuan Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_Global_Balanced_Experts_for_Federated_Long-Tailed_Learning_ICCV_2023_paper.pdf",
        "aff": "Global Balanced Experts for Federated Long-Tailed Learning\nYaopei Zeng1,\u2217, Lei Liu1,\u2217, Li Liu2,\u2020, Li Shen3, Shaoguo Liu4, Baoyuan Wu1,\u2020\n1School of Data Science, Shenzhen Research Institute of Big Data,\nThe Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China\n2Hong Kong University of Science and Technology (Guangzhou), Guangzhou, Guangdong, China\n3JD Explore Academy,4Alibaba Group\nAbstract\nFederated learning (FL) is a prevalent distributed ma-\nchine learning approach that enables collaborative train-\ning of a global model across multiple devices without\nsharing local data. However, the presence of long-tailed\ndata can negatively deteriorate the model\u2019s performance in\nreal-world FL applications. Moreover, existing re-balance\nstrategies are less effective for the federated long-tailed is-\nsue when directly utilizing local label distribution as the\nclass prior at the clients\u2019 side. To this end, we propose\na novel Global Balanced Multi-Expert (GBME) frame-\nwork to optimize a balanced global objective, which does\nnot require additional information beyond the standard FL\npipeline. In particular, a proxy is derived from the accumu-\nlated gradients uploaded by the clients after local training,\nand is shared by all clients as the class prior for re-balance\ntraining. Such a proxy can also guide the client grouping\nto train a multi-expert model, where the knowledge from\ndifferent clients can be aggregated via the ensemble of dif-\nferent experts corresponding to different client groups. To\nfurther strengthen the privacy-preserving ability, we present\na GBME-p algorithm with a theoretical guarantee to pre-\nvent privacy leakage from the proxy. Extensive experiments\non long-tailed decentralized datasets demonstrate the effec-\ntiveness of GBME and GBME-p, both of which show supe-\nrior performance to state-of-the-art methods. The code is\navailable at here.\n1. Introduction\nFederated Learning (FL) is a collaborative training\nmethod to develop a global model by utilizing decentralized\ndata from multiple clients [21]. It enables knowledge aggre-\ngation over disparate data sources while mitigating privacy\n\u2217indicates equal contribution.\n\u2020denotes corresponding author (avrillliu@hkust-gz.edu.cn,\nwubaoyuan@cuhk.edu.cn).\n/uni0000002f/uni00000027/uni00000024/uni00000030 /uni00000025/uni00000036/uni00000030 /uni0000002f/uni00000024/uni00000027/uni00000028 /uni00000035/uni0000002c/uni00000027/uni00000028 /uni00000033/uni00000044/uni00000026/uni00000052/uni00000016/uni00000013/uni00000011/uni00000013/uni00000016/uni00000015/uni00000011/uni00000018/uni00000016/uni00000018/uni00000011/uni00000013/uni00000016/uni0000001a/uni00000011/uni00000018/uni00000017/uni00000013/uni00000011/uni00000013/uni00000017/uni00000015/uni00000011/uni00000018/uni00000017/uni00000018/uni00000011/uni00000013/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c/uni00000026/uni0000002c/uni00000029/uni00000024/uni00000035/uni00000010/uni00000014/uni00000013/uni00000013/uni00000010/uni0000002f/uni00000037/uni0000000f/uni00000003/uni0000002c/uni00000035/uni00000003/uni00000020/uni00000003/uni00000014/uni00000013/uni00000013\n/uni00000029/uni00000048/uni00000047/uni00000024/uni00000059/uni0000004a\n/uni0000002f/uni00000052/uni00000046/uni00000044/uni0000004f/uni00000003/uni00000035/uni00000048/uni00000010/uni00000045/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048\n/uni0000002a/uni0000004f/uni00000052/uni00000045/uni00000044/uni0000004f/uni00000003/uni00000035/uni00000048/uni00000010/uni00000045/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048\n/uni0000002f/uni00000027/uni00000024/uni00000030 /uni00000025/uni00000036/uni00000030 /uni0000002f/uni00000024/uni00000027/uni00000028 /uni00000035/uni0000002c/uni00000027/uni00000028 /uni00000033/uni00000044/uni00000026/uni00000052/uni00000016/uni00000013/uni00000011/uni00000013/uni00000016/uni00000015/uni00000011/uni00000018/uni00000016/uni00000018/uni00000011/uni00000013/uni00000016/uni0000001a/uni00000011/uni00000018/uni00000017/uni00000013/uni00000011/uni00000013/uni00000017/uni00000015/uni00000011/uni00000018/uni00000017/uni00000018/uni00000011/uni00000013/uni0000002c/uni00000050/uni00000044/uni0000004a/uni00000048/uni00000031/uni00000048/uni00000057/uni00000010/uni0000002f/uni00000037\n/uni00000029/uni00000048/uni00000047/uni00000024/uni00000059/uni0000004a\n/uni0000002f/uni00000052/uni00000046/uni00000044/uni0000004f/uni00000003/uni00000035/uni00000048/uni00000010/uni00000045/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048\n/uni0000002a/uni0000004f/uni00000052/uni00000045/uni00000044/uni0000004f/uni00000003/uni00000035/uni00000048/uni00000010/uni00000045/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048Figure 1: Global re-balance VS.Local re-balance1. X-axis\ndenotes several classical re-balance strategies. Global re-\nbalance significantly outperforms local re-balance in the FL\nsetting with long-tailed data, motivating us to optimize a\nglobal balanced objective.\nrisks for individual clients. However, the model\u2019s perfor-\nmance of a FL system can be severely deteriorated in the\npresence of long-tailed data distribution, which is an ubiq-\nuitous problem in various realistic scenarios [13, 36], such\nas medical applications [17], personal information protec-\ntion [44] and autonomous vehicles [26].\nImportantly, it is extremely difficult to learn a balanced\nglobal model in the FL setting with long-tailed data [34],\nespecially for the minority classes [30]. In the concrete,\ndue to data heterogeneity, there may exist a large divergence\namong the imbalanced distributions of different clients, e.g.,\ndifferent local datasets have different imbalance ratios or\nminority classes (visualized in Section 9 in Supplementary\nMaterial ). Additionally, during the standard FL training,\npartial client selection may randomly drop some minority\nsamples at each communication round, further decreasing\nthe model performance on minority classes. Therefore, the\nlong-tailed issue is more challenging in the FL scenarios.\nSeveral techniques have been proposed to tackle the\nfederated long-tailed problem, such as loss re-weighting\n[30, 34], client clustering [6], and client selection [39].\n1Global re-balance means that the re-balance strategies adopt global\nlabel distribution as the class prior, while local re-balance utilizes local\nlabel distribution as the class prior.\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n4815\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Global Features are All You Need for Image Retrieval and Reranking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Global_Features_are_All_You_Need_for_Image_Retrieval_and_ICCV_2023_paper.html",
        "author": "Shihao Shao, Kaifeng Chen, Arjun Karpur, Qinghua Cui, Andr\u00e9 Araujo, Bingyi Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Global_Features_are_All_You_Need_for_Image_Retrieval_and_ICCV_2023_paper.pdf",
        "aff": "Peking University; Google Research",
        "project": "",
        "github": "https://github.com/ShihaoShao-GH/SuperGlobal",
        "arxiv": "2308.06954"
    },
    {
        "title": "Global Knowledge Calibration for Fast Open-Vocabulary Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_Global_Knowledge_Calibration_for_Fast_Open-Vocabulary_Segmentation_ICCV_2023_paper.html",
        "author": "Kunyang Han, Yong Liu, Jun Hao Liew, Henghui Ding, Jiajun Liu, Yitong Wang, Yansong Tang, Yujiu Yang, Jiashi Feng, Yao Zhao, Yunchao Wei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Global_Knowledge_Calibration_for_Fast_Open-Vocabulary_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Global Knowledge Calibration for Fast Open-Vocabulary Segmentation\nKunyang Han1,2\u2217, Yong Liu3\u2217, Jun Hao Liew4, Henghui Ding5, Jiajun Liu4\nYitong Wang4, Yansong Tang3, Yujiu Yang3, Jiashi Feng4, Yao Zhao1,2 \u0000, Yunchao Wei1,2\n1Institute of Information Science, Beijing Jiaotong University\n2Beijing Key Laboratory of Advanced Information Science and Network Technology\n3Tsinghua Shenzhen International Graduate School, Tsinghua University\n4ByteDance5Nanyang Technological University\nAbstract\nRecent advancements in pre-trained vision-language\nmodels, such as CLIP , have enabled the segmentation of ar-\nbitrary concepts solely from textual inputs, a process com-\nmonly referred to as open-vocabulary semantic segmenta-\ntion (OVS). However, existing OVS techniques confront a\nfundamental challenge: the trained classifier tends to over-\nfit on the base classes observed during training, resulting in\nsuboptimal generalization performance to unseen classes.\nTo mitigate this issue, recent studies have proposed the use\nof an additional frozen pre-trained CLIP for classification.\nNonetheless, this approach incurs heavy computational\noverheads as the CLIP vision encoder must be repeatedly\nforward-passed for each mask, rendering it impractical for\nreal-world applications. To address this challenge, our ob-\njective is to develop a fast OVS model that can perform com-\nparably or better without the extra computational burden of\nthe CLIP image encoder during inference. To this end, we\npropose a core idea of preserving the generalizable repre-\nsentation when fine-tuning on known classes. Specifically,\nwe introduce a text diversification strategy that generates\na set of synonyms for each training category, which pre-\nvents the learned representation from collapsing onto spe-\ncific known category names. Additionally, we employ a text-\nguided knowledge distillation method to preserve the gener-\nalizable knowledge of CLIP . Extensive experiments demon-\nstrate that our proposed model achieves robust generaliza-\ntion performance across various datasets. Furthermore,\nwe perform a preliminary exploration of open-vocabulary\nvideo segmentation and present a benchmark that can facil-\nitate future open-vocabulary research in the video domain.\n*Equal contribution. Work done during internships at ByteDance.\n\u0000Corresponding author.\n35 38 41 44 47\nmIoU on unseen categories (PC-59)303540455055mIoU on seen categories (COCO)Ours\nw/ frozen CLIP\nw/o frozen CLIPOurs\nw/ frozen CLIP\nw/o frozen CLIPFigure 1. Performance vs. computational cost . The radius of the\ncircle represents the FLOPs during inference. To avoid overfitting\nto the seen categories, some methods [14, 44] introduce an extra\nfrozen CLIP during inference. However, such a strategy leads to\nheavy computation overhead (red \u2022). In comparison, our method\ngeneralizes well on both seen and unseen categories with much\nsmaller computational cost (blue \u2022).\n1. Introduction\nSemantic segmentation aims to group pixels that belong\nto the same categories. Despite achieving high performance\nin recent years [30, 11, 38, 42, 4, 19, 16, 36, 48, 49], existing\nsemantic segmentation approaches often rely on predefined\nsets of training categories and thus cannot recognize cate-\ngories that were not present during training. This limitation\ngreatly restricts their practical applicability. In contrast, hu-\nmans possess the ability to recognize novel categories in\nan open-vocabulary manner, i.e., identifying objects using\narbitrary text from an unbounded vocabulary. This ability\nhas inspired the development of open-vocabulary segmen-\ntation methods [14, 44, 47, 21, 18, 41, 25]. Unlike tradi-\ntional closed-set segmentation, open-vocabulary segmenta-\ntion can segment arbitrary categories given only text inputs,\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n797\n",
        "project": "",
        "github": "",
        "arxiv": "2303.09181"
    },
    {
        "title": "Global Perception Based Autoregressive Neural Processes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tai_Global_Perception_Based_Autoregressive_Neural_Processes_ICCV_2023_paper.html",
        "author": "Jinyang Tai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tai_Global_Perception_Based_Autoregressive_Neural_Processes_ICCV_2023_paper.pdf",
        "aff": "School of Computer Engineering and Science, Shanghai University, Shanghai, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GlobalMapper: Arbitrary-Shaped Urban Layout Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_GlobalMapper_Arbitrary-Shaped_Urban_Layout_Generation_ICCV_2023_paper.html",
        "author": "Liu He, Daniel Aliaga",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_GlobalMapper_Arbitrary-Shaped_Urban_Layout_Generation_ICCV_2023_paper.pdf",
        "aff": "Purdue University",
        "project": "",
        "github": "",
        "arxiv": "2307.09693"
    },
    {
        "title": "Gloss-Free Sign Language Translation: Improving from Visual-Language Pretraining",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Gloss-Free_Sign_Language_Translation_Improving_from_Visual-Language_Pretraining_ICCV_2023_paper.html",
        "author": "Benjia Zhou, Zhigang Chen, Albert Clap\u00e9s, Jun Wan, Yanyan Liang, Sergio Escalera, Zhen Lei, Du Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Gloss-Free_Sign_Language_Translation_Improving_from_Visual-Language_Pretraining_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Center, Spain; Universitat de Barcelona, Spain; UCAS, China; MUST, Macau, China; MAIS, CASIA, China; CAIR, HKISI, CAS, Hong Kong, China",
        "project": "",
        "github": "https://github.com/zhoubenjia/GFSLT-VLP",
        "arxiv": ""
    },
    {
        "title": "GlowGAN: Unsupervised Learning of HDR Images from LDR Images in the Wild",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_GlowGAN_Unsupervised_Learning_of_HDR_Images_from_LDR_Images_in_ICCV_2023_paper.html",
        "author": "Chao Wang, Ana Serrano, Xingang Pan, Bin Chen, Karol Myszkowski, Hans-Peter Seidel, Christian Theobalt, Thomas Leimk\u00fchler",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_GlowGAN_Unsupervised_Learning_of_HDR_Images_from_LDR_Images_in_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; MPI Informatik; Universidad de Zaragoza",
        "project": "",
        "github": "",
        "arxiv": "2211.12352"
    },
    {
        "title": "GlueGen: Plug and Play Multi-modal Encoders for X-to-image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.html",
        "author": "Can Qin, Ning Yu, Chen Xing, Shu Zhang, Zeyuan Chen, Stefano Ermon, Yun Fu, Caiming Xiong, Ran Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.pdf",
        "aff": "Salesforce AI Research; Northeastern University; Stanford University",
        "project": "",
        "github": "https://github.com/salesforce/GlueGen",
        "arxiv": ""
    },
    {
        "title": "GlueStick: Robust Image Matching by Sticking Points and Lines Together",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.html",
        "author": "R\u00e9mi Pautrat, Iago Su\u00e1rez, Yifan Yu, Marc Pollefeys, Viktor Larsson",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich and Microsoft Mixed Reality and AI Zurich lab; Department of Computer Science, ETH Zurich; Lund University; Qualcomm XR Labs Europe",
        "project": "",
        "github": "https://github.com/cvg/GlueStick",
        "arxiv": ""
    },
    {
        "title": "Going Beyond Nouns With Vision & Language Models Using Synthetic Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cascante-Bonilla_Going_Beyond_Nouns_With_Vision__Language_Models_Using_Synthetic_ICCV_2023_paper.html",
        "author": "Paola Cascante-Bonilla, Khaled Shehada, James Seale Smith, Sivan Doveh, Donghyun Kim, Rameswar Panda, Gul Varol, Aude Oliva, Vicente Ordonez, Rogerio Feris, Leonid Karlinsky",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cascante-Bonilla_Going_Beyond_Nouns_With_Vision__Language_Models_Using_Synthetic_ICCV_2023_paper.pdf",
        "aff": "Rice University; Georgia Institute of Technology; IBM Research; LIGM, \u00b4Ecole des Ponts; MIT-IBM Watson AI Lab; Weizmann Institute of Science",
        "project": "https://synthetic-vic.github.io/",
        "github": "",
        "arxiv": "2303.17590"
    },
    {
        "title": "Going Denser with Open-Vocabulary Part Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Going_Denser_with_Open-Vocabulary_Part_Segmentation_ICCV_2023_paper.html",
        "author": "Peize Sun, Shoufa Chen, Chenchen Zhu, Fanyi Xiao, Ping Luo, Saining Xie, Zhicheng Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Going_Denser_with_Open-Vocabulary_Part_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Meta AI; The University of Hong Kong; New York University",
        "project": "",
        "github": "https://github.com/facebookresearch/VLPart",
        "arxiv": "2305.11173"
    },
    {
        "title": "Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Gradient-Regulated_Meta-Prompt_Learning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Juncheng Li, Minghe Gao, Longhui Wei, Siliang Tang, Wenqiao Zhang, Mengze Li, Wei Ji, Qi Tian, Tat-Seng Chua, Yueting Zhuang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Gradient-Regulated_Meta-Prompt_Learning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "Huawei Cloud; National University of Singapore; Zhejiang University; Huawei Cloud, University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2303.06571"
    },
    {
        "title": "Gradient-based Sampling for Class Imbalanced Semi-supervised Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Gradient-based_Sampling_for_Class_Imbalanced_Semi-supervised_Object_Detection_ICCV_2023_paper.html",
        "author": "Jiaming Li, Xiangru Lin, Wei Zhang, Xiao Tan, Yingying Li, Junyu Han, Errui Ding, Jingdong Wang, Guanbin Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Gradient-based_Sampling_for_Class_Imbalanced_Semi-supervised_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Research Institute, Sun Yat-sen University, Shenzhen, China; Department of Computer Vision Technology (VIS), Baidu Inc., China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
        "project": "",
        "github": "https://github.com/nightkeepers/CI-SSOD",
        "arxiv": ""
    },
    {
        "title": "Gram-based Attentive Neural Ordinary Differential Equations Network for Video Nystagmography Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_Gram-based_Attentive_Neural_Ordinary_Differential_Equations_Network_for_Video_Nystagmography_ICCV_2023_paper.html",
        "author": "Xihe Qiu, Shaojie Shi, Xiaoyu Tan, Chao Qu, Zhijun Fang, Hailing Wang, Yongbin Gao, Peixia Wu, Huawei Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Gram-based_Attentive_Neural_Ordinary_Differential_Equations_Network_for_Video_Nystagmography_ICCV_2023_paper.pdf",
        "aff": "INF Technology (Shanghai) Co., Ltd. Shanghai, China; Donghua University, Shanghai, China; Eye & ENT Hospital of Fudan University, Shanghai, China; Shanghai University of Engineering Science, Shanghai, China",
        "project": "",
        "github": "https://github.com/XiheQiu/Gram-AODE",
        "arxiv": ""
    },
    {
        "title": "Gramian Attention Heads are Strong yet Efficient Vision Learners",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ryu_Gramian_Attention_Heads_are_Strong_yet_Efficient_Vision_Learners_ICCV_2023_paper.html",
        "author": "Jongbin Ryu, Dongyoon Han, Jongwoo Lim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ryu_Gramian_Attention_Heads_are_Strong_yet_Efficient_Vision_Learners_ICCV_2023_paper.pdf",
        "aff": "Ajou University; Seoul National University; NAVER AI Lab",
        "project": "",
        "github": "https://github.com/Lab-LVM/imagenet-models",
        "arxiv": ""
    },
    {
        "title": "Graph Matching with Bi-level Noisy Correspondence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Graph_Matching_with_Bi-level_Noisy_Correspondence_ICCV_2023_paper.html",
        "author": "Yijie Lin, Mouxing Yang, Jun Yu, Peng Hu, Changqing Zhang, Xi Peng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Graph_Matching_with_Bi-level_Noisy_Correspondence_ICCV_2023_paper.pdf",
        "aff": "Tianjin University; Sichuan University; Hangzhou Dianzi University",
        "project": "",
        "github": "https://github.com/XLearning-SCU/2023-ICCV-COMMON",
        "arxiv": "2212.04085"
    },
    {
        "title": "GraphAlign: Enhancing Accurate Feature Alignment by Graph matching for Multi-Modal 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_GraphAlign_Enhancing_Accurate_Feature_Alignment_by_Graph_matching_for_Multi-Modal_ICCV_2023_paper.html",
        "author": "Ziying Song, Haiyue Wei, Lin Bai, Lei Yang, Caiyan Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_GraphAlign_Enhancing_Accurate_Feature_Alignment_by_Graph_matching_for_Multi-Modal_ICCV_2023_paper.pdf",
        "aff": "School of Information Science and Engineering, Hebei University of Science and Technology; School of Computer and Information Technology, Beijing Jiaotong University; State Key Laboratory of Automotive Safety and Energy, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GraphEcho: Graph-Driven Unsupervised Domain Adaptation for Echocardiogram Video Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_GraphEcho_Graph-Driven_Unsupervised_Domain_Adaptation_for_Echocardiogram_Video_Segmentation_ICCV_2023_paper.html",
        "author": "Jiewen Yang, Xinpeng Ding, Ziyang Zheng, Xiaowei Xu, Xiaomeng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_GraphEcho_Graph-Driven_Unsupervised_Domain_Adaptation_for_Echocardiogram_Video_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; Guangdong Provincial People\u2019s Hospital, Institute of Cardiovascular Diseases, GuangZhou, China",
        "project": "",
        "github": "https://github.com/xmed-lab/GraphEcho",
        "arxiv": "2309.11145"
    },
    {
        "title": "Graphics2RAW: Mapping Computer Graphics Images to Sensor RAW Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Seo_Graphics2RAW_Mapping_Computer_Graphics_Images_to_Sensor_RAW_Images_ICCV_2023_paper.html",
        "author": "Donghwan Seo, Abhijith Punnappurath, Luxi Zhao, Abdelrahman Abdelhamed, Sai Kiran Tedla, Sanguk Park , Jihwan Choe, Michael S. Brown",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_Graphics2RAW_Mapping_Computer_Graphics_Images_to_Sensor_RAW_Images_ICCV_2023_paper.pdf",
        "aff": "Samsung AI Center Toronto; York University, Toronto; Google Research; Samsung Electronics",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GridMM: Grid Memory Map for Vision-and-Language Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_GridMM_Grid_Memory_Map_for_Vision-and-Language_Navigation_ICCV_2023_paper.html",
        "author": "Zihan Wang, Xiangyang Li, Jiahao Yang, Yeqi Liu, Shuqiang Jiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_GridMM_Grid_Memory_Map_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf",
        "aff": "Key Lab of Intelligent Information Processing Laboratory of the Chinese Academy of Sciences (CAS), Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; University of Chinese Academy of Sciences, Beijing, 100049, China",
        "project": "",
        "github": "https://github.com/MrZihan/GridMM",
        "arxiv": "2307.12907"
    },
    {
        "title": "GridPull: Towards Scalability in Learning Implicit Representations from 3D Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.html",
        "author": "Chao Chen, Yu-Shen Liu, Zhizhong Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Wayne State University, Detroit, USA; School of Software, Tsinghua University, Beijing, China",
        "project": "",
        "github": "https://github.com/chenchao15/GridPull",
        "arxiv": "2308.13175"
    },
    {
        "title": "Grounded Entity-Landmark Adaptive Pre-Training for Vision-and-Language Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Grounded_Entity-Landmark_Adaptive_Pre-Training_for_Vision-and-Language_Navigation_ICCV_2023_paper.html",
        "author": "Yibo Cui, Liang Xie, Yakun Zhang, Meishan Zhang, Ye Yan, Erwei Yin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Grounded_Entity-Landmark_Adaptive_Pre-Training_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf",
        "aff": "Harbin Institute of Technology (Shenzhen); Defense Innovation Institute, Chinese Academy of Military Science; Tianjin Artificial Intelligence Innovation Center",
        "project": "",
        "github": "https://github.com/CSir1996/VLN-GELA",
        "arxiv": "2308.12587"
    },
    {
        "title": "Grounded Image Text Matching with Mismatched Relation Reasoning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Grounded_Image_Text_Matching_with_Mismatched_Relation_Reasoning_ICCV_2023_paper.html",
        "author": "Yu Wu, Yana Wei, Haozhe Wang, Yongfei Liu, Sibei Yang, Xuming He",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Grounded_Image_Text_Matching_with_Mismatched_Relation_Reasoning_ICCV_2023_paper.pdf",
        "aff": "Unknown Affiliation",
        "project": "",
        "github": "",
        "arxiv": "2308.01236"
    },
    {
        "title": "Grounding 3D Object Affordance from 2D Interactions in Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.html",
        "author": "Yuhang Yang, Wei Zhai, Hongchen Luo, Yang Cao, Jiebo Luo, Zheng-Jun Zha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.pdf",
        "aff": "Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; University of Rochester; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/yyvhang/IAGNet",
        "arxiv": "2303.10437"
    },
    {
        "title": "Group DETR: Fast DETR Training with Group-Wise One-to-Many Assignment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Group_DETR_Fast_DETR_Training_with_Group-Wise_One-to-Many_Assignment_ICCV_2023_paper.html",
        "author": "Qiang Chen, Xiaokang Chen, Jian Wang, Shan Zhang, Kun Yao, Haocheng Feng, Junyu Han, Errui Ding, Gang Zeng, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Group_DETR_Fast_DETR_Training_with_Group-Wise_One-to-Many_Assignment_ICCV_2023_paper.pdf",
        "aff": "Baidu VIS; Key Lab. of Machine Perception (MoE), School of IST, Peking University; Australian National University",
        "project": "",
        "github": "https://github.com/Atten4Vis/GroupDETR",
        "arxiv": "2207.13085"
    },
    {
        "title": "Group Pose: A Simple Baseline for End-to-End Multi-Person Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Group_Pose_A_Simple_Baseline_for_End-to-End_Multi-Person_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Huan Liu, Qiang Chen, Zichang Tan, Jiang-Jiang Liu, Jian Wang, Xiangbo Su, Xiaolong Li, Kun Yao, Junyu Han, Errui Ding, Yao Zhao, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Group_Pose_A_Simple_Baseline_for_End-to-End_Multi-Person_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "Baidu VIS; Institute of Information Science, Beijing Jiaotong University",
        "project": "",
        "github": "https://github.com/Michel-liu/GroupPose-Paddle",
        "arxiv": "2308.07313"
    },
    {
        "title": "GrowCLIP: Data-Aware Automatic Model Growing for Large-scale Contrastive Language-Image Pre-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deng_GrowCLIP_Data-Aware_Automatic_Model_Growing_for_Large-scale_Contrastive_Language-Image_Pre-Training_ICCV_2023_paper.html",
        "author": "Xinchi Deng, Han Shi, Runhui Huang, Changlin Li, Hang Xu, Jianhua Han, James Kwok, Shen Zhao, Wei Zhang, Xiaodan Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_GrowCLIP_Data-Aware_Automatic_Model_Growing_for_Large-scale_Contrastive_Language-Image_Pre-Training_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; Sun Yat-sen University; The Hong Kong University of Science and Technology; University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": "2308.11331"
    },
    {
        "title": "Growing a Brain with Sparsity-Inducing Generation for Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.html",
        "author": "Hyundong Jin, Gyeong-hyeon Kim, Chanho Ahn, Eunwoo Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "Samsung Advanced Institute of Technology (SAIT); School of Computer Science and Engineering, Chung-Ang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Guided Motion Diffusion for Controllable Human Motion Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Karunratanakul_Guided_Motion_Diffusion_for_Controllable_Human_Motion_Synthesis_ICCV_2023_paper.html",
        "author": "Korrawe Karunratanakul, Konpat Preechakul, Supasorn Suwajanakorn, Siyu Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Karunratanakul_Guided_Motion_Diffusion_for_Controllable_Human_Motion_Synthesis_ICCV_2023_paper.pdf",
        "aff": "VISTEC, Thailand; ETH Z\u00fcrich, Switzerland",
        "project": "https://korrawe.github.io/gmd-project/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Guiding Image Captioning Models Toward More Specific Captions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kornblith_Guiding_Image_Captioning_Models_Toward_More_Specific_Captions_ICCV_2023_paper.html",
        "author": "Simon Kornblith, Lala Li, Zirui Wang, Thao Nguyen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kornblith_Guiding_Image_Captioning_Models_Toward_More_Specific_Captions_ICCV_2023_paper.pdf",
        "aff": "Apple AI/ML; Google DeepMind; University of Washington",
        "project": "",
        "github": "",
        "arxiv": "2307.16686"
    },
    {
        "title": "Guiding Local Feature Matching with Surface Curvature",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Guiding_Local_Feature_Matching_with_Surface_Curvature_ICCV_2023_paper.html",
        "author": "Shuzhe Wang, Juho Kannala, Marc Pollefeys, Daniel Barath",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Guiding_Local_Feature_Matching_with_Surface_Curvature_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich, Microsoft; ETH Zurich; Aalto University",
        "project": "",
        "github": "https://github.com/AaltoVision/surface-curvature-estimator",
        "arxiv": ""
    },
    {
        "title": "H3WB: Human3.6M 3D WholeBody Dataset and Benchmark",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_H3WB_Human3.6M_3D_WholeBody_Dataset_and_Benchmark_ICCV_2023_paper.html",
        "author": "Yue Zhu, Nermin Samet, David Picard",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_H3WB_Human3.6M_3D_WholeBody_Dataset_and_Benchmark_ICCV_2023_paper.pdf",
        "aff": "LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS, Marne-la-Vall\u00e9e, France",
        "project": "",
        "github": "https://github.com/wholebody3d/wholebody3d",
        "arxiv": ""
    },
    {
        "title": "HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_HAL3D_Hierarchical_Active_Learning_for_Fine-Grained_3D_Part_Labeling_ICCV_2023_paper.html",
        "author": "Fenggen Yu, Yiming Qian, Francisca Gil-Ureta, Brian Jackson, Eric Bennett, Hao Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_HAL3D_Hierarchical_Active_Learning_for_Fine-Grained_3D_Part_Labeling_ICCV_2023_paper.pdf",
        "aff": "Amazon; Amazon; Simon Fraser University",
        "project": "",
        "github": "",
        "arxiv": "2301.10460"
    },
    {
        "title": "HDG-ODE: A Hierarchical Continuous-Time Model for Human Pose Forecasting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xing_HDG-ODE_A_Hierarchical_Continuous-Time_Model_for_Human_Pose_Forecasting_ICCV_2023_paper.html",
        "author": "Yucheng Xing, Xin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_HDG-ODE_A_Hierarchical_Continuous-Time_Model_for_Human_Pose_Forecasting_ICCV_2023_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, Stony Brook University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HM-ViT: Hetero-Modal Vehicle-to-Vehicle Cooperative Perception with Vision Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_HM-ViT_Hetero-Modal_Vehicle-to-Vehicle_Cooperative_Perception_with_Vision_Transformer_ICCV_2023_paper.html",
        "author": "Hao Xiang, Runsheng Xu, Jiaqi Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_HM-ViT_Hetero-Modal_Vehicle-to-Vehicle_Cooperative_Perception_with_Vision_Transformer_ICCV_2023_paper.pdf",
        "aff": "University of California, Los Angeles",
        "project": "",
        "github": "https://github.com/XHwind/HM-ViT",
        "arxiv": ""
    },
    {
        "title": "HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.html",
        "author": "Sadegh Aliakbarian, Fatemeh Saleh, David Collier, Pashmina Cameron, Darren Cosker",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.pdf",
        "aff": "Microsoft Mixed Reality & AI Lab, Cambridge, UK",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HOSNeRF: Dynamic Human-Object-Scene Neural Radiance Fields from a Single Video",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_HOSNeRF_Dynamic_Human-Object-Scene_Neural_Radiance_Fields_from_a_Single_Video_ICCV_2023_paper.html",
        "author": "Jia-Wei Liu, Yan-Pei Cao, Tianyuan Yang, Zhongcong Xu, Jussi Keppo, Ying Shan, Xiaohu Qie, Mike Zheng Shou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_HOSNeRF_Dynamic_Human-Object-Scene_Neural_Radiance_Fields_from_a_Single_Video_ICCV_2023_paper.pdf",
        "aff": "Tencent PCG; Business School, Institute of Operations Research and Analytics, National University of Singapore; ARC Lab, Tencent PCG; Show Lab, National University of Singapore",
        "project": "https://showlab.github.io/HOSNeRF",
        "github": "https://github.com/showlab/HOSNeRF",
        "arxiv": "2304.12281"
    },
    {
        "title": "HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bakr_HRS-Bench_Holistic_Reliable_and_Scalable_Benchmark_for_Text-to-Image_Models_ICCV_2023_paper.html",
        "author": "Eslam Mohamed Bakr, Pengzhan Sun, Xiaoqian Shen, Faizan Farooq Khan, Li Erran Li, Mohamed Elhoseiny",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bakr_HRS-Bench_Holistic_Reliable_and_Scalable_Benchmark_for_Text-to-Image_Models_ICCV_2023_paper.pdf",
        "aff": "King Abdullah University of Science and Technology (KAUST); National University of Singapore; AWS AI, Amazon",
        "project": "https://eslambakr.github.io/hrsbench.github.io/",
        "github": "https://github.com/eslambakr/hrsbench.github.io",
        "arxiv": ""
    },
    {
        "title": "HSE: Hybrid Species Embedding for Deep Metric Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_HSE_Hybrid_Species_Embedding_for_Deep_Metric_Learning_ICCV_2023_paper.html",
        "author": "Bailin Yang, Haoqiang Sun, Frederick W. B. Li, Zheng Chen, Jianlu Cai, Chao Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_HSE_Hybrid_Species_Embedding_for_Deep_Metric_Learning_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, University of Durham; Faculty of Computer Science and Technology, Zhejiang Gongshang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HSR-Diff: Hyperspectral Image Super-Resolution via Conditional Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Chanyue Wu, Dong Wang, Yunpeng Bai, Hanyu Mao, Ying Li, Qiang Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Faculty of Business and Physical Sciences, Aberystwyth University, U.K.; National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, Shaanxi Provincial Key Laboratory of Speech & Image Information Processing, School of Computer Science, Northwestern Polytechnical University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HTML: Hybrid Temporal-scale Multimodal Learning Framework for Referring Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_HTML_Hybrid_Temporal-scale_Multimodal_Learning_Framework_for_Referring_Video_Object_ICCV_2023_paper.html",
        "author": "Mingfei Han, Yali Wang, Zhihui Li, Lina Yao, Xiaojun Chang, Yu Qiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_HTML_Hybrid_Temporal-scale_Multimodal_Learning_Framework_for_Referring_Video_Object_ICCV_2023_paper.pdf",
        "aff": "Data61, CSIRO; ReLER, AAII, UTS; Shanghai AI Laboratory, Shanghai, China; Shandong Artificial Intelligence, Qilu University of Technology; Department of Computer Vision, Mohamed bin Zayed University of Artificial Intelligence; Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
        "project": "https://mingfei.info/HTML/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HaMuCo: Hand Pose Estimation via Multiview Collaborative Self-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_HaMuCo_Hand_Pose_Estimation_via_Multiview_Collaborative_Self-Supervised_Learning_ICCV_2023_paper.html",
        "author": "Xiaozheng Zheng, Chao Wen, Zhou Xue, Pengfei Ren, Jingyu Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_HaMuCo_Hand_Pose_Estimation_via_Multiview_Collaborative_Self-Supervised_Learning_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications; PICO IDL, ByteDance, Beijing",
        "project": "https://zxz267.github.io/HaMuCo",
        "github": "https://github.com/zxz267/HaMuCo",
        "arxiv": "2302.00988"
    },
    {
        "title": "HairCLIPv2: Unifying Hair Editing via Proxy Feature Blending",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_HairCLIPv2_Unifying_Hair_Editing_via_Proxy_Feature_Blending_ICCV_2023_paper.html",
        "author": "Tianyi Wei, Dongdong Chen, Wenbo Zhou, Jing Liao, Weiming Zhang, Gang Hua, Nenghai Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_HairCLIPv2_Unifying_Hair_Editing_via_Proxy_Feature_Blending_ICCV_2023_paper.pdf",
        "aff": "Microsoft Cloud AI; City University of Hong Kong; Xi\u2019an Jiaotong University; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/wty-ustc/HairCLIPv2",
        "arxiv": ""
    },
    {
        "title": "HairNeRF: Geometry-Aware Image Synthesis for Hairstyle Transfer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.html",
        "author": "Seunggyu Chang, Gihoon Kim, Hayeon Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.pdf",
        "aff": "NAVER Cloud; KAIST; UNIST",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Hallucination Improves the Performance of Unsupervised Visual Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Hallucination_Improves_the_Performance_of_Unsupervised_Visual_Representation_Learning_ICCV_2023_paper.html",
        "author": "Jing Wu, Jennifer Hobbs, Naira Hovakimyan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Hallucination_Improves_the_Performance_of_Unsupervised_Visual_Representation_Learning_ICCV_2023_paper.pdf",
        "aff": "University of Illinois Urbana-Champaign; Intelinair",
        "project": "",
        "github": "",
        "arxiv": "2307.12168"
    },
    {
        "title": "HandR2N2: Iterative 3D Hand Pose Estimation Using a Residual Recurrent Neural Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_HandR2N2_Iterative_3D_Hand_Pose_Estimation_Using_a_Residual_Recurrent_ICCV_2023_paper.html",
        "author": "Wencan Cheng, Jong Hwan Ko",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_HandR2N2_Iterative_3D_Hand_Pose_Estimation_Using_a_Residual_Recurrent_ICCV_2023_paper.pdf",
        "aff": "Department of Artificial Intelligence, Sungkyunkwan University; College of Information and Communication Engineering, Sungkyunkwan University",
        "project": "",
        "github": "https://github.com/cwc1260/HandR2N2",
        "arxiv": ""
    },
    {
        "title": "Handwritten and Printed Text Segmentation: A Signature Case Study",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gholamian_Handwritten_and_Printed_Text_Segmentation_A_Signature_Case_Study_ICCV_2023_paper.html",
        "author": "Sina Gholamian, Ali Vahdat",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gholamian_Handwritten_and_Printed_Text_Segmentation_A_Signature_Case_Study_ICCV_2023_paper.pdf",
        "aff": "Thomson Reuters AI Labs, Toronto, Canada",
        "project": "https://forms.office.com/r/2a5RDg7cAY",
        "github": "",
        "arxiv": "2307.07887"
    },
    {
        "title": "Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Hard_No-Box_Adversarial_Attack_on_Skeleton-Based_Human_Action_Recognition_with_ICCV_2023_paper.html",
        "author": "Zhengzhi Lu, He Wang, Ziyi Chang, Guoan Yang, Hubert P. H. Shum",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Hard_No-Box_Adversarial_Attack_on_Skeleton-Based_Human_Action_Recognition_with_ICCV_2023_paper.pdf",
        "aff": "Durham University, UK and Xi\u2019an Jiaotong University, China; University College London, UK; Xi\u2019an Jiaotong University, China; Durham University, UK",
        "project": "",
        "github": "",
        "arxiv": "2308.05681"
    },
    {
        "title": "Harnessing the Spatial-Temporal Attention of Diffusion Models for High-Fidelity Text-to-Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.html",
        "author": "Qiucheng Wu, Yujian Liu, Handong Zhao, Trung Bui, Zhe Lin, Yang Zhang, Shiyu Chang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; MIT-IBM Watson AI Lab; UC Santa Barbara",
        "project": "",
        "github": "https://github.com/UCSB-NLP-Chang/Diffusion-SpaceTime-Attn",
        "arxiv": "2304.03869"
    },
    {
        "title": "Harvard Glaucoma Detection and Progression: A Multimodal Multitask Dataset and Generalization-Reinforced Semi-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Harvard_Glaucoma_Detection_and_Progression_A_Multimodal_Multitask_Dataset_and_ICCV_2023_paper.html",
        "author": "Yan Luo, Min Shi, Yu Tian, Tobias Elze, Mengyu Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Harvard_Glaucoma_Detection_and_Progression_A_Multimodal_Multitask_Dataset_and_ICCV_2023_paper.pdf",
        "aff": "Harvard Ophthalmology AI Lab, Harvard University",
        "project": "https://ophai.hms.harvard.edu/datasets/harvard-gdp1000",
        "github": "",
        "arxiv": "2308.13411"
    },
    {
        "title": "Hashing Neural Video Decomposition with Multiplicative Residuals in Space-Time",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chan_Hashing_Neural_Video_Decomposition_with_Multiplicative_Residuals_in_Space-Time_ICCV_2023_paper.html",
        "author": "Cheng-Hung Chan, Cheng-Yang Yuan, Cheng Sun, Hwann-Tzong Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Hashing_Neural_Video_Decomposition_with_Multiplicative_Residuals_in_Space-Time_ICCV_2023_paper.pdf",
        "aff": "National Tsing Hua University, Taiwan",
        "project": "https://lightbulb12294.github.io/hashing-nvd/",
        "github": "",
        "arxiv": "2309.14022"
    },
    {
        "title": "Helping Hands: An Object-Aware Ego-Centric Video Recognition Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Helping_Hands_An_Object-Aware_Ego-Centric_Video_Recognition_Model_ICCV_2023_paper.html",
        "author": "Chuhan Zhang, Ankush Gupta, Andrew Zisserman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Helping_Hands_An_Object-Aware_Ego-Centric_Video_Recognition_Model_ICCV_2023_paper.pdf",
        "aff": "VGG, University of Oxford; Google DeepMind, London",
        "project": "",
        "github": "https://github.com/Chuhanxx/helping_hand_for_egocentric_videos",
        "arxiv": "2308.07918"
    },
    {
        "title": "Heterogeneous Diversity Driven Active Learning for Multi-Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Heterogeneous_Diversity_Driven_Active_Learning_for_Multi-Object_Tracking_ICCV_2023_paper.html",
        "author": "Rui Li, Baopeng Zhang, Jun Liu, Wei Liu, Jian Zhao, Zhu Teng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Heterogeneous_Diversity_Driven_Active_Learning_for_Multi-Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "Institute of North Electronic Equipment, Peng Cheng Laboratory, Intelligent Game and Decision Laboratory; Beijing Jiaotong University; Beijing Jiaotong University, Singapore University of Technology and Design; Singapore University of Technology and Design",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Heterogeneous Forgetting Compensation for Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Heterogeneous_Forgetting_Compensation_for_Class-Incremental_Learning_ICCV_2023_paper.html",
        "author": "Jiahua Dong, Wenqi Liang, Yang Cong, Gan Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Heterogeneous_Forgetting_Compensation_for_Class-Incremental_Learning_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, 110169, China; University of Chinese Academy of Sciences, Beijing, 100049, China; South China University of Technology, Guangzhou, 510640, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, 110169, China",
        "project": "",
        "github": "https://github.com/JiahuaDong/HFC",
        "arxiv": "2308.03374"
    },
    {
        "title": "HiFace: High-Fidelity 3D Face Reconstruction by Learning Static and Dynamic Details",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chai_HiFace_High-Fidelity_3D_Face_Reconstruction_by_Learning_Static_and_Dynamic_ICCV_2023_paper.html",
        "author": "Zenghao Chai, Tianke Zhang, Tianyu He, Xu Tan, Tadas Baltrusaitis, HsiangTao Wu, Runnan Li, Sheng Zhao, Chun Yuan, Jiang Bian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_HiFace_High-Fidelity_3D_Face_Reconstruction_by_Learning_Static_and_Dynamic_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore; Tsinghua University; Microsoft Research Asia; Microsoft Mixed Reality & AI Lab; Microsoft Cloud + AI",
        "project": "https://project-hiface.github.io",
        "github": "",
        "arxiv": "2303.11225"
    },
    {
        "title": "HiLo: Exploiting High Low Frequency Relations for Unbiased Panoptic Scene Graph Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_HiLo_Exploiting_High_Low_Frequency_Relations_for_Unbiased_Panoptic_Scene_ICCV_2023_paper.html",
        "author": "Zijian Zhou, Miaojing Shi, Holger Caesar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_HiLo_Exploiting_High_Low_Frequency_Relations_for_Unbiased_Panoptic_Scene_ICCV_2023_paper.pdf",
        "aff": "Intelligent Vehicles Lab, Delft University of Technology; College of Electronic and Information Engineering, Tongji University; Department of Informatics, King\u2019s College London",
        "project": "",
        "github": "https://github.com/franciszzj/HiLo",
        "arxiv": "2303.15994"
    },
    {
        "title": "HiTeA: Hierarchical Temporal-Aware Video-Language Pre-training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_HiTeA_Hierarchical_Temporal-Aware_Video-Language_Pre-training_ICCV_2023_paper.html",
        "author": "Qinghao Ye, Guohai Xu, Ming Yan, Haiyang Xu, Qi Qian, Ji Zhang, Fei Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_HiTeA_Hierarchical_Temporal-Aware_Video-Language_Pre-training_ICCV_2023_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": "2212.14546"
    },
    {
        "title": "HiVLP: Hierarchical Interactive Video-Language Pre-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_HiVLP_Hierarchical_Interactive_Video-Language_Pre-Training_ICCV_2023_paper.html",
        "author": "Bin Shao, Jianzhuang Liu, Renjing Pei, Songcen Xu, Peng Dai, Juwei Lu, Weimian Li, Youliang Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_HiVLP_Hierarchical_Interactive_Video-Language_Pre-Training_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Hidden Biases of End-to-End Driving Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jaeger_Hidden_Biases_of_End-to-End_Driving_Models_ICCV_2023_paper.html",
        "author": "Bernhard Jaeger, Kashyap Chitta, Andreas Geiger",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jaeger_Hidden_Biases_of_End-to-End_Driving_Models_ICCV_2023_paper.pdf",
        "aff": "T\u00fcbingen AI Center; University of T\u00fcbingen",
        "project": "",
        "github": "",
        "arxiv": "2306.07957"
    },
    {
        "title": "Hiding Visual Information via Obfuscating Adversarial Perturbations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Su_Hiding_Visual_Information_via_Obfuscating_Adversarial_Perturbations_ICCV_2023_paper.html",
        "author": "Zhigang Su, Dawei Zhou, Nannan Wang, Decheng Liu, Zhen Wang, Xinbo Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Hiding_Visual_Information_via_Obfuscating_Adversarial_Perturbations_ICCV_2023_paper.pdf",
        "aff": "Zhejiang Lab; Xidian University; Chongqing University of Posts and Telecommunications",
        "project": "",
        "github": "https://github.com/suzhigangssz/AVIH",
        "arxiv": "2209.15304"
    },
    {
        "title": "Hierarchical Contrastive Learning for Pattern-Generalizable Image Corruption Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Hierarchical_Contrastive_Learning_for_Pattern-Generalizable_Image_Corruption_Detection_ICCV_2023_paper.html",
        "author": "Xin Feng, Yifeng Xu, Guangming Lu, Wenjie Pei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Hierarchical_Contrastive_Learning_for_Pattern-Generalizable_Image_Corruption_Detection_ICCV_2023_paper.pdf",
        "aff": "Harbin Institute of Technology, Shenzhen",
        "project": "",
        "github": "https://github.com/xyfJASON/HCL",
        "arxiv": "2308.14061"
    },
    {
        "title": "Hierarchical Generation of Human-Object Interactions with Diffusion Probabilistic Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pi_Hierarchical_Generation_of_Human-Object_Interactions_with_Diffusion_Probabilistic_Models_ICCV_2023_paper.html",
        "author": "Huaijin Pi, Sida Peng, Minghui Yang, Xiaowei Zhou, Hujun Bao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pi_Hierarchical_Generation_of_Human-Object_Interactions_with_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf",
        "aff": "Ant Group; State Key Lab of CAD&CG, Zhejiang University",
        "project": "https://zju3dv.github.io/hghoi",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Hierarchical Point-based Active Learning for Semi-supervised Point Cloud Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Hierarchical_Point-based_Active_Learning_for_Semi-supervised_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Zongyi Xu, Bo Yuan, Shanshan Zhao, Qianni Zhang, Xinbo Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Hierarchical_Point-based_Active_Learning_for_Semi-supervised_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Chongqing University of Posts and Telecommunications, China; Queen Mary University of London, UK; JD Explore Academy, China",
        "project": "",
        "github": "https://github.com/SmiletoE/HPAL",
        "arxiv": "2308.11166"
    },
    {
        "title": "Hierarchical Prior Mining for Non-local Multi-View Stereo",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Hierarchical_Prior_Mining_for_Non-local_Multi-View_Stereo_ICCV_2023_paper.html",
        "author": "Chunlin Ren, Qingshan Xu, Shikun Zhang, Jiaqi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Hierarchical_Prior_Mining_for_Non-local_Multi-View_Stereo_ICCV_2023_paper.pdf",
        "aff": "Northwestern Polytechnical University; Nanyang Technological University",
        "project": "",
        "github": "https://github.com/CLinvx/HPM-MVS",
        "arxiv": "2303.09758"
    },
    {
        "title": "Hierarchical Spatio-Temporal Representation Learning for Gait Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Hierarchical_Spatio-Temporal_Representation_Learning_for_Gait_Recognition_ICCV_2023_paper.html",
        "author": "Lei Wang, Bo Liu, Fangfang Liang, Bincheng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Hierarchical_Spatio-Temporal_Representation_Learning_for_Gait_Recognition_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n19639\n",
        "project": "",
        "github": "",
        "arxiv": "2307.09856"
    },
    {
        "title": "Hierarchical Visual Categories Modeling: A Joint Representation Learning and Density Estimation Framework for Out-of-Distribution Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Hierarchical_Visual_Categories_Modeling_A_Joint_Representation_Learning_and_Density_ICCV_2023_paper.html",
        "author": "Jinglun Li, Xinyu Zhou, Pinxue Guo, Yixuan Sun, Yiwen Huang, Weifeng Ge, Wenqiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Hierarchical_Visual_Categories_Modeling_A_Joint_Representation_Learning_and_Density_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Fudan University; Academy for Engineering and Technology, Fudan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Hierarchical Visual Primitive Experts for Compositional Zero-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Hierarchical_Visual_Primitive_Experts_for_Compositional_Zero-Shot_Learning_ICCV_2023_paper.html",
        "author": "Hanjae Kim, Jiyoung Lee, Seongheon Park, Kwanghoon Sohn",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Hierarchical_Visual_Primitive_Experts_for_Compositional_Zero-Shot_Learning_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; NAVER AI Lab; Yonsei University, Korea Institute of Science and Technology (KIST)",
        "project": "",
        "github": "https://github.com/HanjaeKim98/CoT",
        "arxiv": "2308.04016"
    },
    {
        "title": "Hierarchically Decomposed Graph Convolutional Networks for Skeleton-Based Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Hierarchically_Decomposed_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.html",
        "author": "Jungho Lee, Minhyeok Lee, Dogyoon Lee, Sangyoun Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Hierarchically_Decomposed_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University; School of Electrical and Electronic Engineering, Yonsei University and AIonFlow Research",
        "project": "",
        "github": "https://github.com/Jho-Yonsei/HD-GCN",
        "arxiv": "2208.10741"
    },
    {
        "title": "High Quality Entity Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qi_High_Quality_Entity_Segmentation_ICCV_2023_paper.html",
        "author": "Lu Qi, Jason Kuen, Tiancheng Shen, Jiuxiang Gu, Wenbo Li, Weidong Guo, Jiaya Jia, Zhe Lin, Ming-Hsuan Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_High_Quality_Entity_Segmentation_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n4047\n",
        "project": "",
        "github": "",
        "arxiv": "2211.05776"
    },
    {
        "title": "High-Resolution Document Shadow Removal via A Large-Scale Real-World Dataset and A Frequency-Aware Shadow Erasing Net",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_High-Resolution_Document_Shadow_Removal_via_A_Large-Scale_Real-World_Dataset_and_ICCV_2023_paper.html",
        "author": "Zinuo Li, Xuhang Chen, Chi-Man Pun, Xiaodong Cun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_High-Resolution_Document_Shadow_Removal_via_A_Large-Scale_Real-World_Dataset_and_ICCV_2023_paper.pdf",
        "aff": "University of Macau",
        "project": "",
        "github": "https://github.com/CXH-Research/DocShadow-SD7K",
        "arxiv": "2308.14221"
    },
    {
        "title": "Holistic Geometric Feature Learning for Structured Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Holistic_Geometric_Feature_Learning_for_Structured_Reconstruction_ICCV_2023_paper.html",
        "author": "Ziqiong Lu, Linxi Huan, Qiyuan Ma, Xianwei Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Holistic_Geometric_Feature_Learning_for_Structured_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "The State Key Lab. LIESMARS, Wuhan University",
        "project": "",
        "github": "https://github.com/Geo-Tell/F-Learn",
        "arxiv": "2309.09622"
    },
    {
        "title": "Holistic Label Correction for Noisy Multi-Label Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Holistic_Label_Correction_for_Noisy_Multi-Label_Classification_ICCV_2023_paper.html",
        "author": "Xiaobo Xia, Jiankang Deng, Wei Bao, Yuxuan Du, Bo Han, Shiguang Shan, Tongliang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Holistic_Label_Correction_for_Noisy_Multi-Label_Classification_ICCV_2023_paper.pdf",
        "aff": "JD Explore Academy; Chinese Academy of Sciences; Imperial College London; The University of Sydney; Hong Kong Baptist University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HollowNeRF: Pruning Hashgrid-Based NeRFs with Trainable Collision Mitigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_HollowNeRF_Pruning_Hashgrid-Based_NeRFs_with_Trainable_Collision_Mitigation_ICCV_2023_paper.html",
        "author": "Xiufeng Xie, Riccardo Gherardi, Zhihong Pan, Stephen Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_HollowNeRF_Pruning_Hashgrid-Based_NeRFs_with_Trainable_Collision_Mitigation_ICCV_2023_paper.pdf",
        "aff": "Oppo Mobile Telecommunications Corp., 2479 E Bayshore Rd, Palo Alto, CA, 94303, USA",
        "project": "",
        "github": "",
        "arxiv": "2308.10122"
    },
    {
        "title": "HoloAssist: an Egocentric Human Interaction Dataset for Interactive AI Assistants in the Real World",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.html",
        "author": "Xin Wang, Taein Kwon, Mahdi Rad, Bowen Pan, Ishani Chakraborty, Sean Andrist, Dan Bohus, Ashley Feniello, Bugra Tekin, Felipe Vieira Frujeri, Neel Joshi, Marc Pollefeys",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.pdf",
        "aff": "Microsoft, ETH Zurich; Microsoft",
        "project": "https://holoassist.github.io/",
        "github": "https://github.com/holoassist",
        "arxiv": ""
    },
    {
        "title": "HoloFusion: Towards Photo-realistic 3D Generative Modeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Karnewar_HoloFusion_Towards_Photo-realistic_3D_Generative_Modeling_ICCV_2023_paper.html",
        "author": "Animesh Karnewar, Niloy J. Mitra, Andrea Vedaldi, David Novotny",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Karnewar_HoloFusion_Towards_Photo-realistic_3D_Generative_Modeling_ICCV_2023_paper.pdf",
        "aff": "UCL; Meta AI",
        "project": "",
        "github": "",
        "arxiv": "2308.14244"
    },
    {
        "title": "Homeomorphism Alignment for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Homeomorphism_Alignment_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Lihua Zhou, Mao Ye, Xiatian Zhu, Siying Xiao, Xu-Qian Fan, Ferrante Neri",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Homeomorphism_Alignment_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; Jinan University; University of Surrey",
        "project": "",
        "github": "https://github.com/buerzlh/HMA",
        "arxiv": ""
    },
    {
        "title": "Homography Guided Temporal Fusion for Road Line and Marking Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Homography_Guided_Temporal_Fusion_for_Road_Line_and_Marking_Segmentation_ICCV_2023_paper.html",
        "author": "Shan Wang, Chuong Nguyen, Jiawei Liu, Kaihao Zhang, Wenhan Luo, Yanhao Zhang, Sundaram Muthu, Fahira Afzal Maken, Hongdong Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Homography_Guided_Temporal_Fusion_for_Road_Line_and_Marking_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Data61, CSIRO; Sun Yat-sen University; Australian National University",
        "project": "",
        "github": "https://github.com/ShanWang-Shan/HomoFusion",
        "arxiv": ""
    },
    {
        "title": "HopFIR: Hop-wise GraphFormer with Intragroup Joint Refinement for 3D Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_HopFIR_Hop-wise_GraphFormer_with_Intragroup_Joint_Refinement_for_3D_Human_ICCV_2023_paper.html",
        "author": "Kai Zhai, Qiang Nie, Bo Ouyang, Xiang Li, Shanlin Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_HopFIR_Hop-wise_GraphFormer_with_Intragroup_Joint_Refinement_for_3D_Human_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Hefei University of Technology; Youtu Lab, Tencent",
        "project": "",
        "github": "",
        "arxiv": "2302.14581"
    },
    {
        "title": "Householder Projector for Unsupervised Latent Semantics Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_Householder_Projector_for_Unsupervised_Latent_Semantics_Discovery_ICCV_2023_paper.html",
        "author": "Yue Song, Jichao Zhang, Nicu Sebe, Wei Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Householder_Projector_for_Unsupervised_Latent_Semantics_Discovery_ICCV_2023_paper.pdf",
        "aff": "Department of Information Engineering and Computer Science, University of Trento, Italy; Beijing Jiaotong University, China",
        "project": "",
        "github": "https://github.com/KingJamesSong/HouseholderGAN",
        "arxiv": "2307.08012"
    },
    {
        "title": "How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.html",
        "author": "Zijian Wang, Yadan Luo, Liang Zheng, Zi Huang, Mahsa Baktashmotlagh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.pdf",
        "aff": "The University of Queensland; Australian National University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "How Much Temporal Long-Term Context is Needed for Action Segmentation?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bahrami_How_Much_Temporal_Long-Term_Context_is_Needed_for_Action_Segmentation_ICCV_2023_paper.html",
        "author": "Emad Bahrami, Gianpiero Francesca, Juergen Gall",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bahrami_How_Much_Temporal_Long-Term_Context_is_Needed_for_Action_Segmentation_ICCV_2023_paper.pdf",
        "aff": "University of Bonn, Germany and Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Toyota Motor Europe, Belgium; University of Bonn, Germany",
        "project": "",
        "github": "",
        "arxiv": "2308.11358"
    },
    {
        "title": "How to Boost Face Recognition with StyleGAN?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sevastopolskiy_How_to_Boost_Face_Recognition_with_StyleGAN_ICCV_2023_paper.html",
        "author": "Artem Sevastopolskiy, Yury Malkov, Nikita Durasov, Luisa Verdoliva, Matthias Nie\u00dfner",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sevastopolskiy_How_to_Boost_Face_Recognition_with_StyleGAN_ICCV_2023_paper.pdf",
        "aff": "University Federico II of Naples, Italy; Technical University of Munich, Germany; \u00b4Ecole polytechnique f \u00b4ed\u00b4erale de Lausanne, Switzerland; Twitter, US",
        "project": "",
        "github": "https://github.com/seva100/stylegan-for-facerec",
        "arxiv": ""
    },
    {
        "title": "How to Choose your Best Allies for a Transferable Attack?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Maho_How_to_Choose_your_Best_Allies_for_a_Transferable_Attack_ICCV_2023_paper.html",
        "author": "Thibault Maho, Seyed-Mohsen Moosavi-Dezfooli, Teddy Furon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Maho_How_to_Choose_your_Best_Allies_for_a_Transferable_Attack_ICCV_2023_paper.pdf",
        "aff": "Imperial College London, UK; Univ. Rennes, Inria, CNRS IRISA, Rennes, France",
        "project": "",
        "github": "",
        "arxiv": "2304.02312"
    },
    {
        "title": "Human Part-wise 3D Motion Context Learning for Sign Language Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Human_Part-wise_3D_Motion_Context_Learning_for_Sign_Language_Recognition_ICCV_2023_paper.html",
        "author": "Taeryung Lee, Yeonguk Oh, Kyoung Mu Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Human_Part-wise_3D_Motion_Context_Learning_for_Sign_Language_Recognition_ICCV_2023_paper.pdf",
        "aff": "Dept. of ECE & ASRI, Seoul National University, Seoul, Korea; IPAI, Dept. of ECE & ASRI, Seoul National University, Seoul, Korea",
        "project": "",
        "github": "",
        "arxiv": "2308.09305"
    },
    {
        "title": "Human Preference Score: Better Aligning Text-to-Image Models with Human Preference",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.html",
        "author": "Xiaoshi Wu, Keqiang Sun, Feng Zhu, Rui Zhao, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n2096\n",
        "project": "",
        "github": "",
        "arxiv": "2303.14420"
    },
    {
        "title": "Human from Blur: Human Pose Tracking from Blurry Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Human_from_Blur_Human_Pose_Tracking_from_Blurry_Images_ICCV_2023_paper.html",
        "author": "Yiming Zhao, Denys Rozumnyi, Jie Song, Otmar Hilliges, Marc Pollefeys, Martin R. Oswald",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Human_from_Blur_Human_Pose_Tracking_from_Blurry_Images_ICCV_2023_paper.pdf",
        "aff": "ETH Z\u00fcrich, Microsoft; ETH Z\u00fcrich; ETH Z\u00fcrich, University of Amsterdam",
        "project": "",
        "github": "",
        "arxiv": "2303.17209"
    },
    {
        "title": "Human-Inspired Facial Sketch Synthesis with Dynamic Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Human-Inspired_Facial_Sketch_Synthesis_with_Dynamic_Adaptation_ICCV_2023_paper.html",
        "author": "Fei Gao, Yifan Zhu, Chang Jiang, Nannan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Human-Inspired_Facial_Sketch_Synthesis_with_Dynamic_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Xidian University; Hangzhou Dianzi University; Hangzhou Institute of Technology, Xidian University",
        "project": "",
        "github": "https://github.com/AiArt-HDU/HIDA",
        "arxiv": "2309.00216"
    },
    {
        "title": "Human-centric Scene Understanding for 3D Large-scale Scenarios",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Human-centric_Scene_Understanding_for_3D_Large-scale_Scenarios_ICCV_2023_paper.html",
        "author": "Yiteng Xu, Peishan Cong, Yichen Yao, Runnan Chen, Yuenan Hou, Xinge Zhu, Xuming He, Jingyi Yu, Yuexin Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Human-centric_Scene_Understanding_for_3D_Large-scale_Scenarios_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; The University of Hong Kong; Shanghai AI Laboratory; ShanghaiTech University",
        "project": "",
        "github": "https://github.com/4DVLab/HuCenLife.git",
        "arxiv": "2307.14392"
    },
    {
        "title": "HumanMAC: Masked Motion Completion for Human Motion Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_HumanMAC_Masked_Motion_Completion_for_Human_Motion_Prediction_ICCV_2023_paper.html",
        "author": "Ling-Hao Chen, JiaWei Zhang, Yewen Li, Yiren Pang, Xiaobo Xia, Tongliang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_HumanMAC_Masked_Motion_Completion_for_Human_Motion_Prediction_ICCV_2023_paper.pdf",
        "aff": "HumanMAC: Masked Motion Completion for Human Motion Prediction\nhttps://lhchen.top/Human-MAC\nLing-Hao Chen1*\u2020Jiawei Zhang2\u2020Yewen Li3Yiren Pang2Xiaobo Xia4\u2217\u2021Tongliang Liu4\n1Tsinghua University2Xidian University\n3Nanyang Technological University4The University of Sydney\n{thu.lhchen }@gmail.com {zjw}@stu.xidian.edu.cn {yewen001 }@e.ntu.edu.sg\n{yrpang }@outlook.com {xiaoboxia.uni }@gmail.com {tongliang.liu }@sydney.edu.au\nAbstract\nHuman motion prediction is a classical problem in com-\nputer vision and computer graphics, which has a wide range\nof practical applications. Previous effects achieve great em-\npirical performance based on an encoding-decoding style.\nThe methods of this style work by first encoding previous\nmotions to latent representations and then decoding the la-\ntent representations into predicted motions. However, in\npractice, they are still unsatisfactory due to several issues,\nincluding complicated loss constraints, cumbersome train-\ning processes, and scarce switch of different categories of\nmotions in prediction. In this paper, to address the above\nissues, we jump out of the foregoing style and propose a\nnovel framework from a new perspective. Specifically, our\nframework works in a masked completion fashion. In the\ntraining stage, we learn a motion diffusion model that gen-\nerates motions from random noise. In the inference stage,\nwith a denoising procedure, we make motion prediction\nconditioning on observed motions to output more contin-\nuous and controllable predictions. The proposed frame-\nwork enjoys promising algorithmic properties, which only\nneeds one loss in optimization and is trained in an end-\nto-end manner. Additionally, it accomplishes the switch of\ndifferent categories of motions effectively, which is signifi-\ncant in realistic tasks, e.g., the animation task. Comprehen-\nsive experiments on benchmarks confirm the superiority of\nthe proposed framework. The project page is available at\nhttps://lhchen.top/Human-MAC .\n1. Introduction\nThe problem of Human Motion Prediction (HMP) fo-\ncuses on predicting possible future pose sequences from a\nsequence of observed motions [6, 16, 7, 20, 92, 84], which\nhas a wide range of applications [83, 29, 90, 61, 45, 89, 87,\n30, 99], e.g., autonomous driving [50] and healthcare [71].\nThis problem is complicated and challenging since the pre-\ndicted motions are always required to be continuous ,di-\nverse , and realistic simultaneously [14].\n*This project is led by Ling-Hao Chen and Xiaobo Xia jointly.\n\u2020Equal contribution.\n\u2021Corresponding author.\nObservation \nEncoder\nPrediction \nDecoder\nlatent (a)encoding-decoding\nGenerative\nDiffusion Model\n (b)masked completion ( Ours )\nmaskobservation \nsequences\nprediction\nsequences\nnoisy\nsequences\nFigure 1: Comparison between the encoding-decoding\nfashion and masked motion completion. (a) The methods in\nthe encoding-decoding fashion encode the observation into\na latent explicitly and then decodes the latent into prediction\nresults. (b) The proposed motion diffusion model generates\nmotions from noise in the training stage. In the inference\nstage, it treats HMP as a masked completion task.\nPrior state-of-the-art methods work in an encoding-\ndecoding fashion to tackle the HMP problem, which con-\nditions on previous motion frames and predicts unobserved\nmotions [61, 41, 8, 14, 82]. Technically, these methods first\nencode the previous motion frames to latent representations\nexplicitly and then decode the latent representations into\nprediction results (see Figure 1a) [54, 75, 5, 22, 2].\nAlthough these methods enjoy the good performance\nin some scenarios, they are still unsatisfactory in prac-\ntice. We detail the issues from three aspects. (1) Most\nstate-of-the-art methods rely on multiple loss constraints\nfor high-quality prediction results, e.g., the average pair-\nwise distance [4], final displacement error [19, 33], and\nadversarial loss [6, 20]. Consequently, they need care-\nfully designed hyper-parameters to balance different loss\nconstraints, which makes it laborious for method applica-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n9544\n",
        "project": "",
        "github": "",
        "arxiv": "2302.03665"
    },
    {
        "title": "HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.html",
        "author": "Xuan Ju, Ailing Zeng, Chenchen Zhao, Jianan Wang, Lei Zhang, Qiang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong, International Digital Economy Academy; The Chinese University of Hong Kong; International Digital Economy Academy",
        "project": "https://idea-research.github.io/HumanSD/",
        "github": "https://github.com/idea-research/HumanSD",
        "arxiv": "2304.04269"
    },
    {
        "title": "Humans in 4D: Reconstructing and Tracking Humans with Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Goel_Humans_in_4D_Reconstructing_and_Tracking_Humans_with_Transformers_ICCV_2023_paper.html",
        "author": "Shubham Goel, Georgios Pavlakos, Jathushan Rajasegaran, Angjoo Kanazawa, Jitendra Malik",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Humans_in_4D_Reconstructing_and_Tracking_Humans_with_Transformers_ICCV_2023_paper.pdf",
        "aff": "University of California, Berkeley",
        "project": "https://shubham-goel.github.io/4dhumans/",
        "github": "",
        "arxiv": "2305.20091"
    },
    {
        "title": "Hybrid Spectral Denoising Transformer with Guided Attention",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lai_Hybrid_Spectral_Denoising_Transformer_with_Guided_Attention_ICCV_2023_paper.html",
        "author": "Zeqiang Lai, Chenggang Yan, Ying Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Hybrid_Spectral_Denoising_Transformer_with_Guided_Attention_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of Technology; Hangzhou Dianzi University",
        "project": "",
        "github": "https://github.com/Zeqiang-Lai/HSDT",
        "arxiv": "2303.09040"
    },
    {
        "title": "HybridAugment++: Unified Frequency Spectra Perturbations for Model Robustness",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yucel_HybridAugment_Unified_Frequency_Spectra_Perturbations_for_Model_Robustness_ICCV_2023_paper.html",
        "author": "Mehmet Kerim Yucel, Ramazan Gokberk Cinbis, Pinar Duygulu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yucel_HybridAugment_Unified_Frequency_Spectra_Perturbations_for_Model_Robustness_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Engineering, Middle East Technical University; Hacettepe University, Graduate School of Science and Engineering",
        "project": "",
        "github": "https://github.com/MKYucel/hybrid_augment",
        "arxiv": ""
    },
    {
        "title": "HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Erkoc_HyperDiffusion_Generating_Implicit_Neural_Fields_with_Weight-Space_Diffusion_ICCV_2023_paper.html",
        "author": "Ziya Erko\u00e7, Fangchang Ma, Qi Shan, Matthias Nie\u00dfner, Angela Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Erkoc_HyperDiffusion_Generating_Implicit_Neural_Fields_with_Weight-Space_Diffusion_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich; Apple",
        "project": "https://ziyaerkoc.com/hyperdiffusion",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HyperReenact: One-Shot Reenactment via Jointly Learning to Refine and Retarget Faces",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bounareli_HyperReenact_One-Shot_Reenactment_via_Jointly_Learning_to_Refine_and_Retarget_ICCV_2023_paper.html",
        "author": "Stella Bounareli, Christos Tzelepis, Vasileios Argyriou, Ioannis Patras, Georgios Tzimiropoulos",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bounareli_HyperReenact_One-Shot_Reenactment_via_Jointly_Learning_to_Refine_and_Retarget_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Mathematics, Kingston University London; School of Electronic Engineering and Computer Science, Queen Mary University of London",
        "project": "",
        "github": "https://github.com/StelaBou/HyperReenact",
        "arxiv": "2307.10797"
    },
    {
        "title": "Hyperbolic Audio-visual Zero-shot Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Hyperbolic_Audio-visual_Zero-shot_Learning_ICCV_2023_paper.html",
        "author": "Jie Hong, Zeeshan Hayder, Junlin Han, Pengfei Fang, Mehrtash Harandi, Lars Petersson",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Hyperbolic_Audio-visual_Zero-shot_Learning_ICCV_2023_paper.pdf",
        "aff": "Southeast University; Monash University; Data61-CSIRO; Australian National University",
        "project": "",
        "github": "",
        "arxiv": "2308.12558"
    },
    {
        "title": "Hyperbolic Chamfer Distance for Point Cloud Completion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Hyperbolic_Chamfer_Distance_for_Point_Cloud_Completion_ICCV_2023_paper.html",
        "author": "Fangzhou Lin, Yun Yue, Songlin Hou, Xuechu Yu, Yajun Xu, Kazunori D Yamada, Ziming Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Hyperbolic_Chamfer_Distance_for_Point_Cloud_Completion_ICCV_2023_paper.pdf",
        "aff": "Dell Technologies, USA; Worcester Polytechnic Institute, USA; Tohoku University, Japan; Hokkaido University, Japan",
        "project": "",
        "github": "https://github.com/Zhang-VISLab",
        "arxiv": ""
    },
    {
        "title": "I Can't Believe There's No Images! Learning Visual Tasks Using only Language Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gu_I_Cant_Believe_Theres_No_Images_Learning_Visual_Tasks_Using_ICCV_2023_paper.html",
        "author": "Sophia Gu, Christopher Clark, Aniruddha Kembhavi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_I_Cant_Believe_Theres_No_Images_Learning_Visual_Tasks_Using_ICCV_2023_paper.pdf",
        "aff": "Allen Institute for Arti\ufb01cial Intelligence",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "I-ViT: Integer-only Quantization for Efficient Vision Transformer Inference",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_I-ViT_Integer-only_Quantization_for_Efficient_Vision_Transformer_Inference_ICCV_2023_paper.html",
        "author": "Zhikai Li, Qingyi Gu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_I-ViT_Integer-only_Quantization_for_Efficient_Vision_Transformer_Inference_ICCV_2023_paper.pdf",
        "aff": "Institute of Automation, Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/zkkli/I-ViT",
        "arxiv": ""
    },
    {
        "title": "ICD-Face: Intra-class Compactness Distillation for Face Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_ICD-Face_Intra-class_Compactness_Distillation_for_Face_Recognition_ICCV_2023_paper.html",
        "author": "Zhipeng Yu, Jiaheng Liu, Haoyu Qin, Yichao Wu, Kun Hu, Jiayi Tian, Ding Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_ICD-Face_Intra-class_Compactness_Distillation_for_Face_Recognition_ICCV_2023_paper.pdf",
        "aff": "SEECE, UCAS; Beihang University; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ICE-NeRF: Interactive Color Editing of NeRFs via Decomposition-Aware Weight Optimization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_ICE-NeRF_Interactive_Color_Editing_of_NeRFs_via_Decomposition-Aware_Weight_Optimization_ICCV_2023_paper.html",
        "author": "Jae-Hyeok Lee, Dae-Shik Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ICE-NeRF_Interactive_Color_Editing_of_NeRFs_via_Decomposition-Aware_Weight_Optimization_ICCV_2023_paper.pdf",
        "aff": "KAIST, Daejeon, South Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ICICLE: Interpretable Class Incremental Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rymarczyk_ICICLE_Interpretable_Class_Incremental_Continual_Learning_ICCV_2023_paper.html",
        "author": "Dawid Rymarczyk, Joost van de Weijer, Bartosz Zieli\u0144ski, Bartlomiej Twardowski",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rymarczyk_ICICLE_Interpretable_Class_Incremental_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "Autonomous University of Barcelona; Computer Vision Center; Faculty of Mathematics and Computer Science, Jagiellonian University; Ardigen SA; IDEAS NCBR; Faculty of Mathematics and Computer Science, Jagiellonian University; Doctoral School of Exact and Life Sciences, Jagiellonian University; Ardigen SA; Autonomous University of Barcelona; Computer Vision Center; IDEAS NCBR",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_ICL-D3IE_In-Context_Learning_with_Diverse_Demonstrations_Updating_for_Document_Information_ICCV_2023_paper.html",
        "author": "Jiabang He, Lei Wang, Yi Hu, Ning Liu, Hui Liu, Xing Xu, Heng Tao Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_ICL-D3IE_In-Context_Learning_with_Diverse_Demonstrations_Updating_for_Document_Information_ICCV_2023_paper.pdf",
        "aff": "ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for\nDocument Information Extraction\nJiabang He1, Lei Wang2*, Yi Hu1, Ning Liu3, Hui Liu4, Xing Xu1\u2020, Heng Tao Shen1\n1Center for Future Media & School of Computer Science and Engineering,\nUniversity of Electronic Science and Technology of China\n2Singapore Management University ,3Beijing Forestry University\n4Beijing Rongda Technology Co., Ltd.\nAbstract\nLarge language models (LLMs), such as GPT-3 and\nChatGPT, have demonstrated remarkable results in various\nnatural language processing (NLP) tasks with in-context\nlearning, which involves inference based on a few demon-\nstration examples. Despite their successes in NLP tasks,\nno investigation has been conducted to assess the abil-\nity of LLMs to perform document information extraction\n(DIE) using in-context learning. Applying LLMs to DIE\nposes two challenges: the modality and task gap. To this\nend, we propose a simple but effective in-context learning\nframework called ICL-D3IE , which enables LLMs to per-\nform DIE with different types of demonstration examples.\nSpecifically, we extract the most difficult and distinct seg-\nments from hard training documents as hard demonstra-\ntions for benefiting all test instances. We design demon-\nstrations describing relationships that enable LLMs to un-\nderstand positional relationships. We introduce formatting\ndemonstrations for easy answer extraction. Additionally,\nthe framework improves diverse demonstrations by updat-\ning them iteratively. Our experiments on three widely used\nbenchmark datasets demonstrate that the ICL-D3IE frame-\nwork enables Davinci-003/ChatGPT to achieve superior\nperformance when compared to previous pre-trained meth-\nods fine-tuned with full training in both the in-distribution\n(ID) setting and in the out-of-distribution (OOD) setting.\nCode is available at https://github.com/MAEHCM/\nICL-D3IE .\n1. Introduction\nThe task of visually rich document understanding\n(VRDU), which involves extracting information from\nVRDs [2, 19], requires models that can handle various types\n*Corresponding author. lei.wang.2019@phdcs.smu.edu.sg\n\u2020Corresponding author. xing.xu@uestc.edu.cn\n(a) Pretrained Document Understanding Models\n(b) Large Language Models\nOCRContext \ud835\udfcf:{text:\"TAX 5.4\",Box :[11,12,32,44]}... Q:What\nare the labels for these texts ? A:SUB_TOTAL.TAX_PRICE ,\u2026\nContext \ud835\udc8f:{text:\"J.S PR\",Box :[13 525 469 555]}... Q:What\nare the labels for these texts? A:MENU.NM ,...Context :{text\n:\"1X\",Box:[11 \n13 10 40]} \u2026\nQ:What are \nthe labels for \nthese texts?+\n...A:MENU.CNT,\u2026\nIn-context example \ud835\udfcf In-context example \ud835\udc8f Test example\nTest exampleB-MENU.CNT,\u2026 OCR LaytoutLMv3\n/LayoutLMv2\n\u2026GPT-3/ChatGPTFigure 1: Two approaches for solving the DIE task: (a) pre-\nvious pre-trained document understanding models [15, 42]\nfine-tuned with full training examples, and (b) in-context\nlearning over LLMs with a few examples.\nof documents, such as voice, receipts, forms, emails, and\nadvertisements, and various types of information, includ-\ning rich visuals, large amounts of text, and complex doc-\nument layouts [28, 18, 26]. Recently, fine-tuning based\non pre-trained visual document understanding models has\nyielded impressive results in extracting information from\nVRDs [41, 13, 22, 23, 15, 21], suggesting that the use of\nlarge-scale, unlabeled training documents in pre-training\ndocument understanding models can benefit information\nextraction from VRDs. As shown in Figure 1 (a), a pre-\ntrained model such as LayoutLMv3 [15] can predict labels\nfor entities in a test VRD.\nLarge language models (LLMs), such as GPT-3 [1],\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n19485\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "IDiff-Face: Synthetic-based Face Recognition through Fizzy Identity-Conditioned Diffusion Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Boutros_IDiff-Face_Synthetic-based_Face_Recognition_through_Fizzy_Identity-Conditioned_Diffusion_Model_ICCV_2023_paper.html",
        "author": "Fadi Boutros, Jonas Henry Grebe, Arjan Kuijper, Naser Damer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Boutros_IDiff-Face_Synthetic-based_Face_Recognition_through_Fizzy_Identity-Conditioned_Diffusion_Model_ICCV_2023_paper.pdf",
        "aff": "Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany; Department of Computer Science, TU Darmstadt, Darmstadt, Germany",
        "project": "",
        "github": "https://github.com/fdbtrs/idiff-face",
        "arxiv": ""
    },
    {
        "title": "IHNet: Iterative Hierarchical Network Guided by High-Resolution Estimated Information for Scene Flow Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.html",
        "author": "Yun Wang, Cheng Chi, Min Lin, Xin Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.pdf",
        "aff": "Hubei Key Laboratory of Smart Internet, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan",
        "project": "",
        "github": "https://github.com/wangyunlhr/IHNet",
        "arxiv": ""
    },
    {
        "title": "IIEU: Rethinking Neural Feature Activation from Decision-Making",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_IIEU_Rethinking_Neural_Feature_Activation_from_Decision-Making_ICCV_2023_paper.html",
        "author": "Sudong Cai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_IIEU_Rethinking_Neural_Feature_Activation_from_Decision-Making_ICCV_2023_paper.pdf",
        "aff": "Graduate School of Informatics, Kyoto University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_INSTA-BNN_Binary_Neural_Network_with_INSTAnce-aware_Threshold_ICCV_2023_paper.html",
        "author": "Changhun Lee, Hyungjun Kim, Eunhyeok Park, Jae-Joon Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_INSTA-BNN_Binary_Neural_Network_with_INSTAnce-aware_Threshold_ICCV_2023_paper.pdf",
        "aff": "Pohang University of Science and Technology (POSTECH), Pohang, Korea; SqueezeBits Inc., Seoul, Korea; Seoul National University, Seoul, Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "INT2: Interactive Trajectory Prediction at Intersections",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_INT2_Interactive_Trajectory_Prediction_at_Intersections_ICCV_2023_paper.html",
        "author": "Zhijie Yan, Pengfei Li, Zheng Fu, Shaocong Xu, Yongliang Shi, Xiaoxue Chen, Yuhang Zheng, Yang Li, Tianyu Liu, Chuxuan Li, Nairui Luo, Xu Gao, Yilun Chen, Zuoxu Wang, Yifeng Shi, Pengfei Huang, Zhengxiao Han, Jirui Yuan, Jiangtao Gong, Guyue Zhou, Hang Zhao, Hao Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_INT2_Interactive_Trajectory_Prediction_at_Intersections_ICCV_2023_paper.pdf",
        "aff": "3SMEA, BUAA; 1AIR, THU, 3SMEA, BUAA; 1AIR, THU; 2Baidu Inc.; 1AIR, THU, 5XMU; 1AIR, THU, 4SVM, THU; 1AIR, THU, 7BUCT; 1AIR, THU\u2020; 1AIR, THU, 6ECE, HKUST; 8IIIS, THU",
        "project": "",
        "github": "https://github.com/AIR-DISCOVER/INT2",
        "arxiv": ""
    },
    {
        "title": "IOMatch: Simplifying Open-Set Semi-Supervised Learning with Joint Inliers and Outliers Utilization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_IOMatch_Simplifying_Open-Set_Semi-Supervised_Learning_with_Joint_Inliers_and_Outliers_ICCV_2023_paper.html",
        "author": "Zekun Li, Lei Qi, Yinghuan Shi, Yang Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_IOMatch_Simplifying_Open-Set_Semi-Supervised_Learning_with_Joint_Inliers_and_Outliers_ICCV_2023_paper.pdf",
        "aff": "Southeast University; Nanjing University",
        "project": "",
        "github": "https://github.com/nukezil/IOMatch",
        "arxiv": "2308.13168"
    },
    {
        "title": "IST-Net: Prior-Free Category-Level Pose Estimation with Implicit Space Transformation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_IST-Net_Prior-Free_Category-Level_Pose_Estimation_with_Implicit_Space_Transformation_ICCV_2023_paper.html",
        "author": "Jianhui Liu, Yukang Chen, Xiaoqing Ye, Xiaojuan Qi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_IST-Net_Prior-Free_Category-Level_Pose_Estimation_with_Implicit_Space_Transformation_ICCV_2023_paper.pdf",
        "aff": "Baidu; The University of Hong Kong; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/CVMI-Lab/IST-Net",
        "arxiv": ""
    },
    {
        "title": "ITI-GEN: Inclusive Text-to-Image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.html",
        "author": "Cheng Zhang, Xuanbai Chen, Siqi Chai, Chen Henry Wu, Dmitry Lagun, Thabo Beeler, Fernando De la Torre",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.pdf",
        "aff": "Google; Carnegie Mellon University",
        "project": "https://czhang0528.github.io/iti-gen",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Identification of Systematic Errors of Image Classifiers on Rare Subgroups",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.html",
        "author": "Jan Hendrik Metzen, Robin Hutmacher, N. Grace Hua, Valentyn Boreiko, Dan Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.pdf",
        "aff": "Bosch Center for Artificial Intelligence, Robert Bosch GmbH and University of T\u00fcbingen; Bosch Center for Artificial Intelligence, Robert Bosch GmbH",
        "project": "",
        "github": "",
        "arxiv": "2303.05072"
    },
    {
        "title": "Identity-Consistent Aggregation for Video Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Identity-Consistent_Aggregation_for_Video_Object_Detection_ICCV_2023_paper.html",
        "author": "Chaorui Deng, Da Chen, Qi Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Identity-Consistent_Aggregation_for_Video_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, University of Bath; Australia Institute of Machine Learning, University of Adelaide",
        "project": "",
        "github": "https://github.com/bladewaltz1/clipvid",
        "arxiv": "2308.07737"
    },
    {
        "title": "Identity-Seeking Self-Supervised Representation Learning for Generalizable Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dou_Identity-Seeking_Self-Supervised_Representation_Learning_for_Generalizable_Person_Re-Identification_ICCV_2023_paper.html",
        "author": "Zhaopeng Dou, Zhongdao Wang, Yali Li, Shengjin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dou_Identity-Seeking_Self-Supervised_Representation_Learning_for_Generalizable_Person_Re-Identification_ICCV_2023_paper.pdf",
        "aff": "Department of Electronic Engineering, Tsinghua University, China; Beijing National Research Center for Information Science and Technology (BNRist), China",
        "project": "",
        "github": "https://github.com/dcp15/ISR_ICCV2023_Oral",
        "arxiv": "2308.08887"
    },
    {
        "title": "ImGeoNet: Image-induced Geometry-aware Voxel Representation for Multi-view 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Tao Tu, Shun-Po Chuang, Yu-Lun Liu, Cheng Sun, Ke Zhang, Donna Roy, Cheng-Hao Kuo, Min Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "National Tsing Hua University; Amazon; National Taiwan University; National Yang Ming Chiao Tung University",
        "project": "https://ttaoretw.github.io/imgeonet",
        "github": "",
        "arxiv": "2308.09098"
    },
    {
        "title": "Image-Free Classifier Injection for Zero-Shot Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.html",
        "author": "Anders Christensen, Massimiliano Mancini, A. Sophia Koepke, Ole Winther, Zeynep Akata",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.pdf",
        "aff": "Technical University of Denmark; University of Trento; University of T\u00fcbingen",
        "project": "",
        "github": "https://github.com/ExplainableML/ImageFreeZSL",
        "arxiv": "2308.10599"
    },
    {
        "title": "ImbSAM: A Closer Look at Sharpness-Aware Minimization in Class-Imbalanced Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_ImbSAM_A_Closer_Look_at_Sharpness-Aware_Minimization_in_Class-Imbalanced_Recognition_ICCV_2023_paper.html",
        "author": "Yixuan Zhou, Yi Qu, Xing Xu, Hengtao Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ImbSAM_A_Closer_Look_at_Sharpness-Aware_Minimization_in_Class-Imbalanced_Recognition_ICCV_2023_paper.pdf",
        "aff": "Center for Future Media & School of Computer Science and Engineering, University of Electronic Science and Technology of China; Peng Cheng Laboratory, China; Center for Future Media & School of Computer Science and Engineering, University of Electronic Science and Technology of China",
        "project": "",
        "github": "https://github.com/cool-xuan/Imbalanced_SAM",
        "arxiv": "2308.07815"
    },
    {
        "title": "Imitator: Personalized Speech-driven 3D Facial Animation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Thambiraja_Imitator_Personalized_Speech-driven_3D_Facial_Animation_ICCV_2023_paper.html",
        "author": "Balamurugan Thambiraja, Ikhsanul Habibie, Sadegh Aliakbarian, Darren Cosker, Christian Theobalt, Justus Thies",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Thambiraja_Imitator_Personalized_Speech-driven_3D_Facial_Animation_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Mesh Labs, Microsoft, Cambridge, UK; Max Planck Institute for Informatics, Saarland, Germany",
        "project": "https://balamuruganthambiraja.github.io/Imitator",
        "github": "",
        "arxiv": "2301.00023"
    },
    {
        "title": "Implicit Autoencoder for Point-Cloud Self-Supervised Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Implicit_Autoencoder_for_Point-Cloud_Self-Supervised_Representation_Learning_ICCV_2023_paper.html",
        "author": "Siming Yan, Zhenpei Yang, Haoxiang Li, Chen Song, Li Guan, Hao Kang, Gang Hua, Qixing Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Implicit_Autoencoder_for_Point-Cloud_Self-Supervised_Representation_Learning_ICCV_2023_paper.pdf",
        "aff": "The University of Texas at Austin; Wormpex AI Research",
        "project": "",
        "github": "https://github.com/SimingYan/IAE",
        "arxiv": "2201.00785"
    },
    {
        "title": "Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Implicit_Identity_Representation_Conditioned_Memory_Compensation_Network_for_Talking_Head_ICCV_2023_paper.html",
        "author": "Fa-Ting Hong, Dan Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Implicit_Identity_Representation_Conditioned_Memory_Compensation_Network_for_Talking_Head_ICCV_2023_paper.pdf",
        "aff": "Implicit Identity Representation Conditioned Memory Compensation Network\nfor Talking Head Video Generation\nFa-Ting Hong\nCSE, HKUST\nfhongac@connect.ust.hkDan Xu*\nCSE, HKUST\ndanxu@cse.ust.hk\n(a) Source (b) Driving (d) W arped Image (f) MCNet (Ours) (c) Motion (e) Memory\nFigure 1: The animation illustration of the proposed implicit identity representation conditioned memory compensation\nnetwork (MCNet). MCNet first learns the motion flow ( c) between the source and driving images; ( d) shows possible\nocclusion or deformation artifacts caused by large head motion. The warped images are produced by warping the source\nimage with the motion flow; ( e) presents randomly sampled memory channels of our learned memory bank conditioned with\nimplicit-keypoint representations. Examples of generated results with our memory compensation network are shown in ( f).\nAbstract\nTalking head video generation aims to animate a human\nface in a still image with dynamic poses and expressions us-\ning motion information derived from a target-driving video,\nwhile maintaining the person\u2019s identity in the source im-\nage. However, dramatic and complex motions in the driv-\ning video cause ambiguous generation, because the still\nsource image cannot provide sufficient appearance infor-\nmation for occluded regions or delicate expression vari-\nations, which produces severe artifacts and significantly\ndegrades the generation quality. To tackle this problem,\nwe propose to learn a global facial representation space,\nand design a novel implicit identity representation condi-\ntioned memory compensation network, coined as MCNet,\nfor high-fidelity talking head generation. Specifically, we\ndevise a network module to learn a unified spatial facial\nmeta-memory bank from all training samples, which can\nprovide rich facial structure and appearance priors to com-\npensate warped source facial features for the generation.Furthermore, we propose an effective query mechanism\nbased on implicit identity representations learned from the\ndiscrete keypoints of the source image. It can greatly facil-\nitate the retrieval of more correlated information from the\nmemory bank for the compensation. Extensive experiments\ndemonstrate that MCNet can learn representative and com-\nplementary facial memory, and can clearly outperform pre-\nvious state-of-the-art talking head generation methods on\nVoxCeleb1 and CelebV datasets. Please check our Project.\n1. Introduction\nIn this paper, we aim at addressing the problem of gener-\nating a realistic talking head video given one still source im-\nage and one dynamic driving video, which is widely known\nas talking head video generation. A high-quality talking\nhead generation model needs to imitate vivid facial expres-\nsions and complex head movements, and should be appli-\ncable for different facial identities presented in the source\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n23062\n",
        "project": "",
        "github": "",
        "arxiv": "2307.09906"
    },
    {
        "title": "Implicit Neural Representation for Cooperative Low-light Image Enhancement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement_ICCV_2023_paper.html",
        "author": "Shuzhou Yang, Moxuan Ding, Yanmin Wu, Zihan Li, Jian Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement_ICCV_2023_paper.pdf",
        "aff": "3University of Washington, USA; 1Peking University Shenzhen Graduate School, China; 2Peng Cheng Laboratory, China; 1Peking University Shenzhen Graduate School, China; \u2217Corresponding author; 1Peking University Shenzhen Graduate School, China; \u2020Independent researcher",
        "project": "",
        "github": "https://github.com/Ysz2022/NeRCo",
        "arxiv": "2303.11722"
    },
    {
        "title": "Implicit Temporal Modeling with Learnable Alignment for Video Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tu_Implicit_Temporal_Modeling_with_Learnable_Alignment_for_Video_Recognition_ICCV_2023_paper.html",
        "author": "Shuyuan Tu, Qi Dai, Zuxuan Wu, Zhi-Qi Cheng, Han Hu, Yu-Gang Jiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Implicit_Temporal_Modeling_with_Learnable_Alignment_for_Video_Recognition_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; Carnegie Mellon University; Shanghai Key Lab of Intell. Info. Processing, School of CS, Fudan University",
        "project": "",
        "github": "https://github.com/Francis-Rings/ILA",
        "arxiv": "2304.10465"
    },
    {
        "title": "Improved Knowledge Transfer for Semi-Supervised Domain Adaptation via Trico Training Strategy",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ngo_Improved_Knowledge_Transfer_for_Semi-Supervised_Domain_Adaptation_via_Trico_Training_ICCV_2023_paper.html",
        "author": "Ba Hung Ngo, Yeon Jeong Chae, Jung Eun Kwon, Jae Hyeon Park, Sung In Cho",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_Improved_Knowledge_Transfer_for_Semi-Supervised_Domain_Adaptation_via_Trico_Training_ICCV_2023_paper.pdf",
        "aff": "Department of Multimedia Engineering, Dongguk University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Improved Visual Fine-tuning with Natural Language Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Improved_Visual_Fine-tuning_with_Natural_Language_Supervision_ICCV_2023_paper.html",
        "author": "Junyang Wang, Yuanhong Xu, Juhua Hu, Ming Yan, Jitao Sang, Qi Qian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Improved_Visual_Fine-tuning_with_Natural_Language_Supervision_ICCV_2023_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group, Bellevue, WA 98004, USA; School of Engineering and Technology, University of Washington, Tacoma, WA 98402, USA; School of Computer and Information Technology & Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; Peng Cheng Lab, Shenzhen, China; School of Computer and Information Technology & Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; DAMO Academy, Alibaba Group, Hangzhou, China",
        "project": "",
        "github": "https://github.com/idstcv/TeS",
        "arxiv": "2304.01489"
    },
    {
        "title": "Improving 3D Imaging with Pre-Trained Perpendicular 2D Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Improving_3D_Imaging_with_Pre-Trained_Perpendicular_2D_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Suhyeon Lee, Hyungjin Chung, Minyoung Park, Jonghyuk Park, Wi-Sun Ryu, Jong Chul Ye",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Improving_3D_Imaging_with_Pre-Trained_Perpendicular_2D_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "JLK Inc.; Korea Advanced Institute of Science & Technology",
        "project": "",
        "github": "https://github.com/hyn2028/tpdm",
        "arxiv": "2303.08440"
    },
    {
        "title": "Improving Adversarial Robustness of Masked Autoencoders via Test-time Frequency-domain Prompting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Improving_Adversarial_Robustness_of_Masked_Autoencoders_via_Test-time_Frequency-domain_Prompting_ICCV_2023_paper.html",
        "author": "Qidong Huang, Xiaoyi Dong, Dongdong Chen, Yinpeng Chen, Lu Yuan, Gang Hua, Weiming Zhang, Nenghai Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Improving_Adversarial_Robustness_of_Masked_Autoencoders_via_Test-time_Frequency-domain_Prompting_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; Wormpex AI Research; Shanghai AI Lab; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/shikiw/RobustMAE",
        "arxiv": "2308.10315"
    },
    {
        "title": "Improving CLIP Fine-tuning Performance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Improving_CLIP_Fine-tuning_Performance_ICCV_2023_paper.html",
        "author": "Yixuan Wei, Han Hu, Zhenda Xie, Ze Liu, Zheng Zhang, Yue Cao, Jianmin Bao, Dong Chen, Baining Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_CLIP_Fine-tuning_Performance_ICCV_2023_paper.pdf",
        "aff": "USTC; Microsoft Research Asia; Tsinghua University",
        "project": "",
        "github": "https://github.com/SwinTransformer/Feature-Distillation",
        "arxiv": ""
    },
    {
        "title": "Improving Continuous Sign Language Recognition with Cross-Lingual Signs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.html",
        "author": "Fangyun Wei, Yutong Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia",
        "project": "",
        "github": "",
        "arxiv": "2308.10809"
    },
    {
        "title": "Improving Diversity in Zero-Shot GAN Adaptation with Semantic Variations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_Improving_Diversity_in_Zero-Shot_GAN_Adaptation_with_Semantic_Variations_ICCV_2023_paper.html",
        "author": "Seogkyu Jeon, Bei Liu, Pilhyeon Lee, Kibeom Hong, Jianlong Fu, Hyeran Byun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Improving_Diversity_in_Zero-Shot_GAN_Adaptation_with_Semantic_Variations_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; Microsoft Research Asia",
        "project": "",
        "github": "",
        "arxiv": "2308.10554"
    },
    {
        "title": "Improving Equivariance in State-of-the-Art Supervised Depth and Normal Predictors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_Improving_Equivariance_in_State-of-the-Art_Supervised_Depth_and_Normal_Predictors_ICCV_2023_paper.html",
        "author": "Yuanyi Zhong, Anand Bhattad, Yu-Xiong Wang, David Forsyth",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_Improving_Equivariance_in_State-of-the-Art_Supervised_Depth_and_Normal_Predictors_ICCV_2023_paper.pdf",
        "aff": "University of Illinois Urbana-Champaign",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Improving Generalization in Visual Reinforcement Learning via Conflict-aware Gradient Agreement Augmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Improving_Generalization_in_Visual_Reinforcement_Learning_via_Conflict-aware_Gradient_Agreement_ICCV_2023_paper.html",
        "author": "Siao Liu, Zhaoyu Chen, Yang Liu, Yuzheng Wang, Dingkang Yang, Zhile Zhao, Ziqing Zhou, Xie Yi, Wei Li, Wenqiang Zhang, Zhongxue Gan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Improving_Generalization_in_Visual_Reinforcement_Learning_via_Conflict-aware_Gradient_Agreement_ICCV_2023_paper.pdf",
        "aff": "Academy for Engineering & Technology, Fudan University",
        "project": "",
        "github": "",
        "arxiv": "2308.01194"
    },
    {
        "title": "Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Improving_Generalization_of_Adversarial_Training_via_Robust_Critical_Fine-Tuning_ICCV_2023_paper.html",
        "author": "Kaijie Zhu, Xixu Hu, Jindong Wang, Xing Xie, Ge Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Improving_Generalization_of_Adversarial_Training_via_Robust_Critical_Fine-Tuning_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; City University of Hong Kong; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/Immortalise/RiFT",
        "arxiv": "2308.02533"
    },
    {
        "title": "Improving Lens Flare Removal with General-Purpose Pipeline and Multiple Light Sources Recovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Improving_Lens_Flare_Removal_with_General-Purpose_Pipeline_and_Multiple_Light_ICCV_2023_paper.html",
        "author": "Yuyan Zhou, Dong Liang, Songcan Chen, Sheng-Jun Huang, Shuo Yang, Chongyi Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Improving_Lens_Flare_Removal_with_General-Purpose_Pipeline_and_Multiple_Light_ICCV_2023_paper.pdf",
        "aff": "Imaging Technology Group, DJI Innovations Co. Ltd., Shanghai, China; School of Computer Science, Nankai University, Tianjin, China; MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China",
        "project": "",
        "github": "https://github.com/YuyanZhou1/Improving-Lens-Flare-Removal",
        "arxiv": "2308.16460"
    },
    {
        "title": "Improving Online Lane Graph Extraction by Object-Lane Clustering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Can_Improving_Online_Lane_Graph_Extraction_by_Object-Lane_Clustering_ICCV_2023_paper.html",
        "author": "Yigit Baran Can, Alexander Liniger, Danda Pani Paudel, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Can_Improving_Online_Lane_Graph_Extraction_by_Object-Lane_Clustering_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Lab, ETH Zurich; Computer Vision Lab, ETH Zurich, VISICS, ESAT/PSI, KU Leuven, INSAIT, Sofia University; Computer Vision Lab, ETH Zurich, INSAIT, Sofia University",
        "project": "",
        "github": "",
        "arxiv": "2307.10947"
    },
    {
        "title": "Improving Pixel-based MIM by Reducing Wasted Modeling Capability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Improving_Pixel-based_MIM_by_Reducing_Wasted_Modeling_Capability_ICCV_2023_paper.html",
        "author": "Yuan Liu, Songyang Zhang, Jiacheng Chen, Zhaohui Yu, Kai Chen, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Improving_Pixel-based_MIM_by_Reducing_Wasted_Modeling_Capability_ICCV_2023_paper.pdf",
        "aff": "Shanghai AI Laboratory, The Chinese University of Hong Kong; Simon Fraser University; The Chinese University of Hong Kong; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/open-mmlab/mmpretrain",
        "arxiv": "2308.00261"
    },
    {
        "title": "Improving Representation Learning for Histopathologic Images with Cluster Constraints",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Improving_Representation_Learning_for_Histopathologic_Images_with_Cluster_Constraints_ICCV_2023_paper.html",
        "author": "Weiyi Wu, Chongyang Gao, Joseph DiPalma, Soroush Vosoughi, Saeed Hassanpour",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Improving_Representation_Learning_for_Histopathologic_Images_with_Cluster_Constraints_ICCV_2023_paper.pdf",
        "aff": "Dartmouth College; Northwestern University",
        "project": "",
        "github": "https://github.com/wwyi1828/CluSiam",
        "arxiv": ""
    },
    {
        "title": "Improving Sample Quality of Diffusion Models Using Self-Attention Guidance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Improving_Sample_Quality_of_Diffusion_Models_Using_Self-Attention_Guidance_ICCV_2023_paper.html",
        "author": "Susung Hong, Gyuseong Lee, Wooseok Jang, Seungryong Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Improving_Sample_Quality_of_Diffusion_Models_Using_Self-Attention_Guidance_ICCV_2023_paper.pdf",
        "aff": "Korea University, Seoul, Korea",
        "project": "https://ku-cvlab.github.io/Self-Attention-Guidance/",
        "github": "",
        "arxiv": "2210.00939"
    },
    {
        "title": "Improving Transformer-based Image Matching by Cascaded Capturing Spatially Informative Keypoints",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.html",
        "author": "Chenjie Cao, Yanwei Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.pdf",
        "aff": "School of Data Science, Fudan University",
        "project": "",
        "github": "https://github.com/ewrfcas/CasMTR",
        "arxiv": "2303.02885"
    },
    {
        "title": "Improving Unsupervised Visual Program Inference with Code Rewriting Families",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ganeshan_Improving_Unsupervised_Visual_Program_Inference_with_Code_Rewriting_Families_ICCV_2023_paper.html",
        "author": "Aditya Ganeshan, R. Kenny Jones, Daniel Ritchie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ganeshan_Improving_Unsupervised_Visual_Program_Inference_with_Code_Rewriting_Families_ICCV_2023_paper.pdf",
        "aff": "Brown University",
        "project": "https://bardofcodes.github.io/coref/",
        "github": "https://github.com/bardofcodes/coref",
        "arxiv": ""
    },
    {
        "title": "In-Style: Bridging Text and Uncurated Videos with Style Transfer for Text-Video Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shvetsova_In-Style_Bridging_Text_and_Uncurated_Videos_with_Style_Transfer_for_ICCV_2023_paper.html",
        "author": "Nina Shvetsova, Anna Kukleva, Bernt Schiele, Hilde Kuehne",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shvetsova_In-Style_Bridging_Text_and_Uncurated_Videos_with_Style_Transfer_for_ICCV_2023_paper.pdf",
        "aff": "Max-Planck-Institute for Informatics; Goethe University Frankfurt",
        "project": "",
        "github": "https://github.com/ninatu/in-style",
        "arxiv": ""
    },
    {
        "title": "Incremental Generalized Category Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Incremental_Generalized_Category_Discovery_ICCV_2023_paper.html",
        "author": "Bingchen Zhao, Oisin Mac Aodha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Incremental_Generalized_Category_Discovery_ICCV_2023_paper.pdf",
        "aff": "University of Edinburgh",
        "project": "https://bzhao.me/iNatIGCD",
        "github": "",
        "arxiv": "2304.14310"
    },
    {
        "title": "Indoor Depth Recovery Based on Deep Unfolding with Non-Local Prior",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dai_Indoor_Depth_Recovery_Based_on_Deep_Unfolding_with_Non-Local_Prior_ICCV_2023_paper.html",
        "author": "Yuhui Dai, Junkang Zhang, Faming Fang, Guixu Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_Indoor_Depth_Recovery_Based_on_Deep_Unfolding_with_Non-Local_Prior_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Technology, East China Normal University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing Mistake Severity",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Inducing_Neural_Collapse_to_a_Fixed_Hierarchy-Aware_Frame_for_Reducing_ICCV_2023_paper.html",
        "author": "Tong Liang, Jim Davis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Inducing_Neural_Collapse_to_a_Fixed_Hierarchy-Aware_Frame_for_Reducing_ICCV_2023_paper.pdf",
        "aff": "Ohio State University",
        "project": "",
        "github": "https://github.com/ltong1130ztr/HAFrame",
        "arxiv": "2303.05689"
    },
    {
        "title": "InfiniCity: Infinite-Scale City Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_InfiniCity_Infinite-Scale_City_Synthesis_ICCV_2023_paper.html",
        "author": "Chieh Hubert Lin, Hsin-Ying Lee, Willi Menapace, Menglei Chai, Aliaksandr Siarohin, Ming-Hsuan Yang, Sergey Tulyakov",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_InfiniCity_Infinite-Scale_City_Synthesis_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n22808\n",
        "project": "",
        "github": "",
        "arxiv": "2301.09637"
    },
    {
        "title": "Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Informative_Data_Mining_for_One-Shot_Cross-Domain_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Yuxi Wang, Jian Liang, Jun Xiao, Shuqi Mei, Yuran Yang, Zhaoxiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Informative_Data_Mining_for_One-Shot_Cross-Domain_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; State Key Laboratory of Multimodal Artificial Intelligence Systems; Institute of Automation, Chinese Academy of Sciences; Tencent; Centre for Artificial Intelligence and Robotics, HKISI-CAS; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/yxiwang/IDM",
        "arxiv": "2309.14241"
    },
    {
        "title": "Inherent Redundancy in Spiking Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Inherent_Redundancy_in_Spiking_Neural_Networks_ICCV_2023_paper.html",
        "author": "Man Yao, Jiakui Hu, Guangshe Zhao, Yaoyuan Wang, Ziyang Zhang, Bo Xu, Guoqi Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Inherent_Redundancy_in_Spiking_Neural_Networks_ICCV_2023_paper.pdf",
        "aff": "Institute of Automation, Chinese Academy of Sciences, Beijing, China; Peking University Health Science Center, Peking University, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Automation Science and Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; School of Automation Science and Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; Advanced Computing and Storage Lab, Huawei Technologies Co. Ltd.",
        "project": "",
        "github": "https://github.com/BICLab/ASA-SNN",
        "arxiv": "2308.08227"
    },
    {
        "title": "Innovating Real Fisheye Image Correction with Dual Diffusion Architecture",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Innovating_Real_Fisheye_Image_Correction_with_Dual_Diffusion_Architecture_ICCV_2023_paper.html",
        "author": "Shangrong Yang, Chunyu Lin, Kang Liao, Yao Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Innovating_Real_Fisheye_Image_Correction_with_Dual_Diffusion_Architecture_ICCV_2023_paper.pdf",
        "aff": "Institute of Information Science, Beijing Jiaotong University, Beijing Key Laboratory of Advanced Information Science and Network, Beijing, 100044, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Inspecting the Geographical Representativeness of Images from Text-to-Image Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Basu_Inspecting_the_Geographical_Representativeness_of_Images_from_Text-to-Image_Models_ICCV_2023_paper.html",
        "author": "Abhipsa Basu, R. Venkatesh Babu, Danish Pruthi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Basu_Inspecting_the_Geographical_Representativeness_of_Images_from_Text-to-Image_Models_ICCV_2023_paper.pdf",
        "aff": "FLAIR Lab, IISc Bangalore; Vision and AI Lab, IISc Bangalore",
        "project": "",
        "github": "https://github.com/val-iisc/Geographical_Representativeness",
        "arxiv": "2305.11080"
    },
    {
        "title": "Instance Neural Radiance Field",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Instance_Neural_Radiance_Field_ICCV_2023_paper.html",
        "author": "Yichen Liu, Benran Hu, Junkai Huang, Yu-Wing Tai, Chi-Keung Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Instance_Neural_Radiance_Field_ICCV_2023_paper.pdf",
        "aff": "Dartmouth College; The Hong Kong University of Science and Technology; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/lyclyc52/Instance_NeRF",
        "arxiv": "2304.04395"
    },
    {
        "title": "Instance and Category Supervision are Alternate Learners for Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Instance_and_Category_Supervision_are_Alternate_Learners_for_Continual_Learning_ICCV_2023_paper.html",
        "author": "Xudong Tian, Zhizhong Zhang, Xin Tan, Jun Liu, Chengjie Wang, Yanyun Qu, Guannan Jiang, Yuan Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Instance_and_Category_Supervision_are_Alternate_Learners_for_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "Instance and Category Supervision are Alternate Learners for Continual\nLearning\nXudong Tian1,2,3, Zhizhong Zhang1,3(B), Xin Tan1,2,3, Jun Liu4, Chengjie Wang4, Yanyun Qu5,\nGuannan Jiang6, Yuan Xie1,3(B)\n1East China Normal University,2Shanghai Key Laboratory of Computer Software Testing &\nEvaluating,3Chongqing Institute of East China Normal University,4Tencent YouTu Lab,5Xiamen\nUniversity,6Contemporary Amperex Technology Co., Limited\ntxd51194501066@gmail, {zzzhang,xtan }@cs.ecnu.edu.cn, junsenselee@gmail.com\njasoncjwang@tencent.com, yyqu@xmu.edu.cn, jianggn@catl.com, xieyuan8589@foxmail.com\nAbstract\nContinual Learning (CL) is the constant development of\ncomplex behaviors by building upon previously acquired\nskills. Yet, current CL algorithms tend to incur class-level\nforgetting as the label information is often quickly overwrit-\nten by new knowledge. This motivates attempts to mine\ninstance-level discrimination by resorting to recent self-\nsupervised learning (SSL) techniques. However, previous\nworks have pointed out that the self-supervised learning ob-\njective is essentially a trade-off between invariance to dis-\ntortion and preserving sample information, which seriously\nhinders the unleashing of instance-level discrimination.\nIn this work, we reformulate SSL from the information-\ntheoretic perspective by disentangling the goal of instance-\nlevel discrimination, and tackle the trade-off to promote\ncompact representations with maximally preserved invari-\nance to distortion. On this basis, we develop a novel alter-\nnate learning paradigm to enjoy the complementary mer-\nits of instance-level and category-level supervision, which\nyields improved robustness against forgetting and better\nadaptation to each task. To verify the proposed method, we\nconduct extensive experiments on four different benchmarks\nusing both class-incremental and task-incremental settings,\nwhere the leap in performance and thorough ablation stud-\nies demonstrate the ef\ufb01cacy and ef\ufb01ciency of our modeling\nstrategy.\n1. Introduction\nHumans learn from visual inputs with everchanging sce-\nnarios, both rapidly and \ufb02exibly absorbing new knowledge\nwith constantly emerging concepts, and robustly accumulat-\nXV!Z!\ud835\udc47!~\ud835\udcaf\ud835\udc53\"min!\ud835\udc3c(V\",Z\")max!\ud835\udefd\ud835\udc3c(X,Z\")augmentationFigure 1: Illustration of the trade-off that is widely embod-\nied in recent self-supervised learning techniques. Xdenotes\nthe given sample, VAandZAstand for the augmented view\nand the corresponding embedding obtained from distortion\nTA\u223cT and network f\u03c8, respectively.\ning previously acquired experiences. Modeling such pow-\nerful capability is the central target of continual learning\n(CL), and would be of substantial utility in real-world com-\nputer vision settings [44].\nTo this end, a variety of CL algorithms [7, 8, 19, 28, 40]\nhave been developed to get rid of the requirement of i.i.d\nsamples, and attempt to alleviate catastrophic forgetting\n[23] when learning a continuum of training data. Broadly\nspeaking, studies on this topic can be categorized into three\nschools: (i) rehearsal-based methods [4, 14, 33], which\nstore samples in raw or generative format, and replay them\nto alleviate forgetting; (ii) regularization-based methods\n[32, 36] that impose extra constraints to prediction, gradi-\nent, etc. to consolidate previously learned contents; (iii)\nparameter isolation strategies [13, 22] that dedicate or mask\na part of the model parameters for the training of each task.\nAlbeit the differences, the typical solution is to utilize the\nlabel, i.e., category-level supervision to acquire new knowl-\nedge while accumulating previously learned contents. Al-\nthough this usually leads to fast adaptation, such strategy,\ni.e., supervised learning (SL), is prone to incur class-level\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n5596\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Instance-aware Dynamic Prompt Tuning for Pre-trained Point Cloud Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zha_Instance-aware_Dynamic_Prompt_Tuning_for_Pre-trained_Point_Cloud_Models_ICCV_2023_paper.html",
        "author": "Yaohua Zha, Jinpeng Wang, Tao Dai, Bin Chen, Zhi Wang, Shu-Tao Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zha_Instance-aware_Dynamic_Prompt_Tuning_for_Pre-trained_Point_Cloud_Models_ICCV_2023_paper.pdf",
        "aff": "Research Center of Artificial Intelligence, Peng Cheng Laboratory; College of Computer Science and Software Engineering, Shenzhen University; Tsinghua Shenzhen International Graduate School, Tsinghua University; Harbin Institute of Technology, Shenzhen",
        "project": "",
        "github": "https://github.com/zyh16143998882/ICCV23-IDPT",
        "arxiv": "2304.07221"
    },
    {
        "title": "Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Haque_Instruct-NeRF2NeRF_Editing_3D_Scenes_with_Instructions_ICCV_2023_paper.html",
        "author": "Ayaan Haque, Matthew Tancik, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Haque_Instruct-NeRF2NeRF_Editing_3D_Scenes_with_Instructions_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley",
        "project": "https://instruct-nerf2nerf.github.io",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Integrally_Migrating_Pre-trained_Transformer_Encoder-decoders_for_Visual_Object_Detection_ICCV_2023_paper.html",
        "author": "Feng Liu, Xiaosong Zhang, Zhiliang Peng, Zonghao Guo, Fang Wan, Xiangyang Ji, Qixiang Ye",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Integrally_Migrating_Pre-trained_Transformer_Encoder-decoders_for_Visual_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/LiewFeng/imTED",
        "arxiv": "2205.09613"
    },
    {
        "title": "Integrating Boxes and Masks: A Multi-Object Framework for Unified Visual Tracking and Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.html",
        "author": "Yuanyou Xu, Zongxin Yang, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.pdf",
        "aff": "ReLER, CCAI, Zhejiang University, China; ReLER, CCAI, Zhejiang University, China; Baidu Research, China",
        "project": "",
        "github": "https://github.com/yoxu515/MITS",
        "arxiv": "2308.13266"
    },
    {
        "title": "IntentQA: Context-aware Video Intent Reasoning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_IntentQA_Context-aware_Video_Intent_Reasoning_ICCV_2023_paper.html",
        "author": "Jiapeng Li, Ping Wei, Wenjuan Han, Lifeng Fan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_IntentQA_Context-aware_Video_Intent_Reasoning_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, Xi'an Jiaotong University, Xi'an, China; National Key Laboratory of General Artificial Intelligence, Beijing Institute for General Artificial Intelligence (BIGAI), Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China",
        "project": "",
        "github": "https://github.com/JoseponLee/IntentQA.git",
        "arxiv": ""
    },
    {
        "title": "Inter-Realization Channels: Unsupervised Anomaly Detection Beyond One-Class Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/McIntosh_Inter-Realization_Channels_Unsupervised_Anomaly_Detection_Beyond_One-Class_Classification_ICCV_2023_paper.html",
        "author": "Declan McIntosh, Alexandra Branzan Albu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/McIntosh_Inter-Realization_Channels_Unsupervised_Anomaly_Detection_Beyond_One-Class_Classification_ICCV_2023_paper.pdf",
        "aff": "University of Victoria, Victoria, B.C., Canada",
        "project": "",
        "github": "https://github.com/DeclanMcIntosh/InReaCh",
        "arxiv": ""
    },
    {
        "title": "InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_InterDiff_Generating_3D_Human-Object_Interactions_with_Physics-Informed_Diffusion_ICCV_2023_paper.html",
        "author": "Sirui Xu, Zhengyuan Li, Yu-Xiong Wang, Liang-Yan Gui",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_InterDiff_Generating_3D_Human-Object_Interactions_with_Physics-Informed_Diffusion_ICCV_2023_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign",
        "project": "https://sirui-xu.github.io/InterDiff/",
        "github": "https://github.com/sirui-xu/InterDiff",
        "arxiv": "2308.16905"
    },
    {
        "title": "InterFormer: Real-time Interactive Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_InterFormer_Real-time_Interactive_Image_Segmentation_ICCV_2023_paper.html",
        "author": "You Huang, Hao Yang, Ke Sun, Shengchuan Zhang, Liujuan Cao, Guannan Jiang, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_InterFormer_Real-time_Interactive_Image_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Intelligent Manufacturing Department, Contemporary Amperex Technology Co. Limited (CATL); Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University",
        "project": "",
        "github": "https://github.com/YouHuang67/InterFormer",
        "arxiv": "2304.02942"
    },
    {
        "title": "Interaction-aware Joint Attention Estimation Using People Attributes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nakatani_Interaction-aware_Joint_Attention_Estimation_Using_People_Attributes_ICCV_2023_paper.html",
        "author": "Chihiro Nakatani, Hiroaki Kawashima, Norimichi Ukita",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nakatani_Interaction-aware_Joint_Attention_Estimation_Using_People_Attributes_ICCV_2023_paper.pdf",
        "aff": "University of Hyogo, Japan; Toyota Technological Institute, Japan",
        "project": "",
        "github": "https://github.com/chihina/PJAE",
        "arxiv": "2308.05382"
    },
    {
        "title": "Interactive Class-Agnostic Object Counting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Interactive_Class-Agnostic_Object_Counting_ICCV_2023_paper.html",
        "author": "Yifeng Huang, Viresh Ranjan, Minh Hoai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Interactive_Class-Agnostic_Object_Counting_ICCV_2023_paper.pdf",
        "aff": "Amazon, USA; VinAI Research, Hanoi, Vietnam; Stony Brook University, Stony Brook, NY, USA",
        "project": "https://yifehuang97.github.io/ICACountProjectPage/",
        "github": "",
        "arxiv": "2309.05277"
    },
    {
        "title": "IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable Novel View Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_IntrinsicNeRF_Learning_Intrinsic_Neural_Radiance_Fields_for_Editable_Novel_View_ICCV_2023_paper.html",
        "author": "Weicai Ye, Shuo Chen, Chong Bao, Hujun Bao, Marc Pollefeys, Zhaopeng Cui, Guofeng Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_IntrinsicNeRF_Learning_Intrinsic_Neural_Radiance_Fields_for_Editable_Novel_View_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich, Microsoft; State Key Lab of CAD&CG, Zhejiang University",
        "project": "https://zju3dv.github.io/intrinsic_nerf",
        "github": "",
        "arxiv": "2210.00647"
    },
    {
        "title": "Introducing Language Guidance in Prompt-based Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_paper.html",
        "author": "Muhammad Gul Zain Ali Khan, Muhammad Ferjad Naeem, Luc Van Gool, Didier Stricker, Federico Tombari, Muhammad Zeshan Afzal",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "RPTU, DFKI; TUM, Google; ETH Z\u00fcrich",
        "project": "",
        "github": "",
        "arxiv": "2308.15827"
    },
    {
        "title": "Invariant Feature Regularization for Fair Face Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Invariant_Feature_Regularization_for_Fair_Face_Recognition_ICCV_2023_paper.html",
        "author": "Jiali Ma, Zhongqi Yue, Kagaya Tomoyuki, Suzuki Tomoki, Karlekar Jayashree, Sugiri Pranata, Hanwang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Invariant_Feature_Regularization_for_Fair_Face_Recognition_ICCV_2023_paper.pdf",
        "aff": "Panasonic Connect Co., Ltd. R&D Division; Nanyang Technological University; Panasonic R&D Center Singapore",
        "project": "",
        "github": "https://github.com/milliema/InvReg",
        "arxiv": ""
    },
    {
        "title": "Invariant Training 2D-3D Joint Hard Samples for Few-Shot Point Cloud Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.html",
        "author": "Xuanyu Yi, Jiajun Deng, Qianru Sun, Xian-Sheng Hua, Joo-Hwee Lim, Hanwang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; Terminus Group; Singapore Management University; Institute for Infocomm Research; The University of Sydney",
        "project": "",
        "github": "https://github.com/yxymessi/InvJoint",
        "arxiv": "2308.09694"
    },
    {
        "title": "Inverse Compositional Learning for Weakly-supervised Relation Grounding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Inverse_Compositional_Learning_for_Weakly-supervised_Relation_Grounding_ICCV_2023_paper.html",
        "author": "Huan Li, Ping Wei, Zeyu Ma, Nanning Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Inverse_Compositional_Learning_for_Weakly-supervised_Relation_Grounding_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, Xi'an Jiaotong University, Xi'an, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Inverse Problem Regularization with Hierarchical Variational Autoencoders",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Prost_Inverse_Problem_Regularization_with_Hierarchical_Variational_Autoencoders_ICCV_2023_paper.html",
        "author": "Jean Prost, Antoine Houdard, Andr\u00e9s Almansa, Nicolas Papadakis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Prost_Inverse_Problem_Regularization_with_Hierarchical_Variational_Autoencoders_ICCV_2023_paper.pdf",
        "aff": "Universit\u00e9 Paris Cit\u00e9, CNRS, MAP5, UMR 8145; Ubisoft La Forge, Bordeaux; Univ. Bordeaux, CNRS, Bordeaux INP, IMB, UMR 5251, F-33400 Talence, France",
        "project": "",
        "github": "https://github.com/jprost76/PnP-HVAE",
        "arxiv": "2303.11217"
    },
    {
        "title": "Is Imitation All You Need? Generalized Decision-Making with Dual-Phase Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Is_Imitation_All_You_Need_Generalized_Decision-Making_with_Dual-Phase_Training_ICCV_2023_paper.html",
        "author": "Yao Wei, Yanchao Sun, Ruijie Zheng, Sai Vemprala, Rogerio Bonatti, Shuhang Chen, Ratnesh Madaan, Zhongjie Ba, Ashish Kapoor, Shuang Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Is_Imitation_All_You_Need_Generalized_Decision-Making_with_Dual-Phase_Training_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; Microsoft; Scaled Foundations; Zhejiang University, Jiaxing Research Institute, Zhejiang University",
        "project": "",
        "github": "https://github.com/yunyikristy/DualMind",
        "arxiv": "2307.07909"
    },
    {
        "title": "Isomer: Isomerous Transformer for Zero-shot Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Isomer_Isomerous_Transformer_for_Zero-shot_Video_Object_Segmentation_ICCV_2023_paper.html",
        "author": "Yichen Yuan, Yifan Wang, Lijun Wang, Xiaoqi Zhao, Huchuan Lu, Yu Wang, Weibo Su, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Isomer_Isomerous_Transformer_for_Zero-shot_Video_Object_Segmentation_ICCV_2023_paper.pdf",
        "aff": "OPPO Research Institute; OPPO Research Institute, The Hong Kong Polytechnic University; School of Information and Communication Engineering, Dalian University of Technology, China",
        "project": "",
        "github": "https://github.com/DLUT-yyc/Isomer",
        "arxiv": "2308.06693"
    },
    {
        "title": "Iterative Denoiser and Noise Estimator for Self-Supervised Image Denoising",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Iterative_Denoiser_and_Noise_Estimator_for_Self-Supervised_Image_Denoising_ICCV_2023_paper.html",
        "author": "Yunhao Zou, Chenggang Yan, Ying Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Iterative_Denoiser_and_Noise_Estimator_for_Self-Supervised_Image_Denoising_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of Technology; Hangzhou Dianzi University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Iterative Prompt Learning for Unsupervised Backlit Image Enhancement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.html",
        "author": "Zhexin Liang, Chongyi Li, Shangchen Zhou, Ruicheng Feng, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University",
        "project": "https://zhexinliang.github.io/CLIP_LIT_page/",
        "github": "",
        "arxiv": "2303.17569"
    },
    {
        "title": "Iterative Soft Shrinkage Learning for Efficient Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html",
        "author": "Jiamian Wang, Huan Wang, Yulun Zhang, Yun Fu, Zhiqiang Tao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "Rochester Institute of Technology; Northeastern University; ETH Z\u00fcrich",
        "project": "",
        "github": "https://github.com/Jiamian-Wang/Iterative-Soft-Shrinkage-SR",
        "arxiv": "2303.09650"
    },
    {
        "title": "Iterative Superquadric Recomposition of 3D Objects from Multiple Views",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Alaniz_Iterative_Superquadric_Recomposition_of_3D_Objects_from_Multiple_Views_ICCV_2023_paper.html",
        "author": "Stephan Alaniz, Massimiliano Mancini, Zeynep Akata",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Alaniz_Iterative_Superquadric_Recomposition_of_3D_Objects_from_Multiple_Views_ICCV_2023_paper.pdf",
        "aff": "University of Trento; University of T\u00fcbingen, MPI-IS; University of T\u00fcbingen",
        "project": "",
        "github": "https://github.com/ExplainableML/ISCO",
        "arxiv": "2309.02102"
    },
    {
        "title": "JOTR: 3D Joint Contrastive Learning with Transformers for Occluded Human Mesh Recovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_JOTR_3D_Joint_Contrastive_Learning_with_Transformers_for_Occluded_Human_ICCV_2023_paper.html",
        "author": "Jiahao Li, Zongxin Yang, Xiaohan Wang, Jianxin Ma, Chang Zhou, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_JOTR_3D_Joint_Contrastive_Learning_with_Transformers_for_Occluded_Human_ICCV_2023_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group; ReLER, CCAI, Zhejiang University; DAMO Academy, Alibaba Group; ReLER, CCAI, Zhejiang University",
        "project": "",
        "github": "https://github.com/xljh0520/JOTR",
        "arxiv": "2307.16377"
    },
    {
        "title": "Joint Demosaicing and Deghosting of Time-Varying Exposures for Single-Shot HDR Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Joint_Demosaicing_and_Deghosting_of_Time-Varying_Exposures_for_Single-Shot_HDR_ICCV_2023_paper.html",
        "author": "Jungwoo Kim, Min H. Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Joint_Demosaicing_and_Deghosting_of_Time-Varying_Exposures_for_Single-Shot_HDR_ICCV_2023_paper.pdf",
        "aff": "KAIST",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Joint Implicit Neural Representation for High-fidelity and Compact Vector Fonts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Joint_Implicit_Neural_Representation_for_High-fidelity_and_Compact_Vector_Fonts_ICCV_2023_paper.html",
        "author": "Chia-Hao Chen, Ying-Tian Liu, Zhifei Zhang, Yuan-Chen Guo, Song-Hai Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Joint_Implicit_Neural_Representation_for_High-fidelity_and_Compact_Vector_Fonts_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Joint Metrics Matter: A Better Standard for Trajectory Forecasting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Weng_Joint_Metrics_Matter_A_Better_Standard_for_Trajectory_Forecasting_ICCV_2023_paper.html",
        "author": "Erica Weng, Hana Hoshino, Deva Ramanan, Kris Kitani",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Joint_Metrics_Matter_A_Better_Standard_for_Trajectory_Forecasting_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "",
        "github": "github.com/ericaweng/joint-metrics-matter",
        "arxiv": "2305.06292"
    },
    {
        "title": "Joint-Relation Transformer for Multi-Person Motion Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Joint-Relation_Transformer_for_Multi-Person_Motion_Prediction_ICCV_2023_paper.html",
        "author": "Qingyao Xu, Weibo Mao, Jingze Gong, Chenxin Xu, Siheng Chen, Weidi Xie, Ya Zhang, Yanfeng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Joint-Relation_Transformer_for_Multi-Person_Motion_Prediction_ICCV_2023_paper.pdf",
        "aff": "Shanghai Jiao Tong University, Shanghai AI Laboratory; Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/MediaBrain-SJTU/JRTransformer",
        "arxiv": "2308.04808"
    },
    {
        "title": "Jumping through Local Minima: Quantization in the Loss Landscape of Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Frumkin_Jumping_through_Local_Minima_Quantization_in_the_Loss_Landscape_of_ICCV_2023_paper.html",
        "author": "Natalia Frumkin, Dibakar Gope, Diana Marculescu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Frumkin_Jumping_through_Local_Minima_Quantization_in_the_Loss_Landscape_of_ICCV_2023_paper.pdf",
        "aff": "Arm Inc.; The University of Texas at Austin",
        "project": "",
        "github": "https://github.com/enyac-group/evol-q",
        "arxiv": "2308.10814"
    },
    {
        "title": "KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_KECOR_Kernel_Coding_Rate_Maximization_for_Active_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Yadan Luo, Zhuoxiao Chen, Zhen Fang, Zheng Zhang, Mahsa Baktashmotlagh, Zi Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_KECOR_Kernel_Coding_Rate_Maximization_for_Active_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "The University of Queensland; Harbin Institute of Technology, Shenzhen; University of Technology Sydney",
        "project": "",
        "github": "https://github.com/Luoyadan/KECOR-active-3Ddet",
        "arxiv": "2307.07942"
    },
    {
        "title": "Keep It SimPool: Who Said Supervised Transformers Suffer from Attention Deficit?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Psomas_Keep_It_SimPool_Who_Said_Supervised_Transformers_Suffer_from_Attention_ICCV_2023_paper.html",
        "author": "Bill Psomas, Ioannis Kakogeorgiou, Konstantinos Karantzalos, Yannis Avrithis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Psomas_Keep_It_SimPool_Who_Said_Supervised_Transformers_Suffer_from_Attention_ICCV_2023_paper.pdf",
        "aff": "National Technical University of Athens; Institute of Advanced Research in Artificial Intelligence (IARAI)",
        "project": "",
        "github": "https://github.com/billpsomas/simpool",
        "arxiv": "2309.06891"
    },
    {
        "title": "Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Spencer_Kick_Back__Relax_Learning_to_Reconstruct_the_World_by_ICCV_2023_paper.html",
        "author": "Jaime Spencer, Chris Russell, Simon Hadfield, Richard Bowden",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Spencer_Kick_Back__Relax_Learning_to_Reconstruct_the_World_by_ICCV_2023_paper.pdf",
        "aff": "Oxford Internet Institute; University of Surrey",
        "project": "",
        "github": "https://github.com/jspenmar/slowtv_monodepth",
        "arxiv": "2307.10713"
    },
    {
        "title": "Knowing Where to Focus: Event-aware Transformer for Video Grounding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Knowing_Where_to_Focus_Event-aware_Transformer_for_Video_Grounding_ICCV_2023_paper.html",
        "author": "Jinhyun Jang, Jungin Park, Jin Kim, Hyeongjun Kwon, Kwanghoon Sohn",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Knowing_Where_to_Focus_Event-aware_Transformer_for_Video_Grounding_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; Yonsei University, Korea Institute of Science and Technology (KIST)",
        "project": "",
        "github": "https://github.com/jinhyunj/EaTR",
        "arxiv": "2308.06947"
    },
    {
        "title": "Knowledge Proxy Intervention for Deconfounded Video Question Answering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Knowledge_Proxy_Intervention_for_Deconfounded_Video_Question_Answering_ICCV_2023_paper.html",
        "author": "Jiangtong Li, Li Niu, Liqing Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Knowledge_Proxy_Intervention_for_Deconfounded_Video_Question_Answering_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Knowledge Restore and Transfer for Multi-Label Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Knowledge_Restore_and_Transfer_for_Multi-Label_Class-Incremental_Learning_ICCV_2023_paper.html",
        "author": "Songlin Dong, Haoyu Luo, Yuhang He, Xing Wei, Jie Cheng, Yihong Gong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Knowledge_Restore_and_Transfer_for_Multi-Label_Class-Incremental_Learning_ICCV_2023_paper.pdf",
        "aff": "car\npersoncar\ncar, person\nbicycle car, person, bicyclecar car\nperson person\nbicycle bicycle\nSession1 Training set \u0001\u0002\ncar\n person, bicycleSession2 Training set \u0001\u0003\nSession3 Training set \u0001\u0004\u0472\u0002\n\u0472\u0003\n\u0472\u0004Session1 Test set \u0006\u0002\nSession2 Test set \u0006\u0002\u222a\u0006\u0003\nSession3 Test set \u0006\u0002\u222a\u0006\u0003\u222a\u0006\u0004car\nTraining set Test set\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n18711\n",
        "project": "",
        "github": "",
        "arxiv": "2302.13334"
    },
    {
        "title": "Knowledge-Aware Federated Active Learning with Non-IID Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Knowledge-Aware_Federated_Active_Learning_with_Non-IID_Data_ICCV_2023_paper.html",
        "author": "Yu-Tong Cao, Ye Shi, Baosheng Yu, Jingya Wang, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Knowledge-Aware_Federated_Active_Learning_with_Non-IID_Data_ICCV_2023_paper.pdf",
        "aff": "Sydney AI Centre, School of Computer Science, The University of Sydney; ShanghaiTech University",
        "project": "",
        "github": "https://github.com/ycao5602/KAFAL",
        "arxiv": "2211.13579"
    },
    {
        "title": "Knowledge-Aware Prompt Tuning for Generalizable Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kan_Knowledge-Aware_Prompt_Tuning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Baoshuo Kan, Teng Wang, Wenpeng Lu, Xiantong Zhen, Weili Guan, Feng Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kan_Knowledge-Aware_Prompt_Tuning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "Southern University of Science and Technology; United Imaging Healthcare; Monash University; Qilu University of Technology (Shandong Academy of Sciences)",
        "project": "",
        "github": "",
        "arxiv": "2308.11186"
    },
    {
        "title": "Knowledge-Spreader: Learning Semi-Supervised Facial Action Dynamics by Consistifying Knowledge Granularity",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Knowledge-Spreader_Learning_Semi-Supervised_Facial_Action_Dynamics_by_Consistifying_Knowledge_Granularity_ICCV_2023_paper.html",
        "author": "Xiaotian Li, Xiang Zhang, Taoyue Wang, Lijun Yin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Knowledge-Spreader_Learning_Semi-Supervised_Facial_Action_Dynamics_by_Consistifying_Knowledge_Granularity_ICCV_2023_paper.pdf",
        "aff": "State University of New York at Binghamton",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "L-DAWA: Layer-wise Divergence Aware Weight Aggregation in Federated Self-Supervised Visual Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rehman_L-DAWA_Layer-wise_Divergence_Aware_Weight_Aggregation_in_Federated_Self-Supervised_Visual_ICCV_2023_paper.html",
        "author": "Yasar Abbas Ur Rehman, Yan Gao, Pedro Porto Buarque de Gusmao, Mina Alibeigi, Jiajun Shen, Nicholas D. Lane",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rehman_L-DAWA_Layer-wise_Divergence_Aware_Weight_Aggregation_in_Federated_Self-Supervised_Visual_ICCV_2023_paper.pdf",
        "aff": "University of Cambridge, United Kingdom; TCL AI Lab, Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LA-Net: Landmark-Aware Learning for Reliable Facial Expression Recognition under Label Noise",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_LA-Net_Landmark-Aware_Learning_for_Reliable_Facial_Expression_Recognition_under_Label_ICCV_2023_paper.html",
        "author": "Zhiyu Wu, Jinshi Cui",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_LA-Net_Landmark-Aware_Learning_for_Reliable_Facial_Expression_Recognition_under_Label_ICCV_2023_paper.pdf",
        "aff": "School of Intelligence Science and Technology, Peking University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LAC - Latent Action Composition for Skeleton-based Action Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.html",
        "author": "Di Yang, Yaohui Wang, Antitza Dantcheva, Quan Kong, Lorenzo Garattoni, Gianpiero Francesca, Francois Bremond",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Inria, Universit\u00e9 C\u00f4te d\u2019Azur; Toyota Motor Europe; Woven by Toyota",
        "project": "",
        "github": "https://walker1126.github.io/LAC/",
        "arxiv": "2308.14500"
    },
    {
        "title": "LAN-HDR: Luminance-based Alignment Network for High Dynamic Range Video Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chung_LAN-HDR_Luminance-based_Alignment_Network_for_High_Dynamic_Range_Video_Reconstruction_ICCV_2023_paper.html",
        "author": "Haesoo Chung, Nam Ik Cho",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_LAN-HDR_Luminance-based_Alignment_Network_for_High_Dynamic_Range_Video_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, INMC, Seoul National University, Korea; IPAI, Seoul National University, Korea",
        "project": "",
        "github": "https://github.com/haesoochung/LAN-HDR",
        "arxiv": ""
    },
    {
        "title": "LATR: 3D Lane Detection from Monocular Images with Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_LATR_3D_Lane_Detection_from_Monocular_Images_with_Transformer_ICCV_2023_paper.html",
        "author": "Yueru Luo, Chaoda Zheng, Xu Yan, Tang Kun, Chao Zheng, Shuguang Cui, Zhen Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LATR_3D_Lane_Detection_from_Monocular_Images_with_Transformer_ICCV_2023_paper.pdf",
        "aff": "SSE, CUHK-Shenzhen; Tencent Map, T Lab; FNii, CUHK-Shenzhen",
        "project": "",
        "github": "https://github.com/JMoonr/LATR",
        "arxiv": "2308.04583"
    },
    {
        "title": "LAW-Diffusion: Complex Scene Generation by Diffusion with Layouts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_LAW-Diffusion_Complex_Scene_Generation_by_Diffusion_with_Layouts_ICCV_2023_paper.html",
        "author": "Binbin Yang, Yi Luo, Ziliang Chen, Guangrun Wang, Xiaodan Liang, Liang Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAW-Diffusion_Complex_Scene_Generation_by_Diffusion_with_Layouts_ICCV_2023_paper.pdf",
        "aff": "Sun Yat-Sen University; University of Oxford; Jinan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LD-ZNet: A Latent Diffusion Approach for Text-Based Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.html",
        "author": "Koutilya PNVR, Bharat Singh, Pallabi Ghosh, Behjat Siddiquie, David Jacobs",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.pdf",
        "aff": "University of Maryland College Park\u2020; Amazon\u00a7; Vchar.ai\u2021",
        "project": "https://koutilya-pnvr.github.io/LD-ZNet/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LDL: Line Distance Functions for Panoramic Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_LDL_Line_Distance_Functions_for_Panoramic_Localization_ICCV_2023_paper.html",
        "author": "Junho Kim, Changwoon Choi, Hojun Jang, Young Min Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_LDL_Line_Distance_Functions_for_Panoramic_Localization_ICCV_2023_paper.pdf",
        "aff": "Dept. of Electrical and Computer Engineering, Seoul National University and Interdisciplinary Program in Artificial Intelligence and INMC, Seoul National University; Dept. of Electrical and Computer Engineering, Seoul National University",
        "project": "",
        "github": "https://github.com/82magnolia/panoramic-localization",
        "arxiv": "2308.13989"
    },
    {
        "title": "LDP-Feat: Image Features with Local Differential Privacy",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.html",
        "author": "Francesco Pittaluga, Bingbing Zhuang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.pdf",
        "aff": "NEC Labs America",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LEA2: A Lightweight Ensemble Adversarial Attack via Non-overlapping Vulnerable Frequency Regions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qian_LEA2_A_Lightweight_Ensemble_Adversarial_Attack_via_Non-overlapping_Vulnerable_Frequency_ICCV_2023_paper.html",
        "author": "Yaguan Qian, Shuke He, Chenyu Zhao, Jiaqiang Sha, Wei Wang, Bin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_LEA2_A_Lightweight_Ensemble_Adversarial_Attack_via_Non-overlapping_Vulnerable_Frequency_ICCV_2023_paper.pdf",
        "aff": "/0 /1 /2/3/4 /2/0 /5 /6 /7 /8 /9 /10 /5 /6 /7 /8 /1 /11 /12 /10 /13/14 /15 /10 /2 /16 /17 /10 /18 /12 /19 /18 /5 /19 /15 /2 /8 /8 /19 /20 /21/17 /5 /19/22 /23 /11 /24 /23 /17 /10 /18 /15 /19 /25 /25 /5 /11 /6\n/26 /27 /15 /11 /10 /18 /19 /14 /15 /10 /28 /18 /10 /29 /27 /10 /11 /20 /30/31 /10 /6 /5 /23 /11 /12\n/32 /33 /34 /35 /33 /36 /37 /38 /33 /36/39 /40/41 /42 /43 /35 /44 /45 /46 /45/40/41 /47 /43 /45 /36 /48 /35/49 /43 /33 /50/40/41 /51 /38 /33 /52 /38 /33 /36 /34/42 /43 /33/40/41 /53/45 /38 /53/33 /36 /34/54/41 /33 /36 /55/56 /38 /36/53 /33 /36 /34/57\n/40/42 /58 /43 /50 /50 /59 /50 /60 /42 /58 /38 /45 /36 /58 /45 /41 /49 /43 /45 /61 /38 /33 /36 /34/62 /36 /38 /63 /45 /64 /65 /38 /66 /48/50 /60 /42 /58 /38 /45 /36 /58 /45 /33 /36 /55/67 /45 /58 /43 /36 /50 /59 /50 /34 /48 /41 /46 /33 /36 /34 /68 /43 /50 /35 /41 /47 /43 /38 /36 /33\n/54/56 /45 /38 /61 /38 /36 /34/69 /45 /48/70 /33 /71 /50 /64 /33 /66 /50 /64 /48/50 /60 /42 /45 /58 /35 /64 /38 /66 /48/33 /36 /55/72 /64 /38 /63 /33 /58 /48/38 /36/73 /36 /66 /45 /59 /59 /38 /34 /45 /36 /66 /67 /64 /33 /36 /65 /74 /50 /64 /66 /33 /66 /38 /50 /36 /41 /56 /45 /38 /61 /38 /36 /34/51 /38 /33 /50 /66 /50 /36 /34\n/62 /36 /38 /63 /45 /64 /65 /38 /66 /48 /41 /47 /43 /38 /36 /33\n/57/49 /43 /45 /61 /38 /33 /36 /34/69 /45 /48 /70 /33 /71 /50 /64 /33 /66 /50 /64 /48/50 /60 /75/35 /59 /66 /38 /55 /38 /76/45 /36 /65 /38 /50 /36 /33 /59 /72 /45 /64 /58 /45 /74 /66 /38 /50 /36/67 /45 /58 /43 /36 /50 /59 /50 /34 /48 /41 /77 /74 /74 /59 /38 /58 /33 /66 /38 /50 /36/33 /36 /55/47 /48 /71 /45 /64 /65 /45 /58 /35 /64 /38 /66 /48 /41\n/47 /43 /38 /36 /33\n/2 /14 /12 /8 /18 /19 /20 /8\n/78 /79 /80 /79 /81 /82 /83 /84 /85 /86/87 /88 /84 /83 /87/82 /88 /89 /82 /83 /79 /90 /90 /91 /92 /79 /87 /93 /94 /81 /79 /92/89 /92 /95 /79 /85 /87 /89 /85 /93 /89 /90 /79 /96 /91\n/89 /97 /98 /90 /79 /87/80 /89 /81 /99 /84 /84 /90 /92 /79 /79 /98/81 /79 /100 /85 /89 /90 /81 /79 /82 /83 /84 /85 /86 /87/101 /102 /103 /103 /87 /104 /105/102 /100 /79/82 /84\n/82 /88 /79 /93 /85 /82 /85 /89 /81 /87 /99 /79 /85 /89 /106 /93 /90 /93 /82 /107 /108 /89 /92 /95 /79 /85 /87 /89 /85 /93 /89 /90 /79 /96 /89 /97 /98 /90 /79 /87 /80 /89 /81/89 /90 /87 /84/89 /82 /82 /89 /80 /86\n/82 /89 /85 /94 /79 /82 /97 /84 /92 /79 /90 /87 /83 /93 /82 /88 /84 /100 /82 /79 /96 /82 /85 /89/93 /81 /99 /84 /85 /97 /89 /82 /93 /84 /81 /108 /80 /89 /90 /90 /79 /92/106 /90 /89 /80 /86 /91 /106 /84 /96\n/89 /82 /82 /89 /80 /86 /87 /105/109 /84 /83 /79 /95 /79 /85 /108 /97 /84 /87 /82 /79 /96 /93 /87 /82 /93 /81 /94/79 /81 /87 /79 /97 /106 /90 /79/89 /82 /82 /89 /80 /86 /87/92 /79 /98 /79 /81 /92\n/84 /81 /81 /100 /97 /79 /85 /84 /100 /87 /87 /100 /106 /87 /82 /93 /82 /100 /82 /79 /97 /84 /92 /79 /90 /87 /82 /84 /80 /84 /95 /79 /85 /82 /88 /79 /95 /100 /90 /81 /79 /85 /89 /106 /90 /79 /87 /100 /106 /91\n/87 /98 /89 /80 /79/84 /99 /89/82 /89 /85 /94 /79 /82 /97 /84 /92 /79 /90 /105/110 /81/82 /88 /93 /87 /83 /84 /85 /86 /108 /83 /79/111 /81 /92/82 /88 /85 /79 /79/82 /107 /98 /79 /87\n/84 /99 /97 /84 /92 /79 /90 /87/83 /93 /82 /88/81 /84 /81 /91 /84 /95 /79 /85 /90 /89 /98 /98 /93 /81 /94/95 /100 /90 /81 /79 /85 /89 /106 /90 /79/99 /85 /79 /112 /100 /79 /81 /80 /107/85 /79 /91\n/94 /93 /84 /81 /87 /108/83 /88 /93 /80 /88 /80 /89 /81/80 /84 /95 /79 /85/89 /90 /89 /85 /94 /79/79 /81 /84 /100 /94 /88/95 /100 /90 /81 /79 /85 /89 /106 /90 /79/87 /100 /106 /91\n/87 /98 /89 /80 /79 /105 /113 /89 /87 /79 /92 /84 /81/82 /88 /93 /87 /111 /81 /92 /93 /81 /94 /108 /83 /79 /98 /85 /84 /98 /84 /87 /79 /89/90 /93 /94 /88 /82 /83 /79 /93 /94 /88 /82 /79 /81 /91\n/87 /79 /97 /106 /90 /79 /89 /92 /95 /79 /85 /87 /89 /85 /93 /89 /90 /89 /82 /82 /89 /80 /86 /81 /89 /97 /79 /92/114 /115 /116/117/108 /93 /81 /82 /79 /94 /85 /89 /82 /79 /92/106 /107 /87 /82 /89 /81 /91\n/92 /89 /85 /92 /108 /83 /79 /89 /86 /90 /107 /85 /84 /106 /100 /87 /82 /108 /89 /81 /92/85 /84 /106 /100 /87 /82 /97 /84 /92 /79 /90 /87 /105 /118/84 /85 /79 /84 /95 /79 /85 /108 /83 /79 /89 /81 /91\n/89 /90 /107 /119 /79 /120 /89 /100 /87 /87 /93 /89 /81 /81 /84 /93 /87 /79 /99 /85 /84 /97/82 /88 /79 /98 /79 /85 /87 /98 /79 /80 /82 /93 /95 /79 /84 /99 /99 /85 /79 /112 /100 /79 /81 /80 /107 /89 /81 /92\n/111 /81 /92/82 /88 /89 /82 /120 /89 /100 /87 /87 /93 /89 /81/81 /84 /93 /87 /79/93 /87/90 /84 /80 /89 /82 /79 /92/93 /81/82 /88 /79/95 /100 /90 /81 /79 /85 /89 /106 /90 /79/99 /85 /79 /91\n/112 /100 /79 /81 /80 /107/85 /79 /94 /93 /84 /81 /87 /84 /99 /87 /82 /89 /81 /92 /89 /85 /92/97 /84 /92 /79 /90 /87 /105/121 /88 /79 /85 /79 /99 /84 /85 /79 /108 /83 /79/87 /100 /106 /87 /82 /93 /91\n/82 /100 /82 /79 /87 /82 /89 /81 /92 /89 /85 /92 /97 /84 /92 /79 /90 /87 /83 /93 /82 /88/120 /89 /100 /87 /87 /93 /89 /81/81 /84 /93 /87 /79 /82 /84/79 /81 /87 /100 /85 /79 /82 /88 /79 /100 /87 /79\n/84 /99 /88 /93 /94 /88 /91 /99 /85 /79 /112 /100 /79 /81 /80 /107 /95 /100 /90 /81 /79 /85 /89 /106 /90 /79 /85 /79 /94 /93 /84 /81 /87 /83 /88 /93 /90 /79 /85 /79 /92 /100 /80 /93 /81 /94/89 /82 /82 /89 /80 /86\n/82 /93 /97 /79/80 /84 /81 /87 /100 /97 /98 /82 /93 /84 /81 /105/115 /96 /98 /79 /85 /93 /97 /79 /81 /82 /87 /84 /81/87 /79 /95 /79 /85 /89 /90 /93 /97 /89 /94 /79/92 /89 /82 /89 /87 /79 /82 /87\n/93 /81 /92 /93 /80 /89 /82 /79 /82 /88 /89 /82 /114 /115 /116/117/89 /80 /88 /93 /79 /95 /79 /87 /106 /79 /82 /82 /79 /85 /82 /85 /89 /81 /87 /99 /79 /85 /89 /106 /93 /90 /93 /82 /107 /100 /81 /92 /79 /85 /92 /93 /99 /91\n/99 /79 /85 /79 /81 /82 /92 /79 /99 /79 /81 /92 /79 /92/97 /84 /92 /79 /90 /87 /80 /84 /97 /98 /89 /85 /79 /92/83 /93 /82 /88/79 /96 /82 /79 /81 /87 /93 /95 /79/106 /89 /87 /79 /90 /93 /81 /79 /87\n/89 /81 /92/87 /82 /89 /82 /79 /91 /84 /99 /91 /82 /88 /79 /91 /89 /85 /82 /89 /82 /82 /89 /80 /86 /87 /105\n/122 /123 /124 /11 /8 /18 /23 /16 /27 /20 /8 /5 /23 /11\n/47 /50 /36 /63 /50 /59 /35 /66 /38 /50 /36 /33 /59 /36 /45 /35 /64 /33 /59 /36 /45 /66 /125 /50 /64 /44 /65 /126 /47 /127 /127 /65 /128 /43 /33 /63 /45/71 /45 /45 /36/65 /35 /58 /129\n/58 /45 /65 /65 /60 /35 /59 /59 /48 /45 /76 /74 /59 /50 /48 /45 /55 /38 /36 /38 /76/33 /34 /45 /58 /59 /33 /65 /65 /38 /130 /58 /33 /66 /38 /50 /36 /41 /71 /35 /66 /64 /45 /58 /45 /36 /66 /125 /50 /64 /44 /65\n/43 /33 /63 /45 /65 /43 /50 /125 /36 /66 /43 /33 /66 /45 /63 /45 /36/66 /43 /45 /76/50 /65 /66 /33 /55 /63 /33 /36 /58 /45 /55/47 /127 /127 /65 /33 /64 /45 /63 /35 /59 /36 /45 /64 /129\n/33 /71 /59 /45/66 /50/33 /55 /63 /45 /64 /65 /33 /64 /38 /33 /59 /45 /131 /33 /76/74 /59 /45 /65/132 /40 /54 /41 /54 /133 /41 /54 /134 /41 /40 /135 /136/77 /55 /63 /45 /64 /65 /33 /64 /38 /33 /59\n/33 /66 /66 /33 /58 /44 /65/55 /45 /59 /38 /71 /45 /64 /33 /66 /45 /59 /48/38 /76/74 /50 /65 /45/65 /76/33 /59 /59 /74 /45 /64 /66 /35 /64 /71 /33 /66 /38 /50 /36 /65/66 /50/66 /43 /45/71 /45 /129\n/36 /38 /34 /36/38 /36 /74 /35 /66 /66 /50 /76/38 /65 /59 /45 /33 /55/33 /76 /50 /55 /45 /59 /136/73 /36/34 /45 /36 /45 /64 /33 /59 /41 /33 /55 /63 /45 /64 /65 /33 /64 /38 /33 /59 /33 /66 /129\n/39 /47 /50 /64 /64 /45 /65 /74 /50 /36 /55 /38 /36 /34/33 /35 /66 /43 /50 /64 /137 /52 /38 /33 /36 /48 /33 /34 /35 /33 /36 /138/68 /35 /65 /66 /136 /45 /55 /35 /136 /58 /36\n/139 /140 /141 /142 /143/144 /145 /142\n/146 /147 /141 /141/148 /149\n/148 /150\n/148 /151/152/153 /154 /155 /154 /140 /156 /145 /i255 /158 /143/156 /155 /142/159 /160 /161 /142 /153 /141 /156 /153 /154 /156 /145\n/158 /143/156 /155 /142\n/162 /147 /153 /163 /156 /153 /160 /i255 /160 /156 /164 /156 /162 /147 /153 /163 /156 /153 /160 /i255 /160 /156 /164 /156 /165 /156 /166 /167 /163 /156 /153 /160 /i255 /155 /153 /156 /160 /154 /142 /140 /164 /165 /156 /166 /167 /163 /156 /153 /160 /i255 /155 /153 /156 /160 /154 /142 /140 /164 /168 /169 /145 /140 /142 /153 /156 /144 /145 /142 /i255 /162 /153 /142 /170 /169 /142 /140 /166 /171 /i255 /172 /142 /155 /154 /147 /140 /141 /i255 /147 /173 /i255 /174 /145 /156 /141 /141 /154 /173 /154 /142 /153 /i255 /148 /149 /168 /169 /145 /140 /142 /153 /156 /144 /145 /142 /i255 /162 /153 /142 /170 /169 /142 /140 /166 /171 /i255 /172 /142 /155 /154 /147 /140 /141 /i255 /147 /173 /i255 /174 /145 /156 /141 /141 /154 /173 /154 /142 /153 /i255 /148 /149\n/168 /169 /145 /140 /142 /153 /156 /144 /145 /142 /i255 /162 /153 /142 /170 /169 /142 /140 /166 /171 /i255 /172 /142 /155 /154 /147 /140 /141 /i255 /147 /173 /i255 /166 /145 /156 /141 /141 /154 /173 /154 /142 /153 /i255 /148 /150/168 /169 /145 /140 /142 /153 /156 /144 /145 /142 /i255 /162 /153 /142 /170 /169 /142 /140 /166 /171 /i255 /172 /142 /155 /154 /147 /140 /141 /i255 /147 /173 /i255 /166 /145 /156 /141 /141 /154 /173 /154 /142 /153 /i255 /148 /150/168 /169 /145 /140 /142 /153 /156 /144 /145 /142 /i255 /162 /153 /142 /170 /169 /142 /140 /166 /171 /i255 /172 /142 /155 /154 /147 /140 /141 /i255 /147 /173 /i255 /166 /145 /156 /141 /141 /154 /173 /154 /142 /153 /i255 /148 /150 /168 /169 /145 /140 /142 /153 /156 /144 /145 /142 /i255 /162 /153 /142 /170 /169 /142 /140 /166 /171 /i255 /172 /142 /155 /154 /147 /140 /141 /i255 /147 /173 /i255 /166 /145 /156 /141 /141 /154 /173 /154 /142 /153 /i255 /148 /151/168 /169 /145 /140 /142 /153 /156 /144 /145 /142 /i255 /162 /153 /142 /170 /169 /142 /140 /166 /171 /i255 /172 /142 /155 /154 /147 /140 /141 /i255 /147 /173 /i255 /166 /145 /156 /141 /141 /154 /173 /154 /142 /153 /i255 /148 /151/168 /169 /145 /140 /142 /153 /156 /144 /145 /142 /i255 /162 /153 /142 /170 /169 /142 /140 /166 /171 /i255\n/172 /142 /155 /154 /147 /140 /141 /i255 /147 /173 /i255 /175/147 /160 /142 /145 /141\n/176 /174 /177/159 /160 /161 /142 /153 /141 /156 /153 /154 /156 /145 /i255 /178 /142 /153 /164 /169 /153 /144 /156 /164 /154 /147 /140 /141\n/154 /140 /i255 /162 /153 /142 /170 /169 /142 /140 /166 /171 /179 /176 /147 /143/156 /154 /140\n/159 /160 /161 /142 /153 /141 /156 /153 /154 /156 /145 /i255 /178 /142 /153 /164 /169 /153 /144 /156 /164 /154 /147 /140 /141\n/154 /140 /i255 /180 /181 /156 /164 /154 /156 /145 /179 /176 /147 /143/156 /154 /140\n/182 /38 /34 /35 /64 /45 /40 /136/77 /36/45 /131 /33 /76/74 /59 /45 /50 /60 /50 /35 /64 /45 /36 /65 /45 /76/71 /59 /45 /33 /66 /66 /33 /58 /44 /65 /41 /125 /43 /45 /64 /45 /66 /43 /64 /45 /45 /65 /35 /71 /129\n/65 /66 /38 /66 /35 /66 /45 /76/50 /55 /45 /59 /65 /33 /64 /45 /35 /65 /45 /55 /66 /50 /58 /64 /33 /60 /66 /33 /55 /63 /45 /64 /65 /33 /64 /38 /33 /59 /45 /131 /33 /76/74 /59 /45 /65 /136 /47 /59 /33 /65 /65 /38 /130 /45 /64 /183 /184\n/38 /65 /33 /36/33 /55 /63 /45 /64 /65 /33 /64 /38 /33 /59 /66 /64 /33 /38 /36 /45 /55/76/50 /55 /45 /59 /41 /183 /185 /38 /65 /33 /125 /45 /33 /44 /59 /48/64 /50 /71 /35 /65 /66 /76/50 /55 /45 /59 /41 /33 /36 /55\n/183 /186 /38 /65 /33 /65 /66 /33 /36 /55 /33 /64 /55/76 /50 /55 /45 /59 /136\n/66 /33 /58 /44 /65 /58 /33 /36/71 /45/55 /38 /63 /38 /55 /45 /55/38 /36 /66 /50/125 /43 /38 /66 /45 /129 /71 /50 /131/33 /66 /66 /33 /58 /44 /65 /33 /36 /55/71 /59 /33 /58 /44 /129 /71 /50 /131\n/33 /66 /66 /33 /58 /44 /65 /136 /53/43 /38 /66 /45 /129 /71 /50 /131 /33 /66 /66 /33 /58 /44 /65 /36 /45 /45 /55 /66 /50 /44 /36 /50 /125/33 /59 /59 /66 /43 /45 /38 /36 /60 /50 /64 /76/33 /66 /38 /50 /36\n/33 /71 /50 /35 /66 /66 /43 /45 /66 /33 /64 /34 /45 /66 /76/50 /55 /45 /59 /126 /79 /105 /94 /105 /41 /76/50 /55 /45 /59 /65 /66 /64 /35 /58 /66 /35 /64 /45 /41 /33 /36 /55 /76 /50 /55 /45 /59 /74 /33 /129\n/64 /33 /76/45 /66 /45 /64 /65 /128 /41 /125 /43 /38 /58 /43 /38 /65 /35 /65 /35 /33 /59 /59 /48 /38 /76/74 /64 /33 /58 /66 /38 /58 /33 /71 /59 /45 /71 /45 /58 /33 /35 /65 /45 /33 /36 /33 /55 /63 /45 /64 /129\n/65 /33 /64 /48 /58 /33 /36 /36 /50 /66 /50 /71 /66 /33 /38 /36 /33 /59 /59 /66 /43 /45 /38 /36 /60 /50 /64 /76/33 /66 /38 /50 /36 /33 /71 /50 /35 /66 /66 /43 /45 /66 /33 /64 /34 /45 /66 /76/50 /55 /45 /59\n/38 /36/64 /45 /33 /59 /38 /66 /48 /136/73 /36/58 /50 /36 /66 /64 /33 /65 /66 /41 /71 /59 /33 /58 /44 /129 /71 /50 /131/33 /66 /66 /33 /58 /44 /65/55 /50/36 /50 /66 /64 /45 /52 /35 /38 /64 /45\n/44 /36 /50 /125 /38 /36 /34 /66 /43 /45 /38 /36 /66 /45 /64 /36 /33 /59 /38 /36 /60 /50 /64 /76/33 /66 /38 /50 /36 /50 /60 /66 /43 /45 /66 /33 /64 /34 /45 /66 /76/50 /55 /45 /59 /41 /125 /43 /38 /58 /43\n/58 /33 /36 /71 /45 /60 /35 /64 /66 /43 /45 /64 /65 /45 /74 /33 /64 /33 /66 /45 /55 /38 /36 /66 /50 /52 /35 /45 /64 /48 /129 /71 /33 /65 /45 /55 /33 /36 /55 /66 /64 /33 /36 /65 /60 /45 /64 /129 /71 /33 /65 /45 /55\n/50 /36 /45 /65 /136 /37 /35 /45 /64 /48 /129 /71 /33 /65 /45 /55/33 /66 /66 /33 /58 /44 /65 /64 /45 /52 /35 /38 /64 /45 /45 /131 /66 /45 /36 /65 /38 /63 /45 /52 /35 /45 /64 /38 /45 /65 /50 /60 /66 /43 /45\n/50 /35 /66 /74 /35 /66 /50 /60 /66 /43 /45 /66 /33 /64 /34 /45 /66 /76/50 /55 /45 /59 /132 /40 /133 /41 /54 /40 /41 /54 /187 /41 /57 /54 /135 /41 /125 /43 /38 /58 /43/36 /50 /66 /50 /36 /59 /48\n/76/33 /44 /45 /65/66 /43 /45/66 /33 /64 /34 /45 /66 /76/50 /55 /45 /59 /65 /35 /65 /74 /45 /58 /66 /71 /35 /66 /33 /59 /65 /50/38 /36 /58 /64 /45 /33 /65 /45 /65/52 /35 /45 /64 /48\n/58 /50 /65 /66 /65 /136 /67 /64 /33 /36 /65 /60 /45 /64 /129 /71 /33 /65 /45 /55 /33 /66 /66 /33 /58 /44 /66 /64 /45 /33 /66 /65 /66 /43 /45 /66 /33 /64 /34 /45 /66 /76/50 /55 /45 /59 /33 /65 /33 /74 /35 /64 /45\n/71 /59 /33 /58 /44 /71 /50 /131 /41 /125 /43 /38 /58 /43 /58 /64 /33 /60 /66 /65 /33 /55 /63 /45 /64 /65 /33 /64 /38 /33 /59 /45 /131 /33 /76/74 /59 /45 /65 /35 /65 /38 /36 /34 /33 /65 /35 /71 /65 /66 /38 /129\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n4510\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LERF: Language Embedded Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kerr_LERF_Language_Embedded_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Justin Kerr, Chung Min Kim, Ken Goldberg, Angjoo Kanazawa, Matthew Tancik",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kerr_LERF_Language_Embedded_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley",
        "project": "",
        "github": "",
        "arxiv": "2303.09553"
    },
    {
        "title": "LFS-GAN: Lifelong Few-Shot Image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.html",
        "author": "Juwon Seo, Ji-Su Kang, Gyeong-Moon Park",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.pdf",
        "aff": "Kyung Hee University, Yongin, Republic of Korea; KLleon Tech., Seoul, Republic of Korea",
        "project": "",
        "github": "Available atGithub",
        "arxiv": ""
    },
    {
        "title": "LIMITR: Leveraging Local Information for Medical Image-Text Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.html",
        "author": "Gefen Dawidowicz, Elad Hirsch, Ayellet Tal",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.pdf",
        "aff": "Technion \u2013 Israel Institute of Technology, Cornell Tech; Technion \u2013 Israel Institute of Technology",
        "project": "",
        "github": "https://github.com/gefend/LIMITR",
        "arxiv": "2303.11755"
    },
    {
        "title": "LIST: Learning Implicitly from Spatial Transformers for Single-View 3D Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Arshad_LIST_Learning_Implicitly_from_Spatial_Transformers_for_Single-View_3D_Reconstruction_ICCV_2023_paper.html",
        "author": "Mohammad Samiul Arshad, William J. Beksi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Arshad_LIST_Learning_Implicitly_from_Spatial_Transformers_for_Single-View_3D_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2307.12194"
    },
    {
        "title": "LISTER: Neighbor Decoding for Length-Insensitive Scene Text Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_LISTER_Neighbor_Decoding_for_Length-Insensitive_Scene_Text_Recognition_ICCV_2023_paper.html",
        "author": "Changxu Cheng, Peng Wang, Cheng Da, Qi Zheng, Cong Yao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LISTER_Neighbor_Decoding_for_Length-Insensitive_Scene_Text_Recognition_ICCV_2023_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/AlibabaResearch/AdvancedLiterateMachinery",
        "arxiv": "2308.12774"
    },
    {
        "title": "LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_LLM-Planner_Few-Shot_Grounded_Planning_for_Embodied_Agents_with_Large_Language_ICCV_2023_paper.html",
        "author": "Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M Sadler, Wei-Lun Chao, Yu Su",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_LLM-Planner_Few-Shot_Grounded_Planning_for_Embodied_Agents_with_Large_Language_ICCV_2023_paper.pdf",
        "aff": "The Ohio State University; DEVCOM ARL",
        "project": "https://osu-nlp-group.github.io/LLM-Planner/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LMR: A Large-Scale Multi-Reference Dataset for Reference-Based Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LMR_A_Large-Scale_Multi-Reference_Dataset_for_Reference-Based_Super-Resolution_ICCV_2023_paper.html",
        "author": "Lin Zhang, Xin Li, Dongliang He, Fu Li, Errui Ding, Zhaoxiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LMR_A_Large-Scale_Multi-Reference_Dataset_for_Reference-Based_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Vision Technology (VIS), Baidu Inc.; Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/wdmwhh/MRefSR",
        "arxiv": "2303.04970"
    },
    {
        "title": "LNPL-MIL: Learning from Noisy Pseudo Labels for Promoting Multiple Instance Learning in Whole Slide Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.html",
        "author": "Zhuchen Shao, Yifeng Wang, Yang Chen, Hao Bian, Shaohui Liu, Haoqian Wang, Yongbing Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.pdf",
        "aff": "Harbin Institute of Technology (Shenzhen); Harbin Institute of Technology; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LPFF: A Portrait Dataset for Face Generators Across Large Poses",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_LPFF_A_Portrait_Dataset_for_Face_Generators_Across_Large_Poses_ICCV_2023_paper.html",
        "author": "Yiqian Wu, Jing Zhang, Hongbo Fu, Xiaogang Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_LPFF_A_Portrait_Dataset_for_Face_Generators_Across_Large_Poses_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; State Key Lab of CAD&CG, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2303.14407"
    },
    {
        "title": "LRRU: Long-short Range Recurrent Updating Networks for Depth Completion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_LRRU_Long-short_Range_Recurrent_Updating_Networks_for_Depth_Completion_ICCV_2023_paper.html",
        "author": "Yufei Wang, Bo Li, Ge Zhang, Qi Liu, Tao Gao, Yuchao Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_LRRU_Long-short_Range_Recurrent_Updating_Networks_for_Depth_Completion_ICCV_2023_paper.pdf",
        "aff": "Chang\u2019an University; Northwestern Polytechnical University and Shaanxi Key Laboratory of Information Acquisition and Processing",
        "project": "https://npucvr.github.io/LRRU/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LU-NeRF: Scene and Pose Estimation by Synchronizing Local Unposed NeRFs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_LU-NeRF_Scene_and_Pose_Estimation_by_Synchronizing_Local_Unposed_NeRFs_ICCV_2023_paper.html",
        "author": "Zezhou Cheng, Carlos Esteves, Varun Jampani, Abhishek Kar, Subhransu Maji, Ameesh Makadia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LU-NeRF_Scene_and_Pose_Estimation_by_Synchronizing_Local_Unposed_NeRFs_ICCV_2023_paper.pdf",
        "aff": "University of Massachusetts, Amherst; Google Research",
        "project": "https://zezhoucheng.github.io/lu-nerf/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LVOS: A Benchmark for Long-term Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hong_LVOS_A_Benchmark_for_Long-term_Video_Object_Segmentation_ICCV_2023_paper.html",
        "author": "Lingyi Hong, Wenchao Chen, Zhongying Liu, Wei Zhang, Pinxue Guo, Zhaoyu Chen, Wenqiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_LVOS_A_Benchmark_for_Long-term_Video_Object_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University; Academy for Engineering and Technology, Fudan University; Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University; Academy for Engineering and Technology, Fudan University",
        "project": "",
        "github": "https://lingyihongfd.github.io/lvos.github.io/",
        "arxiv": "2211.10181"
    },
    {
        "title": "LaPE: Layer-adaptive Position Embedding for Vision Transformers with Independent Layer Normalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_LaPE_Layer-adaptive_Position_Embedding_for_Vision_Transformers_with_Independent_Layer_ICCV_2023_paper.html",
        "author": "Runyi Yu, Zhennan Wang, Yinhuai Wang, Kehan Li, Chang Liu, Haoyi Duan, Xiangyang Ji, Jie Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_LaPE_Layer-adaptive_Position_Embedding_for_Vision_Transformers_with_Independent_Layer_ICCV_2023_paper.pdf",
        "aff": "LaPE: Layer-adaptive Position Embedding for Vision Transformers\nwith Independent Layer Normalization\nRunyi Yu1,3\u2217Zhennan Wang2\u2217Yinhuai Wang1\u2217Kehan Li1,3Chang Liu4\nHaoyi Duan5Xiangyang Ji4Jie Chen1,2,3B\n1School of Electronic and Computer Engineering, Peking University, Shenzhen, China2Peng Cheng Laboratory, Shenzhen, China\n3AI for Science (AI4S)-Preferred Program, Peking University Shenzhen Graduate School, China\n4Department of Automation and BNRist, Tsinghua University, Beijing, China\n5School of Computer Science and Technology, Zhejiang University, Zhejiang, China\njiechen2019@pku.edu.cn\nAbstract\nPosition information is critical for Vision Transformers\n(VTs) due to the permutation-invariance of self-attention\noperations. A typical way to introduce position information\nis adding the absolute Position Embedding (PE) to patch\nembedding before entering VTs. However, this approach\noperates the same Layer Normalization (LN) to token em-\nbedding and PE, and delivers the same PE to each layer.\nThis results in restricted and monotonic PE across layers,\nas the shared LN affine parameters are not dedicated to\nPE, and the PE cannot be adjusted on a per-layer basis.\nTo overcome these limitations, we propose using two inde-\npendent LNs for token embeddings and PE in each layer,\nand progressively delivering PE across layers. By imple-\nmenting this approach, VTs will receive layer-adaptive and\nhierarchical PE. We name our method as Layer- adaptive\nPosition Embedding, abbreviated as LaPE, which is sim-\nple, effective, and robust. Extensive experiments on image\nclassification, object detection, and semantic segmentation\ndemonstrate that LaPE significantly outperforms the default\nPE method. For example, LaPE improves +1.06% for CCT\non CIFAR100, +1.57% for DeiT-Ti on ImageNet-1K, +0.7\nbox AP and +0.5 mask AP for ViT-Adapter-Ti on COCO,\nand +1.37 mIoU for tiny Segmenter on ADE20K. This is\nremarkable considering LaPE only increases negligible pa-\nrameters, memory, and computational cost.\n1. Introduction\nVision Transformer (VT) has become one of the most\npopular research topics due to its superior performance on\n\u2217Equal Contribution.BCorresponding author. Project page:\nhttps://github.com/Ingrid725/LaPE\nLNT\nLNPPosition\nEmbeddingToken\nEmbedding\n(b) The proposed LaPE\u2295Independent LN\nHierarchical and Layer -adaptive\u2295 LN\nPosition\nEmbeddingToken\nEmbeddingShared LN\n1-D sinusoidal PE\nVisualization of PE correlation\nMonotonic and Unadjustedlayer1\nVisualization of PE correlation(a) Default PE joining method2 3 4 5\nlayer1 2 3 4 5\n1-D sinusoidal PE\nFigure 1. A brief illustration of the default PE joining method\nand our proposed LaPE. We take T2T-ViT-7 with 1-D sinusoidal\nPE as an example, and we visualize the position correlation of first\n5 layers to explain the emphasis and advantages of our method.\n(a) By default, token embedding and PE are coupled together and\ntreated with the same Layer Normalization (LN) in each layer.\nThis yields monotonic and limited position correlations. (b) We\nargue that each layer\u2019s token embedding and PE need independent\nLNs (LN T, LN P). In this way, the expressiveness of PE is en-\nhanced and the position correlations are adjusted into hierarchical\nand layer-adaptive.\nvarious computer vision tasks, such as image classifica-\ntion, object detection, and semantic segmentation. ViT\n[10] is the first pure transformer model for image classi-\nfication, which outperforms CNNs when applied to large\ntraining data. Since then, many works based on ViT [10]\nhave sprung up. Lots of work improves the tokenization\n[14, 44], self-attention mechanism [23, 45, 35, 9], archite-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n5886\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LaRS: A Diverse Panoptic Maritime Obstacle Detection Dataset and Benchmark",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zust_LaRS_A_Diverse_Panoptic_Maritime_Obstacle_Detection_Dataset_and_Benchmark_ICCV_2023_paper.html",
        "author": "Lojze \u017dust, Janez Per\u0161, Matej Kristan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zust_LaRS_A_Diverse_Panoptic_Maritime_Obstacle_Detection_Dataset_and_Benchmark_ICCV_2023_paper.pdf",
        "aff": "University of Ljubljana",
        "project": "https://lojzezust.github.io/lars-dataset",
        "github": "https://github.com/lojzezust/lars-dataset",
        "arxiv": ""
    },
    {
        "title": "Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_Label_Shift_Adapter_for_Test-Time_Adaptation_under_Covariate_and_Label_ICCV_2023_paper.html",
        "author": "Sunghyun Park, Seunghan Yang, Jaegul Choo, Sungrack Yun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Label_Shift_Adapter_for_Test-Time_Adaptation_under_Covariate_and_Label_ICCV_2023_paper.pdf",
        "aff": "KAIST; Qualcomm AI Research*",
        "project": "",
        "github": "",
        "arxiv": "2308.08810"
    },
    {
        "title": "Label-Efficient Online Continual Object Detection in Streaming Video",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Label-Efficient_Online_Continual_Object_Detection_in_Streaming_Video_ICCV_2023_paper.html",
        "author": "Jay Zhangjie Wu, David Junhao Zhang, Wynne Hsu, Mengmi Zhang, Mike Zheng Shou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Label-Efficient_Online_Continual_Object_Detection_in_Streaming_Video_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; Show Lab; National University of Singapore",
        "project": "",
        "github": "https://github.com/showlab/Efficient-CLS",
        "arxiv": "2206.00309"
    },
    {
        "title": "Label-Free Event-based Object Recognition via Joint Learning with Image Reconstruction from Events",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.html",
        "author": "Hoonhee Cho, Hyeonseong Kim, Yujeong Chae, Kuk-Jin Yoon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology",
        "project": "",
        "github": "https://github.com/Chohoonhee/Ev-LaFOR",
        "arxiv": "2308.09383"
    },
    {
        "title": "Label-Guided Knowledge Distillation for Continual Semantic Segmentation on 2D Images and 3D Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Label-Guided_Knowledge_Distillation_for_Continual_Semantic_Segmentation_on_2D_Images_ICCV_2023_paper.html",
        "author": "Ze Yang, Ruibo Li, Evan Ling, Chi Zhang, Yiming Wang, Dezhao Huang, Keng Teck Ma, Minhoe Hur, Guosheng Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Label-Guided_Knowledge_Distillation_for_Continual_Semantic_Segmentation_on_2D_Images_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; AIRS Company, Hyundai Motor Group; Hyundai Motor Group Innovation Center in Singapore (HMGICS)",
        "project": "",
        "github": "https://github.com/Ze-Yang/LGKD",
        "arxiv": ""
    },
    {
        "title": "Label-Noise Learning with Intrinsically Long-Tailed Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Label-Noise_Learning_with_Intrinsically_Long-Tailed_Data_ICCV_2023_paper.html",
        "author": "Yang Lu, Yiliang Zhang, Bo Han, Yiu-ming Cheung, Hanzi Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Label-Noise_Learning_with_Intrinsically_Long-Tailed_Data_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Hong Kong Baptist University, Hong Kong, China; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Informatics, Xiamen University, Xiamen, China; Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University, Xiamen, China",
        "project": "",
        "github": "https://github.com/Wakings/TABASCO",
        "arxiv": "2208.09833"
    },
    {
        "title": "Landscape Learning for Neural Network Inversion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Landscape_Learning_for_Neural_Network_Inversion_ICCV_2023_paper.html",
        "author": "Ruoshi Liu, Chengzhi Mao, Purva Tendulkar, Hao Wang, Carl Vondrick",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Landscape_Learning_for_Neural_Network_Inversion_ICCV_2023_paper.pdf",
        "aff": "Rutgers University; Columbia University",
        "project": "",
        "github": "",
        "arxiv": "2206.09027"
    },
    {
        "title": "Large Selective Kernel Network for Remote Sensing Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.html",
        "author": "Yuxuan Li, Qibin Hou, Zhaohui Zheng, Ming-Ming Cheng, Jian Yang, Xiang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "VCIP, CS, Nankai University",
        "project": "https://github.com/zcablii/LSKNet",
        "github": "https://github.com/IMPlus-PCALab",
        "arxiv": "2303.09030"
    },
    {
        "title": "Large-Scale Land Cover Mapping with Fine-Grained Classes via Class-Aware Semi-Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Large-Scale_Land_Cover_Mapping_with_Fine-Grained_Classes_via_Class-Aware_Semi-Supervised_ICCV_2023_paper.html",
        "author": "Runmin Dong, Lichao Mou, Mengxuan Chen, Weijia Li, Xin-Yi Tong, Shuai Yuan, Lixian Zhang, Juepeng Zheng, Xiaoxiang Zhu, Haohuan Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Large-Scale_Land_Cover_Mapping_with_Fine-Grained_Classes_via_Class-Aware_Semi-Supervised_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich; Sun Yat-Sen University; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Large-Scale Person Detection and Localization Using Overhead Fisheye Cameras",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Large-Scale_Person_Detection_and_Localization_Using_Overhead_Fisheye_Cameras_ICCV_2023_paper.html",
        "author": "Lu Yang, Liulei Li, Xueshi Xin, Yifan Sun, Qing Song, Wenguan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Large-Scale_Person_Detection_and_Localization_Using_Overhead_Fisheye_Cameras_ICCV_2023_paper.pdf",
        "aff": "ReLER, CCAI, Zhejiang University; Beijing University of Posts and Telecommunications; ReLER, AAII, University of Technology Sydney; Baidu",
        "project": "https://LOAFisheye.github.io/",
        "github": "",
        "arxiv": "2307.08252"
    },
    {
        "title": "Late Stopping: Avoiding Confidently Learning from Mislabeled Examples",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Late_Stopping_Avoiding_Confidently_Learning_from_Mislabeled_Examples_ICCV_2023_paper.html",
        "author": "Suqin Yuan, Lei Feng, Tongliang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Late_Stopping_Avoiding_Confidently_Learning_from_Mislabeled_Examples_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": "2308.13862"
    },
    {
        "title": "Latent-OFER: Detect, Mask, and Reconstruct with Latent Vectors for Occluded Facial Expression Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Latent-OFER_Detect_Mask_and_Reconstruct_with_Latent_Vectors_for_Occluded_ICCV_2023_paper.html",
        "author": "Isack Lee, Eungi Lee, Seok Bong Yoo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Latent-OFER_Detect_Mask_and_Reconstruct_with_Latent_Vectors_for_Occluded_ICCV_2023_paper.pdf",
        "aff": "Department of Artificial Intelligence Convergence, Chonnam National University, Gwangju, Korea",
        "project": "",
        "github": "https://github.com/leeisack/Latent-OFER",
        "arxiv": ""
    },
    {
        "title": "LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LayoutDiffusion_Improving_Graphic_Layout_Generation_by_Discrete_Diffusion_Probabilistic_Models_ICCV_2023_paper.html",
        "author": "Junyi Zhang, Jiaqi Guo, Shizhao Sun, Jian-Guang Lou, Dongmei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LayoutDiffusion_Improving_Graphic_Layout_Generation_by_Discrete_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; Shanghai Jiao Tong University",
        "project": "https://layoutdiffusion.github.io",
        "github": "",
        "arxiv": "2303.11589"
    },
    {
        "title": "LeaF: Learning Frames for 4D Point Cloud Sequence Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_LeaF_Learning_Frames_for_4D_Point_Cloud_Sequence_Understanding_ICCV_2023_paper.html",
        "author": "Yunze Liu, Junyu Chen, Zekai Zhang, Jingwei Huang, Li Yi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_LeaF_Learning_Frames_for_4D_Point_Cloud_Sequence_Understanding_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University, Shanghai Artificial Intelligence Laboratory, Shanghai Qi Zhi Institute; Tsinghua University; Huawei",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Leaping Into Memories: Space-Time Deep Feature Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Stergiou_Leaping_Into_Memories_Space-Time_Deep_Feature_Synthesis_ICCV_2023_paper.html",
        "author": "Alexandros Stergiou, Nikos Deligiannis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Stergiou_Leaping_Into_Memories_Space-Time_Deep_Feature_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Vrije Universiteit Brussel, Belgium & imec, Belgium",
        "project": "",
        "github": "https://github.com/alexandrosstergiou/LEAPS",
        "arxiv": "2303.09941"
    },
    {
        "title": "Learn TAROT with MENTOR: A Meta-Learned Self-Supervised Approach for Trajectory Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.html",
        "author": "Mozhgan Pourkeshavarz, Changhe Chen, Amir Rasouli",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.pdf",
        "aff": "Noah\u2019s Ark Lab, Huawei, Toronto, Canada",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learned Compressive Representations for Single-Photon 3D Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gutierrez-Barragan_Learned_Compressive_Representations_for_Single-Photon_3D_Imaging_ICCV_2023_paper.html",
        "author": "Felipe Gutierrez-Barragan, Fangzhou Mu, Andrei Ardelean, Atul Ingle, Claudio Bruschini, Edoardo Charbon, Yin Li, Mohit Gupta, Andreas Velten",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gutierrez-Barragan_Learned_Compressive_Representations_for_Single-Photon_3D_Imaging_ICCV_2023_paper.pdf",
        "aff": "Ecole Polytechnique Federale de Lausanne; Portland State University; University of Wisconsin-Madison",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learned Image Reasoning Prior Penetrates Deep Unfolding Network for Panchromatic and Multi-spectral Image Fusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learned_Image_Reasoning_Prior_Penetrates_Deep_Unfolding_Network_for_Panchromatic_ICCV_2023_paper.html",
        "author": "Man Zhou, Jie Huang, Naishan Zheng, Chongyi Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learned_Image_Reasoning_Prior_Penetrates_Deep_Unfolding_Network_for_Panchromatic_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, China; S-Lab, Nanyang Technological University, Singapore; Nankai University, China",
        "project": "",
        "github": "https://manman1995.github.io/",
        "arxiv": "2308.16083"
    },
    {
        "title": "Learning Adaptive Neighborhoods for Graph Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Saha_Learning_Adaptive_Neighborhoods_for_Graph_Neural_Networks_ICCV_2023_paper.html",
        "author": "Avishkar Saha, Oscar Mendez, Chris Russell, Richard Bowden",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_Learning_Adaptive_Neighborhoods_for_Graph_Neural_Networks_ICCV_2023_paper.pdf",
        "aff": "Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK; University of Oxford, Oxford, UK",
        "project": "",
        "github": "",
        "arxiv": "2307.09065"
    },
    {
        "title": "Learning Clothing and Pose Invariant 3D Shape Representation for Long-Term Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Clothing_and_Pose_Invariant_3D_Shape_Representation_for_Long-Term_ICCV_2023_paper.html",
        "author": "Feng Liu, Minchul Kim, ZiAng Gu, Anil Jain, Xiaoming Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Clothing_and_Pose_Invariant_3D_Shape_Representation_for_Long-Term_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, Michigan State University, East Lansing MI 48824",
        "project": "http://cvlab.cse.msu.edu/project-reid3dinvar.html",
        "github": "",
        "arxiv": "2308.10658"
    },
    {
        "title": "Learning Concise and Descriptive Attributes for Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Learning_Concise_and_Descriptive_Attributes_for_Visual_Recognition_ICCV_2023_paper.html",
        "author": "An Yan, Yu Wang, Yiwu Zhong, Chengyu Dong, Zexue He, Yujie Lu, William Yang Wang, Jingbo Shang, Julian McAuley",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Learning_Concise_and_Descriptive_Attributes_for_Visual_Recognition_ICCV_2023_paper.pdf",
        "aff": "UC San Diego; University of Wisconsin-Madison; UC Santa Barbara",
        "project": "",
        "github": "",
        "arxiv": "2308.03685"
    },
    {
        "title": "Learning Concordant Attention via Target-aware Alignment for Visible-Infrared Person Re-identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Learning_Concordant_Attention_via_Target-aware_Alignment_for_Visible-Infrared_Person_Re-identification_ICCV_2023_paper.html",
        "author": "Jianbing Wu, Hong Liu, Yuxin Su, Wei Shi, Hao Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Concordant_Attention_via_Target-aware_Alignment_for_Visible-Infrared_Person_Re-identification_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Lab, ETH Z\u00fcrich, Switzerland; Key Laboratory of Machine Perception, Shenzhen Graduate School, Peking University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Continuous Exposure Value Representations for Single-Image HDR Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Learning_Continuous_Exposure_Value_Representations_for_Single-Image_HDR_Reconstruction_ICCV_2023_paper.html",
        "author": "Su-Kai Chen, Hung-Lin Yen, Yu-Lun Liu, Min-Hung Chen, Hou-Ning Hu, Wen-Hsiao Peng, Yen-Yu Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_Continuous_Exposure_Value_Representations_for_Single-Image_HDR_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "NVIDIA; National Yang Ming Chiao Tung University; MediaTek Inc.",
        "project": "https://skchen1993.github.io/CEVR_web/",
        "github": "",
        "arxiv": "2309.03900"
    },
    {
        "title": "Learning Correction Filter via Degradation-Adaptive Regression for Blind Single Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.html",
        "author": "Hongyang Zhou, Xiaobin Zhu, Jianqing Zhu, Zheng Han, Shi-Xue Zhang, Jingyan Qin, Xu-Cheng Yin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.pdf",
        "aff": "University Of Science and Technology Beijing; College of Engineering, Huaqiao University",
        "project": "",
        "github": "https://github.com/edbca/DARSR",
        "arxiv": ""
    },
    {
        "title": "Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_Cross-Modal_Affinity_for_Referring_Video_Object_Segmentation_Targeting_Limited_ICCV_2023_paper.html",
        "author": "Guanghui Li, Mingqi Gao, Heng Liu, Xiantong Zhen, Feng Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Cross-Modal_Affinity_for_Referring_Video_Object_Segmentation_Targeting_Limited_ICCV_2023_paper.pdf",
        "aff": "Southern University of Science and Technology; United Imaging; Anhui University of Technology",
        "project": "",
        "github": "https://github.com/hengliusky/Few_shot_RVOS",
        "arxiv": "2309.02041"
    },
    {
        "title": "Learning Cross-Representation Affinity Consistency for Sparsely Supervised Biomedical Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Cross-Representation_Affinity_Consistency_for_Sparsely_Supervised_Biomedical_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Xiaoyu Liu, Wei Huang, Zhiwei Xiong, Shenglong Zhou, Yueyi Zhang, Xuejin Chen, Zheng-Jun Zha, Feng Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Cross-Representation_Affinity_Consistency_for_Sparsely_Supervised_Biomedical_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/liuxy1103/CRAC",
        "arxiv": ""
    },
    {
        "title": "Learning Data-Driven Vector-Quantized Degradation Model for Animation Video Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.html",
        "author": "Zixi Tuo, Huan Yang, Jianlong Fu, Yujie Dun, Xueming Qian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "Shaanxi Yulan Jiuzhou Intelligent Optoelectronic Technology Co., Ltd; Microsoft Research Asia; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "https://github.com/researchmm/VQD-SR",
        "arxiv": "2303.09826"
    },
    {
        "title": "Learning Depth Estimation for Transparent and Mirror Surfaces",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Costanzino_Learning_Depth_Estimation_for_Transparent_and_Mirror_Surfaces_ICCV_2023_paper.html",
        "author": "Alex Costanzino, Pierluigi Zama Ramirez, Matteo Poggi, Fabio Tosi, Stefano Mattoccia, Luigi Di Stefano",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Costanzino_Learning_Depth_Estimation_for_Transparent_and_Mirror_Surfaces_ICCV_2023_paper.pdf",
        "aff": "CVLAB, Department of Computer Science and Engineering (DISI), University of Bologna, Italy",
        "project": "https://cvlab-unibo.github.io/Depth4ToM/",
        "github": "",
        "arxiv": "2307.15052"
    },
    {
        "title": "Learning Fine-Grained Features for Pixel-Wise Video Correspondences",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_Fine-Grained_Features_for_Pixel-Wise_Video_Correspondences_ICCV_2023_paper.html",
        "author": "Rui Li, Shenglong Zhou, Dong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Fine-Grained_Features_for_Pixel-Wise_Video_Correspondences_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Hefei, China",
        "project": "",
        "github": "https://github.com/qianduoduolr/FGVC",
        "arxiv": "2308.03040"
    },
    {
        "title": "Learning Foresightful Dense Visual Affordance for Deformable Object Manipulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.html",
        "author": "Ruihai Wu, Chuanruo Ning, Hao Dong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.pdf",
        "aff": "School of EECS, PKU; CFCS, School of CS, PKU; BAAI; National Key Laboratory for Multimedia Information Processing, School of CS, PKU",
        "project": "https://hyperplane-lab.github.io/DeformableAffordance",
        "github": "",
        "arxiv": "2303.11057"
    },
    {
        "title": "Learning Gabor Texture Features for Fine-Grained Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Learning_Gabor_Texture_Features_for_Fine-Grained_Recognition_ICCV_2023_paper.html",
        "author": "Lanyun Zhu, Tianrun Chen, Jianxiong Yin, Simon See, Jun Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Learning_Gabor_Texture_Features_for_Fine-Grained_Recognition_ICCV_2023_paper.pdf",
        "aff": "NVIDIA AI Tech Centre; Singapore University of Technology and Design; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2308.05396"
    },
    {
        "title": "Learning Global-aware Kernel for Image Harmonization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.html",
        "author": "Xintian Shen, Jiangning Zhang, Jun Chen, Shipeng Bai, Yue Han, Yabiao Wang, Chengjie Wang, Yong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.pdf",
        "aff": "Youtu Lab, Tencent; Shanghai Jiao Tong University; Youtu Lab, Tencent; APRIL Lab, Zhejiang University",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2305.11676"
    },
    {
        "title": "Learning Hierarchical Features with Joint Latent Space Energy-Based Prior",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Learning_Hierarchical_Features_with_Joint_Latent_Space_Energy-Based_Prior_ICCV_2023_paper.html",
        "author": "Jiali Cui, Ying Nian Wu, Tian Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Learning_Hierarchical_Features_with_Joint_Latent_Space_Energy-Based_Prior_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Stevens Institute of Technology; Department of Statistics, University of California, Los Angeles",
        "project": "https://jcui1224.github.io/hierarchical-representation-ebm-proj/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Human Dynamics in Autonomous Driving Scenarios",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_paper.html",
        "author": "Jingbo Wang, Ye Yuan, Zhengyi Luo, Kevin Xie, Dahua Lin, Umar Iqbal, Sanja Fidler, Sameh Khamis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_paper.pdf",
        "aff": "NVIDIA, Carnegie Mellon University; The Chinese University of Hong Kong; NVIDIA, The Chinese University of Hong Kong; NVIDIA, University of Toronto, Vector Institute; NVIDIA; NVIDIA, University of Toronto",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Human-Human Interactions in Images from Weak Textual Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Alper_Learning_Human-Human_Interactions_in_Images_from_Weak_Textual_Supervision_ICCV_2023_paper.html",
        "author": "Morris Alper, Hadar Averbuch-Elor",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Alper_Learning_Human-Human_Interactions_in_Images_from_Weak_Textual_Supervision_ICCV_2023_paper.pdf",
        "aff": "Tel Aviv University",
        "project": "",
        "github": "https://learning-interactions.github.io",
        "arxiv": "2304.14104"
    },
    {
        "title": "Learning Image Harmonization in the Linear Color Space",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Learning_Image_Harmonization_in_the_Linear_Color_Space_ICCV_2023_paper.html",
        "author": "Ke Xu, Gerhard Petrus Hancke, Rynson W.H. Lau",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Learning_Image_Harmonization_in_the_Linear_Color_Space_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Image-Adaptive Codebooks for Class-Agnostic Image Restoration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Image-Adaptive_Codebooks_for_Class-Agnostic_Image_Restoration_ICCV_2023_paper.html",
        "author": "Kechun Liu, Yitong Jiang, Inchang Choi, Jinwei Gu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Image-Adaptive_Codebooks_for_Class-Agnostic_Image_Restoration_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; SenseBrain; University of Washington",
        "project": "",
        "github": "https://github.com/kechunl/AdaCode",
        "arxiv": "2306.06513"
    },
    {
        "title": "Learning Long-Range Information with Dual-Scale Transformers for Indoor Scene Completion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Long-Range_Information_with_Dual-Scale_Transformers_for_Indoor_Scene_Completion_ICCV_2023_paper.html",
        "author": "Ziqi Wang, Fei Luo, Xiaoxiao Long, Wenxiao Zhang, Chunxia Xiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Long-Range_Information_with_Dual-Scale_Transformers_for_Indoor_Scene_Completion_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Wuhan University; ISTD, Singapore University of Technology and Design",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Navigational Visual Representations with Semantic Map Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Learning_Navigational_Visual_Representations_with_Semantic_Map_Supervision_ICCV_2023_paper.html",
        "author": "Yicong Hong, Yang Zhou, Ruiyi Zhang, Franck Dernoncourt, Trung Bui, Stephen Gould, Hao Tan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Learning_Navigational_Visual_Representations_with_Semantic_Map_Supervision_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; The Australian National University",
        "project": "",
        "github": "https://github.com/YicongHong/Ego2Map-NaViT",
        "arxiv": "2307.12335"
    },
    {
        "title": "Learning Neural Eigenfunctions for Unsupervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Learning_Neural_Eigenfunctions_for_Unsupervised_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Zhijie Deng, Yucen Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Learning_Neural_Eigenfunctions_for_Unsupervised_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Shanghai Jiao Tong University, Shanghai, China; Max Planck Institute for Intelligent Systems, T\u00a8ubingen, Germany",
        "project": "",
        "github": "https://github.com/thudzj/NeuralEigenfunctionSegmentor",
        "arxiv": "2304.02841"
    },
    {
        "title": "Learning Neural Implicit Surfaces with Object-Aware Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Neural_Implicit_Surfaces_with_Object-Aware_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Yiheng Zhang, Zhaofan Qiu, Yingwei Pan, Ting Yao, Tao Mei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Neural_Implicit_Surfaces_with_Object-Aware_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "HiDream.ai Inc.; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Non-Local Spatial-Angular Correlation for Light Field Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.html",
        "author": "Zhengyu Liang, Yingqian Wang, Longguang Wang, Jungang Yang, Shilin Zhou, Yulan Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "Aviation University of Air Force; National University of Defense Technology",
        "project": "",
        "github": "https://github.com/ZhengyuLiang24/EPIT",
        "arxiv": "2302.08058"
    },
    {
        "title": "Learning Optical Flow from Event Camera with Rendered Dataset",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Learning_Optical_Flow_from_Event_Camera_with_Rendered_Dataset_ICCV_2023_paper.html",
        "author": "Xinglong Luo, Kunming Luo, Ao Luo, Zhengning Wang, Ping Tan, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Learning_Optical_Flow_from_Event_Camera_with_Rendered_Dataset_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; The Hong Kong University of Science and Technology; Megvii Technology",
        "project": "",
        "github": "https://github.com/boomluo02/ADMFlow",
        "arxiv": "2303.11011"
    },
    {
        "title": "Learning Point Cloud Completion without Complete Point Clouds: A Pose-Aware Approach",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Learning_Point_Cloud_Completion_without_Complete_Point_Clouds_A_Pose-Aware_ICCV_2023_paper.html",
        "author": "Jihun Kim, Hyeokjun Kweon, Yunseo Yang, Kuk-Jin Yoon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Learning_Point_Cloud_Completion_without_Complete_Point_Clouds_A_Pose-Aware_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n14203\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Pseudo-Relations for Cross-domain Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Pseudo-Relations_for_Cross-domain_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Dong Zhao, Shuang Wang, Qi Zang, Dou Quan, Xiutiao Ye, Rui Yang, Licheng Jiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Pseudo-Relations_for_Cross-domain_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "School of Arti\ufb01cial Intelligence, Xidian University, Shaanxi, China",
        "project": "",
        "github": "https://github.com/DZhaoXd/RTea",
        "arxiv": ""
    },
    {
        "title": "Learning Rain Location Prior for Nighttime Deraining",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Rain_Location_Prior_for_Nighttime_Deraining_ICCV_2023_paper.html",
        "author": "Fan Zhang, Shaodi You, Yu Li, Ying Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Rain_Location_Prior_for_Nighttime_Deraining_ICCV_2023_paper.pdf",
        "aff": "International Digital Economy Academy; Beijing Institute of Technology; University of Amsterdam",
        "project": "",
        "github": "https://github.com/zkawfanx/RLP",
        "arxiv": ""
    },
    {
        "title": "Learning Robust Representations with Information Bottleneck and Memory Network for RGB-D-based Gesture Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_Robust_Representations_with_Information_Bottleneck_and_Memory_Network_for_ICCV_2023_paper.html",
        "author": "Yunan Li, Huizhou Chen, Guanwen Feng, Qiguang Miao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Robust_Representations_with_Information_Bottleneck_and_Memory_Network_for_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Technology, Xidian University, China; Xi\u2019an Key Laboratory of Big Data and Intelligent Vision, China; Key Laboratory of Smart Human-Computer Interaction and Wearable Technology of Shaanxi Province, China; School of Computer Science and Technology, Xidian University, China; Xi\u2019an Key Laboratory of Big Data and Intelligent Vision, China",
        "project": "",
        "github": "https://github.com/Carpumpkin/InBoMem",
        "arxiv": ""
    },
    {
        "title": "Learning Semi-supervised Gaussian Mixture Models for Generalized Category Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery_ICCV_2023_paper.html",
        "author": "Bingchen Zhao, Xin Wen, Kai Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery_ICCV_2023_paper.pdf",
        "aff": "University of Edinburgh; The University of Hong Kong",
        "project": "",
        "github": "https://github.com/DTennant/GPC",
        "arxiv": "2305.06144"
    },
    {
        "title": "Learning Shape Primitives via Implicit Convexity Regularization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Learning_Shape_Primitives_via_Implicit_Convexity_Regularization_ICCV_2023_paper.html",
        "author": "Xiaoyang Huang, Yi Zhang, Kai Chen, Teng Li, Wenjun Zhang, Bingbing Ni",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Learning_Shape_Primitives_via_Implicit_Convexity_Regularization_ICCV_2023_paper.pdf",
        "aff": "Anhui University; Shanghai Jiao Tong University, Shanghai 200240, China; Shanghai Jiao Tong University, Shanghai 200240, China; USC-SJTU Institute of Cultural and Creative Industry",
        "project": "",
        "github": "https://github.com/seanywang0408/ICR",
        "arxiv": ""
    },
    {
        "title": "Learning Spatial-context-aware Global Visual Feature Representation for Instance Image Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Spatial-context-aware_Global_Visual_Feature_Representation_for_Instance_Image_Retrieval_ICCV_2023_paper.html",
        "author": "Zhongyan Zhang, Lei Wang, Luping Zhou, Piotr Koniusz",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Spatial-context-aware_Global_Visual_Feature_Representation_for_Instance_Image_Retrieval_ICCV_2023_paper.pdf",
        "aff": "Data61 rCSIRO, Australian National University; University of Sydney; University of Wollongong",
        "project": "",
        "github": "https://github.com/Zy-Zhang/SpCa",
        "arxiv": ""
    },
    {
        "title": "Learning Support and Trivial Prototypes for Interpretable Image Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.html",
        "author": "Chong Wang, Yuyuan Liu, Yuanhong Chen, Fengbei Liu, Yu Tian, Davis McCarthy, Helen Frazer, Gustavo Carneiro",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.pdf",
        "aff": "Harvard University; CVSSP, University of Surrey; St Vincent\u2019s Hospital Melbourne; St Vincent\u2019s Institute of Medical Research; Australian Institute for Machine Learning, University of Adelaide",
        "project": "",
        "github": "",
        "arxiv": "2301.04011"
    },
    {
        "title": "Learning Symmetry-Aware Geometry Correspondences for 6D Object Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Symmetry-Aware_Geometry_Correspondences_for_6D_Object_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Heng Zhao, Shenxing Wei, Dahu Shi, Wenming Tan, Zheyang Li, Ye Ren, Xing Wei, Yi Yang, Shiliang Pu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Symmetry-Aware_Geometry_Correspondences_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "Xi\u2019an Jiaotong University; Zhejiang University; Hikvision Research Institute",
        "project": "",
        "github": "https://github.com/hikvision-research/GCPose",
        "arxiv": ""
    },
    {
        "title": "Learning Trajectory-Word Alignments for Video-Language Tasks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Learning_Trajectory-Word_Alignments_for_Video-Language_Tasks_ICCV_2023_paper.html",
        "author": "Xu Yang, Zhangzikang Li, Haiyang Xu, Hanwang Zhang, Qinghao Ye, Chenliang Li, Ming Yan, Yu Zhang, Fei Huang, Songfang Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Learning_Trajectory-Word_Alignments_for_Video-Language_Tasks_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science & Engineering, Nanyang Technological University; School of Computer Science & Engineering, Key Lab of New Generation Arti\ufb01cial Intelligence Technology & Its Interdisciplinary Applications (Ministry of Education), Southeast University; DAMO Academy, Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": "2301.01953"
    },
    {
        "title": "Learning Unified Decompositional and Compositional NeRF for Editable Novel View Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Unified_Decompositional_and_Compositional_NeRF_for_Editable_Novel_View_ICCV_2023_paper.html",
        "author": "Yuxin Wang, Wayne Wu, Dan Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Unified_Decompositional_and_Compositional_NeRF_for_Editable_Novel_View_ICCV_2023_paper.pdf",
        "aff": "Shanghai Artificial Intelligence Laboratory; Hong Kong University of Science and Technology",
        "project": "https://w-ted.github.io/publications/udc-nerf",
        "github": "",
        "arxiv": "2308.02840"
    },
    {
        "title": "Learning Versatile 3D Shape Generation with Improved Auto-regressive Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Learning_Versatile_3D_Shape_Generation_with_Improved_Auto-regressive_Models_ICCV_2023_paper.html",
        "author": "Simian Luo, Xuelin Qian, Yanwei Fu, Yinda Zhang, Ying Tai, Zhenyu Zhang, Chengjie Wang, Xiangyang Xue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Learning_Versatile_3D_Shape_Generation_with_Improved_Auto-regressive_Models_ICCV_2023_paper.pdf",
        "aff": "Fudan University; Google; Tencent Youtu Lab",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Vision-and-Language Navigation from YouTube Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Learning_Vision-and-Language_Navigation_from_YouTube_Videos_ICCV_2023_paper.html",
        "author": "Kunyang Lin, Peihao Chen, Diwei Huang, Thomas H. Li, Mingkui Tan, Chuang Gan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Learning_Vision-and-Language_Navigation_from_YouTube_Videos_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology; Peking University Shenzhen Graduate School; MIT-IBM Watson AI Lab",
        "project": "",
        "github": "https://github.com/JeremyLinky/YouTube-VLN",
        "arxiv": "2307.11984"
    },
    {
        "title": "Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.html",
        "author": "Junsheng Zhou, Baorui Ma, Shujuan Li, Yu-Shen Liu, Zhizhong Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.pdf",
        "aff": "Beijing Academy of Artificial Intelligence, Beijing, China; Department of Computer Science, Wayne State University, Detroit, USA; School of Software, Tsinghua University, Beijing, China",
        "project": "",
        "github": "https://github.com/junshengzhou/LevelSetUDF",
        "arxiv": "2308.11441"
    },
    {
        "title": "Learning a Room with the Occ-SDF Hybrid: Signed Distance Function Mingled with Occupancy Aids Scene Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lyu_Learning_a_Room_with_the_Occ-SDF_Hybrid_Signed_Distance_Function_ICCV_2023_paper.html",
        "author": "Xiaoyang Lyu, Peng Dai, Zizhang Li, Dongyu Yan, Yi Lin, Yifan Peng, Xiaojuan Qi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Learning_a_Room_with_the_Occ-SDF_Hybrid_Signed_Distance_Function_ICCV_2023_paper.pdf",
        "aff": "Harbin Institute of Technology; The University of Hong Kong; Zhejiang University; DJI",
        "project": "",
        "github": "https://github.com/shawLyu/Occ-SDF-Hybrid",
        "arxiv": "2303.09152"
    },
    {
        "title": "Learning by Sorting: Self-supervised Learning with Group Ordering Constraints",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shvetsova_Learning_by_Sorting_Self-supervised_Learning_with_Group_Ordering_Constraints_ICCV_2023_paper.html",
        "author": "Nina Shvetsova, Felix Petersen, Anna Kukleva, Bernt Schiele, Hilde Kuehne",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shvetsova_Learning_by_Sorting_Self-supervised_Learning_with_Group_Ordering_Constraints_ICCV_2023_paper.pdf",
        "aff": "Max-Planck-Institute for Informatics; Goethe University Frankfurt; Stanford University; University of Bonn",
        "project": "",
        "github": "https://github.com/ninatu/learning_by_sorting",
        "arxiv": "2301.02009"
    },
    {
        "title": "Learning from Noisy Data for Semi-Supervised 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Learning_from_Noisy_Data_for_Semi-Supervised_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Zehui Chen, Zhenyu Li, Shuo Wang, Dengpan Fu, Feng Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_from_Noisy_Data_for_Semi-Supervised_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "NIO; Harbin Institute of Technology; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/zehuichen123/NoiseDet",
        "arxiv": ""
    },
    {
        "title": "Learning from Noisy Pseudo Labels for Semi-Supervised Temporal Action Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_paper.html",
        "author": "Kun Xia, Le Wang, Sanping Zhou, Gang Hua, Wei Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Applications, Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University; University of Illinois Chicago; Wormpex AI Research",
        "project": "",
        "github": "github.com/kunnxia/NPL",
        "arxiv": ""
    },
    {
        "title": "Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_from_Semantic_Alignment_between_Unpaired_Multiviews_for_Egocentric_Video_ICCV_2023_paper.html",
        "author": "Qitong Wang, Long Zhao, Liangzhe Yuan, Ting Liu, Xi Peng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_from_Semantic_Alignment_between_Unpaired_Multiviews_for_Egocentric_Video_ICCV_2023_paper.pdf",
        "aff": "University of Delaware; Google Research",
        "project": "",
        "github": "https://github.com/wqtwjt1996/SUM-L",
        "arxiv": "2308.11489"
    },
    {
        "title": "Learning in Imperfect Environment: Multi-Label Classification with Long-Tailed Distribution and Partial Labels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_in_Imperfect_Environment_Multi-Label_Classification_with_Long-Tailed_Distribution_and_ICCV_2023_paper.html",
        "author": "Wenqiao Zhang, Changshuo Liu, Lingze Zeng, Bengchin Ooi, Siliang Tang, Yueting Zhuang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_in_Imperfect_Environment_Multi-Label_Classification_with_Long-Tailed_Distribution_and_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore, Singapore; Zhejiang University, China",
        "project": "",
        "github": "https://github.com/wannature/COMIC",
        "arxiv": "2304.10539"
    },
    {
        "title": "Learning to Distill Global Representation for Sparse-View CT",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_to_Distill_Global_Representation_for_Sparse-View_CT_ICCV_2023_paper.html",
        "author": "Zilong Li, Chenglong Ma, Jie Chen, Junping Zhang, Hongming Shan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_to_Distill_Global_Representation_for_Sparse-View_CT_ICCV_2023_paper.pdf",
        "aff": "Institute of Science and Technology for Brain-inspired Intelligence and MOE Frontiers Center for Brain Science, Fudan University, Shanghai 200031, China; Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai 200433, China; Institute of Science and Technology for Brain-inspired Intelligence and MOE Frontiers Center for Brain Science, Fudan University, Shanghai 200433, China",
        "project": "",
        "github": "https://github.com/longzilicart/GloReDi",
        "arxiv": "2308.08463"
    },
    {
        "title": "Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.html",
        "author": "Minho Park, Jooyeol Yun, Seunghwan Choi, Jaegul Choo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST)",
        "project": "",
        "github": "https://pmh9960.github.io/research/GCDP",
        "arxiv": "2308.08157"
    },
    {
        "title": "Learning to Ground Instructional Articles in Videos through Narrations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mavroudi_Learning_to_Ground_Instructional_Articles_in_Videos_through_Narrations_ICCV_2023_paper.html",
        "author": "Effrosyni Mavroudi, Triantafyllos Afouras, Lorenzo Torresani",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mavroudi_Learning_to_Ground_Instructional_Articles_in_Videos_through_Narrations_ICCV_2023_paper.pdf",
        "aff": "Meta AI",
        "project": "https://eval.ai/web/challenges/challenge-page/2082",
        "github": "",
        "arxiv": "2306.03802"
    },
    {
        "title": "Learning to Identify Critical States for Reinforcement Learning from Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_to_Identify_Critical_States_for_Reinforcement_Learning_from_Videos_ICCV_2023_paper.html",
        "author": "Haozhe Liu, Mingchen Zhuge, Bing Li, Yuhui Wang, Francesco Faccio, Bernard Ghanem, J\u00fcrgen Schmidhuber",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_to_Identify_Critical_States_for_Reinforcement_Learning_from_Videos_ICCV_2023_paper.pdf",
        "aff": "AI Initiative, King Abdullah University of Science and Technology; The Swiss AI Lab IDSIA/USI/SUPSI; AI Initiative, King Abdullah University of Science and Technology; AI Initiative, King Abdullah University of Science and Technology; The Swiss AI Lab IDSIA/USI/SUPSI; NNAISENSE",
        "project": "",
        "github": "https://github.com/AI-Initiative-KAUST/VideoRLCS",
        "arxiv": "2308.07795"
    },
    {
        "title": "Learning to Learn: How to Continuously Teach Humans and Machines",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Singh_Learning_to_Learn_How_to_Continuously_Teach_Humans_and_Machines_ICCV_2023_paper.html",
        "author": "Parantak Singh, You Li, Ankur Sikarwar, Stan Weixian Lei, Difei Gao, Morgan B. Talbot, Ying Sun, Mike Zheng Shou, Gabriel Kreiman, Mengmi Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Learning_to_Learn_How_to_Continuously_Teach_Humans_and_Machines_ICCV_2023_paper.pdf",
        "aff": "CFAR and I2R, Agency for Science, Technology and Research, Singapore; Boston Children\u2019s Hospital, Harvard Medical School, USA; Harvard-MIT Health Sciences and Technology, MIT; Show Lab, National University of Singapore, Singapore; Nanyang Technological University (NTU), Singapore; CFAR and I2R, Agency for Science, Technology and Research, Singapore; Boston Children\u2019s Hospital, Harvard Medical School, USA; CFAR and I2R, Agency for Science, Technology and Research, Singapore; University of Wisconsin-Madison, USA",
        "project": "Link provided in the abstract",
        "github": "",
        "arxiv": "2211.15470"
    },
    {
        "title": "Learning to Transform for Generalizable Instance-wise Invariance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Singhal_Learning_to_Transform_for_Generalizable_Instance-wise_Invariance_ICCV_2023_paper.html",
        "author": "Utkarsh Singhal, Carlos Esteves, Ameesh Makadia, Stella X. Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Singhal_Learning_to_Transform_for_Generalizable_Instance-wise_Invariance_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; UC Berkeley, University of Michigan; Google Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning to Upsample by Learning to Sample",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_to_Upsample_by_Learning_to_Sample_ICCV_2023_paper.html",
        "author": "Wenze Liu, Hao Lu, Hongtao Fu, Zhiguo Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_to_Upsample_by_Learning_to_Sample_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China",
        "project": "",
        "github": "https://github.com/tiny-smart/dysample",
        "arxiv": "2308.15085"
    },
    {
        "title": "Learning with Diversity: Self-Expanded Equalization for Better Generalized Deep Metric Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Learning_with_Diversity_Self-Expanded_Equalization_for_Better_Generalized_Deep_Metric_ICCV_2023_paper.html",
        "author": "Jiexi Yan, Zhihui Yin, Erkun Yang, Yanhua Yang, Heng Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Learning_with_Diversity_Self-Expanded_Equalization_for_Better_Generalized_Deep_Metric_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, University of Maryland College Park, USA; School of Electronic Engineering, Xidian University, China; School of Computer Science and Technology, Xidian University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Lecture Presentations Multimodal Dataset: Towards Understanding Multimodality in Educational Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Lecture_Presentations_Multimodal_Dataset_Towards_Understanding_Multimodality_in_Educational_Videos_ICCV_2023_paper.html",
        "author": "Dong Won Lee, Chaitanya Ahuja, Paul Pu Liang, Sanika Natu, Louis-Philippe Morency",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Lecture_Presentations_Multimodal_Dataset_Towards_Understanding_Multimodality_in_Educational_Videos_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University; MIT",
        "project": "",
        "github": "https://github.com/dondongwon/LPMDataset",
        "arxiv": ""
    },
    {
        "title": "Lens Parameter Estimation for Realistic Depth of Field Modeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Piche-Meunier_Lens_Parameter_Estimation_for_Realistic_Depth_of_Field_Modeling_ICCV_2023_paper.html",
        "author": "Dominique Pich\u00e9-Meunier, Yannick Hold-Geoffroy, Jianming Zhang, Jean-Fran\u00e7ois Lalonde",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Piche-Meunier_Lens_Parameter_Estimation_for_Realistic_Depth_of_Field_Modeling_ICCV_2023_paper.pdf",
        "aff": "Adobe; Universit\u00e9 Laval",
        "project": "https://lvsn.github.io/inversedof/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Less is More: Focus Attention for Efficient DETR",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.html",
        "author": "Dehua Zheng, Wenhui Dong, Hailin Hu, Xinghao Chen, Yunhe Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.pdf",
        "aff": "HuazhongUniversityofScienceandTechnology; HuaweiNoah\u2019sArkLab",
        "project": "https://gitee.com/mindspore/models/tree/master/research/cv/Focus-DETR",
        "github": "https://github.com/huawei-noah/noah-research/tree/master/Focus-DETR",
        "arxiv": "2307.12612"
    },
    {
        "title": "Leveraging Inpainting for Single-Image Shadow Removal",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Leveraging_Inpainting_for_Single-Image_Shadow_Removal_ICCV_2023_paper.html",
        "author": "Xiaoguang Li, Qing Guo, Rabab Abdelfattah, Di Lin, Wei Feng, Ivor Tsang, Song Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Leveraging_Inpainting_for_Single-Image_Shadow_Removal_ICCV_2023_paper.pdf",
        "aff": "IHPC and CFAR, Agency for Science, Technology and Research, Singapore; University of South Carolina, USA; Tianjin University, China",
        "project": "",
        "github": "https://github.com/tsingqguo/inpaint4shadow",
        "arxiv": "2302.05361"
    },
    {
        "title": "Leveraging Intrinsic Properties for Non-Rigid Garment Alignment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Leveraging_Intrinsic_Properties_for_Non-Rigid_Garment_Alignment_ICCV_2023_paper.html",
        "author": "Siyou Lin, Boyao Zhou, Zerong Zheng, Hongwen Zhang, Yebin Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Leveraging_Intrinsic_Properties_for_Non-Rigid_Garment_Alignment_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University, Beijing, China",
        "project": "https://jsnln.github.io/iccv2023_intrinsic/index.html",
        "github": "",
        "arxiv": "2308.09519"
    },
    {
        "title": "Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Leveraging_SE3_Equivariance_for_Learning_3D_Geometric_Shape_Assembly_ICCV_2023_paper.html",
        "author": "Ruihai Wu, Chenrui Tie, Yushi Du, Yan Zhao, Hao Dong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Leveraging_SE3_Equivariance_for_Learning_3D_Geometric_Shape_Assembly_ICCV_2023_paper.pdf",
        "aff": "CFCS, School of CS, PKU; School of CS, PKU; School of EECS, PKU",
        "project": "https://crtie.github.io/SE-3-part-assembly/",
        "github": "",
        "arxiv": "2309.06810"
    },
    {
        "title": "Leveraging Spatio-Temporal Dependency for Skeleton-Based Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.html",
        "author": "Jungho Lee, Minhyeok Lee, Suhwan Cho, Sungmin Woo, Sungjun Jang, Sangyoun Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University; School of Electrical and Electronic Engineering, Yonsei University; Korea Institute of Science and Technology (KIST)",
        "project": "",
        "github": "https://github.com/Jho-Yonsei/STC-Net",
        "arxiv": "2212.04761"
    },
    {
        "title": "LexLIP: Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale Image-Text Sparse Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.html",
        "author": "Ziyang Luo, Pu Zhao, Can Xu, Xiubo Geng, Tao Shen, Chongyang Tao, Jing Ma, Qingwei Lin, Daxin Jiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.pdf",
        "aff": "Hong Kong Baptist University, Hong Kong SAR, China; Microsoft Corporation",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_paper.html",
        "author": "Zhiwei Zhang, Zhizhong Zhang, Qian Yu, Ran Yi, Yuan Xie, Lizhuang Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_paper.pdf",
        "aff": "School of Electronic Information and Electrical Engineering, Shanghai Jiaotong Univeristy, China; Department of Computer Science and Engineering, East China Normal University, China",
        "project": "",
        "github": "https://github.com/zhangzw12319/lcps.git",
        "arxiv": "2308.01686"
    },
    {
        "title": "LiDAR-UDA: Self-ensembling Through Time for Unsupervised LiDAR Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shaban_LiDAR-UDA_Self-ensembling_Through_Time_for_Unsupervised_LiDAR_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Amirreza Shaban, JoonHo Lee, Sanghun Jung, Xiangyun Meng, Byron Boots",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shaban_LiDAR-UDA_Self-ensembling_Through_Time_for_Unsupervised_LiDAR_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "University of Washington",
        "project": "",
        "github": "https://github.com/JHLee0513/lidar_uda",
        "arxiv": ""
    },
    {
        "title": "LightDepth: Single-View Depth Self-Supervision from Illumination Decline",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rodriguez-Puigvert_LightDepth_Single-View_Depth_Self-Supervision_from_Illumination_Decline_ICCV_2023_paper.html",
        "author": "Javier Rodr\u00edguez-Puigvert, V\u00edctor M. Batlle, J.M.M. Montiel, Ruben Martinez-Cantin, Pascal Fua, Juan D. Tard\u00f3s, Javier Civera",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rodriguez-Puigvert_LightDepth_Single-View_Depth_Self-Supervision_from_Illumination_Decline_ICCV_2023_paper.pdf",
        "aff": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne; I3A - Universidad de Zaragoza",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LightGlue: Local Feature Matching at Light Speed",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lindenberger_LightGlue_Local_Feature_Matching_at_Light_Speed_ICCV_2023_paper.html",
        "author": "Philipp Lindenberger, Paul-Edouard Sarlin, Marc Pollefeys",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lindenberger_LightGlue_Local_Feature_Matching_at_Light_Speed_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; ETH Zurich, Microsoft Mixed Reality & AI Lab",
        "project": "",
        "github": "github.com/cvg/LightGlue",
        "arxiv": "2306.13643"
    },
    {
        "title": "Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Lighting_Every_Darkness_in_Two_Pairs_A_Calibration-Free_Pipeline_for_ICCV_2023_paper.html",
        "author": "Xin Jin, Jia-Wen Xiao, Ling-Hao Han, Chunle Guo, Ruixun Zhang, Xialei Liu, Chongyi Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Lighting_Every_Darkness_in_Two_Pairs_A_Calibration-Free_Pipeline_for_ICCV_2023_paper.pdf",
        "aff": "VCIP, CS, Nankai University; Peking University; VCIP, CS, Nankai University and S-Lab, Nanyang Technological University",
        "project": "https://srameo.github.io/projects/led-iccv23",
        "github": "",
        "arxiv": "2308.03448"
    },
    {
        "title": "Lighting up NeRF via Unsupervised Decomposition and Enhancement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Lighting_up_NeRF_via_Unsupervised_Decomposition_and_Enhancement_ICCV_2023_paper.html",
        "author": "Haoyuan Wang, Xiaogang Xu, Ke Xu, Rynson W.H. Lau",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Lighting_up_NeRF_via_Unsupervised_Decomposition_and_Enhancement_ICCV_2023_paper.pdf",
        "aff": "Zhejiang Lab, Zhejiang University; Department of Computer Science, City University of Hong Kong",
        "project": "https://onpix.github.io/llnerf",
        "github": "",
        "arxiv": "2307.10664"
    },
    {
        "title": "Lightweight Image Super-Resolution with Superpixel Token Interaction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.html",
        "author": "Aiping Zhang, Wenqi Ren, Yi Liu, Xiaochun Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.pdf",
        "aff": "School of Cyber Science and Technology, Sun Yat-Sen University; Baidu Inc.",
        "project": "",
        "github": "https://github.com/ArcticHare105/SPIN",
        "arxiv": ""
    },
    {
        "title": "Linear Spaces of Meanings: Compositional Structures in Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Trager_Linear_Spaces_of_Meanings_Compositional_Structures_in_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Matthew Trager, Pramuditha Perera, Luca Zancato, Alessandro Achille, Parminder Bhatia, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Trager_Linear_Spaces_of_Meanings_Compositional_Structures_in_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "AWS AI Labs",
        "project": "",
        "github": "",
        "arxiv": "2302.14383"
    },
    {
        "title": "Linear-Covariance Loss for End-to-End Learning of 6D Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Linear-Covariance_Loss_for_End-to-End_Learning_of_6D_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Fulin Liu, Yinlin Hu, Mathieu Salzmann",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Linear-Covariance_Loss_for_End-to-End_Learning_of_6D_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "EPFL, ClearSpace; Beihang University; MagicLeap",
        "project": "",
        "github": "",
        "arxiv": "2303.11516"
    },
    {
        "title": "LinkGAN: Linking GAN Latents to Pixels for Controllable Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.html",
        "author": "Jiapeng Zhu, Ceyuan Yang, Yujun Shen, Zifan Shi, Bo Dai, Deli Zhao, Qifeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.pdf",
        "aff": "2Shanghai AI Laboratory; 1HKUST; 4Alibaba Group; 3Ant Group",
        "project": "http://www.yourprojectlink.com",
        "github": "",
        "arxiv": "2301.04604"
    },
    {
        "title": "Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Lip_Reading_for_Low-resource_Languages_by_Learning_and_Combining_General_ICCV_2023_paper.html",
        "author": "Minsu Kim, Jeong Hun Yeo, Jeongsoo Choi, Yong Man Ro",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Lip_Reading_for_Low-resource_Languages_by_Learning_and_Combining_General_ICCV_2023_paper.pdf",
        "aff": "School of Electrical Engineering, KAIST, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2308.09311"
    },
    {
        "title": "Lip2Vec: Efficient and Robust Visual Speech Recognition via Latent-to-Latent Visual to Audio Representation Mapping",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Djilali_Lip2Vec_Efficient_and_Robust_Visual_Speech_Recognition_via_Latent-to-Latent_Visual_ICCV_2023_paper.html",
        "author": "Yasser Abdelaziz Dahou Djilali, Sanath Narayan, Haithem Boussaid, Ebtessam Almazrouei, Merouane Debbah",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Djilali_Lip2Vec_Efficient_and_Robust_Visual_Speech_Recognition_via_Latent-to-Latent_Visual_ICCV_2023_paper.pdf",
        "aff": "Technology Innovation Institute, UAE",
        "project": "",
        "github": "https://github.com/YasserdahouML/Lip2Vec",
        "arxiv": "2308.06112"
    },
    {
        "title": "LiveHand: Real-time and Photorealistic Neural Hand Rendering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mundra_LiveHand_Real-time_and_Photorealistic_Neural_Hand_Rendering_ICCV_2023_paper.html",
        "author": "Akshay Mundra, Mallikarjun B R, Jiayi Wang, Marc Habermann, Christian Theobalt, Mohamed Elgharib",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mundra_LiveHand_Real-time_and_Photorealistic_Neural_Hand_Rendering_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Informatics, Saarland University; Max Planck Institute for Informatics",
        "project": "https://vcai.mpi-inf.mpg.de/projects/LiveHand/",
        "github": "",
        "arxiv": "2302.07672"
    },
    {
        "title": "LivePose: Online 3D Reconstruction from Monocular Video with Dynamic Camera Poses",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Stier_LivePose_Online_3D_Reconstruction_from_Monocular_Video_with_Dynamic_Camera_ICCV_2023_paper.html",
        "author": "Noah Stier, Baptiste Angles, Liang Yang, Yajie Yan, Alex Colburn, Ming Chuang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_LivePose_Online_3D_Reconstruction_from_Monocular_Video_with_Dynamic_Camera_ICCV_2023_paper.pdf",
        "aff": "Apple, University of California, Santa Barbara; Apple",
        "project": "",
        "github": "https://github.com/apple/ml-live-pose1",
        "arxiv": "2304.00054"
    },
    {
        "title": "LivelySpeaker: Towards Semantic-Aware Co-Speech Gesture Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhi_LivelySpeaker_Towards_Semantic-Aware_Co-Speech_Gesture_Generation_ICCV_2023_paper.html",
        "author": "Yihao Zhi, Xiaodong Cun, Xuelin Chen, Xi Shen, Wen Guo, Shaoli Huang, Shenghua Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhi_LivelySpeaker_Towards_Semantic-Aware_Co-Speech_Gesture_Generation_ICCV_2023_paper.pdf",
        "aff": "Tencent AI Lab; ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging, Shanghai Engineering Research Center of Energy Efficient and Custom AI IC; INRIA; Intellindust; ShanghaiTech University",
        "project": "",
        "github": "https://github.com/zyhbili/LivelySpeaker",
        "arxiv": "2309.09294"
    },
    {
        "title": "LoCUS: Learning Multiscale 3D-consistent Features from Posed Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kloepfer_LoCUS_Learning_Multiscale_3D-consistent_Features_from_Posed_Images_ICCV_2023_paper.html",
        "author": "Dominik A. Kloepfer, Dylan Campbell, Jo\u00e3o F. Henriques",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kloepfer_LoCUS_Learning_Multiscale_3D-consistent_Features_from_Posed_Images_ICCV_2023_paper.pdf",
        "aff": "Visual Geometry Group, University of Oxford; Australian National University",
        "project": "https://www.robots.ox.ac.uk/~vgg/research/locus",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_LoGoPrompt_Synthetic_Text_Images_Can_Be_Good_Visual_Prompts_for_ICCV_2023_paper.html",
        "author": "Cheng Shi, Sibei Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_LoGoPrompt_Synthetic_Text_Images_Can_Be_Good_Visual_Prompts_for_ICCV_2023_paper.pdf",
        "aff": "School of Information Science and Technology, ShanghaiTech University",
        "project": "https://chengshiest.github.io/logo",
        "github": "",
        "arxiv": "2309.01155"
    },
    {
        "title": "LoLep: Single-View View Synthesis with Locally-Learned Planes and Self-Attention Occlusion Inference",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_LoLep_Single-View_View_Synthesis_with_Locally-Learned_Planes_and_Self-Attention_Occlusion_ICCV_2023_paper.html",
        "author": "Cong Wang, Yu-Ping Wang, Dinesh Manocha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_LoLep_Single-View_View_Synthesis_with_Locally-Learned_Planes_and_Self-Attention_Occlusion_ICCV_2023_paper.pdf",
        "aff": "University of Maryland; Tsinghua University; The Beijing Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": "2307.12217"
    },
    {
        "title": "LoTE-Animal: A Long Time-span Dataset for Endangered Animal Behavior Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_LoTE-Animal_A_Long_Time-span_Dataset_for_Endangered_Animal_Behavior_Understanding_ICCV_2023_paper.html",
        "author": "Dan Liu, Jin Hou, Shaoli Huang, Jing Liu, Yuxin He, Bochuan Zheng, Jifeng Ning, Jingdong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_LoTE-Animal_A_Long_Time-span_Dataset_for_Endangered_Animal_Behavior_Understanding_ICCV_2023_paper.pdf",
        "aff": "North Sichuan Medical College; Tencent AI-Lab; China West Normal University; Northwest A&F University",
        "project": "",
        "github": "https://LoTE-Animal.github.io",
        "arxiv": ""
    },
    {
        "title": "Local Context-Aware Active Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Local_Context-Aware_Active_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Tao Sun, Cheng Lu, Haibin Ling",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Local_Context-Aware_Active_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Stony Brook University; XPeng Motors",
        "project": "",
        "github": "https://github.com/tsun/LADA",
        "arxiv": "2208.12856"
    },
    {
        "title": "Local and Global Logit Adjustments for Long-Tailed Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tao_Local_and_Global_Logit_Adjustments_for_Long-Tailed_Learning_ICCV_2023_paper.html",
        "author": "Yingfan Tao, Jingna Sun, Hao Yang, Li Chen, Xu Wang, Wenming Yang, Daniel Du, Min Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_Local_and_Global_Logit_Adjustments_for_Long-Tailed_Learning_ICCV_2023_paper.pdf",
        "aff": "ByteDance Inc; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Local or Global: Selective Knowledge Assimilation for Federated Learning with Limited Labels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Local_or_Global_Selective_Knowledge_Assimilation_for_Federated_Learning_with_ICCV_2023_paper.html",
        "author": "Yae Jee Cho, Gauri Joshi, Dimitrios Dimitriadis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Local_or_Global_Selective_Knowledge_Assimilation_for_Federated_Learning_with_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University, Pittsburgh, PA; Amazon, Seattle, WA",
        "project": "",
        "github": "",
        "arxiv": "2307.08809"
    },
    {
        "title": "Localizing Moments in Long Video Via Multimodal Guidance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Barrios_Localizing_Moments_in_Long_Video_Via_Multimodal_Guidance_ICCV_2023_paper.html",
        "author": "Wayner Barrios, Mattia Soldan, Alberto Mario Ceballos-Arroyo, Fabian Caba Heilbron, Bernard Ghanem",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Barrios_Localizing_Moments_in_Long_Video_Via_Multimodal_Guidance_ICCV_2023_paper.pdf",
        "aff": "Northeastern University; Adobe Research; King Abdullah University of Science and Technology (KAUST); Dartmouth",
        "project": "",
        "github": "https://github.com/waybarrios/guidance-based-video-grounding",
        "arxiv": "2302.13372"
    },
    {
        "title": "Localizing Object-Level Shape Variations with Text-to-Image Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Or Patashnik, Daniel Garibi, Idan Azuri, Hadar Averbuch-Elor, Daniel Cohen-Or",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Independent Researcher; Tel-Aviv University",
        "project": "https://orpatashnik.github.io/local-prompt-mixing/",
        "github": "https://github.com/orpatashnik/local-prompt-mixing",
        "arxiv": "2303.11306"
    },
    {
        "title": "Locally Stylized Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pang_Locally_Stylized_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Hong-Wing Pang, Binh-Son Hua, Sai-Kit Yeung",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pang_Locally_Stylized_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; Trinity College Dublin",
        "project": "",
        "github": "",
        "arxiv": "2309.10684"
    },
    {
        "title": "Locating Noise is Halfway Denoising for Semi-Supervised Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Locating_Noise_is_Halfway_Denoising_for_Semi-Supervised_Segmentation_ICCV_2023_paper.html",
        "author": "Yan Fang, Feng Zhu, Bowen Cheng, Luoqi Liu, Yao Zhao, Yunchao Wei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Locating_Noise_is_Halfway_Denoising_for_Semi-Supervised_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Institute of Information Science, Beijing Jiaotong University; MT Lab, Meitu Inc; University of Illinois Urbana-Champaign; University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Locomotion-Action-Manipulation: Synthesizing Human-Scene Interactions in Complex 3D Environments",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Locomotion-Action-Manipulation_Synthesizing_Human-Scene_Interactions_in_Complex_3D_Environments_ICCV_2023_paper.html",
        "author": "Jiye Lee, Hanbyul Joo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Locomotion-Action-Manipulation_Synthesizing_Human-Scene_Interactions_in_Complex_3D_Environments_ICCV_2023_paper.pdf",
        "aff": "Seoul National University",
        "project": "https://jiyewise.github.io/projects/LAMA/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Logic-induced Diagnostic Reasoning for Semi-supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Logic-induced_Diagnostic_Reasoning_for_Semi-supervised_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Chen Liang, Wenguan Wang, Jiaxu Miao, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Logic-induced_Diagnostic_Reasoning_for_Semi-supervised_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "ReLER, CCAI, Zhejiang University",
        "project": "",
        "github": "https://github.com/leonnnop/LogicDiag",
        "arxiv": "2308.12595"
    },
    {
        "title": "LogicSeg: Parsing Visual Semantics with Neural Logic Learning and Reasoning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_LogicSeg_Parsing_Visual_Semantics_with_Neural_Logic_Learning_and_Reasoning_ICCV_2023_paper.html",
        "author": "Liulei Li, Wenguan Wang, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_LogicSeg_Parsing_Visual_Semantics_with_Neural_Logic_Learning_and_Reasoning_ICCV_2023_paper.pdf",
        "aff": "ReLER, CCAI, Zhejiang University; ReLER, AAII, University of Technology Sydney; ReLER, CCAI, Zhejiang University",
        "project": "",
        "github": "https://github.com/lingorX/LogicSeg/",
        "arxiv": "2309.13556"
    },
    {
        "title": "Long-Range Grouping Transformer for Multi-View 3D Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Long-Range_Grouping_Transformer_for_Multi-View_3D_Reconstruction_ICCV_2023_paper.html",
        "author": "Liying Yang, Zhenwei Zhu, Xuxin Lin, Jian Nong, Yanyan Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Long-Range_Grouping_Transformer_for_Multi-View_3D_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Macau University of Science and Technology",
        "project": "",
        "github": "https://github.com/LiyingCV/Long-Range-Grouping-Transformer",
        "arxiv": "2308.08724"
    },
    {
        "title": "Long-Term Photometric Consistent Novel View Synthesis with Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Long-Term_Photometric_Consistent_Novel_View_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Jason J. Yu, Fereshteh Forghani, Konstantinos G. Derpanis, Marcus A. Brubaker",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Long-Term_Photometric_Consistent_Novel_View_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "York University; York University, Vector Institute for AI",
        "project": "https://yorkucvil.github.io/Photoconsistent-NVS/",
        "github": "",
        "arxiv": "2304.10700"
    },
    {
        "title": "Long-range Multimodal Pretraining for Movie Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Argaw_Long-range_Multimodal_Pretraining_for_Movie_Understanding_ICCV_2023_paper.html",
        "author": "Dawit Mureja Argaw, Joon-Young Lee, Markus Woodson, In So Kweon, Fabian Caba Heilbron",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Argaw_Long-range_Multimodal_Pretraining_for_Movie_Understanding_ICCV_2023_paper.pdf",
        "aff": "Adobe; KAIST",
        "project": "",
        "github": "",
        "arxiv": "2308.09775"
    },
    {
        "title": "Look at the Neighbor: Distortion-aware Unsupervised Domain Adaptation for Panoramic Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Look_at_the_Neighbor_Distortion-aware_Unsupervised_Domain_Adaptation_for_Panoramic_ICCV_2023_paper.html",
        "author": "Xu Zheng, Tianbo Pan, Yunhao Luo, Lin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Look_at_the_Neighbor_Distortion-aware_Unsupervised_Domain_Adaptation_for_Panoramic_ICCV_2023_paper.pdf",
        "aff": "Dept. of CSE, HKUST; AI Thrust, HKUST(GZ); AI Thrust, HKUST(GZ); Brown University",
        "project": "https://vlislab22.github.io/DATR/",
        "github": "",
        "arxiv": "2308.05493"
    },
    {
        "title": "Lossy and Lossless (L2) Post-training Model Size Compression",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Lossy_and_Lossless_L2_Post-training_Model_Size_Compression_ICCV_2023_paper.html",
        "author": "Yumeng Shi, Shihao Bai, Xiuying Wei, Ruihao Gong, Jianlei Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Lossy_and_Lossless_L2_Post-training_Model_Size_Compression_ICCV_2023_paper.pdf",
        "aff": "Beihang University; SenseTime Research",
        "project": "",
        "github": "https://github.com/ModelTC/L2 Compression",
        "arxiv": ""
    },
    {
        "title": "Low-Light Image Enhancement with Illumination-Aware Gamma Correction and Complete Image Modelling Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.html",
        "author": "Yinglong Wang, Zhen Liu, Jianzhuang Liu, Songcen Xu, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.pdf",
        "aff": "Meituan Inc.; Huawei Noah\u2019s Ark Lab; University of Electronic Science and Technology of China; Shenzhen Institute of Advanced Technology; Megvii Technology",
        "project": "",
        "github": "",
        "arxiv": "2308.08220"
    },
    {
        "title": "Low-Light Image Enhancement with Multi-Stage Residue Quantization and Brightness-Aware Attention",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.html",
        "author": "Yunlong Liu, Tao Huang, Weisheng Dong, Fangfang Wu, Xin Li, Guangming Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.pdf",
        "aff": "Xidian University; University at Albany",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Luminance-aware Color Transform for Multiple Exposure Correction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Baek_Luminance-aware_Color_Transform_for_Multiple_Exposure_Correction_ICCV_2023_paper.html",
        "author": "Jong-Hyeon Baek, DaeHyun Kim, Su-Min Choi, Hyo-jun Lee, Hanul Kim, Yeong Jun Koh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Baek_Luminance-aware_Color_Transform_for_Multiple_Exposure_Correction_ICCV_2023_paper.pdf",
        "aff": "Seoul National University of Science and Technology; Chungnam National University; 242dot Inc.",
        "project": "",
        "github": "https://github.com/whdgusdl48/LACT",
        "arxiv": ""
    },
    {
        "title": "M2T: Masking Transformers Twice for Faster Decoding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mentzer_M2T_Masking_Transformers_Twice_for_Faster_Decoding_ICCV_2023_paper.html",
        "author": "Fabian Mentzer, Eirikur Agustson, Michael Tschannen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mentzer_M2T_Masking_Transformers_Twice_for_Faster_Decoding_ICCV_2023_paper.pdf",
        "aff": "Google DeepMind; Google Research",
        "project": "",
        "github": "https://github.com/ (to be released)",
        "arxiv": ""
    },
    {
        "title": "MAAL: Multimodality-Aware Autoencoder-Based Affordance Learning for 3D Articulated Objects",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_Affordance_Learning_for_3D_Articulated_Objects_ICCV_2023_paper.html",
        "author": "Yuanzhi Liang, Xiaohan Wang, Linchao Zhu, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_Affordance_Learning_for_3D_Articulated_Objects_ICCV_2023_paper.pdf",
        "aff": "CCAI, Zhejiang University; ReLER Lab, AAII, University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MAGI: Multi-Annotated Explanation-Guided Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MAGI_Multi-Annotated_Explanation-Guided_Learning_ICCV_2023_paper.html",
        "author": "Yifei Zhang, Siyi Gu, Yuyang Gao, Bo Pan, Xiaofeng Yang, Liang Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MAGI_Multi-Annotated_Explanation-Guided_Learning_ICCV_2023_paper.pdf",
        "aff": "Emory University, Atlanta, GA, United States",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.html",
        "author": "Rajeev Yasarla, Hong Cai, Jisoo Jeong, Yunxiao Shi, Risheek Garrepalli, Fatih Porikli",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.pdf",
        "aff": "Qualcomm AI Research",
        "project": "",
        "github": "",
        "arxiv": "2307.14336"
    },
    {
        "title": "MAP: Towards Balanced Generalization of IID and OOD through Model-Agnostic Adapters",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MAP_Towards_Balanced_Generalization_of_IID_and_OOD_through_Model-Agnostic_ICCV_2023_paper.html",
        "author": "Min Zhang, Junkun Yuan, Yue He, Wenbin Li, Zhengyu Chen, Kun Kuang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MAP_Towards_Balanced_Generalization_of_IID_and_OOD_through_Model-Agnostic_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Nanjing University; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MAPConNet: Self-supervised 3D Pose Transfer with Mesh and Point Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_MAPConNet_Self-supervised_3D_Pose_Transfer_with_Mesh_and_Point_Contrastive_ICCV_2023_paper.html",
        "author": "Jiaze Sun, Zhixiang Chen, Tae-Kyun Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_MAPConNet_Self-supervised_3D_Pose_Transfer_with_Mesh_and_Point_Contrastive_ICCV_2023_paper.pdf",
        "aff": "University of Sheffield; Korea Advanced Institute of Science and Technology; Imperial College London",
        "project": "",
        "github": "https://github.com/justin941208/MAPConNet",
        "arxiv": "2304.13819"
    },
    {
        "title": "MARS: Model-agnostic Biased Object Removal without Additional Supervision for Weakly-Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jo_MARS_Model-agnostic_Biased_Object_Removal_without_Additional_Supervision_for_Weakly-Supervised_ICCV_2023_paper.html",
        "author": "Sanghyun Jo, In-Jae Yu, Kyungsu Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_MARS_Model-agnostic_Biased_Object_Removal_without_Additional_Supervision_for_Weakly-Supervised_ICCV_2023_paper.pdf",
        "aff": "Samsung Electronics, Suwon, Korea; OGQ, Seoul, Korea; Department of Data Convergence and Future Medicine, Sungkyunkwan University, Seoul, Korea",
        "project": "",
        "github": "https://github.com/shjo-april/MARS",
        "arxiv": "2304.09913"
    },
    {
        "title": "MAS: Towards Resource-Efficient Federated Multiple-Task Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhuang_MAS_Towards_Resource-Efficient_Federated_Multiple-Task_Learning_ICCV_2023_paper.html",
        "author": "Weiming Zhuang, Yonggang Wen, Lingjuan Lyu, Shuai Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhuang_MAS_Towards_Resource-Efficient_Federated_Multiple-Task_Learning_ICCV_2023_paper.pdf",
        "aff": "Sony AI; Nanyang Technological University; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2307.11285"
    },
    {
        "title": "MATE: Masked Autoencoders are Online 3D Test-Time Learners",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mirza_MATE_Masked_Autoencoders_are_Online_3D_Test-Time_Learners_ICCV_2023_paper.html",
        "author": "M. Jehanzeb Mirza, Inkyu Shin, Wei Lin, Andreas Schriebl, Kunyang Sun, Jaesung Choe, Mateusz Kozinski, Horst Possegger, In So Kweon, Kuk-Jin Yoon, Horst Bischof",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mirza_MATE_Masked_Autoencoders_are_Online_3D_Test-Time_Learners_ICCV_2023_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST), South Korea; Institute for Computer Graphics and Vision, Graz University of Technology, Austria; Christian Doppler Laboratory for Embedded Machine Learning; Southeast University, China; Institute for Computer Graphics and Vision, Graz University of Technology, Austria",
        "project": "",
        "github": "",
        "arxiv": "2211.11432"
    },
    {
        "title": "MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_MAtch_eXpand_and_Improve_Unsupervised_Finetuning_for_Zero-Shot_Action_Recognition_ICCV_2023_paper.html",
        "author": "Wei Lin, Leonid Karlinsky, Nina Shvetsova, Horst Possegger, Mateusz Kozinski, Rameswar Panda, Rogerio Feris, Hilde Kuehne, Horst Bischof",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MAtch_eXpand_and_Improve_Unsupervised_Finetuning_for_Zero-Shot_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "Institute of Computer Graphics and Vision, Graz University of Technology, Austria; Goethe University Frankfurt, Germany; MIT-IBM Watson AI Lab, USA; University of Bonn, Germany; MIT-IBM Watson AI Lab, USA",
        "project": "",
        "github": "https://github.com/wlin-at/MAXI",
        "arxiv": "2303.08914"
    },
    {
        "title": "MB-TaylorFormer: Multi-Branch Efficient Transformer Expanded by Taylor Formula for Image Dehazing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_Transformer_Expanded_by_Taylor_Formula_for_Image_ICCV_2023_paper.html",
        "author": "Yuwei Qiu, Kaihao Zhang, Chenxi Wang, Wenhan Luo, Hongdong Li, Zhi Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_Transformer_Expanded_by_Taylor_Formula_for_Image_ICCV_2023_paper.pdf",
        "aff": "Sun Y at-sen University, Guangdong Provincial Key Laboratory of Robotics and Digital Intelligent Manufacturing Technology; Sun Y at-sen University; Australian National University",
        "project": "",
        "github": "https://github.com/FVL2020/ICCV-2023-MB-TaylorFomer",
        "arxiv": ""
    },
    {
        "title": "MBPTrack: Improving 3D Point Cloud Tracking with Memory Networks and Box Priors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MBPTrack_Improving_3D_Point_Cloud_Tracking_with_Memory_Networks_and_ICCV_2023_paper.html",
        "author": "Tian-Xing Xu, Yuan-Chen Guo, Yu-Kun Lai, Song-Hai Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MBPTrack_Improving_3D_Point_Cloud_Tracking_with_Memory_Networks_and_ICCV_2023_paper.pdf",
        "aff": "Cardiff University, United Kingdom; Tsinghua University, China",
        "project": "",
        "github": "",
        "arxiv": "2303.05071"
    },
    {
        "title": "MDCS: More Diverse Experts with Consistency Self-distillation for Long-tailed Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MDCS_More_Diverse_Experts_with_Consistency_Self-distillation_for_Long-tailed_Recognition_ICCV_2023_paper.html",
        "author": "Qihao Zhao, Chen Jiang, Wei Hu, Fan Zhang, Jun Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MDCS_More_Diverse_Experts_with_Consistency_Self-distillation_for_Long-tailed_Recognition_ICCV_2023_paper.pdf",
        "aff": "Singapore University of Technology and Design, Singapore; Beijing University of Chemical Technology, China",
        "project": "",
        "github": "https://github.com/fistyee/MDCS",
        "arxiv": "2308.09922"
    },
    {
        "title": "MEFLUT: Unsupervised 1D Lookup Tables for Multi-exposure Image Fusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_MEFLUT_Unsupervised_1D_Lookup_Tables_for_Multi-exposure_Image_Fusion_ICCV_2023_paper.html",
        "author": "Ting Jiang, Chuan Wang, Xinpeng Li, Ru Li, Haoqiang Fan, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_MEFLUT_Unsupervised_1D_Lookup_Tables_for_Multi-exposure_Image_Fusion_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China, Megvii Technology; Megvii Technology",
        "project": "",
        "github": "https://github.com/Hedlen/MEFLUT",
        "arxiv": "2309.11847"
    },
    {
        "title": "MEGA: Multimodal Alignment Aggregation and Distillation For Cinematic Video Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sadoughi_MEGA_Multimodal_Alignment_Aggregation_and_Distillation_For_Cinematic_Video_Segmentation_ICCV_2023_paper.html",
        "author": "Najmeh Sadoughi, Xinyu Li, Avijit Vajpayee, David Fan, Bing Shuai, Hector Santos-Villalobos, Vimal Bhat, Rohith MV",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sadoughi_MEGA_Multimodal_Alignment_Aggregation_and_Distillation_For_Cinematic_Video_Segmentation_ICCV_2023_paper.pdf",
        "aff": "AWS AI Labs; Amazon Prime Video",
        "project": "",
        "github": "",
        "arxiv": "2308.11185"
    },
    {
        "title": "MGMAE: Motion Guided Masking for Video Masked Autoencoding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_MGMAE_Motion_Guided_Masking_for_Video_Masked_Autoencoding_ICCV_2023_paper.html",
        "author": "Bingkun Huang, Zhiyu Zhao, Guozhen Zhang, Yu Qiao, Limin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_MGMAE_Motion_Guided_Masking_for_Video_Masked_Autoencoding_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; Shanghai AI Lab",
        "project": "",
        "github": "https://github.com/MCG-NJU/MGMAE",
        "arxiv": "2308.10794"
    },
    {
        "title": "MHCN: A Hyperbolic Neural Network Model for Multi-view Hierarchical Clustering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_MHCN_A_Hyperbolic_Neural_Network_Model_for_Multi-view_Hierarchical_Clustering_ICCV_2023_paper.html",
        "author": "Fangfei Lin, Bing Bai, Yiwen Guo, Hao Chen, Yazhou Ren, Zenglin Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MHCN_A_Hyperbolic_Neural_Network_Model_for_Multi-view_Hierarchical_Clustering_ICCV_2023_paper.pdf",
        "aff": "Tencent Security Big Data Lab, China; Harbin Institute of Technology Shenzhen, China; University of California, Davis, USA; University of Electronic Science and Technology of China, China; Independent Researcher",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MHEntropy: Entropy Meets Multiple Hypotheses for Pose and Shape Recovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_MHEntropy_Entropy_Meets_Multiple_Hypotheses_for_Pose_and_Shape_Recovery_ICCV_2023_paper.html",
        "author": "Rongyu Chen, Linlin Yang, Angela Yao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MHEntropy_Entropy_Meets_Multiple_Hypotheses_for_Pose_and_Shape_Recovery_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore",
        "project": "https://gloryyrolg.github.io/MHEntropy",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MI-GAN: A Simple Baseline for Image Inpainting on Mobile Devices",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.html",
        "author": "Andranik Sargsyan, Shant Navasardyan, Xingqian Xu, Humphrey Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.pdf",
        "aff": "Picsart AI Research (PAIR); Picsart AI Research (PAIR), SHI Labs @ Georgia Tech, Oregon & UIUC",
        "project": "",
        "github": "https://github.com/Picsart-AI-Research/MI-GAN",
        "arxiv": ""
    },
    {
        "title": "MIMO-NeRF: Fast Neural Rendering with Multi-input Multi-output Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kaneko_MIMO-NeRF_Fast_Neural_Rendering_with_Multi-input_Multi-output_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Takuhiro Kaneko",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kaneko_MIMO-NeRF_Fast_Neural_Rendering_with_Multi-input_Multi-output_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "NTT Communication Science Laboratories, NTT Corporation",
        "project": "https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/mimo-nerf/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MMST-ViT: Climate Change-aware Crop Yield Prediction via Multi-Modal Spatial-Temporal Vision Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_MMST-ViT_Climate_Change-aware_Crop_Yield_Prediction_via_Multi-Modal_Spatial-Temporal_Vision_ICCV_2023_paper.html",
        "author": "Fudong Lin, Summer Crawford, Kaleb Guillot, Yihe Zhang, Yan Chen, Xu Yuan, Li Chen, Shelby Williams, Robert Minvielle, Xiangming Xiao, Drew Gholson, Nicolas Ashwell, Tri Setiyono, Brenda Tubana, Lu Peng, Magdy Bayoumi, Nian-Feng Tzeng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MMST-ViT_Climate_Change-aware_Crop_Yield_Prediction_via_Multi-Modal_Spatial-Temporal_Vision_ICCV_2023_paper.pdf",
        "aff": "LSU AgCenter; Louisiana State University; University of Connecticut; University of Delaware; University of Oklahoma; Tulane University; Mississippi State University; University of Louisiana at Lafayette",
        "project": "",
        "github": "https://github.com/fudong03/MMST-ViT",
        "arxiv": ""
    },
    {
        "title": "MMVP: Motion-Matrix-Based Video Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_MMVP_Motion-Matrix-Based_Video_Prediction_ICCV_2023_paper.html",
        "author": "Yiqi Zhong, Luming Liang, Ilya Zharkov, Ulrich Neumann",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_MMVP_Motion-Matrix-Based_Video_Prediction_ICCV_2023_paper.pdf",
        "aff": "University of Southern California; Microsoft",
        "project": "https://...",
        "github": "https://github.com/...",
        "arxiv": "2308.16154"
    },
    {
        "title": "MODA: Mapping-Once Audio-driven Portrait Animation with Dual Attentions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MODA_Mapping-Once_Audio-driven_Portrait_Animation_with_Dual_Attentions_ICCV_2023_paper.html",
        "author": "Yunfei Liu, Lijian Lin, Fei Yu, Changyin Zhou, Yu Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MODA_Mapping-Once_Audio-driven_Portrait_Animation_with_Dual_Attentions_ICCV_2023_paper.pdf",
        "aff": "Vistring Inc.; International Digital Economy Academy (IDEA)",
        "project": "https://tinyurl.com/iccv23-moda",
        "github": "",
        "arxiv": "2307.10008"
    },
    {
        "title": "MOSE: A New Dataset for Video Object Segmentation in Complex Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ding_MOSE_A_New_Dataset_for_Video_Object_Segmentation_in_Complex_ICCV_2023_paper.html",
        "author": "Henghui Ding, Chang Liu, Shuting He, Xudong Jiang, Philip H.S. Torr, Song Bai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MOSE_A_New_Dataset_for_Video_Object_Segmentation_in_Complex_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; University of Oxford; ByteDance",
        "project": "https://henghuiding.github.io/MOSE",
        "github": "",
        "arxiv": "2302.01872"
    },
    {
        "title": "MOST: Multiple Object Localization with Self-Supervised Transformers for Object Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rambhatla_MOST_Multiple_Object_Localization_with_Self-Supervised_Transformers_for_Object_Discovery_ICCV_2023_paper.html",
        "author": "Sai Saketh Rambhatla, Ishan Misra, Rama Chellappa, Abhinav Shrivastava",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rambhatla_MOST_Multiple_Object_Localization_with_Self-Supervised_Transformers_for_Object_Discovery_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; Meta; Johns Hopkins University, University of Maryland, College Park; Meta, Johns Hopkins University, University of Maryland, College Park",
        "project": "rssaketh.github.io/most",
        "github": "https://github.com/rssaketh/most",
        "arxiv": "2304.05387"
    },
    {
        "title": "MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision Transformer with Heterogeneous Attention",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zeng_MPCViT_Searching_for_Accurate_and_Efficient_MPC-Friendly_Vision_Transformer_with_ICCV_2023_paper.html",
        "author": "Wenxuan Zeng, Meng Li, Wenjie Xiong, Tong Tong, Wen-jie Lu, Jin Tan, Runsheng Wang, Ru Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_MPCViT_Searching_for_Accurate_and_Efficient_MPC-Friendly_Vision_Transformer_with_ICCV_2023_paper.pdf",
        "aff": "Peking University; Ant Group; Virginia Tech",
        "project": "",
        "github": "https://github.com/PKU-SEC-Lab/mpcvit",
        "arxiv": "2211.13955"
    },
    {
        "title": "MPI-Flow: Learning Realistic Optical Flow with Multiplane Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_MPI-Flow_Learning_Realistic_Optical_Flow_with_Multiplane_Images_ICCV_2023_paper.html",
        "author": "Yingping Liang, Jiaming Liu, Debing Zhang, Ying Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_MPI-Flow_Learning_Realistic_Optical_Flow_with_Multiplane_Images_ICCV_2023_paper.pdf",
        "aff": "Xiaohongshu Inc.; Beijing Institute of Technology",
        "project": "",
        "github": "https://github.com/Sharpiless/MPI-Flow",
        "arxiv": ""
    },
    {
        "title": "MRM: Masked Relation Modeling for Medical Image Pre-Training with Genetics",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.html",
        "author": "Qiushi Yang, Wuyang Li, Baopu Li, Yixuan Yuan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; City University of Hong Kong, The Chinese University of Hong Kong; Independent Researcher",
        "project": "",
        "github": "https://github.com/CityU-AIM-Group/MRM",
        "arxiv": ""
    },
    {
        "title": "MRN: Multiplexed Routing Network for Incremental Multilingual Text Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_MRN_Multiplexed_Routing_Network_for_Incremental_Multilingual_Text_Recognition_ICCV_2023_paper.html",
        "author": "Tianlun Zheng, Zhineng Chen, Bingchen Huang, Wei Zhang, Yu-Gang Jiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_MRN_Multiplexed_Routing_Network_for_Incremental_Multilingual_Text_Recognition_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Fudan University, China; Shanghai Collaborative Innovation Center of Intelligent Visual Computing, China; Gaoding AI, China",
        "project": "",
        "github": "https://github.com/simplify23/MRN",
        "arxiv": "2305.14758"
    },
    {
        "title": "MSI: Maximize Support-Set Information for Few-Shot Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Moon_MSI_Maximize_Support-Set_Information_for_Few-Shot_Segmentation_ICCV_2023_paper.html",
        "author": "Seonghyeon Moon, Samuel S. Sohn, Honglu Zhou, Sejong Yoon, Vladimir Pavlovic, Muhammad Haris Khan, Mubbasir Kapadia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_MSI_Maximize_Support-Set_Information_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Rutgers University; The College of New Jersey; Mohamed Bin Zayed University of Artificial Intelligence; NEC Laboratories America",
        "project": "",
        "github": "https://github.com/moonsh/MSI-Maximize-Support-Set-Information",
        "arxiv": "2212.04673"
    },
    {
        "title": "MST-compression: Compressing and Accelerating Binary Neural Networks with Minimum Spanning Tree",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Vo_MST-compression_Compressing_and_Accelerating_Binary_Neural_Networks_with_Minimum_Spanning_ICCV_2023_paper.html",
        "author": "Quang Hieu Vo, Linh-Tam Tran, Sung-Ho Bae, Lok-Won Kim, Choong Seon Hong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Vo_MST-compression_Compressing_and_Accelerating_Binary_Neural_Networks_with_Minimum_Spanning_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, Kyung Hee University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MULLER: Multilayer Laplacian Resizer for Vision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tu_MULLER_Multilayer_Laplacian_Resizer_for_Vision_ICCV_2023_paper.html",
        "author": "Zhengzhong Tu, Peyman Milanfar, Hossein Talebi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_MULLER_Multilayer_Laplacian_Resizer_for_Vision_ICCV_2023_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "https://github.com/google-research/google-research/tree/master/muller",
        "arxiv": "2304.02859"
    },
    {
        "title": "MUVA: A New Large-Scale Benchmark for Multi-View Amodal Instance Segmentation in the Shopping Scenario",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Zhixuan Li, Weining Ye, Juan Terven, Zachary Bennett, Ying Zheng, Tingting Jiang, Tiejun Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "National Engineering Research Center of Visual Technology, National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University, Beijing 100871, China; Beijing Academy of Artificial Intelligence, Beijing 100084, China; AiFi Inc., California 94010, United States; National Engineering Research Center of Visual Technology, National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University, Beijing 100871, China",
        "project": "https://zhixuanli.github.io/project/2023_ICCV_MUV_A",
        "github": "https://zhixuanli.github.io/project",
        "arxiv": ""
    },
    {
        "title": "MUter: Machine Unlearning on Adversarially Trained Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MUter_Machine_Unlearning_on_Adversarially_Trained_Models_ICCV_2023_paper.html",
        "author": "Junxu Liu, Mingsheng Xue, Jian Lou, Xiaoyu Zhang, Li Xiong, Zhan Qin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MUter_Machine_Unlearning_on_Adversarially_Trained_Models_ICCV_2023_paper.pdf",
        "aff": "Renmin University of China; Xidian University; Emory University; ZJU-Hangzhou Global Scientific and Technological Innovation Center; Guangzhou Institute of Technology, Xidian University; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MV-DeepSDF: Implicit Modeling with Multi-Sweep Point Clouds for 3D Vehicle Reconstruction in Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.html",
        "author": "Yibo Liu, Kelly Zhu, Guile Wu, Yuan Ren, Bingbing Liu, Yang Liu, Jinjun Shan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab, University of Toronto; York University; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab, York University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MV-Map: Offboard HD-Map Generation with Multi-view Consistency",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_MV-Map_Offboard_HD-Map_Generation_with_Multi-view_Consistency_ICCV_2023_paper.html",
        "author": "Ziyang Xie, Ziqi Pang, Yu-Xiong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_MV-Map_Offboard_HD-Map_Generation_with_Multi-view_Consistency_ICCV_2023_paper.pdf",
        "aff": "University of Illinois Urbana-Champaign and Fudan University; University of Illinois Urbana-Champaign",
        "project": "",
        "github": "https://github.com/ZiYang-xie/MV-Map",
        "arxiv": ""
    },
    {
        "title": "MVPSNet: Fast Generalizable Multi-view Photometric Stereo",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MVPSNet_Fast_Generalizable_Multi-view_Photometric_Stereo_ICCV_2023_paper.html",
        "author": "Dongxu Zhao, Daniel Lichy, Pierre-Nicolas Perrin, Jan-Michael Frahm, Soumyadip Sengupta",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MVPSNet_Fast_Generalizable_Multi-view_Photometric_Stereo_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; University of North Carolina at Chapel Hill",
        "project": "",
        "github": "",
        "arxiv": "2305.11167"
    },
    {
        "title": "MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Jing Zhao, Heliang Zheng, Chaoyue Wang, Long Lan, Wenjing Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "National University of Defense Technology, Changsha, China; JD Explore Academy, Beijing, China",
        "project": "https://magicfusion.github.io/",
        "github": "",
        "arxiv": "2303.13126"
    },
    {
        "title": "Make Encoder Great Again in 3D GAN Inversion through Geometry and Occlusion-Aware Encoding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Make_Encoder_Great_Again_in_3D_GAN_Inversion_through_Geometry_ICCV_2023_paper.html",
        "author": "Ziyang Yuan, Yiming Zhu, Yu Li, Hongyu Liu, Chun Yuan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Make_Encoder_Great_Again_in_3D_GAN_Inversion_through_Geometry_ICCV_2023_paper.pdf",
        "aff": "International Digital Economy Academy (IDEA); Hong Kong University of Science and Technology; Tsinghua Shenzhen International Graduate School",
        "project": "",
        "github": "https://eg3d-goae.github.io",
        "arxiv": "2303.12326"
    },
    {
        "title": "Make-An-Animation: Large-Scale Text-conditional 3D Human Motion Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.html",
        "author": "Samaneh Azadi, Akbar Shah, Thomas Hayes, Devi Parikh, Sonal Gupta",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.pdf",
        "aff": "Sonal Gupta; Meta AI; Devi Parikh",
        "project": "https://azadis.github.io/make-an-animation",
        "github": "https://github.com/azadis/make-an-animation",
        "arxiv": ""
    },
    {
        "title": "Make-It-3D: High-fidelity 3D Creation from A Single Image with Diffusion Prior",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.html",
        "author": "Junshu Tang, Tengfei Wang, Bo Zhang, Ting Zhang, Ran Yi, Lizhuang Ma, Dong Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; HKUST; Shanghai Jiao Tong University",
        "project": "https://make-it-3d.github.io/",
        "github": "https://github.com/make-it-3d",
        "arxiv": ""
    },
    {
        "title": "Manipulate by Seeing: Creating Manipulation Controllers from Pre-Trained Representations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Manipulate_by_Seeing_Creating_Manipulation_Controllers_from_Pre-Trained_Representations_ICCV_2023_paper.html",
        "author": "Jianren Wang, Sudeep Dasari, Mohan Kumar Srirama, Shubham Tulsiani, Abhinav Gupta",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Manipulate_by_Seeing_Creating_Manipulation_Controllers_from_Pre-Trained_Representations_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "https://agi-labs.github.io/manipulate-by-seeing/",
        "github": "https://github.com/agi-labs/manipulate-by-seeing",
        "arxiv": "2303.08135"
    },
    {
        "title": "MapFormer: Boosting Change Detection by Using Pre-change Information",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bernhard_MapFormer_Boosting_Change_Detection_by_Using_Pre-change_Information_ICCV_2023_paper.html",
        "author": "Maximilian Bernhard, Niklas Strau\u00df, Matthias Schubert",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bernhard_MapFormer_Boosting_Change_Detection_by_Using_Pre-change_Information_ICCV_2023_paper.pdf",
        "aff": "LMU Munich, MCML",
        "project": "",
        "github": "https://github.com/mxbh/mapformer",
        "arxiv": ""
    },
    {
        "title": "MapPrior: Bird's-Eye View Map Layout Estimation with Generative Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_MapPrior_Birds-Eye_View_Map_Layout_Estimation_with_Generative_Models_ICCV_2023_paper.html",
        "author": "Xiyue Zhu, Vlas Zyrianov, Zhijian Liu, Shenlong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MapPrior_Birds-Eye_View_Map_Layout_Estimation_with_Generative_Models_ICCV_2023_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign; MIT",
        "project": "https://mapprior.github.io",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "March in Chat: Interactive Prompting for Remote Embodied Referring Expression",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_March_in_Chat_Interactive_Prompting_for_Remote_Embodied_Referring_Expression_ICCV_2023_paper.html",
        "author": "Yanyuan Qiao, Yuankai Qi, Zheng Yu, Jing Liu, Qi Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_March_in_Chat_Interactive_Prompting_for_Remote_Embodied_Referring_Expression_ICCV_2023_paper.pdf",
        "aff": "Australian Institute for Machine Learning, The University of Adelaide; Institute of Automation, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/YanyuanQiao/MiC",
        "arxiv": "2308.10141"
    },
    {
        "title": "Markov Game Video Augmentation for Action Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Aziere_Markov_Game_Video_Augmentation_for_Action_Segmentation_ICCV_2023_paper.html",
        "author": "Nicolas Aziere, Sinisa Todorovic",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Aziere_Markov_Game_Video_Augmentation_for_Action_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Oregon State University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MasQCLIP for Open-Vocabulary Universal Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MasQCLIP_for_Open-Vocabulary_Universal_Image_Segmentation_ICCV_2023_paper.html",
        "author": "Xin Xu, Tianyi Xiong, Zheng Ding, Zhuowen Tu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MasQCLIP_for_Open-Vocabulary_Universal_Image_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Peking University; University of California, San Diego; Tsinghua University",
        "project": "https://masqclip.github.io/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.html",
        "author": "Mingdeng Cao, Xintao Wang, Zhongang Qi, Ying Shan, Xiaohu Qie, Yinqiang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.pdf",
        "aff": "1The University of Tokyo, 2ARC Lab, Tencent PCG; 2ARC Lab, Tencent PCG; 1The University of Tokyo",
        "project": "",
        "github": "https://github.com/TencentARC/MasaCtrl",
        "arxiv": "2304.08465"
    },
    {
        "title": "Mask-Attention-Free Transformer for 3D Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lai_Mask-Attention-Free_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Xin Lai, Yuhui Yuan, Ruihang Chu, Yukang Chen, Han Hu, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Mask-Attention-Free_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; The Chinese University of Hong Kong, SmartMore; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/dvlab-research/Mask-Attention-Free-Transformer",
        "arxiv": "2309.01692"
    },
    {
        "title": "Masked Autoencoders Are Stronger Knowledge Distillers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lao_Masked_Autoencoders_Are_Stronger_Knowledge_Distillers_ICCV_2023_paper.html",
        "author": "Shanshan Lao, Guanglu Song, Boxiao Liu, Yu Liu, Yujiu Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_Masked_Autoencoders_Are_Stronger_Knowledge_Distillers_ICCV_2023_paper.pdf",
        "aff": "Sensetime Research; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Masked Autoencoders are Efficient Class Incremental Learners",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Masked_Autoencoders_are_Efficient_Class_Incremental_Learners_ICCV_2023_paper.html",
        "author": "Jiang-Tian Zhai, Xialei Liu, Andrew D. Bagdanov, Ke Li, Ming-Ming Cheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Masked_Autoencoders_are_Efficient_Class_Incremental_Learners_ICCV_2023_paper.pdf",
        "aff": "VCIP, CS, Nankai University; MICC, University of Florence; Tencent Youtu Lab",
        "project": "",
        "github": "https://github.com/scok30/MAE-CIL",
        "arxiv": "2308.12510"
    },
    {
        "title": "Masked Diffusion Transformer is a Strong Image Synthesizer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.html",
        "author": "Shanghua Gao, Pan Zhou, Ming-Ming Cheng, Shuicheng Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.pdf",
        "aff": "Nankai University; Sea AI Lab",
        "project": "",
        "github": "https://github.com/sail-sg/MDT",
        "arxiv": "2303.14389"
    },
    {
        "title": "Masked Motion Predictors are Strong 3D Action Representation Learners",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.html",
        "author": "Yunyao Mao, Jiajun Deng, Wengang Zhou, Yao Fang, Wanli Ouyang, Houqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.pdf",
        "aff": "CAS Key Laboratory of Technology in GIPAS, EEIS Department, University of Science and Technology of China; Merchants Union Consumer Finance Company Limited; CAS Key Laboratory of Technology in GIPAS, EEIS Department, University of Science and Technology of China; Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; The University of Sydney",
        "project": "",
        "github": "https://github.com/maoyunyao/MAMP",
        "arxiv": "2308.07092"
    },
    {
        "title": "Masked Retraining Teacher-Student Framework for Domain Adaptive Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Masked_Retraining_Teacher-Student_Framework_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.html",
        "author": "Zijing Zhao, Sitong Wei, Qingchao Chen, Dehui Li, Yifan Yang, Yuxin Peng, Yang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Masked_Retraining_Teacher-Student_Framework_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Masked Retraining Teacher-Student Framework for\nDomain Adaptive Object Detection\nZijing Zhao1Sitong Wei1Qingchao Chen2Dehui Li3Yifan Yang3Yuxin Peng1Yang Liu1*\n1Wangxuan Institute of Computer Technology, Peking University\n2National Institute of Health Data Science, Peking University3Tencent Intelligent Mobility\nzijingzhao@stu.pku.edu.cn {weisitong, qingchao.chen, pengyuxin, yangliu }@pku.edu.cn\n{dehuili, lvanyang }@tencent.com\nAbstract\nDomain adaptive Object Detection (DAOD) leverages a\nlabeled domain (source) to learn an object detector gen-\neralizing to a novel domain without annotation (target).\nRecent advances use a teacher-student framework, i.e., a\nstudent model is supervised by the pseudo labels from a\nteacher model. Though great success, they suffer from the\nlimited number of pseudo boxes with incorrect predictions\ncaused by the domain shift, misleading the student model to\nget sub-optimal results. To mitigate this problem, we pro-\npose Masked Retraining Teacher-student framework (MRT)\nwhich leverages masked autoencoder and selective retrain-\ning mechanism on detection transformer. Specifically, we\npresent a customized design of masked autoencoder branch,\nmasking the multi-scale feature maps of target images and\nreconstructing features by the encoder of the student model\nand an auxiliary decoder. This helps the student model cap-\nture target domain characteristics and become a more data-\nefficient learner to gain knowledge from the limited number\nof pseudo boxes. Furthermore, we adopt selective retrain-\ning mechanism, periodically re-initializing certain parts of\nthe student parameters with masked autoencoder refined\nweights to allow the model to jump out of the local opti-\nmum biased to the incorrect pseudo labels. Experimental\nresults on three DAOD benchmarks demonstrate the effec-\ntiveness of our method. Code can be found at https://\ngithub.com/JeremyZhao1998/MRT-release .\n1. Introduction\nObject detection has a wide range of real-world appli-\ncation scenarios, and has been deeply studied in computer\nvision researches. CNN-based [35, 32, 40] and transformer-\nbased [3, 51] detectors have shown great success in chal-\nlenging benchmarks. However, they suffer from domain\n*Corresponding author\n(a) Performance under Limited Number of \nBounding Box Annotations(b) Performance of Category \u201cbicycle\u201d \nduring Teaching Process39.38 \n24.11 \n20.73 \n13.79 40.40 \n25.46 \n22.57 \n16.66 \n10.0020.0030.0040.00\n1  1/2  1/3  1/5Performance (mAP)\nSampling Ratio of Bounding Boxes\nBaseline Baseline + MAE0.40.420.440.460.480.50.52\n1 21 41 61 81 101 121AP@50 of Category \u201cbicycle\u201d\nTraining Epoch Number\n Baseline  Baseline + Retrain(a) mAP under limited boxes\n(a) Performance under Limited Number of \nBounding Box Annotations(b) Performance of Category \u201cbicycle\u201d \nduring Teaching Process39.38 \n24.11 \n20.73 \n13.79 40.40 \n25.46 \n22.57 \n16.66 \n10.0020.0030.0040.00\n1  1/2  1/3  1/5Performance (mAP)\nSampling Ratio of Bounding Boxes\nBaseline Baseline + MAE0.40.420.440.460.480.50.52\n1 21 41 61 81 101 121AP@50 of Category \u201cbicycle\u201d\nTraining Epoch Number\n Baseline  Baseline + Retrain (b) Category AP during training\nFigure 1. (a) Performance under limited number of box an-\nnotations . We adopt MAE in training target images with ground\ntruth labels, but manually reduce the amount of bounding boxes.\nMAE boosts the performance by a large margin under limited\nboxes. (b) Performance of Category \u201cbicycle\u201d during training .\nThe performance declines rapidly due to the local optimum caused\nby incorrect pseudo boxes. With the help of retraining (every 40\nepochs), the model is able to jump out of the local optimum.\nshift where there is an obvious distribution gap between the\npretraining data and the deployed environment.\nTo mitigate the performance drop caused by domain shift\nwithout extra annotation, unsupervised domain adaptation\n(UDA) has been studied in classification, segmentation and\nobject detection tasks, where the model is trained on a la-\nbeled source domain and an unlabeled target domain, and\nis expected to generalize well on the target domain. As a\nbranch of UDA, unsupervised domain adaptive object de-\ntection (DAOD) researches [9, 49, 29, 48] utilize numerous\ntechniques such as adversarial alignment, image-to-image\ntranslation, GNNs and mean teacher training, widely im-\nproving domain adaptation performance of object detectors.\nAmong these approaches, [29, 48, 5, 20] use a teacher-\nstudent framework where a teacher model produces pseudo\nlabels of the unlabeled target images to supervise a stu-\ndent model, and has achieved significant performance gains.\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n19039\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Masked Spatio-Temporal Structure Prediction for Self-supervised Learning on Point Cloud Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Masked_Spatio-Temporal_Structure_Prediction_for_Self-supervised_Learning_on_Point_Cloud_ICCV_2023_paper.html",
        "author": "Zhiqiang Shen, Xiaoxiao Sheng, Hehe Fan, Longguang Wang, Yulan Guo, Qiong Liu, Hao Wen, Xi Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Masked_Spatio-Temporal_Structure_Prediction_for_Self-supervised_Learning_on_Point_Cloud_ICCV_2023_paper.pdf",
        "aff": "Sun Yat-sen University; Shanghai Jiao Tong University; Aviation University of Air Force; Zhejiang University; CloudWalk",
        "project": "",
        "github": "https://github.com/JohnsonSign/MaST-Pre",
        "arxiv": "2308.09245"
    },
    {
        "title": "Masked Spiking Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Masked_Spiking_Transformer_ICCV_2023_paper.html",
        "author": "Ziqing Wang, Yuetong Fang, Jiahang Cao, Qiang Zhang, Zhongrui Wang, Renjing Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Masked_Spiking_Transformer_ICCV_2023_paper.pdf",
        "aff": "The University of Hong Kong; ACCESS - AI Chip Center for Emerging Smart Systems; The Hong Kong University of Science and Technology (Guangzhou); The Hong Kong University of Science and Technology (Guangzhou); North Carolina State University",
        "project": "",
        "github": "https://github.com/bic-L/Masked-Spiking-Transformer",
        "arxiv": "2210.01208"
    },
    {
        "title": "Mastering Spatial Graph Prediction of Road Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sotiris_Mastering_Spatial_Graph_Prediction_of_Road_Networks_ICCV_2023_paper.html",
        "author": "Anagnostidis Sotiris, Aurelien Lucchi, Thomas Hofmann",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sotiris_Mastering_Spatial_Graph_Prediction_of_Road_Networks_ICCV_2023_paper.pdf",
        "aff": "ETH Z\u00fcrich; University of Basel",
        "project": "",
        "github": "",
        "arxiv": "2210.00828"
    },
    {
        "title": "MatrixCity: A Large-scale City Dataset for City-scale Neural Rendering and Beyond",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_MatrixCity_A_Large-scale_City_Dataset_for_City-scale_Neural_Rendering_and_ICCV_2023_paper.html",
        "author": "Yixuan Li, Lihan Jiang, Linning Xu, Yuanbo Xiangli, Zhenzhi Wang, Dahua Lin, Bo Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MatrixCity_A_Large-scale_City_Dataset_for_City-scale_Neural_Rendering_and_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong, Shanghai AI Laboratory; The Chinese University of Hong Kong; Shanghai AI Laboratory",
        "project": "https://city-super.github.io/matrixcity/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MatrixVT: Efficient Multi-Camera to BEV Transformation for 3D Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_MatrixVT_Efficient_Multi-Camera_to_BEV_Transformation_for_3D_Perception_ICCV_2023_paper.html",
        "author": "Hongyu Zhou, Zheng Ge, Zeming Li, Xiangyu Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_MatrixVT_Efficient_Multi-Camera_to_BEV_Transformation_for_3D_Perception_ICCV_2023_paper.pdf",
        "aff": "MEGVII Technology",
        "project": "",
        "github": "",
        "arxiv": "2211.10593"
    },
    {
        "title": "MeMOTR: Long-Term Memory-Augmented Transformer for Multi-Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_MeMOTR_Long-Term_Memory-Augmented_Transformer_for_Multi-Object_Tracking_ICCV_2023_paper.html",
        "author": "Ruopeng Gao, Limin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_MeMOTR_Long-Term_Memory-Augmented_Transformer_for_Multi-Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; Shanghai AI Lab",
        "project": "",
        "github": "https://github.com/MCG-NJU/MeMOTR",
        "arxiv": "2307.15700"
    },
    {
        "title": "MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ding_MeViS_A_Large-scale_Benchmark_for_Video_Segmentation_with_Motion_Expressions_ICCV_2023_paper.html",
        "author": "Henghui Ding, Chang Liu, Shuting He, Xudong Jiang, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MeViS_A_Large-scale_Benchmark_for_Video_Segmentation_with_Motion_Expressions_ICCV_2023_paper.pdf",
        "aff": "School of EEE, Nanyang Technological University; S-Lab, Nanyang Technological University",
        "project": "https://henghuiding.github.io/MeViS",
        "github": "",
        "arxiv": "2308.08544"
    },
    {
        "title": "Measuring Asymmetric Gradient Discrepancy in Parallel Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.html",
        "author": "Fan Lyu, Qing Sun, Fanhua Shang, Liang Wan, Wei Feng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "College of Intelligence and Computing, Tianjin University",
        "project": "",
        "github": "https://github.com/fanlyu/maxdo",
        "arxiv": ""
    },
    {
        "title": "MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training for X-ray Diagnosis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.html",
        "author": "Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.pdf",
        "aff": "Cooperative Medianet Innovation Center, Shanghai Jiao Tong University; Shanghai AI Laboratory",
        "project": "https://chaoyi-wu.github.io/MedKLIP/",
        "github": "https://github.com/chaoyi-wu/MedKLIP",
        "arxiv": ""
    },
    {
        "title": "Membrane Potential Batch Normalization for Spiking Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Membrane_Potential_Batch_Normalization_for_Spiking_Neural_Networks_ICCV_2023_paper.html",
        "author": "Yufei Guo, Yuhan Zhang, Yuanpei Chen, Weihang Peng, Xiaode Liu, Liwen Zhang, Xuhui Huang, Zhe Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Membrane_Potential_Batch_Normalization_for_Spiking_Neural_Networks_ICCV_2023_paper.pdf",
        "aff": "Intelligent Science & Technology Academy of CASIC, China; Scientific Research Laboratory of Aerospace Intelligent Systems and Technology, China",
        "project": "",
        "github": "",
        "arxiv": "2308.08359"
    },
    {
        "title": "Memory-and-Anticipation Transformer for Online Action Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Memory-and-Anticipation_Transformer_for_Online_Action_Understanding_ICCV_2023_paper.html",
        "author": "Jiahao Wang, Guo Chen, Yifei Huang, Limin Wang, Tong Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Memory-and-Anticipation_Transformer_for_Online_Action_Understanding_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/Echo0125/Memory-and-Anticipation-Transformer",
        "arxiv": "2308.07893"
    },
    {
        "title": "MemorySeg: Online LiDAR Semantic Segmentation with a Latent Memory",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_MemorySeg_Online_LiDAR_Semantic_Segmentation_with_a_Latent_Memory_ICCV_2023_paper.html",
        "author": "Enxu Li, Sergio Casas, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MemorySeg_Online_LiDAR_Semantic_Segmentation_with_a_Latent_Memory_ICCV_2023_paper.pdf",
        "aff": "Waabi University of Toronto",
        "project": "https://waabi.ai/research/memoryseg",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Mesh2Tex: Generating Mesh Textures from Image Queries",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.html",
        "author": "Alexey Bokhovkin, Shubham Tulsiani, Angela Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich; Carnegie Mellon University",
        "project": "alexeybokhovkin.github.io/mesh2tex/",
        "github": "https://github.com/alexeybokhovkin/mesh2tex",
        "arxiv": "2304.05868"
    },
    {
        "title": "Meta OOD Learning For Continuously Adaptive OOD Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Meta_OOD_Learning_For_Continuously_Adaptive_OOD_Detection_ICCV_2023_paper.html",
        "author": "Xinheng Wu, Jie Lu, Zhen Fang, Guangquan Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Meta_OOD_Learning_For_Continuously_Adaptive_OOD_Detection_ICCV_2023_paper.pdf",
        "aff": "Australian Artificial Intelligence Institute, University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": "2309.11705"
    },
    {
        "title": "Meta-ZSDETR: Zero-shot DETR with Meta-learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Meta-ZSDETR_Zero-shot_DETR_with_Meta-learning_ICCV_2023_paper.html",
        "author": "Lu Zhang, Chenbo Zhang, Jiajia Zhao, Jihong Guan, Shuigeng Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Meta-ZSDETR_Zero-shot_DETR_with_Meta-learning_ICCV_2023_paper.pdf",
        "aff": "Science and Technology on Complex System Control and Intelligent Agent Cooperation Laboratory, China; Shanghai Key Lab of Intelligent Information Processing, and School of Computer Science, Fudan University, China; Department of Computer Science & Technology, Tongji University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MetaBEV: Solving Sensor Failures for 3D Detection and Map Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ge_MetaBEV_Solving_Sensor_Failures_for_3D_Detection_and_Map_Segmentation_ICCV_2023_paper.html",
        "author": "Chongjian Ge, Junsong Chen, Enze Xie, Zhongdao Wang, Lanqing Hong, Huchuan Lu, Zhenguo Li, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_MetaBEV_Solving_Sensor_Failures_for_3D_Detection_and_Map_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Dalian University of Technology; The University of Hong Kong; Huawei Noah\u2019s Ark Lab",
        "project": "https://chongjiange.github.io/metabev.html",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MetaF2N: Blind Image Super-Resolution by Learning Efficient Model Adaptation from Faces",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.html",
        "author": "Zhicun Yin, Ming Liu, Xiaoming Li, Hui Yang, Longan Xiao, Wangmeng Zuo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.pdf",
        "aff": "Harbin Institute of Technology, Peng Cheng Laboratory; Harbin Institute of Technology; Shanghai Transsion Co, Ltd",
        "project": "",
        "github": "https://github.com/yinzhicun/MetaF2N",
        "arxiv": "2309.08113"
    },
    {
        "title": "MetaGCD: Learning to Continually Learn in Generalized Category Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MetaGCD_Learning_to_Continually_Learn_in_Generalized_Category_Discovery_ICCV_2023_paper.html",
        "author": "Yanan Wu, Zhixiang Chi, Yang Wang, Songhe Feng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MetaGCD_Learning_to_Continually_Learn_in_Generalized_Category_Discovery_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Software Engineering, Concordia University, Montreal, H3G2J1, Canada; Key Laboratory of Big Data & Artificial Intelligence in Transportation, Ministry of Education, Beijing Jiaotong University, Beijing, 100044, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, 100044, China; Department of Electrical and Computer Engineering, University of Toronto, Toronto, M5G1V7, Canada",
        "project": "",
        "github": "",
        "arxiv": "2308.11063"
    },
    {
        "title": "Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.html",
        "author": "Wei Yin, Chi Zhang, Hao Chen, Zhipeng Cai, Gang Yu, Kaixuan Wang, Xiaozhi Chen, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n9043\n",
        "project": "",
        "github": "",
        "arxiv": "2307.10984"
    },
    {
        "title": "Mimic3D: Thriving 3D-Aware GANs via 3D-to-2D Imitation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Mimic3D_Thriving_3D-Aware_GANs_via_3D-to-2D_Imitation_ICCV_2023_paper.html",
        "author": "Xingyu Chen, Yu Deng, Baoyuan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Mimic3D_Thriving_3D-Aware_GANs_via_3D-to-2D_Imitation_ICCV_2023_paper.pdf",
        "aff": "Xiaobing.AI",
        "project": "https://seanchenxy.github.io/Mimic3DWeb",
        "github": "https://github.com/seanchenxy/Mimic3DWeb",
        "arxiv": "2303.09036"
    },
    {
        "title": "MiniROAD: Minimal RNN Framework for Online Action Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.html",
        "author": "Joungbin An, Hyolim Kang, Su Ho Han, Ming-Hsuan Yang, Seon Joo Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; Yonsei University, UC Merced, Google Research",
        "project": "",
        "github": "https://github.com/jbistanbul/MiniROAD",
        "arxiv": ""
    },
    {
        "title": "Minimal Solutions to Generalized Three-View Relative Pose Problem",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Minimal_Solutions_to_Generalized_Three-View_Relative_Pose_Problem_ICCV_2023_paper.html",
        "author": "Yaqing Ding, Chiang-Heng Chien, Viktor Larsson, Karl \u00c5str\u00f6m, Benjamin Kimia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Minimal_Solutions_to_Generalized_Three-View_Relative_Pose_Problem_ICCV_2023_paper.pdf",
        "aff": "School of Engineering, Brown University; Centre for Mathematical Sciences, Lund University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Minimal Solutions to Uncalibrated Two-view Geometry with Known Epipoles",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nakano_Minimal_Solutions_to_Uncalibrated_Two-view_Geometry_with_Known_Epipoles_ICCV_2023_paper.html",
        "author": "Gaku Nakano",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nakano_Minimal_Solutions_to_Uncalibrated_Two-view_Geometry_with_Known_Epipoles_ICCV_2023_paper.pdf",
        "aff": "NEC Corporation, 1753 Shimonumabe, Kawasaki, Japan",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Minimum Latency Deep Online Video Stabilization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Minimum_Latency_Deep_Online_Video_Stabilization_ICCV_2023_paper.html",
        "author": "Zhuofan Zhang, Zhen Liu, Ping Tan, Bing Zeng, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Minimum_Latency_Deep_Online_Video_Stabilization_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China, Megvii Technology; University of Electronic Science and Technology of China; The Hong Kong University of Science and Technology; Megvii Technology",
        "project": "",
        "github": "https://github.com/liuzhen03/NNDVS",
        "arxiv": "2212.02073"
    },
    {
        "title": "Mining bias-target Alignment from Voronoi Cells",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nahon_Mining_bias-target_Alignment_from_Voronoi_Cells_ICCV_2023_paper.html",
        "author": "R\u00e9mi Nahon, Van-Tam Nguyen, Enzo Tartaglione",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nahon_Mining_bias-target_Alignment_from_Voronoi_Cells_ICCV_2023_paper.pdf",
        "aff": "LTCI, T \u00b4el\u00b4ecom Paris, Institut Polytechnique de Paris, France",
        "project": "",
        "github": "",
        "arxiv": "2305.03691"
    },
    {
        "title": "Misalign, Contrast then Distill: Rethinking Misalignments in Language-Image Pre-training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Misalign_Contrast_then_Distill_Rethinking_Misalignments_in_Language-Image_Pre-training_ICCV_2023_paper.html",
        "author": "Bumsoo Kim, Yeonsik Jo, Jinhyung Kim, Seunghwan Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Misalign_Contrast_then_Distill_Rethinking_Misalignments_in_Language-Image_Pre-training_ICCV_2023_paper.pdf",
        "aff": "LG AI Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Mitigating_Adversarial_Vulnerability_through_Causal_Parameter_Estimation_by_Adversarial_Double_ICCV_2023_paper.html",
        "author": "Byung-Kwan Lee, Junho Kim, Yong Man Ro",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Mitigating_Adversarial_Vulnerability_through_Causal_Parameter_Estimation_by_Adversarial_Double_ICCV_2023_paper.pdf",
        "aff": "Image and Video Systems Lab, School of Electrical Engineering, KAIST, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2307.07250"
    },
    {
        "title": "Mitigating and Evaluating Static Bias of Action Representations in the Background and the Foreground",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Mitigating_and_Evaluating_Static_Bias_of_Action_Representations_in_the_ICCV_2023_paper.html",
        "author": "Haoxin Li, Yuan Liu, Hanwang Zhang, Boyang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Mitigating_and_Evaluating_Static_Bias_of_Action_Representations_in_the_ICCV_2023_paper.pdf",
        "aff": "Guangzhou University; Nanyang Technological University",
        "project": "",
        "github": "https://github.com/lihaoxin05/StillMix",
        "arxiv": "2211.12883"
    },
    {
        "title": "MixBag: Bag-Level Data Augmentation for Learning from Label Proportions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Asanomi_MixBag_Bag-Level_Data_Augmentation_for_Learning_from_Label_Proportions_ICCV_2023_paper.html",
        "author": "Takanori Asanomi, Shinnosuke Matsuo, Daiki Suehiro, Ryoma Bise",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Asanomi_MixBag_Bag-Level_Data_Augmentation_for_Learning_from_Label_Proportions_ICCV_2023_paper.pdf",
        "aff": "Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; RIKEN AIP, Japan",
        "project": "",
        "github": "",
        "arxiv": "2308.08822"
    },
    {
        "title": "MixCycle: Mixup Assisted Semi-Supervised 3D Single Object Tracking with Cycle Consistency",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MixCycle_Mixup_Assisted_Semi-Supervised_3D_Single_Object_Tracking_with_Cycle_ICCV_2023_paper.html",
        "author": "Qiao Wu, Jiaqi Yang, Kun Sun, Chu'ai Zhang, Yanning Zhang, Mathieu Salzmann",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MixCycle_Mixup_Assisted_Semi-Supervised_3D_Single_Object_Tracking_with_Cycle_ICCV_2023_paper.pdf",
        "aff": "\u00b4Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne; Northwestern Polytechnical University; China University of Geosciences, Wuhan",
        "project": "",
        "github": "https://github.com/Mumuqiao/MixCycle",
        "arxiv": "2303.09219"
    },
    {
        "title": "MixPath: A Unified Approach for One-shot Neural Architecture Search",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chu_MixPath_A_Unified_Approach_for_One-shot_Neural_Architecture_Search_ICCV_2023_paper.html",
        "author": "Xiangxiang Chu, Shun Lu, Xudong Li, Bo Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_MixPath_A_Unified_Approach_for_One-shot_Neural_Architecture_Search_ICCV_2023_paper.pdf",
        "aff": "; cxxgtxy@gmail.com; lushun19s@ict.ac.cn; lixudong16@mails.ucas.edu.cn",
        "project": "",
        "github": "",
        "arxiv": "2001.05887"
    },
    {
        "title": "MixReorg: Cross-Modal Mixed Patch Reorganization is a Good Mask Learner for Open-World Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_MixReorg_Cross-Modal_Mixed_Patch_Reorganization_is_a_Good_Mask_Learner_ICCV_2023_paper.html",
        "author": "Kaixin Cai, Pengzhen Ren, Yi Zhu, Hang Xu, Jianzhuang Liu, Changlin Li, Guangrun Wang, Xiaodan Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_MixReorg_Cross-Modal_Mixed_Patch_Reorganization_is_a_Good_Mask_Learner_ICCV_2023_paper.pdf",
        "aff": "Shenzhen Campus of Sun Yat-sen University; University of Technology Sydney; Huawei Noah\u2019s Ark Lab; University of Oxford; Shenzhen Campus of Sun Yat-sen University, MBZUAI, DarkMatter AI Research",
        "project": "",
        "github": "",
        "arxiv": "2308.04829"
    },
    {
        "title": "MixSpeech: Cross-Modality Self-Learning with Audio-Visual Stream Mixup for Visual Speech Translation and Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_MixSpeech_Cross-Modality_Self-Learning_with_Audio-Visual_Stream_Mixup_for_Visual_Speech_ICCV_2023_paper.html",
        "author": "Xize Cheng, Tao Jin, Rongjie Huang, Linjun Li, Wang Lin, Zehan Wang, Ye Wang, Huadai Liu, Aoxiong Yin, Zhou Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_MixSpeech_Cross-Modality_Self-Learning_with_Audio-Visual_Stream_Mixup_for_Visual_Speech_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2303.05309"
    },
    {
        "title": "MixSynthFormer: A Transformer Encoder-like Structure with Mixed Synthetic Self-attention for Efficient Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_MixSynthFormer_A_Transformer_Encoder-like_Structure_with_Mixed_Synthetic_Self-attention_for_ICCV_2023_paper.html",
        "author": "Yuran Sun, Alan William Dougherty, Zhuoying Zhang, Yi King Choi, Chuan Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_MixSynthFormer_A_Transformer_Encoder-like_Structure_with_Mixed_Synthetic_Self-attention_for_ICCV_2023_paper.pdf",
        "aff": "The University of Hong Kong",
        "project": "",
        "github": "https://github.com/ireneesun/MixSynthFormer.git",
        "arxiv": ""
    },
    {
        "title": "Mixed Neural Voxels for Fast Multi-view Video Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Mixed_Neural_Voxels_for_Fast_Multi-view_Video_Synthesis_ICCV_2023_paper.html",
        "author": "Feng Wang, Sinan Tan, Xinghang Li, Zeyue Tian, Yafei Song, Huaping Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Mixed_Neural_Voxels_for_Fast_Multi-view_Video_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; Beijing National Research Center for Information Science and Technology(BNRist), Department of Computer Science and Technology, Tsinghua University; XR Lab, DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/fengres/mixvoxels",
        "arxiv": "2212.00190"
    },
    {
        "title": "MoTIF: Learning Motion Trajectories with Local Implicit Neural Functions for Continuous Space-Time Video Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.html",
        "author": "Yi-Hsin Chen, Si-Cun Chen, Yi-Hsin Chen, Yen-Yu Lin, Wen-Hsiao Peng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.pdf",
        "aff": "National Yang Ming Chiao Tung University, Taiwan",
        "project": "",
        "github": "https://github.com/sichun233746/MoTIF",
        "arxiv": "2307.07988"
    },
    {
        "title": "Modality Unifying Network for Visible-Infrared Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Modality_Unifying_Network_for_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.html",
        "author": "Hao Yu, Xu Cheng, Wei Peng, Weihao Liu, Guoying Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Modality_Unifying_Network_for_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf",
        "aff": "Department of Psychiatry and Behavioral Sciences, Stanford University, USA; School of Computer Science, Nanjing University of Information Science and Technology, China; School of Computer Science and Technology, Soochow University, China; Center for Machine Vision and Signal Analysis, University of Oulu, Finland",
        "project": "",
        "github": "",
        "arxiv": "2309.06262"
    },
    {
        "title": "Model Calibration in Dense Classification with Adaptive Label Perturbation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.html",
        "author": "Jiawei Liu, Changkun Ye, Shan Wang, Ruikai Cui, Jing Zhang, Kaihao Zhang, Nick Barnes",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.pdf",
        "aff": "The Australian National University",
        "project": "",
        "github": "https://github.com/Carlisle-Liu/ASLP",
        "arxiv": "2307.13539"
    },
    {
        "title": "ModelGiF: Gradient Fields for Model Functional Distance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_ModelGiF_Gradient_Fields_for_Model_Functional_Distance_ICCV_2023_paper.html",
        "author": "Jie Song, Zhengqi Xu, Sai Wu, Gang Chen, Mingli Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_ModelGiF_Gradient_Fields_for_Model_Functional_Distance_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University",
        "project": "",
        "github": "https://github.com/zju-vipa/modelgif",
        "arxiv": "2309.11013"
    },
    {
        "title": "Modeling the Relative Visual Tempo for Self-supervised Skeleton-based Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Modeling_the_Relative_Visual_Tempo_for_Self-supervised_Skeleton-based_Action_Recognition_ICCV_2023_paper.html",
        "author": "Yisheng Zhu, Hu Han, Zhengtao Yu, Guangcan Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Modeling_the_Relative_Visual_Tempo_for_Self-supervised_Skeleton-based_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "School of Automation, Southeast University; Nanjing University of Posts and Telecommunications; Faculty of Information Engineering and Automation, Kunming University of Science and Technology; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS)",
        "project": "",
        "github": "https://github.com/Zhuysheng/RVTCLR",
        "arxiv": ""
    },
    {
        "title": "MolGrapher: Graph-based Visual Recognition of Chemical Structures",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Morin_MolGrapher_Graph-based_Visual_Recognition_of_Chemical_Structures_ICCV_2023_paper.html",
        "author": "Lucas Morin, Martin Danelljan, Maria Isabel Agea, Ahmed Nassar, Valery Weber, Ingmar Meijer, Peter Staar, Fisher Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Morin_MolGrapher_Graph-based_Visual_Recognition_of_Chemical_Structures_ICCV_2023_paper.pdf",
        "aff": "IBM Research; ETH Zurich",
        "project": "",
        "github": "https://github.com/DS4SD/MolGrapher",
        "arxiv": "2308.12234"
    },
    {
        "title": "Moment Detection in Long Tutorial Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Croitoru_Moment_Detection_in_Long_Tutorial_Videos_ICCV_2023_paper.html",
        "author": "Ioana Croitoru, Simion-Vlad Bogolin, Samuel Albanie, Yang Liu, Zhaowen Wang, Seunghyun Yoon, Franck Dernoncourt, Hailin Jin, Trung Bui",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Croitoru_Moment_Detection_in_Long_Tutorial_Videos_ICCV_2023_paper.pdf",
        "aff": "Moment Detection in Long Tutorial Videos\nIoana Croitoru*Simion-Vlad Bogolin3Samuel Albanie2Yang Liu4\nZhaowen Wang1Seunghyun Yoon1Franck Dernoncourt1Hailin Jin1Trung Bui1\n1Adobe Research2Department of Engineering, University of Cambridge\n3Filtir4Wangxuan Inst. of Computer Technology, Peking University\nAbstract\nTutorial videos play an increasingly important role in\nprofessional development and self-directed education. For\nusers to realise the full benefits of this medium, tutorial\nvideos must be efficiently searchable. In this work, we fo-\ncus on the task of moment detection, in which the goal is\nto localise the temporal window where a given event occurs\nwithin a given tutorial video. Prior work on moment de-\ntection has focused primarily on short videos (typically on\nvideos shorter than three minutes). However, many tutorial\nvideos are substantially longer (stretching to hours in dura-\ntion), presenting significant challenges for existing moment\ndetection approaches.\nTo study this problem, we propose the first dataset\nof untrimmed, long-form tutorial videos for the task of\nMoment Detection called the Behance Moment Detection\n(BMD) dataset. BMD videos have an average duration\nof over one hour and are characterised by slowly evolv-\ning visual content and wide-ranging dialogue. To meet\nthe unique challenges of this dataset, we propose a new\nframework, LONG MOMENT -DETR, and demonstrate that\nit outperforms strong baselines. Additionally, we introduce\na variation of the dataset that contains YouTube Chapter\nannotations and show that the features obtained by our\nframework can be successfully used to boost the perfor-\nmance on the task of chapter detection. Code and data\ncan be found at https://github.com/ioanacroi/\nlongmoment-detr .\n1. Introduction\nEnabled by cheaper disk storage and networking tech-\nnology, long-form videos of tutorial content are proliferat-\ning. As such, there is a pressing need to develop effective\ntools for searching within videos. In this work, we consider\nthis problem through the lens of moment detection \u2014 given\na video and a natural language query, our task is to find the\n*Work done during an internship at Adobe. Now at V7 Labs.\nFigure 1. LONG MOMENT -DETR.Our framework performs mo-\nment detection and unlike previous state of the art methods, it\nworks on long tutorial videos.\ntemporal span of the video that best matches the query (as\nshown in Fig. 1). Beyond tutorial content, this task also has\napplications in domains such as security and entertainment.\nTo study moment detection in the long-form setting, we\nintroduce, the first database of long tutorial videos with\nmanual annotations for validation and testing, called Be-\nhance Moment Detection (BMD). The videos, which are\ncollected from the Behance platform1, consist of tutorial\nvideos that teach skills with various creative tools such as\ndrawing, movie editing, animation and photo editing.\nExisting moment detection datasets predominantly fea-\nture short videos centered on human activities, such as\ncooking or swimming. In contrast, our BMD dataset em-\nphasizes long tutorial videos that explore the use of soft-\nware tools for digital artistry. Typically, these tutorials in-\nvolve screen-sharing sessions detailing creative processes,\noften spanning several hours. Efficiently localizing specific\nsegments in such long videos can greatly enhance user nav-\n1https://behance.net\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n2594\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MonoDETR_Depth-guided_Transformer_for_Monocular_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Renrui Zhang, Han Qiu, Tai Wang, Ziyu Guo, Ziteng Cui, Yu Qiao, Hongsheng Li, Peng Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MonoDETR_Depth-guided_Transformer_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "2Shanghai Artificial Intelligence Laboratory; 1CUHK MMLab, 2Shanghai Artificial Intelligence Laboratory; 1CUHK MMLab, 2Shanghai Artificial Intelligence Laboratory, 3Centre for Perceptual and Interactive Intelligence (CPII)",
        "project": "",
        "github": "https://github.com/ZrrSkywalker/MonoDETR",
        "arxiv": "2203.13310"
    },
    {
        "title": "MonoNeRD: NeRF-like Representations for Monocular 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MonoNeRD_NeRF-like_Representations_for_Monocular_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Junkai Xu, Liang Peng, Haoran Cheng, Hao Li, Wei Qian, Ke Li, Wenxiao Wang, Deng Cai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MonoNeRD_NeRF-like_Representations_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "State Key Lab of CAD & CG, Zhejiang University; FABU Inc.; FABU Inc.; School of Software Technology, Zhejiang University; Fullong Inc",
        "project": "",
        "github": "https://github.com/cskkxjk/MonoNeRD",
        "arxiv": "2308.09421"
    },
    {
        "title": "MonoNeRF: Learning a Generalizable Dynamic Radiance Field from Monocular Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tian_MonoNeRF_Learning_a_Generalizable_Dynamic_Radiance_Field_from_Monocular_Videos_ICCV_2023_paper.html",
        "author": "Fengrui Tian, Shaoyi Du, Yueqi Duan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_MonoNeRF_Learning_a_Generalizable_Dynamic_Radiance_Field_from_Monocular_Videos_ICCV_2023_paper.pdf",
        "aff": "Department of Electronic Engineering, Tsinghua University; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Applications, and Institute of Arti\ufb01cial Intelligence and Robotics, Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": "2212.13056"
    },
    {
        "title": "Monocular 3D Object Detection with Bounding Box Denoising in 3D by Perceiver",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.html",
        "author": "Xianpeng Liu, Ce Zheng, Kelvin B Cheng, Nan Xue, Guo-Jun Qi, Tianfu Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.pdf",
        "aff": "North Carolina State University; OPPO Seattle Research Center, USA; University of Central Florida; Ant Group",
        "project": "https://xianpeng919.github.io/monoxiver",
        "github": "https://github.com/xianpeng919/monoxiver",
        "arxiv": "2304.01289"
    },
    {
        "title": "Monte Carlo Linear Clustering with Single-Point Supervision is Enough for Infrared Small Target Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Monte_Carlo_Linear_Clustering_with_Single-Point_Supervision_is_Enough_for_ICCV_2023_paper.html",
        "author": "Boyang Li, Yingqian Wang, Longguang Wang, Fei Zhang, Ting Liu, Zaiping Lin, Wei An, Yulan Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Monte_Carlo_Linear_Clustering_with_Single-Point_Supervision_is_Enough_for_ICCV_2023_paper.pdf",
        "aff": "Shanghai Jiao Tong University; Aviation University of Air Force; National University of Defense Technology",
        "project": "",
        "github": "https://github.com/YeRen123455/SIRST-Single-Point-Supervision",
        "arxiv": "2304.04442"
    },
    {
        "title": "MoreauGrad: Sparse and Robust Interpretation of Neural Networks via Moreau Envelope",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MoreauGrad_Sparse_and_Robust_Interpretation_of_Neural_Networks_via_Moreau_ICCV_2023_paper.html",
        "author": "Jingwei Zhang, Farzan Farnia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MoreauGrad_Sparse_and_Robust_Interpretation_of_Neural_Networks_via_Moreau_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/buyeah1109/MoreauGrad",
        "arxiv": "2302.05294"
    },
    {
        "title": "MosaiQ: Quantum Generative Adversarial Networks for Image Generation on NISQ Computers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.html",
        "author": "Daniel Silver, Tirthak Patel, William Cutler, Aditya Ranjan, Harshitta Gandhi, Devesh Tiwari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.pdf",
        "aff": "Rice University; Northeastern University",
        "project": "",
        "github": "",
        "arxiv": "2308.11096"
    },
    {
        "title": "Most Important Person-Guided Dual-Branch Cross-Patch Attention for Group Affect Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_Most_Important_Person-Guided_Dual-Branch_Cross-Patch_Attention_for_Group_Affect_Recognition_ICCV_2023_paper.html",
        "author": "Hongxia Xie, Ming-Xian Lee, Tzu-Jui Chen, Hung-Jen Chen, Hou-I Liu, Hong-Han Shuai, Wen-Huang Cheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Most_Important_Person-Guided_Dual-Branch_Cross-Patch_Attention_for_Group_Affect_Recognition_ICCV_2023_paper.pdf",
        "aff": "University of Illinois Urbana-Champaign; National Taiwan University; National Yang Ming Chiao Tung University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Motion-Guided Masking for Spatiotemporal Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Motion-Guided_Masking_for_Spatiotemporal_Representation_Learning_ICCV_2023_paper.html",
        "author": "David Fan, Jue Wang, Shuai Liao, Yi Zhu, Vimal Bhat, Hector Santos-Villalobos, Rohith MV, Xinyu Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Motion-Guided_Masking_for_Spatiotemporal_Representation_Learning_ICCV_2023_paper.pdf",
        "aff": "AWS AI Labs; Amazon Fulfillment Technology; Amazon Prime Video",
        "project": "",
        "github": "",
        "arxiv": "2308.12962"
    },
    {
        "title": "MotionBERT: A Unified Perspective on Learning Human Motion Representations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_MotionBERT_A_Unified_Perspective_on_Learning_Human_Motion_Representations_ICCV_2023_paper.html",
        "author": "Wentao Zhu, Xiaoxuan Ma, Zhaoyang Liu, Libin Liu, Wayne Wu, Yizhou Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MotionBERT_A_Unified_Perspective_on_Learning_Human_Motion_Representations_ICCV_2023_paper.pdf",
        "aff": "Peking University; Shanghai AI Laboratory",
        "project": "https://motionbert.github.io/",
        "github": "https://github.com/motionbert",
        "arxiv": "2210.06551"
    },
    {
        "title": "MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving Camera Videos with Spherical Buffers and Padded Convolutions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Parger_MotionDeltaCNN_Sparse_CNN_Inference_of_Frame_Differences_in_Moving_Camera_ICCV_2023_paper.html",
        "author": "Mathias Parger, Chengcheng Tang, Thomas Neff, Christopher D. Twigg, Cem Keskin, Robert Wang, Markus Steinberger",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Parger_MotionDeltaCNN_Sparse_CNN_Inference_of_Frame_Differences_in_Moving_Camera_ICCV_2023_paper.pdf",
        "aff": "Meta Reality Labs; Graz University of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MotionLM: Multi-Agent Motion Forecasting as Language Modeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Seff_MotionLM_Multi-Agent_Motion_Forecasting_as_Language_Modeling_ICCV_2023_paper.html",
        "author": "Ari Seff, Brian Cera, Dian Chen, Mason Ng, Aurick Zhou, Nigamaa Nayakanti, Khaled S. Refaat, Rami Al-Rfou, Benjamin Sapp",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Seff_MotionLM_Multi-Agent_Motion_Forecasting_as_Language_Modeling_ICCV_2023_paper.pdf",
        "aff": "Waymo",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Movement Enhancement toward Multi-Scale Video Feature Representation for Temporal Action Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Movement_Enhancement_toward_Multi-Scale_Video_Feature_Representation_for_Temporal_Action_ICCV_2023_paper.html",
        "author": "Zixuan Zhao, Dongqi Wang, Xu Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Movement_Enhancement_toward_Multi-Scale_Video_Feature_Representation_for_Temporal_Action_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, Shanghai Jiao Tong University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multi-Directional Subspace Editing in Style-Space",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Naveh_Multi-Directional_Subspace_Editing_in_Style-Space_ICCV_2023_paper.html",
        "author": "Chen Naveh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Naveh_Multi-Directional_Subspace_Editing_in_Style-Space_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Reichman University",
        "project": "https://chennaveh.github.io/MDSE/",
        "github": "https://github.com/chennaveh/MDSE",
        "arxiv": "2211.11825"
    },
    {
        "title": "Multi-Event Video-Text Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multi-Event_Video-Text_Retrieval_ICCV_2023_paper.html",
        "author": "Gengyuan Zhang, Jisen Ren, Jindong Gu, Volker Tresp",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multi-Event_Video-Text_Retrieval_ICCV_2023_paper.pdf",
        "aff": "LMU Munich, Munich, Germany; University of Oxford, Oxford, United Kingdom; LMU Munich, Munich, Germany; Munich Center for Machine Learning, Munich, Germany",
        "project": "",
        "github": "https://github.com/gengyuanmax/MeVTR",
        "arxiv": "2308.11551"
    },
    {
        "title": "Multi-Frequency Representation Enhancement with Privilege Information for Video Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.html",
        "author": "Fei Li, Linfeng Zhang, Zikun Liu, Juan Lei, Zhenbo Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "Samsung Research China; Tsinghua University; China Agricultural University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multi-Label Knowledge Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Multi-Label_Knowledge_Distillation_ICCV_2023_paper.html",
        "author": "Penghui Yang, Ming-Kun Xie, Chen-Chen Zong, Lei Feng, Gang Niu, Masashi Sugiyama, Sheng-Jun Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Multi-Label_Knowledge_Distillation_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; RIKEN Center for Advanced Intelligence Project; The University of Tokyo, Tokyo, Japan; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics; MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, Nanjing, China",
        "project": "",
        "github": "https://github.com/penghui-yang/L2D",
        "arxiv": "2308.06453"
    },
    {
        "title": "Multi-Label Self-Supervised Learning with Scene Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Multi-Label_Self-Supervised_Learning_with_Scene_Images_ICCV_2023_paper.html",
        "author": "Ke Zhu, Minghao Fu, Jianxin Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Multi-Label_Self-Supervised_Learning_with_Scene_Images_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "project": "",
        "github": "",
        "arxiv": "2308.03286"
    },
    {
        "title": "Multi-Metrics Adaptively Identifies Backdoors in Federated Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Multi-Metrics_Adaptively_Identifies_Backdoors_in_Federated_Learning_ICCV_2023_paper.html",
        "author": "Siquan Huang, Yijiang Li, Chong Chen, Leyu Shi, Ying Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Multi-Metrics_Adaptively_Identifies_Backdoors_in_Federated_Learning_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; School of Computer Science and Engineering, South China University of Technology",
        "project": "",
        "github": "",
        "arxiv": "2303.06601"
    },
    {
        "title": "Multi-Modal Continual Test-Time Adaptation for 3D Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Haozhi Cao, Yuecong Xu, Jianfei Yang, Pengyu Yin, Shenghai Yuan, Lihua Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Institute for Infocomm Research, A*STAR, Singapore; Nanyang Technological University",
        "project": "https://sites.google.com/view/mmcotta",
        "github": "",
        "arxiv": "2303.10457"
    },
    {
        "title": "Multi-Modal Gated Mixture of Local-to-Global Experts for Dynamic Image Fusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.html",
        "author": "Bing Cao, Yiming Sun, Pengfei Zhu, Qinghua Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.pdf",
        "aff": "Tianjin Key Lab of Machine Learning, College of Intelligence and Computing, Tianjin University, China; Haihe Laboratory of Information Technology Application Innovation, China",
        "project": "",
        "github": "https://github.com/SunYM2020/MoE-Fusion",
        "arxiv": "2302.01392"
    },
    {
        "title": "Multi-Modal Neural Radiance Field for Monocular Dense SLAM with a Light-Weight ToF Sensor",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-Modal_Neural_Radiance_Field_for_Monocular_Dense_SLAM_with_a_ICCV_2023_paper.html",
        "author": "Xinyang Liu, Yijin Li, Yanbin Teng, Hujun Bao, Guofeng Zhang, Yinda Zhang, Zhaopeng Cui",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-Modal_Neural_Radiance_Field_for_Monocular_Dense_SLAM_with_a_ICCV_2023_paper.pdf",
        "aff": "Google; State Key Lab of CAD&CG, Zhejiang University",
        "project": "https://zju3dv.github.io/tof_slam/",
        "github": "",
        "arxiv": "2308.14383"
    },
    {
        "title": "Multi-Object Discovery by Low-Dimensional Object Motion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Safadoust_Multi-Object_Discovery_by_Low-Dimensional_Object_Motion_ICCV_2023_paper.html",
        "author": "Sadra Safadoust, Fatma G\u00fcney",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Safadoust_Multi-Object_Discovery_by_Low-Dimensional_Object_Motion_ICCV_2023_paper.pdf",
        "aff": "KUIS AI Center and Department of Computer Engineering, Koc University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multi-Object Navigation with Dynamically Learned Neural Implicit Representations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Marza_Multi-Object_Navigation_with_Dynamically_Learned_Neural_Implicit_Representations_ICCV_2023_paper.html",
        "author": "Pierre Marza, Laetitia Matignon, Olivier Simonin, Christian Wolf",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Marza_Multi-Object_Navigation_with_Dynamically_Learned_Neural_Implicit_Representations_ICCV_2023_paper.pdf",
        "aff": "Naver Labs Europe; INSA Lyon; UCBL",
        "project": "https://pierremarza.github.io/projects/dynamic_implicit_representations/",
        "github": "",
        "arxiv": "2210.05129"
    },
    {
        "title": "Multi-Scale Bidirectional Recurrent Network with Hybrid Correlation for Point Cloud Based Scene Flow Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Multi-Scale_Bidirectional_Recurrent_Network_with_Hybrid_Correlation_for_Point_Cloud_ICCV_2023_paper.html",
        "author": "Wencan Cheng, Jong Hwan Ko",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Multi-Scale_Bidirectional_Recurrent_Network_with_Hybrid_Correlation_for_Point_Cloud_ICCV_2023_paper.pdf",
        "aff": "Department of Artificial Intelligence, Sungkyunkwan University; College of Information and Communication Engineering, Sungkyunkwan University",
        "project": "",
        "github": "https://github.com/cwc1260/MSBRN",
        "arxiv": ""
    },
    {
        "title": "Multi-Scale Residual Low-Pass Filter Network for Image Deblurring",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Multi-Scale_Residual_Low-Pass_Filter_Network_for_Image_Deblurring_ICCV_2023_paper.html",
        "author": "Jiangxin Dong, Jinshan Pan, Zhongbao Yang, Jinhui Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Multi-Scale_Residual_Low-Pass_Filter_Network_for_Image_Deblurring_ICCV_2023_paper.pdf",
        "aff": "Nanjing University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multi-Task Learning with Knowledge Distillation for Dense Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.html",
        "author": "Yangyang Xu, Yibo Yang, Lefei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.pdf",
        "aff": "King Abdullah University of Science and Technology, Jeddah, Saudi Arabia; Institute of Arti\ufb01cial Intelligence and School of Computer Science, Wuhan University, Wuhan, China; Hubei Luojia Laboratory, Wuhan, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multi-View Active Fine-Grained Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Du_Multi-View_Active_Fine-Grained_Visual_Recognition_ICCV_2023_paper.html",
        "author": "Ruoyi Du, Wenqing Yu, Heqing Wang, Ting-En Lin, Dongliang Chang, Zhanyu Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Du_Multi-View_Active_Fine-Grained_Visual_Recognition_ICCV_2023_paper.pdf",
        "aff": "Beijing University of Posts and Telecommunications, China; Not specified",
        "project": "",
        "github": "https://github.com/PRIS-CV/MAFR",
        "arxiv": ""
    },
    {
        "title": "Multi-body Depth and Camera Pose Estimation from Multiple Views",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dal_Cin_Multi-body_Depth_and_Camera_Pose_Estimation_from_Multiple_Views_ICCV_2023_paper.html",
        "author": "Andrea Porfiri Dal Cin, Giacomo Boracchi, Luca Magri",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dal_Cin_Multi-body_Depth_and_Camera_Pose_Estimation_from_Multiple_Views_ICCV_2023_paper.pdf",
        "aff": "Politecnico di Milano",
        "project": "",
        "github": "https://github.com/andreadalcin/MultiBodySfM",
        "arxiv": ""
    },
    {
        "title": "Multi-grained Temporal Prototype Learning for Few-shot Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-grained_Temporal_Prototype_Learning_for_Few-shot_Video_Object_Segmentation_ICCV_2023_paper.html",
        "author": "Nian Liu, Kepan Nan, Wangbo Zhao, Yuanwei Liu, Xiwen Yao, Salman Khan, Hisham Cholakkal, Rao Muhammad Anwer, Junwei Han, Fahad Shahbaz Khan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-grained_Temporal_Prototype_Learning_for_Few-shot_Video_Object_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Northwestern Polytechnical University; CVL, Link\u00f6ping University; National University of Singapore; Mohamed bin Zayed University of Artificial Intelligence",
        "project": "",
        "github": "https://github.com/nankepan/VIPMT",
        "arxiv": "2309.11160"
    },
    {
        "title": "Multi-granularity Interaction Simulation for Unsupervised Interactive Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Multi-granularity_Interaction_Simulation_for_Unsupervised_Interactive_Segmentation_ICCV_2023_paper.html",
        "author": "Kehan Li, Yian Zhao, Zhennan Wang, Zesen Cheng, Peng Jin, Xiangyang Ji, Li Yuan, Chang Liu, Jie Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Multi-granularity_Interaction_Simulation_for_Unsupervised_Interactive_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Multi-granularity Interaction Simulation for Unsupervised\nInteractive Segmentation\nKehan Li1,3Yian Zhao1,3Zhennan Wang2Zesen Cheng1,3Peng Jin1,3\nXiangyang Ji4Li Yuan1,2,3Chang Liu4*Jie Chen1,2,3\u2217\n1School of Electronic and Computer Engineering, Peking University, Shenzhen, China\n2Peng Cheng Laboratory, Shenzhen, China\n3AI for Science (AI4S)-Preferred Program, Peking University, Shenzhen, China\n4Department of Automation and BNRist, Tsinghua University, Beijing, China\nliuchang2022@tsinghua.edu.cn jiechen2019@pku.edu.cn\nAbstract\nInteractive segmentation enables users to segment as\nneeded by providing cues of objects, which introduces\nhuman-computer interaction for many fields, such as im-\nage editing and medical image analysis. Typically, mas-\nsive and expansive pixel-level annotations are spent to train\ndeep models by object-oriented interactions with manu-\nally labeled object masks. In this work, we reveal that\ninformative interactions can be made by simulation with\nsemantic-consistent yet diverse region exploration in an un-\nsupervised paradigm. Concretely, we introduce a Multi-\ngranularity Interaction Simulation ( MIS) approach to open\nup a promising direction for unsupervised interactive seg-\nmentation. Drawing on the high-quality dense features pro-\nduced by recent self-supervised models, we propose to grad-\nually merge patches or regions with similar features to form\nmore extensive regions and thus, every merged region serves\nas a semantic-meaningful multi-granularity proposal. By\nrandomly sampling these proposals and simulating possi-\nble interactions based on them, we provide meaningful in-\nteraction at multiple granularities to teach the model to un-\nderstand interactions. Our MIS significantly outperforms\nnon-deep learning unsupervised methods and is even com-\nparable with some previous deep-supervised methods with-\nout any annotation.\n1. Introduction\nInteractive segmentation aims at obtaining high-quality\nobject masks with limited user interaction, allowing users\nto segment objects as needed. During the development\nof interactive segmentation, various interactive forms like\n*Corresponding author. Project page: https://lkhl.github.io/MIS\nTraining PhaseInference Phase\nMISRegion\nProposal\nImage\nSampled Mask\nSegmenter\n\ud835\udc73\ud835\udc94\ud835\udc86\ud835\udc88Multi-granularity Proposals\n\u00b7\u00b7\u00b7\nClick\nSimulator\nImage & Click Prediction\nSegmenter Segmenter\nFigure 1. Top: To tackle the reliance on object annotations of\nprevious interactive segmentation methods caused by interaction\nsimulation, we propose Multi-granularity Interaction Simulation\n(MIS ) that simulates interaction by meaningful regions at multiple\ngranularities. Down: The model learns from MIS to successfully\nunderstand interactions and produce acceptable segmentation.\nbounding boxes [20, 32, 43], scribbles [2, 11, 22], and\nclicks [44, 17, 25, 35, 8, 36, 24, 9] have been explored.\nAmong them, the click-based interaction becomes the main-\nstream due to its simplicity and well-established training\nand evaluation protocols.\nState-of-the-art methods for click-based interactive seg-\nmentation are based on deep learning, following the ba-\nsic paradigm proposed by Xu et al. [44]. Specifically,\nthese methods encode clicks to a distance map and adapt\na semantic segmentation model ( e.g., FCN [28]) to take\nthe encoded click map as input, and then train the model\nwith interaction-segmentation pairs. Since it is impractical\nto collect interaction sequences from real users, previous\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n666\n",
        "project": "",
        "github": "",
        "arxiv": "2303.13399"
    },
    {
        "title": "Multi-interactive Feature Learning and a Full-time Multi-modality Benchmark for Image Fusion and Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.html",
        "author": "Jinyuan Liu, Zhu Liu, Guanyao Wu, Long Ma, Risheng Liu, Wei Zhong, Zhongxuan Luo, Xin Fan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.pdf",
        "aff": "International School of Information Science Engineering, Dalian University of Technology; Peng Cheng Laboratory; International School of Information Science Engineering, Dalian University of Technology; School of Mechanical Engineering, Dalian University of Technology",
        "project": "",
        "github": "https://github.com/JinyuanLiu-CV/SegMiF",
        "arxiv": "2308.02097"
    },
    {
        "title": "Multi-label Affordance Mapping from Egocentric Vision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mur-Labadia_Multi-label_Affordance_Mapping_from_Egocentric_Vision_ICCV_2023_paper.html",
        "author": "Lorenzo Mur-Labadia, Jose J. Guerrero, Ruben Martinez-Cantin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mur-Labadia_Multi-label_Affordance_Mapping_from_Egocentric_Vision_ICCV_2023_paper.pdf",
        "aff": "I3A - Universidad de Zaragoza",
        "project": "",
        "github": "",
        "arxiv": "2309.02120"
    },
    {
        "title": "Multi-task View Synthesis with Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Multi-task_View_Synthesis_with_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Shuhong Zheng, Zhipeng Bao, Martial Hebert, Yu-Xiong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Multi-task_View_Synthesis_with_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "University of Illinois Urbana-Champaign; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/zsh2000/MuvieNeRF",
        "arxiv": ""
    },
    {
        "title": "Multi-view Self-supervised Disentanglement for General Image Denoising",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Multi-view_Self-supervised_Disentanglement_for_General_Image_Denoising_ICCV_2023_paper.html",
        "author": "Hao Chen, Chenyuan Qu, Yu Zhang, Chen Chen, Jianbo Jiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Multi-view_Self-supervised_Disentanglement_for_General_Image_Denoising_ICCV_2023_paper.pdf",
        "aff": "University of Central Florida; University of Birmingham; Shanghai Jiao Tong University",
        "project": "https://chqwer2.github.io/MeD/",
        "github": "",
        "arxiv": "2309.05049"
    },
    {
        "title": "Multi-view Spectral Polarization Propagation for Video Glass Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_Multi-view_Spectral_Polarization_Propagation_for_Video_Glass_Segmentation_ICCV_2023_paper.html",
        "author": "Yu Qiao, Bo Dong, Ao Jin, Yu Fu, Seung-Hwan Baek, Felix Heide, Pieter Peers, Xiaopeng Wei, Xin Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_Multi-view_Spectral_Polarization_Propagation_for_Video_Glass_Segmentation_ICCV_2023_paper.pdf",
        "aff": "",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multi-weather Image Restoration via Domain Translation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.html",
        "author": "Prashant W. Patil, Sunil Gupta, Santu Rana, Svetha Venkatesh, Subrahmanyam Murala",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.pdf",
        "aff": "Trinity College Dublin, Ireland; Deakin University, Geelong Warun Ponds Campus, VIC, Australia",
        "project": "",
        "github": "https://github.com/pwp1208/Domain_Translation_Multi-weather_Restoration",
        "arxiv": ""
    },
    {
        "title": "Multi3DRefer: Grounding Text Description to Multiple 3D Objects",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multi3DRefer_Grounding_Text_Description_to_Multiple_3D_Objects_ICCV_2023_paper.html",
        "author": "Yiming Zhang, ZeMing Gong, Angel X. Chang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multi3DRefer_Grounding_Text_Description_to_Multiple_3D_Objects_ICCV_2023_paper.pdf",
        "aff": "Simon Fraser University; Simon Fraser University, Alberta Machine Intelligence Institute (Amii)",
        "project": "https://3dlg-hcvc.github.io/multi3drefer/",
        "github": "",
        "arxiv": "2309.05251"
    },
    {
        "title": "Multimodal Distillation for Egocentric Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Radevski_Multimodal_Distillation_for_Egocentric_Action_Recognition_ICCV_2023_paper.html",
        "author": "Gorjan Radevski, Dusan Grujicic, Matthew Blaschko, Marie-Francine Moens, Tinne Tuytelaars",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Radevski_Multimodal_Distillation_for_Egocentric_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "KU Leuven University, Belgium",
        "project": "",
        "github": "https://github.com/gorjanradevski/multimodal-distillation",
        "arxiv": "2307.07483"
    },
    {
        "title": "Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.html",
        "author": "Alberto Baldrati, Davide Morelli, Giuseppe Cartella, Marcella Cornia, Marco Bertini, Rita Cucchiara",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.pdf",
        "aff": "University of Florence, Italy; University of Modena and Reggio Emilia, Italy; IIT-CNR, Italy",
        "project": "",
        "github": "https://github.com/aimagelab/multimodal-garment-designer",
        "arxiv": "2304.02051"
    },
    {
        "title": "Multimodal High-order Relation Transformer for Scene Boundary Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Multimodal_High-order_Relation_Transformer_for_Scene_Boundary_Detection_ICCV_2023_paper.html",
        "author": "Xi Wei, Zhangxiang Shi, Tianzhu Zhang, Xiaoyuan Yu, Lei Xiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Multimodal_High-order_Relation_Transformer_for_Scene_Boundary_Detection_ICCV_2023_paper.pdf",
        "aff": "Huawei Cloud; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.html",
        "author": "Alessandro Flaborea, Luca Collorone, Guido Maria D'Amely di Melendugno, Stefano D'Arrigo, Bardh Prenkaj, Fabio Galasso",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.pdf",
        "aff": "Sapienza University of Rome, Italy",
        "project": "",
        "github": "https://github.com/aleflabo/MoCoDAD",
        "arxiv": ""
    },
    {
        "title": "Multimodal Optimal Transport-based Co-Attention Transformer with Global Structure Consistency for Survival Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Multimodal_Optimal_Transport-based_Co-Attention_Transformer_with_Global_Structure_Consistency_for_ICCV_2023_paper.html",
        "author": "Yingxue Xu, Hao Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multimodal_Optimal_Transport-based_Co-Attention_Transformer_with_Global_Structure_Consistency_for_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology",
        "project": "",
        "github": "https://github.com/Innse/MOTCat",
        "arxiv": "2306.08330"
    },
    {
        "title": "Multimodal Variational Auto-encoder based Audio-Visual Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mao_Multimodal_Variational_Auto-encoder_based_Audio-Visual_Segmentation_ICCV_2023_paper.html",
        "author": "Yuxin Mao, Jing Zhang, Mochu Xiang, Yiran Zhong, Yuchao Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Multimodal_Variational_Auto-encoder_based_Audio-Visual_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Northwestern Polytechnical University & Shaanxi Key Laboratory of Information Acquisition and Processing; Australian National University; Shanghai AI Laboratory",
        "project": "https://npucvr.github.io/MMV-AE-AVS",
        "github": "https://github.com/OpenNLPLab/MMV-AE-AVS",
        "arxiv": ""
    },
    {
        "title": "Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.html",
        "author": "Wenhao Tang, Sheng Huang, Xiaoxian Zhang, Fengtao Zhou, Yi Zhang, Bo Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology; Chongqing University; Walmart Global Tech",
        "project": "",
        "github": "https://github.com/DearCaat/MHIM-MIL",
        "arxiv": "2307.15254"
    },
    {
        "title": "Multiple Planar Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multiple_Planar_Object_Tracking_ICCV_2023_paper.html",
        "author": "Zhicheng Zhang, Shengzhe Liu, Jufeng Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multiple_Planar_Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "VCIP & TMCC & DISSec, College of Computer Science, Nankai University",
        "project": "",
        "github": "https://zzcheng.top/MPOT",
        "arxiv": ""
    },
    {
        "title": "Multiscale Representation for Real-Time Anti-Aliasing Neural Rendering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Multiscale_Representation_for_Real-Time_Anti-Aliasing_Neural_Rendering_ICCV_2023_paper.html",
        "author": "Dongting Hu, Zhenkai Zhang, Tingbo Hou, Tongliang Liu, Huan Fu, Mingming Gong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Multiscale_Representation_for_Real-Time_Anti-Aliasing_Neural_Rendering_ICCV_2023_paper.pdf",
        "aff": "University of Sydney; Google; Alibaba Group; University of Melbourne",
        "project": "",
        "github": "",
        "arxiv": "2304.10075"
    },
    {
        "title": "Multiscale Structure Guided Diffusion for Image Deblurring",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.html",
        "author": "Mengwei Ren, Mauricio Delbracio, Hossein Talebi, Guido Gerig, Peyman Milanfar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.pdf",
        "aff": "New York University; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2212.01789"
    },
    {
        "title": "Muscles in Action",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chiquier_Muscles_in_Action_ICCV_2023_paper.html",
        "author": "Mia Chiquier, Carl Vondrick",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chiquier_Muscles_in_Action_ICCV_2023_paper.pdf",
        "aff": "Columbia University",
        "project": "",
        "github": "",
        "arxiv": "2212.02978"
    },
    {
        "title": "NAPA-VQ: Neighborhood-Aware Prototype Augmentation with Vector Quantization for Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_Augmentation_with_Vector_Quantization_for_Continual_Learning_ICCV_2023_paper.html",
        "author": "Tamasha Malepathirana, Damith Senanayake, Saman Halgamuge",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_Augmentation_with_Vector_Quantization_for_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "Dept. of Mechanical Engineering, The University of Melbourne",
        "project": "",
        "github": "https://github.com/TamashaM/NAPA-VQ.git",
        "arxiv": ""
    },
    {
        "title": "NCHO: Unsupervised Learning for Neural 3D Composition of Humans and Objects",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_NCHO_Unsupervised_Learning_for_Neural_3D_Composition_of_Humans_and_ICCV_2023_paper.html",
        "author": "Taeksoo Kim, Shunsuke Saito, Hanbyul Joo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_NCHO_Unsupervised_Learning_for_Neural_3D_Composition_of_Humans_and_ICCV_2023_paper.pdf",
        "aff": "Meta Reality Labs; Seoul National University",
        "project": "https://taeksuu.github.io/ncho",
        "github": "",
        "arxiv": "2305.14345"
    },
    {
        "title": "NDC-Scene: Boost Monocular 3D Semantic Scene Completion in Normalized Device Coordinates Space",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yao_NDC-Scene_Boost_Monocular_3D_Semantic_Scene_Completion_in_Normalized_Device_ICCV_2023_paper.html",
        "author": "Jiawei Yao, Chuming Li, Keqiang Sun, Yingjie Cai, Hao Li, Wanli Ouyang, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_NDC-Scene_Boost_Monocular_3D_Semantic_Scene_Completion_in_Normalized_Device_ICCV_2023_paper.pdf",
        "aff": "CPII under InnoHK; CUHK-SenseTime Joint Laboratory; The University of Sydney; University of Washington; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/Jiawei-Yao0812/NDCScene",
        "arxiv": ""
    },
    {
        "title": "NDDepth: Normal-Distance Assisted Monocular Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_NDDepth_Normal-Distance_Assisted_Monocular_Depth_Estimation_ICCV_2023_paper.html",
        "author": "Shuwei Shao, Zhongcai Pei, Weihai Chen, Xingming Wu, Zhengguo Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_NDDepth_Normal-Distance_Assisted_Monocular_Depth_Estimation_ICCV_2023_paper.pdf",
        "aff": "/0 /1 /1 /2 /3 /4 /5 /6 /0 /7 /8 /9/10 /11 /12 /1 /13 /14 /4 /10 /15 /16 /2 /17 /14 /14 /13 /14 /4 /2 /18/19 /7 /15 /7 /16 /20 /11 /10 /8 /1 /2 /3 /4 /5/21 /14 /4 /13 /9/10 /4 /13 /7 /15\n/22 /23 /24 /25 /26 /27 /22 /23 /28 /29/30 /31 /32/33 /23 /29 /34 /35 /36 /28 /27 /37 /26 /27/32 /31 /30/38/26 /27 /23 /28 /27 /39 /23 /26 /34/32 /31 /30 /40 /41 /27 /34 /35 /42/27 /34 /35/38 /24/32 /31 /30/33 /23 /26 /34 /35 /35 /24 /29/43 /27/44\n/30/22 /36 /23 /29 /29 /45 /29 /46 /47 /24 /48 /29 /42/28 /48 /27 /29 /34/22 /36 /27 /26 /34 /36 /26 /28 /34 /49/50 /45 /26 /36 /48 /51 /27 /36 /28 /45 /50 /34 /35 /27 /34 /26 /26 /51 /27 /34 /35 /52 /53 /26 /27 /23 /28 /34 /35/54 /34 /27 /55 /26 /51 /56 /27 /48 /57 /52 /53 /26 /27 /58 /27 /34 /35 /52 /39 /23 /27 /34 /28 /59\n/32/60 /28 /34 /35 /61 /23 /29 /24/62 /34 /34 /29 /55 /28 /48 /27 /29 /34/62 /34 /56 /48 /27 /48 /24 /48 /26 /52 /53 /26 /27 /23 /28 /34 /35/54 /34 /27 /55 /26 /51 /56 /27 /48 /57 /52 /60 /28 /34 /35 /61 /23 /29 /24 /52 /33 /23 /26 /58 /27 /28 /34 /35 /52 /39 /23 /27 /34 /28\n/44/22 /63 /64/49 /26 /65 /28 /51 /48 /42/26 /34 /48 /52 /62 /34 /56 /48 /27 /48 /24 /48 /26 /46 /29 /51 /62 /34 /46 /29 /36 /29 /42/42 /63 /26 /56 /26 /28 /51 /36 /23 /52 /47 /40 /22 /66 /47 /63 /52 /22 /27 /34 /35 /28 /65 /29 /51 /26\n/67 /68 /69 /68 /70 /71 /72 /73/74 /75 /76 /77 /78 /73/69 /70 /78 /70 /75 /79 /80 /81 /82 /83 /71 /71 /84 /75 /85 /83 /84 /78 /79/75 /77 /86 /87 /76 /81 /76 /88 /89 /84 /71 /90 /68 /91 /71 /89 /84 /75 /85 /83 /84 /68 /86\n/17 /92 /14 /4 /8 /10 /16 /4\n/93/94 /95 /94 /96 /97 /98 /99 /100 /101 /102 /103 /104 /105/102 /106 /104 /107 /108 /99 /104 /107 /94 /95/105 /99 /106 /101 /100 /99 /109 /95/109 /107 /101 /102 /106 /103 /100 /102 /99 /101/99 /104 /110\n/104 /102 /95 /104 /107 /94 /95/111 /100 /94 /108 /104 /105 /102 /112 /107 /106 /107 /94 /95 /96 /94 /108 /108 /97 /95 /107 /104 /113 /101 /97 /102 /104 /94/107 /104 /106 /114 /100 /94 /99 /101/99 /103 /103 /98 /107 /96 /99 /110\n/104 /107 /94 /95 /106 /115 /116 /95 /104 /105 /107 /106 /103 /99 /103 /102 /100 /117 /109 /102 /103 /100 /94 /103 /94 /106 /102 /99 /95 /94 /112 /102 /98 /103 /105 /113 /106 /107 /96 /106 /118 /119 /102 /94 /108 /102 /104 /100 /113 /120 /110\n/101 /100 /107 /112 /102 /95/101 /102 /102 /103 /98 /102 /99 /100 /95 /107 /95 /119/111 /100 /99 /108 /102 /109 /94 /100 /121 /111 /94 /100 /108 /94 /95 /94 /96 /97 /98 /99 /100 /101 /102 /103 /104 /105/102 /106 /104 /107 /110\n/108 /99 /104 /107 /94 /95 /114 /113 /99 /106 /106 /97 /108 /107 /95 /119 /104 /105 /99 /104 /122 /123/106 /96 /102 /95 /102 /106 /99 /100 /102 /96 /94 /95 /106 /104 /107 /104 /97 /104 /102 /101 /114 /113 /103 /107 /102 /96 /102 /110\n/109 /107 /106 /102/103 /98 /99 /95 /102 /106 /115 /124 /99 /100 /104 /107 /96 /97 /98 /99 /100 /98 /113 /117/109 /102/107 /95 /104 /100 /94 /101 /97 /96 /102/99 /95 /102 /109/95 /94 /100 /108 /99 /98 /110\n/101 /107 /106 /104 /99 /95 /96 /102/105 /102 /99 /101/104 /105 /99 /104 /94 /97 /104 /103 /97 /104 /106 /103 /107 /125 /102 /98 /110 /98 /102 /112 /102 /98 /106 /97 /100 /111 /99 /96 /102/95 /94 /100 /108 /99 /98 /99 /95 /101\n/103 /98 /99 /95 /102 /110 /104 /94 /110 /94 /100 /107 /119 /107 /95/101 /107 /106 /104 /99 /95 /96 /102/111 /94 /100/101 /102 /100 /107 /112 /107 /95 /119/101 /102 /103 /104 /105/99 /104 /102 /99 /96 /105/103 /94 /106 /107 /110\n/104 /107 /94 /95 /115/93 /102 /99 /95 /109 /105 /107 /98 /102 /117 /104 /105 /102/95 /94 /100 /108 /99 /98 /99 /95 /101/101 /107 /106 /104 /99 /95 /96 /102/99 /100 /102/100 /102 /119 /97 /98 /99 /100 /107 /126 /102 /101\n/114 /113 /99 /101 /102 /112 /102 /98 /94 /103 /102 /101 /103 /98 /99 /95 /102 /110 /99 /109 /99 /100 /102 /96 /94 /95 /106 /107 /106 /104 /102 /95 /96 /113 /96 /94 /95 /106 /104 /100 /99 /107 /95 /104 /115 /127 /102 /111 /97 /100 /110\n/104 /105 /102 /100 /107 /95 /104 /102 /119 /100 /99 /104 /102/99 /95/99 /101 /101 /107 /104 /107 /94 /95 /99 /98 /101 /102 /103 /104 /105/105 /102 /99 /101/104 /94/107 /108 /103 /100 /94 /112 /102/104 /105 /102/100 /94 /110\n/114 /97 /106 /104 /95 /102 /106 /106/94 /111 /104 /105 /102/103 /100 /94 /103 /94 /106 /102 /101/111 /100 /99 /108 /102 /109 /94 /100 /121 /115/128 /94/111 /97 /98 /98 /113/102 /125 /103 /98 /94 /107 /104 /104 /105 /102\n/106 /104 /100 /102 /95 /119 /104 /105 /106 /94 /111 /104 /105 /102 /106 /102/104 /109 /94/105 /102 /99 /101 /106 /117 /109 /102/101 /102 /112 /102 /98 /94 /103/99 /95/102 /111 /111 /102 /96 /104 /107 /112 /102/96 /94 /95 /110\n/104 /100 /99 /106 /104 /107 /112 /102/107 /104 /102 /100 /99 /104 /107 /112 /102/100 /102 /129 /95 /102 /108 /102 /95 /104 /108 /94 /101 /97 /98 /102/104 /105 /99 /104 /100 /102 /129 /95 /102 /106/101 /102 /103 /104 /105/107 /95\n/99/96 /94 /108 /103 /98 /102 /108 /102 /95 /104 /99 /100 /113/108 /99 /95 /95 /102 /100/99 /96 /96 /94 /100 /101 /107 /95 /119/104 /94/104 /105 /102/101 /102 /103 /104 /105/97 /95 /96 /102 /100 /110\n/104 /99 /107 /95 /104 /113 /115/130 /125 /104 /102 /95 /106 /107 /112 /102/102 /125 /103 /102 /100 /107 /108 /102 /95 /104 /106/107 /95 /101 /107 /96 /99 /104 /102/104 /105 /99 /104 /104 /105 /102/103 /100 /94 /103 /94 /106 /102 /101\n/108 /102 /104 /105 /94 /101 /102 /125 /96 /102 /102 /101 /106 /103 /100 /102 /112 /107 /94 /97 /106 /106 /104 /99 /104 /102 /110 /94 /111 /110 /104 /105 /102 /110 /99 /100 /104 /96 /94 /108 /103 /102 /104 /107 /104 /94 /100 /106 /94 /95 /104 /105 /102\n/131 /132 /133 /110 /123 /102 /103 /104 /105 /110 /112 /134 /117 /135 /116 /128 /128 /116 /99 /95 /101/136 /133 /131/137 /138 /139 /110 /123/101 /99 /104 /99 /106 /102 /104 /106 /115 /131 /94 /104 /99 /114 /98 /113 /117\n/107 /104 /140 /141 /142 /143 /144/145 /144 /146 /99 /108 /94 /95 /119/99 /98 /98 /106 /97 /114 /108 /107 /106 /106 /107 /94 /95 /106/94 /95/104 /105 /102/135 /116 /128 /128 /116/101 /102 /103 /104 /105\n/103 /100 /102 /101 /107 /96 /104 /107 /94 /95/94 /95 /98 /107 /95 /102/114 /102 /95 /96 /105 /108 /99 /100 /121/99 /104 /104 /105 /102/106 /97 /114 /108 /107 /106 /106 /107 /94 /95/104 /107 /108 /102 /115/128 /105 /102\n/106 /94 /97 /100 /96 /102/96 /94 /101 /102 /107 /106/99 /112 /99 /107 /98 /99 /114 /98 /102/99 /104/147 /148 /148 /149 /150 /151 /152 /152 /153 /154 /148 /147 /155 /156 /157 /158 /159 /160 /152\n/161 /147 /155 /162 /163 /154 /161 /147 /164 /159 /152 /165 /166 /166 /163 /149 /148 /147 /115\n/167 /168 /169 /15 /4 /8 /7 /18 /20 /16 /4 /13 /7 /15\n/170/29 /34 /29 /36 /24 /45 /28 /51 /49 /26 /65 /48 /23/26 /56 /48 /27 /42/28 /48 /27 /29 /34/65 /45 /28 /57 /56 /28 /42/29 /51 /26 /28 /34 /49/42/29 /51 /26 /27 /42/171\n/65 /29 /51 /48 /28 /34 /48 /51 /29 /45 /26 /27 /34/36 /29 /42/65 /24 /48 /26 /51 /55 /27 /56 /27 /29 /34 /52 /25 /27 /48 /23/28 /65 /65 /45 /27 /36 /28 /48 /27 /29 /34 /56 /51 /28 /34 /35 /27 /34 /35\n/46 /51 /29 /42/51 /29 /172 /29 /48 /27 /36 /56/173 /174 /175 /52 /175 /176 /177 /52 /56 /36 /26 /34 /26/24 /34 /49 /26 /51 /56 /48 /28 /34 /49 /27 /34 /35/173 /175 /178 /177 /48 /29/28 /24 /35 /171\n/42/26 /34 /48 /26 /49/51 /26 /28 /45 /27 /48 /57/173 /179 /180 /177 /59/66 /23 /26/48 /28 /56 /181/28 /27 /42/56 /48 /29/26 /56 /48 /27 /42/28 /48 /26/48 /23 /26/49 /26 /65 /48 /23\n/42/28 /65/46 /51 /29 /42/28 /56 /27 /34 /35 /45 /26 /63 /182 /53/27 /42/28 /35 /26 /59 /39 /29 /34 /56 /27 /49 /26 /51 /27 /34 /35/48 /23 /28 /48 /28 /179 /183/27 /42/171\n/28 /35 /26/36 /28 /34/172 /26/65 /51 /29 /58 /26 /36 /48 /26 /49/46 /51 /29 /42/27 /34 /184 /34 /27 /48 /26/34 /24 /42/172 /26 /51 /29 /46 /185 /183/56 /36 /26 /34 /26 /56 /52\n/56 /24 /36 /23/28 /48 /28 /56 /181/27 /56 /27 /34 /49 /26 /26 /49/27 /45 /45 /171 /65 /29 /56 /26 /49/28 /34 /49/27 /34 /23 /26 /51 /26 /34 /48 /45 /57/28 /42/172 /27 /35 /24 /29 /24 /56 /59\n/60 /26 /34 /36 /26 /52 /56 /29 /45 /55 /27 /34 /35/27 /48 /51 /26 /45 /27 /28 /172 /45 /57/65 /51 /26 /56 /26 /34 /48 /56 /28/46 /29 /51 /42/27 /49 /28 /172 /45 /26/36 /23 /28 /45 /45 /26 /34 /35 /26\n/46 /29 /51 /48 /51 /28 /49 /27 /48 /27 /29 /34 /28 /45 /42/26 /48 /23 /29 /49 /56 /173 /185 /175 /52 /185 /179 /177 /49 /24 /26/48 /29/48 /23 /26 /27 /51 /27 /34 /23 /26 /51 /26 /34 /48 /45 /27 /42/27 /171\n/40 /39 /29 /51 /51 /26 /56 /65 /29 /34 /49 /27 /34 /35/28 /24 /48 /23 /29 /51\n/186 /187/188 /189 /190 /i255\n/192 /193 /i255\n/194 /193 /195 /187/188 /196/186 /187/188 /189 /190 /i255\n/192 /193 /i255\n/197 /198 /199 /192 /188 /200 /201 /190\n/186 /187/188 /189 /190 /i255\n/192 /193 /i255\n/197 /190 /202 /192 /203\n/194 /193 /195 /187/188 /196 /204 /197 /198 /199 /192 /188 /200 /201 /190 /i255 /192 /193 /i255 /197 /190 /202 /192 /203\n/205 /27 /35 /24 /51 /26 /175 /59 /17/92 /8 /13 /2 /206 /13 /11 /11 /20 /14 /4 /8 /10 /4 /13 /7 /15/7 /206 /4 /5 /2 /8 /2 /11 /10 /4 /13 /7 /15 /14 /5 /13 /3/10 /9/7 /15 /207/13 /9/10 /207 /2 /208\n/14 /20 /8 /206 /10 /16 /2 /15 /7 /8 /9/10 /11 /208 /3 /11 /10 /15 /2 /12 /4 /7 /12 /7 /8 /13 /207 /13 /15/18 /13 /14 /4 /10 /15 /16 /2 /10 /15 /18/18 /2 /3 /4 /5 /9/10 /3 /59\n/48 /28 /48 /27 /29 /34 /56 /52 /48 /57 /65 /27 /36 /28 /45 /45 /57 /27 /34 /55 /29 /45 /55 /27 /34 /35 /45 /29 /25 /171 /49 /27 /42/26 /34 /56 /27 /29 /34 /28 /45 /28 /34 /49 /56 /65 /28 /51 /56 /26 /49 /27 /56 /171\n/48 /28 /34 /36 /26 /56 /29 /51 /181 /34 /29 /25 /34/28 /34 /49/184 /209 /26 /49/29 /172 /58 /26 /36 /48 /56 /59\n/63 /26 /36 /26 /34 /48 /45 /57 /52 /42/24 /36 /23 /65 /51 /29 /35 /51 /26 /56 /56 /23 /28 /56 /172 /26 /26 /34 /42/28 /49 /26 /27 /34 /48 /23 /27 /56 /184 /26 /45 /49 /172 /26 /34 /171\n/26 /184 /48 /27 /34 /35/46 /51 /29 /42/48 /23 /26/26 /209 /65 /45 /29 /56 /27 /29 /34/29 /46 /49 /26 /26 /65/45 /26 /28 /51 /34 /27 /34 /35/173 /175 /175 /52 /175 /185 /52 /179 /185 /52 /179 /52\n/174 /210 /177 /59/170 /29 /56 /48 /26 /46 /46 /29 /51 /48 /56 /46 /29 /36 /24 /56 /29 /34/49 /26 /56 /27 /35 /34 /27 /34 /35/27 /34 /36 /51 /26 /28 /56 /27 /34 /35 /45 /57/36 /29 /42/65 /45 /27 /171\n/36 /28 /48 /26 /49 /28 /34 /49 /65 /29 /25 /26 /51 /46 /24 /45 /34 /26 /48 /25 /29 /51 /181 /56 /52 /25 /23 /27 /36 /23 /51 /26 /34 /49 /26 /51 /56 /48 /23 /26 /48 /28 /56 /181 /28 /23 /28 /51 /49\n/184 /48 /48 /27 /34 /35 /65 /51 /29 /172 /45 /26 /42/25 /27 /48 /23 /29 /24 /48 /48 /23 /26 /23 /26 /45 /65 /29 /46 /28 /49 /49 /27 /48 /27 /29 /34 /28 /45 /35 /24 /27 /49 /28 /34 /36 /26 /59 /38/26\n/28 /51 /35 /24 /26 /48 /23 /28 /48 /51 /26 /28 /45 /171 /25 /29 /51 /45 /49/185 /183/56 /36 /26 /34 /26 /56 /24 /56 /24 /28 /45 /45 /57/23 /28 /55 /26 /28 /23 /27 /35 /23/49 /26 /35 /51 /26 /26\n/29 /46 /51 /26 /35 /24 /45 /28 /51 /27 /48 /57 /28 /34 /49 /65 /51 /29 /65 /26 /51 /56 /36 /26 /34 /26 /65 /51 /27 /29 /51 /56 /56 /23 /29 /24 /45 /49 /172 /26 /27 /34 /36 /29 /51 /65 /29 /51 /28 /48 /26 /49\n/27 /34 /48 /29/48 /23 /26/46 /51 /28 /42/26 /25 /29 /51 /181/48 /29/27 /42/65 /51 /29 /55 /26/48 /23 /26/34 /28 /48 /24 /51 /26/29 /46 /48 /23 /26/56 /29 /45 /24 /48 /27 /29 /34 /59\n/37 /45 /28 /34 /26 /56 /28 /51 /26 /28 /36 /29 /42/42/29 /34/51 /26 /65 /51 /26 /56 /26 /34 /48 /28 /48 /27 /29 /34/46 /29 /51 /42/29 /49 /26 /45 /27 /34 /35/35 /26 /29 /42/26 /48 /171\n/51 /27 /36 /65 /51 /27 /29 /51 /181 /34 /29 /25 /45 /26 /49 /35 /26 /29 /46 /185 /183/56 /36 /26 /34 /26 /56 /173 /185 /52 /180 /52 /179 /178 /177 /59 /47 /51 /26 /36 /26 /34 /48 /25 /29 /51 /181\n/172 /57/37 /28 /48 /27 /45 /102 /104 /99 /98 /115 /173 /185 /174 /177 /27 /34 /48 /51 /29 /49 /24 /36 /26 /49/28 /65 /27 /26 /36 /26 /171 /25 /27 /56 /26/65 /45 /28 /34 /28 /51 /27 /48 /57/65 /51 /27 /29 /51\n/28 /34 /49/24 /56 /26 /49/48 /23 /26 /29 /46 /46 /56 /26 /48 /55 /26 /36 /48 /29 /51 /184 /26 /45 /49/48 /29/172 /29 /51 /51 /29 /25/27 /34 /46 /29 /51 /42/28 /48 /27 /29 /34/46 /51 /29 /42\n/36 /29 /171 /65 /45 /28 /34 /28 /51 /65 /27 /209 /26 /45 /56 /59 /60 /29 /25 /26 /55 /26 /51 /52 /48 /23 /26 /51 /26 /27 /56 /34 /29/49 /27 /51 /26 /36 /48 /36 /29 /34 /56 /48 /51 /28 /27 /34 /48 /27 /42/171\n/65 /29 /56 /26 /49/29 /34/48 /23 /26/29 /46 /46 /56 /26 /48 /55 /26 /36 /48 /29 /51 /184 /26 /45 /49/48 /29/23 /26 /45 /65/27 /48 /45 /26 /28 /51 /34/28 /172 /29 /24 /48 /65 /45 /28 /171\n/34 /28 /51 /51 /26 /35 /27 /29 /34 /56 /27 /34/48 /23 /26 /27 /51 /42/26 /48 /23 /29 /49 /59 /62 /34/28 /49 /49 /27 /48 /27 /29 /34 /52 /48 /23 /26 /65 /45 /28 /34 /28 /51 /27 /48 /57/65 /51 /27 /29 /51\n/48 /26 /34 /49 /56 /48 /29 /46 /28 /27 /45 /27 /34 /23 /27 /35 /23 /171 /36 /24 /51 /55 /28 /48 /24 /51 /26 /51 /26 /35 /27 /29 /34 /56 /52 /46 /29 /51 /26 /209 /28 /42 /65 /45 /26 /52 /172 /24 /56 /23 /26 /56 /52\n/48 /51 /26 /26 /56 /52 /28 /34 /49/29 /48 /23 /26 /51 /36 /45 /24 /48 /48 /26 /51 /52 /27 /34 /26 /55 /27 /48 /28 /172 /45 /57/49 /26 /48 /26 /51 /27 /29 /51 /28 /48 /27 /34 /35/48 /23 /26/49 /26 /65 /48 /23\n/28 /36 /36 /24 /51 /28 /36 /57 /59\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n7931\n",
        "project": "",
        "github": "",
        "arxiv": "2309.10592"
    },
    {
        "title": "NEMTO: Neural Environment Matting for Novel View and Relighting Synthesis of Transparent Objects",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_NEMTO_Neural_Environment_Matting_for_Novel_View_and_Relighting_Synthesis_ICCV_2023_paper.html",
        "author": "Dongqing Wang, Tong Zhang, Sabine S\u00fcsstrunk",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_NEMTO_Neural_Environment_Matting_for_Novel_View_and_Relighting_Synthesis_ICCV_2023_paper.pdf",
        "aff": "School of Computer and Communication Sciences, EPFL",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "NIR-assisted Video Enhancement via Unpaired 24-hour Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.html",
        "author": "Muyao Niu, Zhihang Zhong, Yinqiang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.pdf",
        "aff": "The University of Tokyo",
        "project": "",
        "github": "https://github.com/MyNiuuu/NVEU",
        "arxiv": ""
    },
    {
        "title": "NLOS-NeuS: Non-line-of-sight Neural Implicit Surface",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fujimura_NLOS-NeuS_Non-line-of-sight_Neural_Implicit_Surface_ICCV_2023_paper.html",
        "author": "Yuki Fujimura, Takahiro Kushida, Takuya Funatomi, Yasuhiro Mukaigawa",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fujimura_NLOS-NeuS_Non-line-of-sight_Neural_Implicit_Surface_ICCV_2023_paper.pdf",
        "aff": "Ritsumeikan University; Nara Institute of Science and Technology",
        "project": "https://yfujimura.github.io/nlos-neus/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "NPC: Neural Point Characters from Video",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Su_NPC_Neural_Point_Characters_from_Video_ICCV_2023_paper.html",
        "author": "Shih-Yang Su, Timur Bagautdinov, Helge Rhodin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Su_NPC_Neural_Point_Characters_from_Video_ICCV_2023_paper.pdf",
        "aff": "The University of British Columbia; Reality Labs Research",
        "project": "https://lemonatsu.github.io/npc/",
        "github": "",
        "arxiv": "2304.02013"
    },
    {
        "title": "NSF: Neural Surface Fields for Human Modeling from Monocular Depth",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xue_NSF_Neural_Surface_Fields_for_Human_Modeling_from_Monocular_Depth_ICCV_2023_paper.html",
        "author": "Yuxuan Xue, Bharat Lal Bhatnagar, Riccardo Marin, Nikolaos Sarafianos, Yuanlu Xu, Gerard Pons-Moll, Tony Tung",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xue_NSF_Neural_Surface_Fields_for_Human_Modeling_from_Monocular_Depth_ICCV_2023_paper.pdf",
        "aff": "Meta Reality Labs Research; T\u00a8ubingen AI Center, University of T \u00a8ubingen, Max Planck Institute for Informatics, Meta Reality Labs Research; T\u00a8ubingen AI Center, University of T \u00a8ubingen; T\u00a8ubingen AI Center, University of T \u00a8ubingen, Max Planck Institute for Informatics",
        "project": "https://yuxuan-xue.com/nsf",
        "github": "",
        "arxiv": "2308.14847"
    },
    {
        "title": "Name Your Colour For the Task: Artificially Discover Colour Naming via Colour Quantisation Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Su_Name_Your_Colour_For_the_Task_Artificially_Discover_Colour_Naming_ICCV_2023_paper.html",
        "author": "Shenghan Su, Lin Gu, Yue Yang, Zenghui Zhang, Tatsuya Harada",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Name_Your_Colour_For_the_Task_Artificially_Discover_Colour_Naming_ICCV_2023_paper.pdf",
        "aff": "RIKEN AIP; The University of Tokyo; Shanghai Jiao Tong University; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/ryeocthiv/CQFormer",
        "arxiv": "2212.03434"
    },
    {
        "title": "Narrator: Towards Natural Control of Human-Scene Interaction Generation via Relationship Reasoning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xuan_Narrator_Towards_Natural_Control_of_Human-Scene_Interaction_Generation_via_Relationship_ICCV_2023_paper.html",
        "author": "Haibiao Xuan, Xiongzheng Li, Jinsong Zhang, Hongwen Zhang, Yebin Liu, Kun Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xuan_Narrator_Towards_Natural_Control_of_Human-Scene_Interaction_Generation_via_Relationship_ICCV_2023_paper.pdf",
        "aff": "Tianjin University; Tsinghua University",
        "project": "http://cic.tju.edu.cn/faculty/likun/projects/Narrator",
        "github": "",
        "arxiv": "2303.09410"
    },
    {
        "title": "NaviNeRF: NeRF-based 3D Representation Disentanglement by Latent Semantic Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_NaviNeRF_NeRF-based_3D_Representation_Disentanglement_by_Latent_Semantic_Navigation_ICCV_2023_paper.html",
        "author": "Baao Xie, Bohan Li, Zequn Zhang, Junting Dong, Xin Jin, Jingyu Yang, Wenjun Zeng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_NaviNeRF_NeRF-based_3D_Representation_Disentanglement_by_Latent_Semantic_Navigation_ICCV_2023_paper.pdf",
        "aff": "Eastern Institute of Technology, Ningbo; Tianjin University; Northwest Normal University; Ningbo Institute of Digital Twin; Zhejiang University",
        "project": "",
        "github": "Available at the provided link in the paper",
        "arxiv": "2304.11342"
    },
    {
        "title": "Navigating to Objects Specified by Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Krantz_Navigating_to_Objects_Specified_by_Images_ICCV_2023_paper.html",
        "author": "Jacob Krantz, Theophile Gervet, Karmesh Yadav, Austin Wang, Chris Paxton, Roozbeh Mottaghi, Dhruv Batra, Jitendra Malik, Stefan Lee, Devendra Singh Chaplot",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Krantz_Navigating_to_Objects_Specified_by_Images_ICCV_2023_paper.pdf",
        "aff": "Oregon State; Georgia Tech; Meta AI; UC Berkeley; Carnegie Mellon; University of Washington",
        "project": "jacobkrantz.github.io/modular-iin",
        "github": "",
        "arxiv": "2304.01192"
    },
    {
        "title": "NeILF++: Inter-Reflectable Light Fields for Geometry and Material Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_NeILF_Inter-Reflectable_Light_Fields_for_Geometry_and_Material_Estimation_ICCV_2023_paper.html",
        "author": "Jingyang Zhang, Yao Yao, Shiwei Li, Jingbo Liu, Tian Fang, David McKinnon, Yanghai Tsin, Long Quan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeILF_Inter-Reflectable_Light_Fields_for_Geometry_and_Material_Estimation_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology; Nanjing University; Apple",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "NeMF: Inverse Volume Rendering with Neural Microflake Field",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_NeMF_Inverse_Volume_Rendering_with_Neural_Microflake_Field_ICCV_2023_paper.html",
        "author": "Youjia Zhang, Teng Xu, Junqing Yu, Yuteng Ye, Yanqing Jing, Junle Wang, Jingyi Yu, Wei Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeMF_Inverse_Volume_Rendering_with_Neural_Microflake_Field_ICCV_2023_paper.pdf",
        "aff": "Tencent; Huazhong University of Science and Technology; ShanghaiTech University",
        "project": "",
        "github": "https://github.com/YoujiaZhang/NeMF",
        "arxiv": "2304.00782"
    },
    {
        "title": "NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Irshad_NeO_360_Neural_Fields_for_Sparse_View_Synthesis_of_Outdoor_ICCV_2023_paper.html",
        "author": "Muhammad Zubair Irshad, Sergey Zakharov, Katherine Liu, Vitor Guizilini, Thomas Kollar, Adrien Gaidon, Zsolt Kira, Rares Ambrus",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Irshad_NeO_360_Neural_Fields_for_Sparse_View_Synthesis_of_Outdoor_ICCV_2023_paper.pdf",
        "aff": "Toyota Research Institute; Georgia Institute of Technology",
        "project": "zubair-irshad.github.io/projects/neo360.html",
        "github": "",
        "arxiv": "2308.12967"
    },
    {
        "title": "NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Chenfeng Xu, Bichen Wu, Ji Hou, Sam Tsai, Ruilong Li, Jialiang Wang, Wei Zhan, Zijian He, Peter Vajda, Kurt Keutzer, Masayoshi Tomizuka",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Meta AI; University of California, Berkeley",
        "project": "",
        "github": "https://github.com/facebookresearch/NeRF-Det",
        "arxiv": ""
    },
    {
        "title": "NeRF-LOAM: Neural Implicit Representation for Large-Scale Incremental LiDAR Odometry and Mapping",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deng_NeRF-LOAM_Neural_Implicit_Representation_for_Large-Scale_Incremental_LiDAR_Odometry_and_ICCV_2023_paper.html",
        "author": "Junyuan Deng, Qi Wu, Xieyuanli Chen, Songpengcheng Xia, Zhen Sun, Guoqing Liu, Wenxian Yu, Ling Pei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_NeRF-LOAM_Neural_Implicit_Representation_for_Large-Scale_Incremental_LiDAR_Odometry_and_ICCV_2023_paper.pdf",
        "aff": "College of Intelligence Science and Technology, National University of Defense Technology; Shanghai Key Laboratory of Navigation and Location Based Services, Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/JunyuanDeng/NeRF-LOAM",
        "arxiv": ""
    },
    {
        "title": "NeRF-MS: Neural Radiance Fields with Multi-Sequence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_NeRF-MS_Neural_Radiance_Fields_with_Multi-Sequence_ICCV_2023_paper.html",
        "author": "Peihao Li, Shaohui Wang, Chen Yang, Bingbing Liu, Weichao Qiu, Haoqian Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeRF-MS_Neural_Radiance_Fields_with_Multi-Sequence_ICCV_2023_paper.pdf",
        "aff": "Shenzhen International Graduate School, Tsinghua University; Huawei Noah\u2019s Ark Lab; Shenzhen International Graduate School, Tsinghua University; Shenzhen Institute of Future Media Technology; Shanghai Jiao Tong University",
        "project": "https://nerf-ms.github.io/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "NeRFrac: Neural Radiance Fields through Refractive Surface",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhan_NeRFrac_Neural_Radiance_Fields_through_Refractive_Surface_ICCV_2023_paper.html",
        "author": "Yifan Zhan, Shohei Nobuhara, Ko Nishino, Yinqiang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhan_NeRFrac_Neural_Radiance_Fields_through_Refractive_Surface_ICCV_2023_paper.pdf",
        "aff": "Kyoto University, Japan; The University of Tokyo, Japan",
        "project": "",
        "github": "https://github.com/Yifever20002/NeRFrac",
        "arxiv": ""
    },
    {
        "title": "NeSS-ST: Detecting Good and Stable Keypoints with a Neural Stability Score and the Shi-Tomasi detector",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pakulev_NeSS-ST_Detecting_Good_and_Stable_Keypoints_with_a_Neural_Stability_ICCV_2023_paper.html",
        "author": "Konstantin Pakulev, Alexander Vakhitov, Gonzalo Ferrer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pakulev_NeSS-ST_Detecting_Good_and_Stable_Keypoints_with_a_Neural_Stability_ICCV_2023_paper.pdf",
        "aff": "Skolkovo Institute of Science and Technology; SLAMcore",
        "project": "",
        "github": "https://github.com/KonstantinPakulev/NeSS-ST",
        "arxiv": ""
    },
    {
        "title": "NeTO:Neural Reconstruction of Transparent Objects with Self-Occlusion Aware Refraction-Tracing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_NeTONeural_Reconstruction_of_Transparent_Objects_with_Self-Occlusion_Aware_Refraction-Tracing_ICCV_2023_paper.html",
        "author": "Zongcheng Li, Xiaoxiao Long, Yusen Wang, Tuo Cao, Wenping Wang, Fei Luo, Chunxia Xiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeTONeural_Reconstruction_of_Transparent_Objects_with_Self-Occlusion_Aware_Refraction-Tracing_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Wuhan University; The University of Hong Kong; Texas A&M University",
        "project": "https://www.xxlong.site/NeTO/",
        "github": "",
        "arxiv": "2303.11219"
    },
    {
        "title": "Nearest Neighbor Guidance for Out-of-Distribution Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_Nearest_Neighbor_Guidance_for_Out-of-Distribution_Detection_ICCV_2023_paper.html",
        "author": "Jaewoo Park, Yoon Gyo Jung, Andrew Beng Jin Teoh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Nearest_Neighbor_Guidance_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; Northeastern University; Yonsei University, AiV Co.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Neglected Free Lunch - Learning Image Classifiers Using Annotation Byproducts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_Neglected_Free_Lunch_-_Learning_Image_Classifiers_Using_Annotation_Byproducts_ICCV_2023_paper.html",
        "author": "Dongyoon Han, Junsuk Choe, Seonghyeok Chun, John Joon Young Chung, Minsuk Chang, Sangdoo Yun, Jean Y. Song, Seong Joon Oh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Neglected_Free_Lunch_-_Learning_Image_Classifiers_Using_Annotation_Byproducts_ICCV_2023_paper.pdf",
        "aff": "Dante Company; University of Michigan; University of T\u00fcbingen; Sogang University; NAVER AI Lab; DGIST",
        "project": "",
        "github": "github.com/naver-ai/NeglectedFreeLunch",
        "arxiv": ""
    },
    {
        "title": "NerfAcc: Efficient Sampling Accelerates NeRFs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_NerfAcc_Efficient_Sampling_Accelerates_NeRFs_ICCV_2023_paper.html",
        "author": "Ruilong Li, Hang Gao, Matthew Tancik, Angjoo Kanazawa",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NerfAcc_Efficient_Sampling_Accelerates_NeRFs_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley",
        "project": "",
        "github": "https://www.nerfacc.com",
        "arxiv": "2305.04966"
    },
    {
        "title": "Nerfbusters: Removing Ghostly Artifacts from Casually Captured NeRFs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Warburg_Nerfbusters_Removing_Ghostly_Artifacts_from_Casually_Captured_NeRFs_ICCV_2023_paper.html",
        "author": "Frederik Warburg, Ethan Weber, Matthew Tancik, Aleksander Holynski, Angjoo Kanazawa",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Warburg_Nerfbusters_Removing_Ghostly_Artifacts_from_Casually_Captured_NeRFs_ICCV_2023_paper.pdf",
        "aff": "University of California, Berkeley",
        "project": "",
        "github": "",
        "arxiv": "2304.10532"
    },
    {
        "title": "NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_NeuRBF_A_Neural_Fields_Representation_with_Adaptive_Radial_Basis_Functions_ICCV_2023_paper.html",
        "author": "Zhang Chen, Zhong Li, Liangchen Song, Lele Chen, Jingyi Yu, Junsong Yuan, Yi Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_NeuRBF_A_Neural_Fields_Representation_with_Adaptive_Radial_Basis_Functions_ICCV_2023_paper.pdf",
        "aff": "OPPO US Research Center; University at Buffalo; ShanghaiTech University",
        "project": "https://oppo-us-research.github.io/NeuRBF-website/",
        "github": "https://github.com/OPPO-US-Research/NeuRBF",
        "arxiv": ""
    },
    {
        "title": "NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-view Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_NeuS2_Fast_Learning_of_Neural_Implicit_Surfaces_for_Multi-view_Reconstruction_ICCV_2023_paper.html",
        "author": "Yiming Wang, Qin Han, Marc Habermann, Kostas Daniilidis, Christian Theobalt, Lingjie Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_NeuS2_Fast_Learning_of_Neural_Implicit_Surfaces_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "University of Pennsylvania, Max Planck Institute for Informatics; University of Pennsylvania; Peking University; Max Planck Institute for Informatics; University of Pennsylvania, Peking University",
        "project": "https://vcai.mpi-inf.mpg.de/projects/NeuS2/",
        "github": "",
        "arxiv": "2212.05231"
    },
    {
        "title": "Neural Characteristic Function Learning for Conditional Image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.html",
        "author": "Shengxi Li, Jialu Zhang, Yifei Li, Mai Xu, Xin Deng, Li Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.pdf",
        "aff": "School of Electronic and Information Engineering, Beihang University, Beijing, China; School of Cyber Science and Technology, Beihang University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Neural Collage Transfer: Artistic Reconstruction via Material Manipulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Neural_Collage_Transfer_Artistic_Reconstruction_via_Material_Manipulation_ICCV_2023_paper.html",
        "author": "Ganghun Lee, Minji Kim, Yunsu Lee, Minsu Lee, Byoung-Tak Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Neural_Collage_Transfer_Artistic_Reconstruction_via_Material_Manipulation_ICCV_2023_paper.pdf",
        "aff": "Seoul National University",
        "project": "",
        "github": "https://github.com/northadventure/CollageRL",
        "arxiv": ""
    },
    {
        "title": "Neural Deformable Models for 3D Bi-Ventricular Heart Shape Reconstruction and Modeling from 2D Sparse Cardiac Magnetic Resonance Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Neural_Deformable_Models_for_3D_Bi-Ventricular_Heart_Shape_Reconstruction_and_ICCV_2023_paper.html",
        "author": "Meng Ye, Dong Yang, Mikael Kanski, Leon Axel, Dimitris Metaxas",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Neural_Deformable_Models_for_3D_Bi-Ventricular_Heart_Shape_Reconstruction_and_ICCV_2023_paper.pdf",
        "aff": "Rutgers University; NVIDIA; New York University School of Medicine",
        "project": "",
        "github": "",
        "arxiv": "2307.07693"
    },
    {
        "title": "Neural Fields for Structured Lighting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shandilya_Neural_Fields_for_Structured_Lighting_ICCV_2023_paper.html",
        "author": "Aarrushi Shandilya, Benjamin Attal, Christian Richardt, James Tompkin, Matthew O'toole",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shandilya_Neural_Fields_for_Structured_Lighting_ICCV_2023_paper.pdf",
        "aff": "Meta Reality Labs Research; Brown University; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Neural Haircut: Prior-Guided Strand-Based Hair Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sklyarova_Neural_Haircut_Prior-Guided_Strand-Based_Hair_Reconstruction_ICCV_2023_paper.html",
        "author": "Vanessa Sklyarova, Jenya Chelishev, Andreea Dogaru, Igor Medvedev, Victor Lempitsky, Egor Zakharov",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sklyarova_Neural_Haircut_Prior-Guided_Strand-Based_Hair_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Cinemersive Labs; FAU Erlangen-N\u00fcrnberg; Samsung AI Center; Rockstar Games",
        "project": "https://samsunglabs.github.io/NeuralHaircut/",
        "github": "",
        "arxiv": "2306.05872"
    },
    {
        "title": "Neural Implicit Surface Evolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Novello_Neural_Implicit_Surface_Evolution_ICCV_2023_paper.html",
        "author": "Tiago Novello, Vinicius da Silva, Guilherme Schardong, Luiz Schirmer, Helio Lopes, Luiz Velho",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Novello_Neural_Implicit_Surface_Evolution_ICCV_2023_paper.pdf",
        "aff": "IMPA; PUC-Rio; U Coimbra; Unisinos",
        "project": "",
        "github": "",
        "arxiv": "2201.09636"
    },
    {
        "title": "Neural Interactive Keypoint Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Neural_Interactive_Keypoint_Detection_ICCV_2023_paper.html",
        "author": "Jie Yang, Ailing Zeng, Feng Li, Shilong Liu, Ruimao Zhang, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Neural_Interactive_Keypoint_Detection_ICCV_2023_paper.pdf",
        "aff": "International Digital Economy Academy; School of Data Science, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen",
        "project": "",
        "github": "https://github.com/IDEA-Research/Click-Pose",
        "arxiv": "2308.10174"
    },
    {
        "title": "Neural LiDAR Fields for Novel View Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Neural_LiDAR_Fields_for_Novel_View_Synthesis_ICCV_2023_paper.html",
        "author": "Shengyu Huang, Zan Gojcic, Zian Wang, Francis Williams, Yoni Kasten, Sanja Fidler, Konrad Schindler, Or Litany",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Neural_LiDAR_Fields_for_Novel_View_Synthesis_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; NVIDIA; NVIDIA, University of Toronto, Vector Institute",
        "project": "https://research.nvidia.com/labs/toronto-ai/nfl/",
        "github": "",
        "arxiv": "2305.01643"
    },
    {
        "title": "Neural Microfacet Fields for Inverse Rendering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mai_Neural_Microfacet_Fields_for_Inverse_Rendering_ICCV_2023_paper.html",
        "author": "Alexander Mai, Dor Verbin, Falko Kuester, Sara Fridovich-Keil",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_Neural_Microfacet_Fields_for_Inverse_Rendering_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; UC San Diego; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2303.17806"
    },
    {
        "title": "Neural Radiance Field with LiDAR maps",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chang_Neural_Radiance_Field_with_LiDAR_maps_ICCV_2023_paper.html",
        "author": "MingFang Chang, Akash Sharma, Michael Kaess, Simon Lucey",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Neural_Radiance_Field_with_LiDAR_maps_ICCV_2023_paper.pdf",
        "aff": "The University of Adelaide; Carnegie Mellon University",
        "project": "https://anonymous.com/project",
        "github": "https://github.com/anonymous",
        "arxiv": ""
    },
    {
        "title": "Neural Reconstruction of Relightable Human Model from Monocular Video",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Neural_Reconstruction_of_Relightable_Human_Model_from_Monocular_Video_ICCV_2023_paper.html",
        "author": "Wenzhang Sun, Yunlong Che, Han Huang, Yandong Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Neural_Reconstruction_of_Relightable_Human_Model_from_Monocular_Video_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of Technology, Beijing, China; AI2Robotics, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Neural Video Depth Stabilizer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Neural_Video_Depth_Stabilizer_ICCV_2023_paper.html",
        "author": "Yiran Wang, Min Shi, Jiaqi Li, Zihao Huang, Zhiguo Cao, Jianming Zhang, Ke Xian, Guosheng Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Neural_Video_Depth_Stabilizer_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence and Automation, Huazhong University of Science and Technology; Adobe Research; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/RaymondWang987/NVDS",
        "arxiv": "2307.08695"
    },
    {
        "title": "Neural-PBIR Reconstruction of Shape, Material, and Illumination",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Neural-PBIR_Reconstruction_of_Shape_Material_and_Illumination_ICCV_2023_paper.html",
        "author": "Cheng Sun, Guangyan Cai, Zhengqin Li, Kai Yan, Cheng Zhang, Carl Marshall, Jia-Bin Huang, Shuang Zhao, Zhao Dong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Neural-PBIR_Reconstruction_of_Shape_Material_and_Illumination_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; Meta RLR; National Tsing Hua University; University of California, Irvine",
        "project": "",
        "github": "https://neural-pbir.github.io/",
        "arxiv": "2304.13445"
    },
    {
        "title": "No Fear of Classifier Biases: Neural Collapse Inspired Federated Learning with Synthetic and Fixed Classifier",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_No_Fear_of_Classifier_Biases_Neural_Collapse_Inspired_Federated_Learning_ICCV_2023_paper.html",
        "author": "Zexi Li, Xinyi Shang, Rui He, Tao Lin, Chao Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_No_Fear_of_Classifier_Biases_Neural_Collapse_Inspired_Federated_Learning_ICCV_2023_paper.pdf",
        "aff": "Xiamen University; Zhejiang University; Westlake University",
        "project": "",
        "github": "https://github.com/ZexiLee/ICCV-2023-FedETF",
        "arxiv": "2303.10058"
    },
    {
        "title": "Noise-Aware Learning from Web-Crawled Image-Text Data for Image Captioning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Noise-Aware_Learning_from_Web-Crawled_Image-Text_Data_for_Image_Captioning_ICCV_2023_paper.html",
        "author": "Wooyoung Kang, Jonghwan Mun, Sungjun Lee, Byungseok Roh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Noise-Aware_Learning_from_Web-Crawled_Image-Text_Data_for_Image_Captioning_ICCV_2023_paper.pdf",
        "aff": "Kakao Brain",
        "project": "",
        "github": "https://github.com/kakaobrain/noc",
        "arxiv": "2212.13563"
    },
    {
        "title": "Noise2Info: Noisy Image to Information of Noise for Self-Supervised Image Denoising",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Noise2Info_Noisy_Image_to_Information_of_Noise_for_Self-Supervised_Image_ICCV_2023_paper.html",
        "author": "Jiachuan Wang, Shimin Di, Lei Chen, Charles Wang Wai Ng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Noise2Info_Noisy_Image_to_Information_of_Noise_for_Self-Supervised_Image_ICCV_2023_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology (Guangzhou), Guangdong Province, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Non-Coaxial Event-Guided Motion Deblurring with Spatial Alignment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Non-Coaxial_Event-Guided_Motion_Deblurring_with_Spatial_Alignment_ICCV_2023_paper.html",
        "author": "Hoonhee Cho, Yuhwan Jeong, Taewoo Kim, Kuk-Jin Yoon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Non-Coaxial_Event-Guided_Motion_Deblurring_with_Spatial_Alignment_ICCV_2023_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology",
        "project": "https://sites.google.com/view/neid2023single",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Non-Semantics Suppressed Mask Learning for Unsupervised Video Semantic Compression",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Non-Semantics_Suppressed_Mask_Learning_for_Unsupervised_Video_Semantic_Compression_ICCV_2023_paper.html",
        "author": "Yuan Tian, Guo Lu, Guangtao Zhai, Zhiyong Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Non-Semantics_Suppressed_Mask_Learning_for_Unsupervised_Video_Semantic_Compression_ICCV_2023_paper.pdf",
        "aff": "Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Nonrigid Object Contact Estimation With Regional Unwrapping Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_Nonrigid_Object_Contact_Estimation_With_Regional_Unwrapping_Transformer_ICCV_2023_paper.html",
        "author": "Wei Xie, Zimeng Zhao, Shiying Li, Binghui Zuo, Yangang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Nonrigid_Object_Contact_Estimation_With_Regional_Unwrapping_Transformer_ICCV_2023_paper.pdf",
        "aff": "Southeast University, China",
        "project": "",
        "github": "",
        "arxiv": "2308.14074"
    },
    {
        "title": "Normalizing Flows for Human Pose Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hirschorn_Normalizing_Flows_for_Human_Pose_Anomaly_Detection_ICCV_2023_paper.html",
        "author": "Or Hirschorn, Shai Avidan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hirschorn_Normalizing_Flows_for_Human_Pose_Anomaly_Detection_ICCV_2023_paper.pdf",
        "aff": "Tel-Aviv University, Israel",
        "project": "",
        "github": "https://github.com/orhir/STG-NF",
        "arxiv": "2211.10946"
    },
    {
        "title": "Not All Features Matter: Enhancing Few-shot CLIP with Adaptive Prior Refinement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Not_All_Features_Matter_Enhancing_Few-shot_CLIP_with_Adaptive_Prior_ICCV_2023_paper.html",
        "author": "Xiangyang Zhu, Renrui Zhang, Bowei He, Aojun Zhou, Dong Wang, Bin Zhao, Peng Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Not_All_Features_Matter_Enhancing_Few-shot_CLIP_with_Adaptive_Prior_ICCV_2023_paper.pdf",
        "aff": "Shanghai Artificial Intelligence Laboratory; City University of Hong Kong; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/yangyangyang127/APE",
        "arxiv": "2304.01195"
    },
    {
        "title": "Not All Steps are Created Equal: Selective Diffusion Distillation for Image Manipulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.html",
        "author": "Luozhou Wang, Shuai Yang, Shu Liu, Ying-cong Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.pdf",
        "aff": "SmartMore; The Hong Kong University of Science and Technology (Guangzhou); The Hong Kong University of Science and Technology, HKUST (Guangzhou) - SmartMore Joint Lab.",
        "project": "",
        "github": "https://github.com/AndysonYs/Selective-Diffusion-Distillation",
        "arxiv": "2307.08448"
    },
    {
        "title": "Not Every Side Is Equal: Localization Uncertainty Estimation for Semi-Supervised 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Not_Every_Side_Is_Equal_Localization_Uncertainty_Estimation_for_Semi-Supervised_ICCV_2023_paper.html",
        "author": "Chuxin Wang, Wenfei Yang, Tianzhu Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_Every_Side_Is_Equal_Localization_Uncertainty_Estimation_for_Semi-Supervised_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Deep Space Exploration Lab; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Novel Scenes & Classes: Towards Adaptive Open-set Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Novel_Scenes__Classes_Towards_Adaptive_Open-set_Object_Detection_ICCV_2023_paper.html",
        "author": "Wuyang Li, Xiaoqing Guo, Yixuan Yuan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Novel_Scenes__Classes_Towards_Adaptive_Open-set_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; University of Oxford; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/CityU-AIM-Group/SOMA",
        "arxiv": ""
    },
    {
        "title": "Novel-View Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Novel-View_Synthesis_and_Pose_Estimation_for_Hand-Object_Interaction_from_Sparse_ICCV_2023_paper.html",
        "author": "Wentian Qu, Zhaopeng Cui, Yinda Zhang, Chenyu Meng, Cuixia Ma, Xiaoming Deng, Hongan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Novel-View_Synthesis_and_Pose_Estimation_for_Hand-Object_Interaction_from_Sparse_ICCV_2023_paper.pdf",
        "aff": "Google; State Key Lab of CAD &CG, Zhejiang University; Institute of Software, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "project": "https://iscas3dv.github.io/HO-NeRF",
        "github": "",
        "arxiv": "2308.11198"
    },
    {
        "title": "OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_OCHID-Fi_Occlusion-Robust_Hand_Pose_Estimation_in_3D_via_RF-Vision_ICCV_2023_paper.html",
        "author": "Shujie Zhang, Tianyue Zheng, Zhe Chen, Jingzhi Hu, Abdelwahed Khamis, Jiajun Liu, Jun Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OCHID-Fi_Occlusion-Robust_Hand_Pose_Estimation_in_3D_via_RF-Vision_ICCV_2023_paper.pdf",
        "aff": "Fudan University; Nanyang Technological University; CSIRO",
        "project": "",
        "github": "https://github.com/DeepWiSe888/OCHID-Fi",
        "arxiv": ""
    },
    {
        "title": "OFVL-MS: Once for Visual Localization across Multiple Indoor Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_OFVL-MS_Once_for_Visual_Localization_across_Multiple_Indoor_Scenes_ICCV_2023_paper.html",
        "author": "Tao Xie, Kun Dai, Siyi Lu, Ke Wang, Zhiqiang Jiang, Jinghan Gao, Dedong Liu, Jie Xu, Lijun Zhao, Ruifeng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_OFVL-MS_Once_for_Visual_Localization_across_Multiple_Indoor_Scenes_ICCV_2023_paper.pdf",
        "aff": "Harbin Institute of Technology, Zhengzhou Research Institute; Harbin Institute of Technology; Harbin Institute of Technology, China Coal Science and Technology Intelligent Storage Technology Co., Ltd.",
        "project": "",
        "github": "https://github.com/mooncake199809/UFVL-Net",
        "arxiv": ""
    },
    {
        "title": "OPERA: Omni-Supervised Representation Learning with Hierarchical Supervisions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_OPERA_Omni-Supervised_Representation_Learning_with_Hierarchical_Supervisions_ICCV_2023_paper.html",
        "author": "Chengkun Wang, Wenzhao Zheng, Zheng Zhu, Jie Zhou, Jiwen Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_OPERA_Omni-Supervised_Representation_Learning_with_Hierarchical_Supervisions_ICCV_2023_paper.pdf",
        "aff": "PhiGent Robotics, China; Department of Automation, Tsinghua University, China; Beijing National Research Center for Information Science and Technology, China",
        "project": "",
        "github": "https://github.com/wangck20/OPERA",
        "arxiv": "2210.05557"
    },
    {
        "title": "ORC: Network Group-based Knowledge Distillation using Online Role Change",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Choi_ORC_Network_Group-based_Knowledge_Distillation_using_Online_Role_Change_ICCV_2023_paper.html",
        "author": "Junyong Choi, Hyeon Cho, Seokhwa Cheung, Wonjun Hwang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_ORC_Network_Group-based_Knowledge_Distillation_using_Online_Role_Change_ICCV_2023_paper.pdf",
        "aff": "Ajou University, Korea; Naver AI Lab; Ajou University, Korea; Hyundai Motor Company; Ajou University, Korea",
        "project": "",
        "github": "https://github.com/choijunyong/ORCKD",
        "arxiv": "2206.01186"
    },
    {
        "title": "Object as Query: Lifting Any 2D Object Detector to 3D Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Object_as_Query_Lifting_Any_2D_Object_Detector_to_3D_ICCV_2023_paper.html",
        "author": "Zitian Wang, Zehao Huang, Jiahui Fu, Naiyan Wang, Si Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Object_as_Query_Lifting_Any_2D_Object_Detector_to_3D_ICCV_2023_paper.pdf",
        "aff": "Object as Query: Lifting any 2D Object Detector to 3D Detection\nZitian Wang1Zehao Huang2Jiahui Fu1Naiyan Wang2Si Liu1\n1Institute of Artificial Intelligence, Beihang University\n2TuSimple\n{wangzt.kghl,zehaohuang18,winsty }@gmail.com {jiahuifu,liusi }@buaa.edu.cn\nAbstract\n3D object detection from multi-view images has drawn\nmuch attention over the past few years. Existing methods\nmainly establish 3D representations from multi-view im-\nages and adopt a dense detection head for object detec-\ntion, or employ object queries distributed in 3D space to\nlocalize objects. In this paper, we design Multi-View 2D\nObjects guided 3D Object Detector (MV2D), which can lift\nany 2D object detector to multi-view 3D object detection.\nSince 2D detections can provide valuable priors for object\nexistence, MV2D exploits 2D detectors to generate object\nqueries conditioned on the rich image semantics. These\ndynamically generated queries help MV2D to recall ob-\njects in the field of view and show a strong capability of\nlocalizing 3D objects. For the generated queries, we de-\nsign a sparse cross attention module to force them to fo-\ncus on the features of specific objects, which suppresses\ninterference from noises. The evaluation results on the\nnuScenes dataset demonstrate the dynamic object queries\nand sparse feature aggregation can promote 3D detection\ncapability. MV2D also exhibits a state-of-the-art perfor-\nmance among existing methods. We hope MV2D can serve\nas a new baseline for future research. Code is available at\nhttps://github.com/tusen-ai/MV2D .\n1. Introduction\nCamera-based 3D object detection in unconstrained real-\nworld scenes has drawn much attention over the past few\nyears. Early monocular 3D object detection methods [30,\n45, 1, 36, 18, 39, 40] typically build their framework fol-\nlowing the 2D object detection pipeline. The 3D location\nand attributes of objects are directly predicted from a sin-\ngle view image. Though these methods have achieved great\nprogress, they are incapable of utilizing the geometric con-\nfiguration of surrounding cameras and multi-view image\ncorrespondences, which are pivotal for the 3D position of\nobjects in the real world. Moreover, adapting these methods\nto multi-view setting relies on sophisticated cross-camera\n(a) original image(b)fixed queries\n(c) 2D detection(d) generated queries from 2D detection\nFigure 1. Motivation of MV2D. The 3D detector with fixed object\nqueries (fixed queries means the queries are invariant for differ-\nent inputs) might mislocate or ignore some objects (b), which are\nhowever successfully detected by a 2D detector (c). If generating\nobject queries based on 2D detector, a 3D detector can produce\nmore precise locations (d).\npost-processing, which further causes degraded efficiency\nand efficacy. To handle these problems, recent researchers\n[41, 16, 23, 22, 26] propose to directly localize objects in\n3D world space based on multi-view images, providing a\nnew paradigm for vision-based 3D object detection.\nAccording to the representation of fused features, current\nmulti-view 3D object detection methods can be mainly di-\nvided into two streams: dense 3D methods and sparse query\nmethods. Concretely, dense 3D methods render multi-view\nfeatures into 3D space, such as Bird\u2019s-Eye-View (BEV) fea-\nture space [16, 22, 23, 5] or voxel feature space [35, 21].\nHowever, since the computational costs are squarely pro-\nportional to the range of 3D space, they inevitably cannot\nscale up to large-scale scenarios [9]. Alternatively, query-\nbased methods [41, 26] adopt learnable object queries to ag-\ngregate features from multi-view images and predict object\nbounding boxes based on query features. Although fixed\nnumber of object queries avoid computational cost explod-\ning with 3D space, the query number and position relied on\nempirical prior may cause false positive or undetected ob-\njects in dynamic scenarios.\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n3791\n",
        "project": "",
        "github": "",
        "arxiv": "2301.02364"
    },
    {
        "title": "Object-Centric Multiple Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Object-Centric_Multiple_Object_Tracking_ICCV_2023_paper.html",
        "author": "Zixu Zhao, Jiaze Wang, Max Horn, Yizhuo Ding, Tong He, Zechen Bai, Dominik Zietlow, Carl-Johann Simon-Gabriel, Bing Shuai, Zhuowen Tu, Thomas Brox, Bernt Schiele, Yanwei Fu, Francesco Locatello, Zheng Zhang, Tianjun Xiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Object-Centric_Multiple_Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "Fudan University; The Chinese University of Hong Kong; Amazon Web Services",
        "project": "",
        "github": "https://github.com/amazon-science/object-centric-multiple-object-tracking",
        "arxiv": "2309.00233"
    },
    {
        "title": "Object-aware Gaze Target Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tonini_Object-aware_Gaze_Target_Detection_ICCV_2023_paper.html",
        "author": "Francesco Tonini, Nicola Dall'Asen, Cigdem Beyan, Elisa Ricci",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tonini_Object-aware_Gaze_Target_Detection_ICCV_2023_paper.pdf",
        "aff": "University of Trento, Trento, Italy; Fondazione Bruno Kessler, Trento, Italy; University of Trento, Trento, Italy; University of Trento, Trento, Italy; University of Pisa, Pisa, Italy",
        "project": "",
        "github": "https://github.com/francescotonini/object-aware-gaze-target-detection",
        "arxiv": "2307.09662"
    },
    {
        "title": "ObjectFusion: Multi-modal 3D Object Detection with Object-Centric Fusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_ObjectFusion_Multi-modal_3D_Object_Detection_with_Object-Centric_Fusion_ICCV_2023_paper.html",
        "author": "Qi Cai, Yingwei Pan, Ting Yao, Chong-Wah Ngo, Tao Mei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_ObjectFusion_Multi-modal_3D_Object_Detection_with_Object-Centric_Fusion_ICCV_2023_paper.pdf",
        "aff": "HiDream.ai Inc; Singapore Management University; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_ObjectSDF_Improved_Object-Compositional_Neural_Implicit_Surfaces_ICCV_2023_paper.html",
        "author": "Qianyi Wu, Kaisiyuan Wang, Kejie Li, Jianmin Zheng, Jianfei Cai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_ObjectSDF_Improved_Object-Compositional_Neural_Implicit_Surfaces_ICCV_2023_paper.pdf",
        "aff": "University of Oxford; Nanyang Technological University; University of Sydney; Monash University",
        "project": "",
        "github": "https://qianyiwu.github.io/objectsdf++",
        "arxiv": ""
    },
    {
        "title": "Objects Do Not Disappear: Video Object Detection by Single-Frame Object Location Anticipation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Objects_Do_Not_Disappear_Video_Object_Detection_by_Single-Frame_Object_ICCV_2023_paper.html",
        "author": "Xin Liu, Fatemeh Karimi Nejadasl, Jan C. van Gemert, Olaf Booij, Silvia L. Pintea",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Objects_Do_Not_Disappear_Video_Object_Detection_by_Single-Frame_Object_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Lab, Delft University of Technology; Institute for Biodiversity and Ecosystem Dynamics, University of Amsterdam",
        "project": "",
        "github": "https://github.com/L-KID/Video-object-detection-by-location-anticipation",
        "arxiv": "2308.04770"
    },
    {
        "title": "OccFormer: Dual-path Transformer for Vision-based 3D Semantic Occupancy Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_OccFormer_Dual-path_Transformer_for_Vision-based_3D_Semantic_Occupancy_Prediction_ICCV_2023_paper.html",
        "author": "Yunpeng Zhang, Zheng Zhu, Dalong Du",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OccFormer_Dual-path_Transformer_for_Vision-based_3D_Semantic_Occupancy_Prediction_ICCV_2023_paper.pdf",
        "aff": "PhiGent Robotics",
        "project": "",
        "github": "https://github.com/zhangyp15/OccFormer",
        "arxiv": "2304.05316"
    },
    {
        "title": "Occ^2Net: Robust Image Matching Based on 3D Occupancy Estimation for Occluded Regions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.html",
        "author": "Miao Fan, Mingrui Chen, Chen Hu, Shuchang Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.pdf",
        "aff": "MEGVII Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "OmniLabel: A Challenging Benchmark for Language-Based Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Schulter_OmniLabel_A_Challenging_Benchmark_for_Language-Based_Object_Detection_ICCV_2023_paper.html",
        "author": "Samuel Schulter, Vijay Kumar B G, Yumin Suh, Konstantinos M. Dafnis, Zhixing Zhang, Shiyu Zhao, Dimitris Metaxas",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Schulter_OmniLabel_A_Challenging_Benchmark_for_Language-Based_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Rutgers University; NEC Laboratories America",
        "project": "https://www.omnilabel.org",
        "github": "",
        "arxiv": "2304.11463"
    },
    {
        "title": "OmniZoomer: Learning to Move and Zoom in on Sphere at High-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_OmniZoomer_Learning_to_Move_and_Zoom_in_on_Sphere_at_ICCV_2023_paper.html",
        "author": "Zidong Cao, Hao Ai, Yan-Pei Cao, Ying Shan, Xiaohu Qie, Lin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_OmniZoomer_Learning_to_Move_and_Zoom_in_on_Sphere_at_ICCV_2023_paper.pdf",
        "aff": "AI Thrust, HKUST(GZ); AI Thrust, HKUST(GZ); Dept. of CSE, HKUST; AI Thrust, HKUST(GZ); ARC Lab, Tencent PCG; ARC Lab, Tencent PCG",
        "project": "http://vlislab22.github.io/OmniZoomer/",
        "github": "",
        "arxiv": "2308.08114"
    },
    {
        "title": "Omnidirectional Information Gathering for Knowledge Transfer-Based Audio-Visual Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.html",
        "author": "Jinyu Chen, Wenguan Wang, Si Liu, Hongsheng Li, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; ReLER, CCAI, Zhejiang University; Institute of Arti\ufb01cial Intelligence, Beihang University",
        "project": "",
        "github": "https://github.com/chenjinyubuaa/ORAN",
        "arxiv": "2308.10306"
    },
    {
        "title": "OmnimatteRF: Robust Omnimatte with 3D Background Modeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.html",
        "author": "Geng Lin, Chen Gao, Jia-Bin Huang, Changil Kim, Yipeng Wang, Matthias Zwicker, Ayush Saraf",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; Meta",
        "project": "https://omnimatte-rf.github.io",
        "github": "",
        "arxiv": "2309.07749"
    },
    {
        "title": "On the Audio-visual Synchronization for Lip-to-Speech Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Niu_On_the_Audio-visual_Synchronization_for_Lip-to-Speech_Synthesis_ICCV_2023_paper.html",
        "author": "Zhe Niu, Brian Mak",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_On_the_Audio-visual_Synchronization_for_Lip-to-Speech_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2303.00502"
    },
    {
        "title": "On the Effectiveness of Spectral Discriminators for Perceptual Quality Improvement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_On_the_Effectiveness_of_Spectral_Discriminators_for_Perceptual_Quality_Improvement_ICCV_2023_paper.html",
        "author": "Xin Luo, Yunan Zhu, Shunxin Xu, Dong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_On_the_Effectiveness_of_Spectral_Discriminators_for_Perceptual_Quality_Improvement_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Hefei, China",
        "project": "",
        "github": "https://github.com/Luciennnnnnn/DualFormer",
        "arxiv": "2307.12027"
    },
    {
        "title": "On the Robustness of Normalizing Flows for Inverse Problems in Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hong_On_the_Robustness_of_Normalizing_Flows_for_Inverse_Problems_in_ICCV_2023_paper.html",
        "author": "Seongmin Hong, Inbum Park, Se Young Chun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_On_the_Robustness_of_Normalizing_Flows_for_Inverse_Problems_in_ICCV_2023_paper.pdf",
        "aff": "Dept. of ECE, Seoul National University, Republic of Korea; INMC & IPAI, Seoul National University, Republic of Korea",
        "project": "",
        "github": "",
        "arxiv": "2212.04319"
    },
    {
        "title": "On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_On_the_Robustness_of_Open-World_Test-Time_Training_Self-Training_with_Dynamic_ICCV_2023_paper.html",
        "author": "Yushu Li, Xun Xu, Yongyi Su, Kui Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_On_the_Robustness_of_Open-World_Test-Time_Training_Self-Training_with_Dynamic_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology; Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR)",
        "project": "",
        "github": "https://github.com/Yushu-Li/OWTTT",
        "arxiv": "2308.09942"
    },
    {
        "title": "Once Detected, Never Lost: Surpassing Human Performance in Offline LiDAR based 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Once_Detected_Never_Lost_Surpassing_Human_Performance_in_Offline_LiDAR_ICCV_2023_paper.html",
        "author": "Lue Fan, Yuxue Yang, Yiming Mao, Feng Wang, Yuntao Chen, Naiyan Wang, Zhaoxiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Once_Detected_Never_Lost_Surpassing_Human_Performance_in_Offline_LiDAR_ICCV_2023_paper.pdf",
        "aff": "Hunan University; Centre for Artificial Intelligence and Robotics (HKISI CAS); TuSimple; Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences (UCAS); State Key Laboratory of Multimodal Artificial Intelligence Systems",
        "project": "",
        "github": "https://github.com/tusen-ai/SST",
        "arxiv": "2304.12315"
    },
    {
        "title": "One-Shot Generative Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_One-Shot_Generative_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Ceyuan Yang, Yujun Shen, Zhiyi Zhang, Yinghao Xu, Jiapeng Zhu, Zhirong Wu, Bolei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_One-Shot_Generative_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "HKUST; UCLA; ByteDance Inc.; Shanghai AI Laboratory; CUHK; CUHK; MSRA; ByteDance Inc.; Ant Group",
        "project": "",
        "github": "https://genforce.github.io/genda/",
        "arxiv": "2111.09876"
    },
    {
        "title": "One-Shot Recognition of Any Material Anywhere Using Contrastive Learning with Physics-Based Rendering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Drehwald_One-Shot_Recognition_of_Any_Material_Anywhere_Using_Contrastive_Learning_with_ICCV_2023_paper.html",
        "author": "Manuel S. Drehwald, Sagi Eppel, Jolina Li, Han Hao, Alan Aspuru-Guzik",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Drehwald_One-Shot_Recognition_of_Any_Material_Anywhere_Using_Contrastive_Learning_with_ICCV_2023_paper.pdf",
        "aff": "Karlsruhe Institute of Technology; University of Toronto; Vector Institute, University of Toronto; University of Toronto, Innoviz",
        "project": "",
        "github": "https://github.com/ZuseZ4/MatSim-Dataset-Generator-Scripts-And-Neural-net",
        "arxiv": "2212.00648"
    },
    {
        "title": "One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_One-bit_Flip_is_All_You_Need_When_Bit-flip_Attack_Meets_ICCV_2023_paper.html",
        "author": "Jianshuo Dong, Han Qiu, Yiming Li, Tianwei Zhang, Yuanjie Li, Zeqi Lai, Chao Zhang, Shu-Tao Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_One-bit_Flip_is_All_You_Need_When_Bit-flip_Attack_Meets_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University, Zhongguancun Laboratory; Zhejiang University, HIC-ZJU, Ant Group; Tsinghua University; Nanyang Technological University",
        "project": "",
        "github": "https://github.com/jianshuod/TBA",
        "arxiv": "2308.07934"
    },
    {
        "title": "One-shot Implicit Animatable Avatars with Model-based Priors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_One-shot_Implicit_Animatable_Avatars_with_Model-based_Priors_ICCV_2023_paper.html",
        "author": "Yangyi Huang, Hongwei Yi, Weiyang Liu, Haofan Wang, Boxi Wu, Wenxiao Wang, Binbin Lin, Debing Zhang, Deng Cai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_One-shot_Implicit_Animatable_Avatars_with_Model-based_Priors_ICCV_2023_paper.pdf",
        "aff": "Xiaohongshu Inc.; Fullong Inc.; State Key Lab of CAD & CG, Zhejiang University; School of Software Technology, Zhejiang University; University of Cambridge; Max Planck Institute for Intelligent Systems, T\u00fcbingen",
        "project": "",
        "github": "https://huangyangyi.github.io/ELICIT",
        "arxiv": "2212.02469"
    },
    {
        "title": "Online Class Incremental Learning on Stochastic Blurry Task Boundary via Mask and Visual Prompt Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Moon_Online_Class_Incremental_Learning_on_Stochastic_Blurry_Task_Boundary_via_ICCV_2023_paper.html",
        "author": "Jun-Yeong Moon, Keon-Hee Park, Jung Uk Kim, Gyeong-Moon Park",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_Online_Class_Incremental_Learning_on_Stochastic_Blurry_Task_Boundary_via_ICCV_2023_paper.pdf",
        "aff": "Kyung Hee University, Yongin, Republic of Korea",
        "project": "",
        "github": "https://github.com/moonjunyyy/Si-Blurry",
        "arxiv": "2308.09303"
    },
    {
        "title": "Online Clustered Codebook",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Online_Clustered_Codebook_ICCV_2023_paper.html",
        "author": "Chuanxia Zheng, Andrea Vedaldi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Online_Clustered_Codebook_ICCV_2023_paper.pdf",
        "aff": "Visual Geometry Group, University of Oxford",
        "project": "",
        "github": "",
        "arxiv": "2307.15139"
    },
    {
        "title": "Online Continual Learning on Hierarchical Label Expansion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.html",
        "author": "Byung Hyun Lee, Okchul Jung, Jonghyun Choi, Se Young Chun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.pdf",
        "aff": "Yonsei University, Republic of Korea; Dept. of ECE, Seoul National University, Republic of Korea; INMC & IPAI, Seoul National University, Republic of Korea",
        "project": "",
        "github": "",
        "arxiv": "2308.14374"
    },
    {
        "title": "Online Prototype Learning for Online Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Online_Prototype_Learning_for_Online_Continual_Learning_ICCV_2023_paper.html",
        "author": "Yujie Wei, Jiaxin Ye, Zhizhong Huang, Junping Zhang, Hongming Shan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Online_Prototype_Learning_for_Online_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "Institute of Science and Technology for Brain-inspired Intelligence, Fudan University; Institute of Science and Technology for Brain-inspired Intelligence, Fudan University; MOE Frontiers Center for Brain Science, Fudan University; Shanghai Center for Brain Science and Brain-inspired Technology; Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University",
        "project": "",
        "github": "https://github.com/weilllllls/OnPro",
        "arxiv": "2308.00301"
    },
    {
        "title": "OnlineRefer: A Simple Online Baseline for Referring Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_OnlineRefer_A_Simple_Online_Baseline_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.html",
        "author": "Dongming Wu, Tiancai Wang, Yuang Zhang, Xiangyu Zhang, Jianbing Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_OnlineRefer_A_Simple_Online_Baseline_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf",
        "aff": "MEGVII Technology; Beijing Institute of Technology; SKL-IOTSC, CIS, University of Macau; Shanghai Jiao Tong University; Beijing Academy of Arti\ufb01cial Intelligence",
        "project": "",
        "github": "https://github.com/wudongming97/OnlineRefer",
        "arxiv": "2307.09356"
    },
    {
        "title": "Open Set Video HOI detection from Action-Centric Chain-of-Look Prompting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xi_Open_Set_Video_HOI_detection_from_Action-Centric_Chain-of-Look_Prompting_ICCV_2023_paper.html",
        "author": "Nan Xi, Jingjing Meng, Junsong Yuan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xi_Open_Set_Video_HOI_detection_from_Action-Centric_Chain-of-Look_Prompting_ICCV_2023_paper.pdf",
        "aff": "Amazon; State University of New York at Buffalo",
        "project": "",
        "github": "https://github.com/southnx/ACoLP",
        "arxiv": ""
    },
    {
        "title": "Open-Vocabulary Object Detection With an Open Corpus",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Open-Vocabulary_Object_Detection_With_an_Open_Corpus_ICCV_2023_paper.html",
        "author": "Jiong Wang, Huiming Zhang, Haiwen Hong, Xuan Jin, Yuan He, Hui Xue, Zhou Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Open-Vocabulary_Object_Detection_With_an_Open_Corpus_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group; Zhejiang University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Open-Vocabulary Semantic Segmentation with Decoupled One-Pass Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_Open-Vocabulary_Semantic_Segmentation_with_Decoupled_One-Pass_Network_ICCV_2023_paper.html",
        "author": "Cong Han, Yujie Zhong, Dengjie Li, Kai Han, Lin Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Open-Vocabulary_Semantic_Segmentation_with_Decoupled_One-Pass_Network_ICCV_2023_paper.pdf",
        "aff": "Meituan Inc.; The University of Hong Kong",
        "project": "",
        "github": "https://github.com/CongHan0808/DeOP.git",
        "arxiv": "2304.01198"
    },
    {
        "title": "Open-domain Visual Entity Recognition: Towards Recognizing Millions of Wikipedia Entities",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Open-domain_Visual_Entity_Recognition_Towards_Recognizing_Millions_of_Wikipedia_Entities_ICCV_2023_paper.html",
        "author": "Hexiang Hu, Yi Luan, Yang Chen, Urvashi Khandelwal, Mandar Joshi, Kenton Lee, Kristina Toutanova, Ming-Wei Chang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Open-domain_Visual_Entity_Recognition_Towards_Recognizing_Millions_of_Wikipedia_Entities_ICCV_2023_paper.pdf",
        "aff": "Georgia Institute of Technology; Google Deepmind",
        "project": "https://open-vision-language.github.io/oven",
        "github": "",
        "arxiv": "2302.11154"
    },
    {
        "title": "Open-vocabulary Object Segmentation with Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Open-vocabulary_Object_Segmentation_with_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Ziyi Li, Qinye Zhou, Xiaoyun Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Open-vocabulary_Object_Segmentation_with_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Coop. Medianet Innovation Center, Shanghai Jiao Tong University, China; Shanghai AI Laboratory, China; Coop. Medianet Innovation Center, Shanghai Jiao Tong University, China",
        "project": "https://lipurple.github.io/Grounded_Diffusion/",
        "github": "https://github.com/lipurple/Grounded_Diffusion",
        "arxiv": "2301.05221"
    },
    {
        "title": "Open-vocabulary Panoptic Segmentation with Embedding Modulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Open-vocabulary_Panoptic_Segmentation_with_Embedding_Modulation_ICCV_2023_paper.html",
        "author": "Xi Chen, Shuang Li, Ser-Nam Lim, Antonio Torralba, Hengshuang Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Open-vocabulary_Panoptic_Segmentation_with_Embedding_Modulation_ICCV_2023_paper.pdf",
        "aff": "Massachusetts Institute of Technology; Meta AI; The University of Hong Kong; The University of Hong Kong, Massachusetts Institute of Technology",
        "project": "https://opsnet-page.github.io",
        "github": "",
        "arxiv": "2303.11324"
    },
    {
        "title": "Open-vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Open-vocabulary_Video_Question_Answering_A_New_Benchmark_for_Evaluating_the_ICCV_2023_paper.html",
        "author": "Dohwan Ko, Ji Soo Lee, Miso Choi, Jaewon Chu, Jihwan Park, Hyunwoo J. Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Open-vocabulary_Video_Question_Answering_A_New_Benchmark_for_Evaluating_the_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, Korea University",
        "project": "",
        "github": "https://github.com/mlvlab/OVQA",
        "arxiv": "2308.09363"
    },
    {
        "title": "OpenOccupancy: A Large Scale Benchmark for Surrounding Semantic Occupancy Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_OpenOccupancy_A_Large_Scale_Benchmark_for_Surrounding_Semantic_Occupancy_Perception_ICCV_2023_paper.html",
        "author": "Xiaofeng Wang, Zheng Zhu, Wenbo Xu, Yunpeng Zhang, Yi Wei, Xu Chi, Yun Ye, Dalong Du, Jiwen Lu, Xingang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_OpenOccupancy_A_Large_Scale_Benchmark_for_Surrounding_Semantic_Occupancy_Perception_ICCV_2023_paper.pdf",
        "aff": "PhiGent Robotics; Tsinghua University; Institute of Automation, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/JeffWang987/OpenOccupancy",
        "arxiv": "2303.03991"
    },
    {
        "title": "Optimizing the Placement of Roadside LiDARs for Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Optimizing_the_Placement_of_Roadside_LiDARs_for_Autonomous_Driving_ICCV_2023_paper.html",
        "author": "Wentao Jiang, Hao Xiang, Xinyu Cai, Runsheng Xu, Jiaqi Ma, Yikang Li, Gim Hee Lee, Si Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Optimizing_the_Placement_of_Roadside_LiDARs_for_Autonomous_Driving_ICCV_2023_paper.pdf",
        "aff": "NUS; UCLA; Beihang University; Shanghai AI Laboratory",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Ord2Seq: Regarding Ordinal Regression as Label Sequence Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Ord2Seq_Regarding_Ordinal_Regression_as_Label_Sequence_Prediction_ICCV_2023_paper.html",
        "author": "Jinhong Wang, Yi Cheng, Jintai Chen, TingTing Chen, Danny Chen, Jian Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Ord2Seq_Regarding_Ordinal_Regression_as_Label_Sequence_Prediction_ICCV_2023_paper.pdf",
        "aff": "University of Notre Dame; Zhejiang University",
        "project": "",
        "github": "https://github.com/wjh892521292/Ord2Seq",
        "arxiv": "2307.09004"
    },
    {
        "title": "Order-Prompted Tag Sequence Generation for Video Tagging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Order-Prompted_Tag_Sequence_Generation_for_Video_Tagging_ICCV_2023_paper.html",
        "author": "Zongyang Ma, Ziqi Zhang, Yuxin Chen, Zhongang Qi, Yingmin Luo, Zekun Li, Chunfeng Yuan, Bing Li, Xiaohu Qie, Ying Shan, Weiming Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Order-Prompted_Tag_Sequence_Generation_for_Video_Tagging_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences; Tencent PCG; ARC Lab; CNCERT/CC",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Order-preserving Consistency Regularization for Domain Adaptation and Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jing_Order-preserving_Consistency_Regularization_for_Domain_Adaptation_and_Generalization_ICCV_2023_paper.html",
        "author": "Mengmeng Jing, Xiantong Zhen, Jingjing Li, Cees G. M. Snoek",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Order-preserving_Consistency_Regularization_for_Domain_Adaptation_and_Generalization_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; University of Amsterdam",
        "project": "",
        "github": "",
        "arxiv": "2309.13258"
    },
    {
        "title": "Ordered Atomic Activity for Fine-grained Interactive Traffic Scenario Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Agarwal_Ordered_Atomic_Activity_for_Fine-grained_Interactive_Traffic_Scenario_Understanding_ICCV_2023_paper.html",
        "author": "Nakul Agarwal, Yi-Ting Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_Ordered_Atomic_Activity_for_Fine-grained_Interactive_Traffic_Scenario_Understanding_ICCV_2023_paper.pdf",
        "aff": "National Yang Ming Chiao Tung University; Honda Research Institute USA",
        "project": "https://usa.honda-ri.com/oats",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Ordinal Label Distribution Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.html",
        "author": "Changsong Wen, Xin Zhang, Xingxu Yao, Jufeng Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.pdf",
        "aff": "VCIP & TMCC & DISSec, College of Computer Science, Nankai University",
        "project": "",
        "github": "https://downdric23.github.io/",
        "arxiv": ""
    },
    {
        "title": "OrthoPlanes: A Novel Representation for Better 3D-Awareness of GANs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_OrthoPlanes_A_Novel_Representation_for_Better_3D-Awareness_of_GANs_ICCV_2023_paper.html",
        "author": "Honglin He, Zhuoqian Yang, Shikai Li, Bo Dai, Wayne Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_OrthoPlanes_A_Novel_Representation_for_Better_3D-Awareness_of_GANs_ICCV_2023_paper.pdf",
        "aff": "School of Computer and Communication Sciences, EPFL; Shanghai AI Laboratory, Tsinghua University; Shanghai AI Laboratory",
        "project": "https://orthoplanes.github.io/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Out-of-Distribution Detection for Monocular Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hornauer_Out-of-Distribution_Detection_for_Monocular_Depth_Estimation_ICCV_2023_paper.html",
        "author": "Julia Hornauer, Adrian Holzbock, Vasileios Belagiannis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hornauer_Out-of-Distribution_Detection_for_Monocular_Depth_Estimation_ICCV_2023_paper.pdf",
        "aff": "Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, Germany; Ulm University, Germany",
        "project": "",
        "github": "",
        "arxiv": "2308.06072"
    },
    {
        "title": "Out-of-Domain GAN Inversion via Invertibility Decomposition for Photo-Realistic Human Face Manipulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Out-of-Domain_GAN_Inversion_via_Invertibility_Decomposition_for_Photo-Realistic_Human_Face_ICCV_2023_paper.html",
        "author": "Xin Yang, Xiaogang XU, Yingcong Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Out-of-Domain_GAN_Inversion_via_Invertibility_Decomposition_for_Photo-Realistic_Human_Face_ICCV_2023_paper.pdf",
        "aff": "4Zhejiang Lab5Zhejiang University; 1HKUST (GZ)2HKUST3HKUST (GZ) - SmartMore Joint Lab",
        "project": "",
        "github": "https://github.com/AbnerVictor/OOD-GAN-inversion",
        "arxiv": "2212.09262"
    },
    {
        "title": "Overcoming Forgetting Catastrophe in Quantization-Aware Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Overcoming_Forgetting_Catastrophe_in_Quantization-Aware_Training_ICCV_2023_paper.html",
        "author": "Ting-An Chen, De-Nian Yang, Ming-Syan Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Overcoming_Forgetting_Catastrophe_in_Quantization-Aware_Training_ICCV_2023_paper.pdf",
        "aff": "Graduate Institute of Electrical Engineering, National Taiwan University, Taiwan; Institute of Information Science, Academia Sinica, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taiwan",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Overwriting Pretrained Bias with Finetuning Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Overwriting_Pretrained_Bias_with_Finetuning_Data_ICCV_2023_paper.html",
        "author": "Angelina Wang, Olga Russakovsky",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Overwriting_Pretrained_Bias_with_Finetuning_Data_ICCV_2023_paper.pdf",
        "aff": "Princeton University",
        "project": "",
        "github": "",
        "arxiv": "2303.06167"
    },
    {
        "title": "OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_OxfordTVG-HIC_Can_Machine_Make_Humorous_Captions_from_Images_ICCV_2023_paper.html",
        "author": "Runjia Li, Shuyang Sun, Mohamed Elhoseiny, Philip Torr",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_OxfordTVG-HIC_Can_Machine_Make_Humorous_Captions_from_Images_ICCV_2023_paper.pdf",
        "aff": "Torr Vision Group, University of Oxford; KAUST",
        "project": "https://torrvision.com/tvghic/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "P1AC: Revisiting Absolute Pose From a Single Affine Correspondence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ventura_P1AC_Revisiting_Absolute_Pose_From_a_Single_Affine_Correspondence_ICCV_2023_paper.html",
        "author": "Jonathan Ventura, Zuzana Kukelova, Torsten Sattler, D\u00e1niel Bar\u00e1th",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ventura_P1AC_Revisiting_Absolute_Pose_From_a_Single_Affine_Correspondence_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science & Software Engineering, Cal Poly, San Luis Obispo; Visual Recognition Group, Faculty of Electrical Engineering, Czech Technical University in Prague; Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague; Computer Vision and Geometry Group, ETH Z \u00a8urich",
        "project": "",
        "github": "https://github.com/jonathanventura/P1AC/",
        "arxiv": "2011.08790"
    },
    {
        "title": "P2C: Self-Supervised Point Cloud Completion from Single Partial Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cui_P2C_Self-Supervised_Point_Cloud_Completion_from_Single_Partial_Clouds_ICCV_2023_paper.html",
        "author": "Ruikai Cui, Shi Qiu, Saeed Anwar, Jiawei Liu, Chaoyue Xing, Jing Zhang, Nick Barnes",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_P2C_Self-Supervised_Point_Cloud_Completion_from_Single_Partial_Clouds_ICCV_2023_paper.pdf",
        "aff": "King Fahd University of Petroleum and Minerals; Australian National University",
        "project": "",
        "github": "https://github.com/CuiRuikai/Partial2Complete",
        "arxiv": "2307.14726"
    },
    {
        "title": "PADCLIP: Pseudo-labeling with Adaptive Debiasing in CLIP for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lai_PADCLIP_Pseudo-labeling_with_Adaptive_Debiasing_in_CLIP_for_Unsupervised_Domain_ICCV_2023_paper.html",
        "author": "Zhengfeng Lai, Noranart Vesdapunt, Ning Zhou, Jun Wu, Cong Phuoc Huynh, Xuelu Li, Kah Kuen Fu, Chen-Nee Chuah",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_PADCLIP_Pseudo-labeling_with_Adaptive_Debiasing_in_CLIP_for_Unsupervised_Domain_ICCV_2023_paper.pdf",
        "aff": "Amazon; University of California, Davis",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PADDLES: Phase-Amplitude Spectrum Disentangled Early Stopping for Learning with Noisy Labels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_PADDLES_Phase-Amplitude_Spectrum_Disentangled_Early_Stopping_for_Learning_with_Noisy_ICCV_2023_paper.html",
        "author": "Huaxi Huang, Hui Kang, Sheng Liu, Olivier Salvado, Thierry Rakotoarivelo, Dadong Wang, Tongliang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PADDLES_Phase-Amplitude_Spectrum_Disentangled_Early_Stopping_for_Learning_with_Noisy_ICCV_2023_paper.pdf",
        "aff": "Data61, CSIRO; NYU Center for Data Science; The University of Sydney",
        "project": "",
        "github": "https://github.com/CoderHHX/PADDLES",
        "arxiv": "2212.03462"
    },
    {
        "title": "PARF: Primitive-Aware Radiance Fusion for Indoor Scene Novel View Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ying_PARF_Primitive-Aware_Radiance_Fusion_for_Indoor_Scene_Novel_View_Synthesis_ICCV_2023_paper.html",
        "author": "Haiyang Ying, Baowei Jiang, Jinzhi Zhang, Di Xu, Tao Yu, Qionghai Dai, Lu Fang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ying_PARF_Primitive-Aware_Radiance_Fusion_for_Indoor_Scene_Novel_View_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Huawei Cloud",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PARIS: Part-level Reconstruction and Motion Analysis for Articulated Objects",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PARIS_Part-level_Reconstruction_and_Motion_Analysis_for_Articulated_Objects_ICCV_2023_paper.html",
        "author": "Jiayi Liu, Ali Mahdavi-Amiri, Manolis Savva",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PARIS_Part-level_Reconstruction_and_Motion_Analysis_for_Articulated_Objects_ICCV_2023_paper.pdf",
        "aff": "Simon Fraser University",
        "project": "https://3dlg-hcvc.github.io/paris/",
        "github": "",
        "arxiv": "2308.07391"
    },
    {
        "title": "PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nie_PARTNER_Level_up_the_Polar_Representation_for_LiDAR_3D_Object_ICCV_2023_paper.html",
        "author": "Ming Nie, Yujing Xue, Chunwei Wang, Chaoqiang Ye, Hang Xu, Xinge Zhu, Qingqiu Huang, Michael Bi Mi, Xinchao Wang, Li Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_PARTNER_Level_up_the_Polar_Representation_for_LiDAR_3D_Object_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore; Huawei Noah\u2019s Ark Lab; Huawei International Pte Ltd; School of Data Science, Fudan University; Huawei ADS",
        "project": "",
        "github": "",
        "arxiv": "2308.03982"
    },
    {
        "title": "PASTA: Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chattopadhyay_PASTA_Proportional_Amplitude_Spectrum_Training_Augmentation_for_Syn-to-Real_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Prithvijit Chattopadhyay, Kartik Sarangmath, Vivek Vijaykumar, Judy Hoffman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chattopadhyay_PASTA_Proportional_Amplitude_Spectrum_Training_Augmentation_for_Syn-to-Real_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "Georgia Institute of Technology",
        "project": "",
        "github": "https://github.com/prithv1/PASTA",
        "arxiv": "2212.00979"
    },
    {
        "title": "PATMAT: Person Aware Tuning of Mask-Aware Transformer for Face Inpainting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Motamed_PATMAT_Person_Aware_Tuning_of_Mask-Aware_Transformer_for_Face_Inpainting_ICCV_2023_paper.html",
        "author": "Saman Motamed, Jianjin Xu, Chen Henry Wu, Christian H\u00e4ne, Jean-Charles Bazin, Fernando De la Torre",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Motamed_PATMAT_Person_Aware_Tuning_of_Mask-Aware_Transformer_for_Face_Inpainting_ICCV_2023_paper.pdf",
        "aff": "Independent Researcher; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "project": "",
        "github": "https://github.com/humansensinglab/PATMAT",
        "arxiv": "2304.06107"
    },
    {
        "title": "PC-Adapter: Topology-Aware Adapter for Efficient Domain Adaption on Point Clouds with Rectified Pseudo-label",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_PC-Adapter_Topology-Aware_Adapter_for_Efficient_Domain_Adaption_on_Point_Clouds_ICCV_2023_paper.html",
        "author": "Joonhyung Park, Hyunjin Seo, Eunho Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_PC-Adapter_Topology-Aware_Adapter_for_Efficient_Domain_Adaption_on_Point_Clouds_ICCV_2023_paper.pdf",
        "aff": "KAIST, AITRICS; KAIST",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PDiscoNet: Semantically consistent part discovery for fine-grained recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/van_der_Klis_PDiscoNet_Semantically_consistent_part_discovery_for_fine-grained_recognition_ICCV_2023_paper.html",
        "author": "Robert van der Klis, Stephan Alaniz, Massimiliano Mancini, Cassio F. Dantas, Dino Ienco, Zeynep Akata, Diego Marcos",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/van_der_Klis_PDiscoNet_Semantically_consistent_part_discovery_for_fine-grained_recognition_ICCV_2023_paper.pdf",
        "aff": "University of Trento; University of T\u00fcbingen; WUR; INRAE/UMR TETIS; Inria",
        "project": "",
        "github": "https://github.com/robertdvdk/part_detection",
        "arxiv": "2309.03173"
    },
    {
        "title": "PEANUT: Predicting and Navigating to Unseen Targets",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.html",
        "author": "Albert J. Zhai, Shenlong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign",
        "project": "",
        "github": "https://ajzhai.github.io/PEANUT",
        "arxiv": "2212.02497"
    },
    {
        "title": "PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PETRv2_A_Unified_Framework_for_3D_Perception_from_Multi-Camera_Images_ICCV_2023_paper.html",
        "author": "Yingfei Liu, Junjie Yan, Fan Jia, Shuailin Li, Aqi Gao, Tiancai Wang, Xiangyu Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PETRv2_A_Unified_Framework_for_3D_Perception_from_Multi-Camera_Images_ICCV_2023_paper.pdf",
        "aff": "MEGVII Technology",
        "project": "",
        "github": "https://github.com/megvii-research/PETR",
        "arxiv": "2206.01256"
    },
    {
        "title": "PG-RCNN: Semantic Surface Point Generation for 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Inyong Koo, Inyoung Lee, Se-Ho Kim, Hee-Seon Kim, Woo-jin Jeon, Changick Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "KAIST",
        "project": "",
        "github": "https://github.com/quotation2520/PG-RCNN",
        "arxiv": ""
    },
    {
        "title": "PGFed: Personalize Each Client's Global Objective for Federated Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_PGFed_Personalize_Each_Clients_Global_Objective_for_Federated_Learning_ICCV_2023_paper.html",
        "author": "Jun Luo, Matias Mendieta, Chen Chen, Shandong Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_PGFed_Personalize_Each_Clients_Global_Objective_for_Federated_Learning_ICCV_2023_paper.pdf",
        "aff": "Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA; Department of Radiology, University of Pittsburgh, Pittsburgh, PA; Department of Biomedical Informatics, University of Pittsburgh, Pittsburgh, PA; Department of Bioengineering, University of Pittsburgh, Pittsburgh, PA; Center for Research in Computer Vision, University of Central Florida, Orlando, FL; Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA",
        "project": "",
        "github": "https://github.com/ljaiverson/pgfed",
        "arxiv": ""
    },
    {
        "title": "PHRIT: Parametric Hand Representation with Implicit Template",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_PHRIT_Parametric_Hand_Representation_with_Implicit_Template_ICCV_2023_paper.html",
        "author": "Zhisheng Huang, Yujin Chen, Di Kang, Jinlu Zhang, Zhigang Tu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PHRIT_Parametric_Hand_Representation_with_Implicit_Template_ICCV_2023_paper.pdf",
        "aff": "Wuhan University; Technical University of Munich; Tencent AI Lab",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PIDRo: Parallel Isomeric Attention with Dynamic Routing for Text-Video Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guan_PIDRo_Parallel_Isomeric_Attention_with_Dynamic_Routing_for_Text-Video_Retrieval_ICCV_2023_paper.html",
        "author": "Peiyan Guan, Renjing Pei, Bin Shao, Jianzhuang Liu, Weimian Li, Jiaxi Gu, Hang Xu, Songcen Xu, Youliang Yan, Edmund Y. Lam",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_PIDRo_Parallel_Isomeric_Attention_with_Dynamic_Routing_for_Text-Video_Retrieval_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; The University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PIRNet: Privacy-Preserving Image Restoration Network via Wavelet Lifting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deng_PIRNet_Privacy-Preserving_Image_Restoration_Network_via_Wavelet_Lifting_ICCV_2023_paper.html",
        "author": "Xin Deng, Chao Gao, Mai Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_PIRNet_Privacy-Preserving_Image_Restoration_Network_via_Wavelet_Lifting_ICCV_2023_paper.pdf",
        "aff": "School of Electronic and Information Engineering, Beihang University, Beijing, China; School of Cyber Science and Technology, Beihang University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PNI : Industrial Anomaly Detection using Position and Neighborhood Information",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.html",
        "author": "Jaehyeok Bae, Jae-Han Lee, Seyun Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.pdf",
        "aff": "Gauss Labs Inc., Seoul National University; Gauss Labs Inc.",
        "project": "",
        "github": "https://github.com/wogur110/PNI_Anomaly_Detection",
        "arxiv": "2211.12634"
    },
    {
        "title": "PODA: Prompt-driven Zero-shot Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick P\u00e9rez, Raoul de Charette",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Inria, Valeo.ai; Inria",
        "project": "https://astra-vision.github.io/PODA",
        "github": "https://github.com/astra-vision/PODA",
        "arxiv": "2212.03241"
    },
    {
        "title": "PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.html",
        "author": "Gwanghyun Kim, Ji Ha Jang, Se Young Chun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.pdf",
        "aff": "Dept. of Electrical and Computer Engineering, Seoul National University, Republic of Korea; Dept. of Electrical and Computer Engineering, INMC & IPAI, Seoul National University, Republic of Korea",
        "project": "gwang-kim.github.io/podia_3d",
        "github": "https://github.com/gwang-kim/podia_3d",
        "arxiv": ""
    },
    {
        "title": "PPR: Physically Plausible Reconstruction from Monocular Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_PPR_Physically_Plausible_Reconstruction_from_Monocular_Videos_ICCV_2023_paper.html",
        "author": "Gengshan Yang, Shuo Yang, John Z. Zhang, Zachary Manchester, Deva Ramanan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_PPR_Physically_Plausible_Reconstruction_from_Monocular_Videos_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PRANC: Pseudo RAndom Networks for Compacting Deep Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nooralinejad_PRANC_Pseudo_RAndom_Networks_for_Compacting_Deep_Models_ICCV_2023_paper.html",
        "author": "Parsa Nooralinejad, Ali Abbasi, Soroush Abbasi Koohpayegani, Kossar Pourahmadi Meibodi, Rana Muhammad Shahroz Khan, Soheil Kolouri, Hamed Pirsiavash",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nooralinejad_PRANC_Pseudo_RAndom_Networks_for_Compacting_Deep_Models_ICCV_2023_paper.pdf",
        "aff": "Vanderbilt University; University of California, Davis",
        "project": "",
        "github": "https://github.com/UCDvision/PRANC",
        "arxiv": "2206.08464"
    },
    {
        "title": "PRIOR: Prototype Representation Joint Learning from Medical Images and Reports",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_PRIOR_Prototype_Representation_Joint_Learning_from_Medical_Images_and_Reports_ICCV_2023_paper.html",
        "author": "Pujin Cheng, Li Lin, Junyan Lyu, Yijin Huang, Wenhan Luo, Xiaoying Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_PRIOR_Prototype_Representation_Joint_Learning_from_Medical_Images_and_Reports_ICCV_2023_paper.pdf",
        "aff": "Queensland Brain Institute, The University of Queensland; Shenzhen Campus of Sun Yat-sen University; Department of Electronic and Electrical Engineering, Southern University of Science and Technology; School of Biomedical Engineering, University of British Columbia; Department of Electrical and Electronic Engineering, The University of Hong Kong",
        "project": "",
        "github": "https://github.com/QtacierP/PRIOR",
        "arxiv": "2307.12577"
    },
    {
        "title": "PVT++: A Simple End-to-End Latency-Aware Visual Tracking Framework",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_PVT_A_Simple_End-to-End_Latency-Aware_Visual_Tracking_Framework_ICCV_2023_paper.html",
        "author": "Bowen Li, Ziyuan Huang, Junjie Ye, Yiming Li, Sebastian Scherer, Hang Zhao, Changhong Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PVT_A_Simple_End-to-End_Latency-Aware_Visual_Tracking_Framework_ICCV_2023_paper.pdf",
        "aff": "Tongji University; Carnegie Mellon University; National University of Singapore; New York University; Tsinghua University",
        "project": "",
        "github": "https://github.com/Jaraxxus-Me/PVT_pp.git",
        "arxiv": ""
    },
    {
        "title": "Pairwise Similarity Learning is SimPLE",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Pairwise_Similarity_Learning_is_SimPLE_ICCV_2023_paper.html",
        "author": "Yandong Wen, Weiyang Liu, Yao Feng, Bhiksha Raj, Rita Singh, Adrian Weller, Michael J. Black, Bernhard Sch\u00f6lkopf",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Pairwise_Similarity_Learning_is_SimPLE_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems; University of Cambridge; The Alan Turing Institute; Carnegie Mellon University",
        "project": "simple.is.tue.mpg.de",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PanFlowNet: A Flow-Based Deep Network for Pan-Sharpening",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_PanFlowNet_A_Flow-Based_Deep_Network_for_Pan-Sharpening_ICCV_2023_paper.html",
        "author": "Gang Yang, Xiangyong Cao, Wenzhe Xiao, Man Zhou, Aiping Liu, Xun Chen, Deyu Meng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_PanFlowNet_A_Flow-Based_Deep_Network_for_Pan-Sharpening_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; Macao Institute of Systems Engineering, Macau University of Science and Technology, Taipa, Macao; Xi\u2019an Jiaotong University; University of Science and Technology of China",
        "project": "",
        "github": "Code is available at Github (specific link not provided)",
        "arxiv": "2305.07774"
    },
    {
        "title": "Panoramas from Photons",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jungerman_Panoramas_from_Photons_ICCV_2023_paper.html",
        "author": "Sacha Jungerman, Atul Ingle, Mohit Gupta",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jungerman_Panoramas_from_Photons_ICCV_2023_paper.pdf",
        "aff": "Panoramas from Photons\nSacha Jungerman\u2020\nsjungerman@wisc.eduAtul Ingle\u00a7\ningle2@pdx.eduMohit Gupta\u2020\nmohitg@cs.wisc.edu\n\u2020University of Wisconsin-Madison\u00a7Portland State University\nAbstract\nScene reconstruction in the presence of high-speed mo-\ntion and low illumination is important in many applica-\ntions such as augmented and virtual reality, drone naviga-\ntion, and autonomous robotics. Traditional motion estima-\ntion techniques fail in such conditions, suffering from too\nmuch blur in the presence of high-speed motion and strong\nnoise in low-light conditions. Single-photon cameras have\nrecently emerged as a promising technology capable of cap-\nturing hundreds of thousands of photon frames per second\nthanks to their high speed and extreme sensitivity. Unfortu-\nnately, traditional computer vision techniques are not well\nsuited for dealing with the binary-valued photon data cap-\ntured by these cameras because these are corrupted by ex-\ntreme Poisson noise. Here we present a method capable\nof estimating extreme scene motion under challenging con-\nditions, such as low light or high dynamic range, from a\nsequence of high-speed image frames such as those cap-\ntured by a single-photon camera. Our method relies on it-\neratively improving a motion estimate by grouping and ag-\ngregating frames after-the-fact, in a stratified manner. We\ndemonstrate the creation of high-quality panoramas under\nfast motion and extremely low light, and super-resolution\nresults using a custom single-photon camera prototype. For\ncode and supplemental material see our project webpage.\n1. Introduction\nAccurate recovery of motion from a sequence of images\nis one of the most fundamental tasks in computer vision,\nwith numerous applications in robotics, augmented reality,\nuser interfaces, and autonomous navigation. When success-\nfully estimated, motion information can be used to locate\nand track the camera or different objects in the scene [7],\nperform motion-aware video compression [19] or stabiliza-\ntion [22], relate multiple sensors, merge information across\ndifferent viewpoints, and even reconstruct city-scale 3D\nmodels using only images from the web [1, 34, 28].\nImage sequences can be used to estimate different kinds\n\u2021This research was supported in part by an NSF CAREER award\n1943149, NSF award CNS-2107060 and NSF ECCS-2138471.of motion ranging in complexity and degrees of freedom,\nfrom global motion models, such as simple translations,\nprojective warps, or 3D (6-DoF) camera pose, to non-rigid,\nlocal motion models such as optical flow. However, re-\ngardless of the motion model, traditional methods cannot\nrecover motion that is simply too fast for the camera to cap-\nture. This is especially challenging when capturing scenes\nin low-light conditions\u2014the camera will compensate by in-\ncreasing the exposure, thereby introducing motion blur, as\nseen in Fig. 1(a), or increasing the gain (ISO), thereby in-\ntroducing noise [14]. Fundamentally, the image degradation\nassociated with faster motion or a darker scene causes tra-\nditional motion estimation methods to fail.\nOne way to handle fast motion is by using specialized\nhigh-speed cameras. However, such cameras are not only\nbulky and costly but also suffer from extremely low signal-\nto-noise ratio due to both low signal values and high readout\nnoise, at least an order of magnitude higher than conven-\ntional CMOS cameras1. This requires the scenes to be well\nilluminated, often in a controlled setting, further limiting\ntheir scope and widespread adoption.\nFortunately, there is an emerging class of sensors called\nsingle-photon cameras, which are capable of high-speed\nimaging in low-light conditions. Single-photon cameras\nbased on single-photon avalanche diode (SPAD) technol-\nogy [6] provide extreme sensitivity, are cheap to manufac-\nture, and are increasingly becoming commonplace, recently\ngetting deployed in consumer devices such as iPhones. The\nkey benefit of SPADs is that they do not suffer from read-\nnoise, enabling captures at hundreds of thousands of frames\nper second even in extremely low flux, while being limited\nonly by the fundamental photon noise.\nAlthough single-photon cameras can capture scene in-\nformation at unprecedented sensitivity and speed, each in-\ndividual captured frame is binary valued: a pixel is \u201con\u201d if\nat least one photon is detected during the exposure time and\n\u201coff\u201d otherwise. This binary imaging model presents unique\nchallenges. Traditional image registration techniques rely\non feature-based matching, or direct optimization using dif-\nferences between pixel intensities, both of which rely on\nimage gradients to converge to a solution. Individual binary\n1For example, the Phantom v2640 has read noise up to 58e\u2212.\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n10626\n",
        "project": "",
        "github": "",
        "arxiv": "2309.03811"
    },
    {
        "title": "ParCNetV2: Oversized Kernel with Enhanced Attention",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ParCNetV2_Oversized_Kernel_with_Enhanced_Attention_ICCV_2023_paper.html",
        "author": "Ruihan Xu, Haokui Zhang, Wenze Hu, Shiliang Zhang, Xiaoyu Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ParCNetV2_Oversized_Kernel_with_Enhanced_Attention_ICCV_2023_paper.pdf",
        "aff": "Intellifusion; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University",
        "project": "",
        "github": "https://github.com/XuRuihan/ParCNetV2",
        "arxiv": "2211.07157"
    },
    {
        "title": "Parallax-Tolerant Unsupervised Deep Image Stitching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.html",
        "author": "Lang Nie, Chunyu Lin, Kang Liao, Shuaicheng Liu, Yao Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.pdf",
        "aff": "Institute of Information Science, Beijing Jiaotong University, Beijing, China; University of Electronic Science and Technology of China, Chengdu, China",
        "project": "",
        "github": "https://github.com/nie-lang/UDIS2",
        "arxiv": "2302.08207"
    },
    {
        "title": "Parallel Attention Interaction Network for Few-Shot Skeleton-Based Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Parallel_Attention_Interaction_Network_for_Few-Shot_Skeleton-Based_Action_Recognition_ICCV_2023_paper.html",
        "author": "Xingyu Liu, Sanping Zhou, Le Wang, Gang Hua",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Parallel_Attention_Interaction_Network_for_Few-Shot_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "Wormpex AI Research; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Applications, and Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Parameterized Cost Volume for Stereo Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zeng_Parameterized_Cost_Volume_for_Stereo_Matching_ICCV_2023_paper.html",
        "author": "Jiaxi Zeng, Chengtang Yao, Lidong Yu, Yuwei Wu, Yunde Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_Parameterized_Cost_Volume_for_Stereo_Matching_ICCV_2023_paper.pdf",
        "aff": "Autonomous Driving Algorithm, Deeproute; Guangdong Laboratory of Machine Perception and Intelligent Computing, Shenzhen MSU-BIT University, China; Beijing Key Laboratory of Intelligent Information Technology, School of Computer Science & Technology, Beijing Institute of Technology, China",
        "project": "",
        "github": "https://github.com/jiaxiZeng/Parameterized-Cost-Volume-for-Stereo-Matching",
        "arxiv": ""
    },
    {
        "title": "Parametric Classification for Generalized Category Discovery: A Baseline Study",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Parametric_Classification_for_Generalized_Category_Discovery_A_Baseline_Study_ICCV_2023_paper.html",
        "author": "Xin Wen, Bingchen Zhao, Xiaojuan Qi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Parametric_Classification_for_Generalized_Category_Discovery_A_Baseline_Study_ICCV_2023_paper.pdf",
        "aff": "The University of Hong Kong; University of Edinburgh",
        "project": "",
        "github": "https://github.com/CVMI-Lab/SimGCD",
        "arxiv": "2211.11727"
    },
    {
        "title": "Parametric Depth Based Feature Representation Learning for Object Detection and Segmentation in Bird's-Eye View",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Parametric_Depth_Based_Feature_Representation_Learning_for_Object_Detection_and_ICCV_2023_paper.html",
        "author": "Jiayu Yang, Enze Xie, Miaomiao Liu, Jose M. Alvarez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Parametric_Depth_Based_Feature_Representation_Learning_for_Object_Detection_and_ICCV_2023_paper.pdf",
        "aff": "NVIDIA; The University of Hong Kong; Australian National University",
        "project": "",
        "github": "https://github.com/NVlabs/ParametricBEV",
        "arxiv": ""
    },
    {
        "title": "Parametric Information Maximization for Generalized Category Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chiaroni_Parametric_Information_Maximization_for_Generalized_Category_Discovery_ICCV_2023_paper.html",
        "author": "Florent Chiaroni, Jose Dolz, Ziko Imtiaz Masud, Amar Mitiche, Ismail Ben Ayed",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chiaroni_Parametric_Information_Maximization_for_Generalized_Category_Discovery_ICCV_2023_paper.pdf",
        "aff": "Thales Digital Solutions, Montreal, Canada; \u00b4ETS Montreal, Montreal, Canada; \u00b4ETS Montreal & Thales Digital Solutions, Montreal, Canada; INRS, Montreal, Canada",
        "project": "",
        "github": "https://github.com/ThalesGroup/pim-generalized-category-discovery",
        "arxiv": "2212.00334"
    },
    {
        "title": "Part-Aware Transformer for Generalizable Person Re-identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ni_Part-Aware_Transformer_for_Generalizable_Person_Re-identification_ICCV_2023_paper.html",
        "author": "Hao Ni, Yuke Li, Lianli Gao, Heng Tao Shen, Jingkuan Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Part-Aware_Transformer_for_Generalizable_Person_Re-identification_ICCV_2023_paper.pdf",
        "aff": "Shenzhen Institute for Advanced Study, UESTC; University of Electronic Science and Technology of China (UESTC)",
        "project": "",
        "github": "https://github.com/liyuke65535/Part-Aware-Transformer",
        "arxiv": "2308.03322"
    },
    {
        "title": "Partition Speeds Up Learning Implicit Neural Representations Based on Exponential-Increase Hypothesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Partition_Speeds_Up_Learning_Implicit_Neural_Representations_Based_on_Exponential-Increase_ICCV_2023_paper.html",
        "author": "Ke Liu, Feng Liu, Haishuai Wang, Ning Ma, Jiajun Bu, Bo Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Partition_Speeds_Up_Learning_Implicit_Neural_Representations_Based_on_Exponential-Increase_ICCV_2023_paper.pdf",
        "aff": "School of Computing and Information Systems, The University of Melbourne, Australia; Zhejiang Provincial Key Laboratory of Service Robot, College of Computer Science, Zhejiang University, Hangzhou, China; Department of Computer Science, Hong Kong Baptist University, Hong Kong SAR, China",
        "project": "",
        "github": "Code is released here (\u5177\u4f53\u7684\u94fe\u63a5\u6ca1\u6709\u5728\u6587\u672c\u4e2d\u63d0\u4f9b)",
        "arxiv": ""
    },
    {
        "title": "Partition-And-Debias: Agnostic Biases Mitigation via a Mixture of Biases-Specific Experts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Partition-And-Debias_Agnostic_Biases_Mitigation_via_a_Mixture_of_Biases-Specific_Experts_ICCV_2023_paper.html",
        "author": "Jiaxuan Li, Duc Minh Vo, Hideki Nakayama",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Partition-And-Debias_Agnostic_Biases_Mitigation_via_a_Mixture_of_Biases-Specific_Experts_ICCV_2023_paper.pdf",
        "aff": "The University of Tokyo, Japan",
        "project": "",
        "github": "https://github.com/Jiaxuan-Li/PnD",
        "arxiv": ""
    },
    {
        "title": "Passive Ultra-Wideband Single-Photon Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Passive_Ultra-Wideband_Single-Photon_Imaging_ICCV_2023_paper.html",
        "author": "Mian Wei, Sotiris Nousias, Rahul Gulve, David B. Lindell, Kiriakos N. Kutulakos",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Passive_Ultra-Wideband_Single-Photon_Imaging_ICCV_2023_paper.pdf",
        "aff": "Dept. of Electrical and Computer Engineering, University of Toronto; Dept. of Computer Science, University of Toronto",
        "project": "https://compimaging.dgp.toronto.edu/ultra-wideband",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PatchCT: Aligning Patch Set and Label Set with Conditional Transport for Multi-Label Image Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.html",
        "author": "Miaoge Li, Dongsheng Wang, Xinyang Liu, Zequn Zeng, Ruiying Lu, Bo Chen, Mingyuan Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory of Radar Signal Processing, Xidian University, Xi'an, Shanxi 710071, China; McCombs School of Business, The University of Texas at Austin, Austin, TX 78712, USA",
        "project": "",
        "github": "",
        "arxiv": "2307.09066"
    },
    {
        "title": "Perceptual Artifacts Localization for Image Synthesis Tasks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.html",
        "author": "Lingzhi Zhang, Zhengjie Xu, Connelly Barnes, Yuqian Zhou, Qing Liu, He Zhang, Sohrab Amirghodsi, Zhe Lin, Eli Shechtman, Jianbo Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.pdf",
        "aff": "University of Pennsylvania; Adobe Inc. and University of Pennsylvania; Adobe Inc.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Perceptual Grouping in Contrastive Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ranasinghe_Perceptual_Grouping_in_Contrastive_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Kanchana Ranasinghe, Brandon McKinzie, Sachin Ravi, Yinfei Yang, Alexander Toshev, Jonathon Shlens",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ranasinghe_Perceptual_Grouping_in_Contrastive_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "Apple",
        "project": "",
        "github": "",
        "arxiv": "2210.09996"
    },
    {
        "title": "Periodically Exchange Teacher-Student for Source-Free Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Periodically_Exchange_Teacher-Student_for_Source-Free_Object_Detection_ICCV_2023_paper.html",
        "author": "Qipeng Liu, Luojun Lin, Zhifeng Shen, Zhifeng Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Periodically_Exchange_Teacher-Student_for_Source-Free_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "College of Computer and Data Science, Fuzhou University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Perpetual Humanoid Control for Real-time Simulated Avatars",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.html",
        "author": "Zhengyi Luo, Jinkun Cao, AlexanderWinkler, Kris Kitani, Weipeng Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.pdf",
        "aff": "Reality Labs Research, Meta; Reality Labs Research, Meta; Carnegie Mellon University; Carnegie Mellon University",
        "project": "",
        "github": "https://zhengyiluo.github.io/PHC/",
        "arxiv": ""
    },
    {
        "title": "Persistent-Transient Duality: A Multi-Mechanism Approach for Modeling Human-Object Interaction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tran_Persistent-Transient_Duality_A_Multi-Mechanism_Approach_for_Modeling_Human-Object_Interaction_ICCV_2023_paper.html",
        "author": "Hung Tran, Vuong Le, Svetha Venkatesh, Truyen Tran",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tran_Persistent-Transient_Duality_A_Multi-Mechanism_Approach_for_Modeling_Human-Object_Interaction_ICCV_2023_paper.pdf",
        "aff": "Amazon; Applied AI Institute, Deakin University",
        "project": "",
        "github": "",
        "arxiv": "2307.12729"
    },
    {
        "title": "Person Re-Identification without Identification via Event anonymization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ahmad_Person_Re-Identification_without_Identification_via_Event_anonymization_ICCV_2023_paper.html",
        "author": "Shafiq Ahmad, Pietro Morerio, Alessio Del Bue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ahmad_Person_Re-Identification_without_Identification_via_Event_anonymization_ICCV_2023_paper.pdf",
        "aff": "Pattern Analysis & Computer Vision (PA VIS) - Istituto Italino di Tecnologia, Italy; Pattern Analysis & Computer Vision (PA VIS) - Istituto Italino di Tecnologia, Italy; Universita degli Studi di Genova, Italy",
        "project": "",
        "github": "https://github.com/IIT-PAVIS/ReId_without_Id",
        "arxiv": "2308.04402"
    },
    {
        "title": "Personalized Image Generation for Color Vision Deficiency Population",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.html",
        "author": "Shuyi Jiang, Daochang Liu, Dingquan Li, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.pdf",
        "aff": "Peng Cheng Laboratory; The University of Sydney",
        "project": "",
        "github": "https://github.com/Jiangshuyi0V0/CVD-GAN.git",
        "arxiv": ""
    },
    {
        "title": "Personalized Semantics Excitation for Federated Image Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.html",
        "author": "Haifeng Xia, Kai Li, Zhengming Ding",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.pdf",
        "aff": "NEC Labs, America; Department of Computer Science, Tulane University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PhaseMP: Robust 3D Pose Estimation via Phase-conditioned Human Motion Prior",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_PhaseMP_Robust_3D_Pose_Estimation_via_Phase-conditioned_Human_Motion_Prior_ICCV_2023_paper.html",
        "author": "Mingyi Shi, Sebastian Starke, Yuting Ye, Taku Komura, Jungdam Won",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PhaseMP_Robust_3D_Pose_Estimation_via_Phase-conditioned_Human_Motion_Prior_ICCV_2023_paper.pdf",
        "aff": "Meta; Seoul National University; The University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_paper.html",
        "author": "Teng Hu, Jiangning Zhang, Liang Liu, Ran Yi, Siqi Kou, Haokun Zhu, Xu Chen, Yabiao Wang, Chengjie Wang, Lizhuang Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_paper.pdf",
        "aff": "Youtu Lab, Tencent; Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/sjtuplayer/few-shot-diffusion",
        "arxiv": "2309.03729"
    },
    {
        "title": "PhysDiff: Physics-Guided Human Motion Diffusion Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_PhysDiff_Physics-Guided_Human_Motion_Diffusion_Model_ICCV_2023_paper.html",
        "author": "Ye Yuan, Jiaming Song, Umar Iqbal, Arash Vahdat, Jan Kautz",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PhysDiff_Physics-Guided_Human_Motion_Diffusion_Model_ICCV_2023_paper.pdf",
        "aff": "NVIDIA",
        "project": "https://nvlabs.github.io/PhysDiff",
        "github": "",
        "arxiv": "2212.02500"
    },
    {
        "title": "Physically-Plausible Illumination Distribution Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ershov_Physically-Plausible_Illumination_Distribution_Estimation_ICCV_2023_paper.html",
        "author": "Egor Ershov, Vasily Tesalin, Ivan Ermakov, Michael S. Brown",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ershov_Physically-Plausible_Illumination_Distribution_Estimation_ICCV_2023_paper.pdf",
        "aff": "IITP RAS, MIPT; MIPT, Skoltech; York University; IITP RAS",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Physics-Augmented Autoencoder for 3D Skeleton-Based Gait Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Physics-Augmented_Autoencoder_for_3D_Skeleton-Based_Gait_Recognition_ICCV_2023_paper.html",
        "author": "Hongji Guo, Qiang Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Physics-Augmented_Autoencoder_for_3D_Skeleton-Based_Gait_Recognition_ICCV_2023_paper.pdf",
        "aff": "Rensselaer Polytechnic Institute, Troy, NY 12180",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Physics-Driven Turbulence Image Restoration with Stochastic Refinement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jaiswal_Physics-Driven_Turbulence_Image_Restoration_with_Stochastic_Refinement_ICCV_2023_paper.html",
        "author": "Ajay Jaiswal, Xingguang Zhang, Stanley H. Chan, Zhangyang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jaiswal_Physics-Driven_Turbulence_Image_Restoration_with_Stochastic_Refinement_ICCV_2023_paper.pdf",
        "aff": "Purdue University; University of Texas at Austin",
        "project": "",
        "github": "https://github.com/VITA-Group/PiRN",
        "arxiv": "2307.10603"
    },
    {
        "title": "PivotNet: Vectorized Pivot Learning for End-to-end HD Map Construction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ding_PivotNet_Vectorized_Pivot_Learning_for_End-to-end_HD_Map_Construction_ICCV_2023_paper.html",
        "author": "Wenjie Ding, Limeng Qiao, Xi Qiu, Chi Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_PivotNet_Vectorized_Pivot_Learning_for_End-to-end_HD_Map_Construction_ICCV_2023_paper.pdf",
        "aff": "MEGVII Technology",
        "project": "",
        "github": "",
        "arxiv": "2308.16477"
    },
    {
        "title": "Pix2Video: Video Editing using Image Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.html",
        "author": "Duygu Ceylan, Chun-Hao P. Huang, Niloy J. Mitra",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.pdf",
        "aff": "Adobe Research, University College London; Adobe Research",
        "project": "https://duyguceylan.github.io/pix2video.github.io/",
        "github": "https://github.com/duyguceylan/pix2video.github.io",
        "arxiv": "2303.12688"
    },
    {
        "title": "Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Pixel_Adaptive_Deep_Unfolding_Transformer_for_Hyperspectral_Image_Reconstruction_ICCV_2023_paper.html",
        "author": "Miaoyu Li, Ying Fu, Ji Liu, Yulun Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pixel_Adaptive_Deep_Unfolding_Transformer_for_Hyperspectral_Image_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of Technology; Baidu Inc.; ETH Z\u00fcrich",
        "project": "",
        "github": "https://github.com/MyuLi/PADUT",
        "arxiv": "2308.10820"
    },
    {
        "title": "Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_Pixel-Aligned_Recurrent_Queries_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Yiming Xie, Huaizu Jiang, Georgia Gkioxari, Julian Straub",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Pixel-Aligned_Recurrent_Queries_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "California Institute of Technology; Northeastern University; Meta Reality Labs Research",
        "project": "",
        "github": "https://ymingxie.github.io/parq",
        "arxiv": ""
    },
    {
        "title": "Pixel-Wise Contrastive Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Pixel-Wise_Contrastive_Distillation_ICCV_2023_paper.html",
        "author": "Junqiang Huang, Zichao Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Pixel-Wise_Contrastive_Distillation_ICCV_2023_paper.pdf",
        "aff": "Shopee",
        "project": "",
        "github": "",
        "arxiv": "2211.00218"
    },
    {
        "title": "PlanarTrack: A Large-scale Challenging Benchmark for Planar Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PlanarTrack_A_Large-scale_Challenging_Benchmark_for_Planar_Object_Tracking_ICCV_2023_paper.html",
        "author": "Xinran Liu, Xiaoqiong Liu, Ziruo Yi, Xin Zhou, Thanh Le, Libo Zhang, Yan Huang, Qing Yang, Heng Fan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PlanarTrack_A_Large-scale_Challenging_Benchmark_for_Planar_Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "Institute of Software, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; Self-Employed; Department of Computer Science and Engineering, University of North Texas, Denton, USA",
        "project": "",
        "github": "https://hengfan2010.github.io/projects/PlanarTrack/",
        "arxiv": "2303.07625"
    },
    {
        "title": "PlaneRecTR: Unified Query Learning for 3D Plane Recovery from a Single View",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_PlaneRecTR_Unified_Query_Learning_for_3D_Plane_Recovery_from_a_ICCV_2023_paper.html",
        "author": "Jingjia Shi, Shuaifeng Zhi, Kai Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PlaneRecTR_Unified_Query_Learning_for_3D_Plane_Recovery_from_a_ICCV_2023_paper.pdf",
        "aff": "National University of Defense Technology, China",
        "project": "",
        "github": "https://github.com/SJingjia/PlaneRecTR",
        "arxiv": "2307.13756"
    },
    {
        "title": "PlankAssembly: Robust 3D Reconstruction from Three Orthographic Views with Learnt Shape Programs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_PlankAssembly_Robust_3D_Reconstruction_from_Three_Orthographic_Views_with_Learnt_ICCV_2023_paper.html",
        "author": "Wentao Hu, Jia Zheng, Zixin Zhang, Xiaojun Yuan, Jian Yin, Zihan Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PlankAssembly_Robust_3D_Reconstruction_from_Three_Orthographic_Views_with_Learnt_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; Manycore Tech Inc.; Sun Yat-Sen University, Guangdong Key Laboratory of Big Data Analysis and Processing",
        "project": "",
        "github": "https://manycore-research.github.io/PlankAssembly",
        "arxiv": "2308.05744"
    },
    {
        "title": "Plausible Uncertainties for Human Pose Regression",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bramlage_Plausible_Uncertainties_for_Human_Pose_Regression_ICCV_2023_paper.html",
        "author": "Lennart Bramlage, Michelle Karg, Crist\u00f3bal Curio",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bramlage_Plausible_Uncertainties_for_Human_Pose_Regression_ICCV_2023_paper.pdf",
        "aff": "Cognitive Systems Group, Reutlingen University, Germany; Continental AG",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Pluralistic Aging Diffusion Autoencoder",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Pluralistic_Aging_Diffusion_Autoencoder_ICCV_2023_paper.html",
        "author": "Peipei Li, Rui Wang, Huaibo Huang, Ran He, Zhaofeng He",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pluralistic_Aging_Diffusion_Autoencoder_ICCV_2023_paper.pdf",
        "aff": "CRIPAC&MAIS, Institute of Automation, Chinese Academy of Sciences; Beijing University of Posts and Telecommunications",
        "project": "",
        "github": "",
        "arxiv": "2303.11086"
    },
    {
        "title": "Poincare ResNet",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/van_Spengler_Poincare_ResNet_ICCV_2023_paper.html",
        "author": "Max van Spengler, Erwin Berkhout, Pascal Mettes",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/van_Spengler_Poincare_ResNet_ICCV_2023_paper.pdf",
        "aff": "VIS Lab, Informatics Institute, University of Amsterdam; Department of Oral Radiology, Academic Center for Dentistry, University of Amsterdam & VU Amsterdam",
        "project": "",
        "github": "",
        "arxiv": "2303.14027"
    },
    {
        "title": "Point Contrastive Prediction with Semantic Clustering for Self-Supervised Learning on Point Cloud Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sheng_Point_Contrastive_Prediction_with_Semantic_Clustering_for_Self-Supervised_Learning_on_ICCV_2023_paper.html",
        "author": "Xiaoxiao Sheng, Zhiqiang Shen, Gang Xiao, Longguang Wang, Yulan Guo, Hehe Fan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sheng_Point_Contrastive_Prediction_with_Semantic_Clustering_for_Self-Supervised_Learning_on_ICCV_2023_paper.pdf",
        "aff": "Sun Yat-sen University; Aviation University of Air Force; Zhejiang University; Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2308.09247"
    },
    {
        "title": "Point-Query Quadtree for Crowd Counting, Localization, and More",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Point-Query_Quadtree_for_Crowd_Counting_Localization_and_More_ICCV_2023_paper.html",
        "author": "Chengxin Liu, Hao Lu, Zhiguo Cao, Tongliang Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Point-Query_Quadtree_for_Crowd_Counting_Localization_and_More_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Image Processing and Intelligent Control, Ministry of Education, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China; The University of Sydney, Australia",
        "project": "",
        "github": "https://github.com/cxliu0/PET",
        "arxiv": "2308.13814"
    },
    {
        "title": "Point-SLAM: Dense Neural Point Cloud-based SLAM",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.html",
        "author": "Erik Sandstr\u00f6m, Yue Li, Luc Van Gool, Martin R. Oswald",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.pdf",
        "aff": "KU Leuven, Belgium; University of Amsterdam, Netherlands; ETH Z\u00fcrich, Switzerland",
        "project": "",
        "github": "https://github.com/eriksandstroem/Point-SLAM",
        "arxiv": ""
    },
    {
        "title": "Point-TTA: Test-Time Adaptation for Point Cloud Registration Using Multitask Meta-Auxiliary Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hatem_Point-TTA_Test-Time_Adaptation_for_Point_Cloud_Registration_Using_Multitask_Meta-Auxiliary_ICCV_2023_paper.html",
        "author": "Ahmed Hatem, Yiming Qian, Yang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hatem_Point-TTA_Test-Time_Adaptation_for_Point_Cloud_Registration_Using_Multitask_Meta-Auxiliary_ICCV_2023_paper.pdf",
        "aff": "University of Manitoba; Concordia University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Point2Mask_Point-supervised_Panoptic_Segmentation_via_Optimal_Transport_ICCV_2023_paper.html",
        "author": "Wentong Li, Yuqian Yuan, Song Wang, Jianke Zhu, Jianshu Li, Jian Liu, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Point2Mask_Point-supervised_Panoptic_Segmentation_via_Optimal_Transport_ICCV_2023_paper.pdf",
        "aff": "Ant Group; The HongKong Polytechnical University; Zhejiang University",
        "project": "",
        "github": "https://github.com/LiWentomng/Point2Mask",
        "arxiv": "2308.01779"
    },
    {
        "title": "PointCLIP V2: Prompting CLIP and GPT for Powerful 3D Open-world Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_PointCLIP_V2_Prompting_CLIP_and_GPT_for_Powerful_3D_Open-world_ICCV_2023_paper.html",
        "author": "Xiangyang Zhu, Renrui Zhang, Bowei He, Ziyu Guo, Ziyao Zeng, Zipeng Qin, Shanghang Zhang, Peng Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_PointCLIP_V2_Prompting_CLIP_and_GPT_for_Powerful_3D_Open-world_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; The Chinese University of Hong Kong; Yale University; Shanghai Artificial Intelligence Laboratory; Peking University",
        "project": "",
        "github": "https://github.com/yangyangyang127/PointCLIP_V2",
        "arxiv": "2211.11682"
    },
    {
        "title": "PointDC: Unsupervised Semantic Segmentation of 3D Point Clouds via Cross-Modal Distillation and Super-Voxel Clustering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.html",
        "author": "Zisheng Chen, Hongbin Xu, Weitao Chen, Zhipeng Zhou, Haihong Xiao, Baigui Sun, Xuansong Xie, Wenxiong kang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology; South China University of Technology, Alibaba Group; South China University of Technology, Pazhou Laboratory; Chinese Academy of Science; Alibaba Group",
        "project": "",
        "github": "https://github.com/SCUT-BIP-Lab/PointDC",
        "arxiv": ""
    },
    {
        "title": "PointMBF: A Multi-scale Bidirectional Fusion Network for Unsupervised RGB-D Point Cloud Registration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_PointMBF_A_Multi-scale_Bidirectional_Fusion_Network_for_Unsupervised_RGB-D_Point_ICCV_2023_paper.html",
        "author": "Mingzhi Yuan, Kexue Fu, Zhihao Li, Yucong Meng, Manning Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PointMBF_A_Multi-scale_Bidirectional_Fusion_Network_for_Unsupervised_RGB-D_Point_ICCV_2023_paper.pdf",
        "aff": "Digital Medical Research Center, School of Basic Medical Sciences, Fudan University, China; Shandong Computer Science Center (National Supercomputer Center in Jinan)",
        "project": "",
        "github": "https://github.com/phdymz/PointMBF",
        "arxiv": ""
    },
    {
        "title": "PointOdyssey: A Large-Scale Synthetic Dataset for Long-Term Point Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_PointOdyssey_A_Large-Scale_Synthetic_Dataset_for_Long-Term_Point_Tracking_ICCV_2023_paper.html",
        "author": "Yang Zheng, Adam W. Harley, Bokui Shen, Gordon Wetzstein, Leonidas J. Guibas",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_PointOdyssey_A_Large-Scale_Synthetic_Dataset_for_Long-Term_Point_Tracking_ICCV_2023_paper.pdf",
        "aff": "Stanford University",
        "project": "https://pointodyssey.com",
        "github": "",
        "arxiv": "2307.15055"
    },
    {
        "title": "PolicyCleanse: Backdoor Detection and Mitigation for Competitive Reinforcement Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_PolicyCleanse_Backdoor_Detection_and_Mitigation_for_Competitive_Reinforcement_Learning_ICCV_2023_paper.html",
        "author": "Junfeng Guo, Ang Li, Lixu Wang, Cong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_PolicyCleanse_Backdoor_Detection_and_Mitigation_for_Competitive_Reinforcement_Learning_ICCV_2023_paper.pdf",
        "aff": "PolicyCleanse: Backdoor Detection and Mitigation for\nCompetitive Reinforcement Learning\nJunfeng Guo1Ang Li2Lixu Wang3Cong Liu4\n1University of Maryland, College Park2Simular Research3Northwestern University4UC Riverside\n{junfeng.guo}@utdallas.edu {me@angli}.ai {lixuwang2025}@u.northwestern.edu\n{congl}@ucr.edu\nAbstract\nWhile real-world applications of reinforcement learning\n(RL) are becoming popular, the security and robustness of\nRL systems are worthy of more attention and exploration. In\nparticular, recent works have revealed that, in a multi-agent\nRL environment, backdoor trigger actions can be injected\ninto a victim agent (a.k.a. Trojan agent), which can result in\na catastrophic failure as soon as it sees the backdoor trigger\naction. To ensure the security of RL agents against malicious\nbackdoors, in this work, we propose the problem of Back-\ndoor Detection in a multi-agent competitive reinforcement\nlearning system, with the objective of detecting Trojan agents\nas well as the corresponding potential trigger actions, and\nfurther trying to mitigate their Trojan behavior. In order to\nsolve this problem, we propose PolicyCleanse that is\nbased on the property that the activated Trojan agent\u2019s accu-\nmulated rewards degrade noticeably after several timesteps.\nAlong with PolicyCleanse , we also design a machine\nunlearning-based approach that can effectively mitigate the\ndetected backdoor. Extensive experiments demonstrate that\nthe proposed methods can accurately detect Trojan agents,\nand outperform existing backdoor mitigation baseline ap-\nproaches by at least 3%in winning rate across various types\nof agents and environments.\n1. Introduction\nReinforcement Learning (RL) is proposed to train smart\nagents to take actions that can help them to acquire maxi-\nmum accumulative rewards in a given environment. Such\nincentive-driven properties make people believe RL can learn\ngeneral human-level intelligent agents [ 34], and in recent\nyears, RL has demonstrated its effectiveness in various appli-\ncations and fields such as computer vision [ 2,18,36], game\nplaying [ 37], robotics technology [ 28], and traffic control[30]. Given the fact that most real-world RL applications\nare safety-critical [ 6,32], it becomes increasingly important\nand essential to ensure the security and robustness of RL\nagents. Consistent with previous work [ 7,12,39,44], we\nhere investigate the security problem of two-player competi-\ntive reinforcement learning (CRL) [ 1], one of the basic and\nrepresentative deep RL application scenario [ 1,27,7,12].\nFor CRL systems, two agents are trained to compete with\neach other, and observations of each agent are determined\nby the complex dynamics between the environment and all\nagents\u2019 actions [ 39,1,7]. In this case, theoretically speaking,\none CRL agent can manipulate its opponent\u2019s observations\nby taking well-crafted actions [7, 44, 39].\nA number of recent studies have shown that CRL systems\nare vulnerable to various types of adversarial attacks [ 7,44,\n39,12,13]. One of the most representative attacks is the\nbackdoor attack (e.g., BackdooRL [ 39]) that can compromise\na CRL system by embedding adversary-specified backdoor\ntrigger actions to a particular agent (as seen in Fig. 1). More\nspecifically, in the training phase, BackdooRL embeds a\nsequence of trigger actions into a victim agent, which we\ncall the Trojan agent . Then during inference, if an agent\nis compromised to take inconspicuous trigger actions, the\nTrojan agent fails as soon as it observes such trigger actions.\nNote that this attack mechanism is quite different from the\nbackdoor attack of regular DRL, where the Trojan trigger is\ndirectly added to the observations of the Trojan agent [ 17,3].\nTo better ensure the security of CRL, in this work, we con-\nsider a problem named Backdoor Detection in CRL, which\naims at detecting and mitigating the potential backdoor risk\nassociated with a pre-trained RL agent. The problem is much\nmore challenging than the case of conventional RL as the\ncomplexity of dynamics between the agents and the envi-\nronment in multi-agent scenarios is too high to model and\nanalyze. What\u2019s more, unlike the backdoor detection prob-\nlem in supervised learning [ 10,38,11,23,5], the backdoor\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n4699\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Ponder: Point Cloud Pre-training via Neural Rendering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Ponder_Point_Cloud_Pre-training_via_Neural_Rendering_ICCV_2023_paper.html",
        "author": "Di Huang, Sida Peng, Tong He, Honghui Yang, Xiaowei Zhou, Wanli Ouyang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Ponder_Point_Cloud_Pre-training_via_Neural_Rendering_ICCV_2023_paper.pdf",
        "aff": "The University of Sydney, Shanghai AI Laboratory; Zhejiang University; Shanghai AI Laboratory, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2301.00157"
    },
    {
        "title": "Pose-Free Neural Radiance Fields via Implicit Pose Regularization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Pose-Free_Neural_Radiance_Fields_via_Implicit_Pose_Regularization_ICCV_2023_paper.html",
        "author": "Jiahui Zhang, Fangneng Zhan, Yingchen Yu, Kunhao Liu, Rongliang Wu, Xiaoqin Zhang, Ling Shao, Shijian Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Pose-Free_Neural_Radiance_Fields_via_Implicit_Pose_Regularization_ICCV_2023_paper.pdf",
        "aff": "UCAS-Terminus AI Lab, UCAS; Max Planck Institute for Informatics; Nanyang Technological University; Wenzhou University",
        "project": "",
        "github": "",
        "arxiv": "2308.15049"
    },
    {
        "title": "PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle Adjustment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.html",
        "author": "Jianyuan Wang, Christian Rupprecht, David Novotny",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.pdf",
        "aff": "Visual Geometry Group, University of Oxford; Meta AI",
        "project": "https://posediffusion.github.io/",
        "github": "",
        "arxiv": "2306.15667"
    },
    {
        "title": "PoseFix: Correcting 3D Human Poses with Natural Language",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Delmas_PoseFix_Correcting_3D_Human_Poses_with_Natural_Language_ICCV_2023_paper.html",
        "author": "Ginger Delmas, Philippe Weinzaepfel, Francesc Moreno-Noguer, Gr\u00e9gory Rogez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Delmas_PoseFix_Correcting_3D_Human_Poses_with_Natural_Language_ICCV_2023_paper.pdf",
        "aff": "NA VER LABS Europe; Institut de Rob `otica i Inform `atica Industrial, CSIC-UPC, Barcelona, Spain",
        "project": "https://europe.naverlabs.com/research/computer-vision/posefix/",
        "github": "",
        "arxiv": "2309.08480"
    },
    {
        "title": "PourIt!: Weakly-Supervised Liquid Perception from a Single Image for Visual Closed-Loop Robotic Pouring",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.html",
        "author": "Haitao Lin, Yanwei Fu, Xiangyang Xue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.pdf",
        "aff": "Fudan University; Fudan University, Academy for Engineering and Technology, and Engineering Research Center of AI and Robotics; Fudan University, School of Data Science, and Fudan ISTBI\u2014ZJNU Algorithm Centre for Brain-inspired Intelligence, Zhejiang Normal University, Jinhua, China",
        "project": "https://hetolin.github.io/PourIt",
        "github": "",
        "arxiv": "2307.11299"
    },
    {
        "title": "Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Practical_Membership_Inference_Attacks_Against_Large-Scale_Multi-Modal_Models_A_Pilot_ICCV_2023_paper.html",
        "author": "Myeongseob Ko, Ming Jin, Chenguang Wang, Ruoxi Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Practical_Membership_Inference_Attacks_Against_Large-Scale_Multi-Modal_Models_A_Pilot_ICCV_2023_paper.pdf",
        "aff": "Washington University in St. Louis; Virginia Tech",
        "project": "",
        "github": "https://github.com/ruoxi-jia-group/CLIP-MIA",
        "arxiv": ""
    },
    {
        "title": "Pre-Training-Free Image Manipulation Localization through Non-Mutually Exclusive Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Pre-Training-Free_Image_Manipulation_Localization_through_Non-Mutually_Exclusive_Contrastive_Learning_ICCV_2023_paper.html",
        "author": "Jizhe Zhou, Xiaochen Ma, Xia Du, Ahmed Y. Alhammadi, Wentao Feng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Pre-Training-Free_Image_Manipulation_Localization_through_Non-Mutually_Exclusive_Contrastive_Learning_ICCV_2023_paper.pdf",
        "aff": "School of Computer and Information Engineering, Xiamen University of Technology; College of Computer Science, Sichuan University; Strategy Affairs Office, Mohamed Bin Zayed University for Humanities",
        "project": "",
        "github": "https://github.com/Knightzjz/NCL-IML",
        "arxiv": ""
    },
    {
        "title": "Pre-training Vision Transformers with Very Limited Synthesized Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nakamura_Pre-training_Vision_Transformers_with_Very_Limited_Synthesized_Images_ICCV_2023_paper.html",
        "author": "Ryo Nakamura, Hirokatsu Kataoka, Sora Takashima, Edgar Josafat Martinez Noriega, Rio Yokota, Nakamasa Inoue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_Pre-training_Vision_Transformers_with_Very_Limited_Synthesized_Images_ICCV_2023_paper.pdf",
        "aff": "National Institute of Advanced Industrial Science and Technology (AIST), Tokyo Institute of Technology; National Institute of Advanced Industrial Science and Technology (AIST), Fukuoka University; National Institute of Advanced Industrial Science and Technology (AIST)",
        "project": "",
        "github": "https://github.com/ryoo-nakamura/OFDB/",
        "arxiv": "2307.14710"
    },
    {
        "title": "PreSTU: Pre-Training for Scene-Text Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kil_PreSTU_Pre-Training_for_Scene-Text_Understanding_ICCV_2023_paper.html",
        "author": "Jihyung Kil, Soravit Changpinyo, Xi Chen, Hexiang Hu, Sebastian Goodman, Wei-Lun Chao, Radu Soricut",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kil_PreSTU_Pre-Training_for_Scene-Text_Understanding_ICCV_2023_paper.pdf",
        "aff": "The Ohio State University; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2209.05534"
    },
    {
        "title": "Predict to Detect: Prediction-guided 3D Object Detection using Sequential Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Predict_to_Detect_Prediction-guided_3D_Object_Detection_using_Sequential_Images_ICCV_2023_paper.html",
        "author": "Sanmin Kim, Youngseok Kim, In-Jae Lee, Dongsuk Kum",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Predict_to_Detect_Prediction-guided_3D_Object_Detection_using_Sequential_Images_ICCV_2023_paper.pdf",
        "aff": "KAIST",
        "project": "",
        "github": "",
        "arxiv": "2306.08528"
    },
    {
        "title": "Preface: A Data-driven Volumetric Prior for Few-shot Ultra High-resolution Face Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.html",
        "author": "Marcel C. B\u00fchler, Kripasindhu Sarkar, Tanmay Shah, Gengyan Li, Daoye Wang, Leonhard Helminger, Sergio Orts-Escolano, Dmitry Lagun, Otmar Hilliges, Thabo Beeler, Abhimitra Meka",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; Google",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Preparing the Future for Continual Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Preparing_the_Future_for_Continual_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Zihan Lin, Zilei Wang, Yixin Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Preparing_the_Future_for_Continual_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Preserve Your Own Correlation: A Noise Prior for Video Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Preserve_Your_Own_Correlation_A_Noise_Prior_for_Video_Diffusion_ICCV_2023_paper.html",
        "author": "Songwei Ge, Seungjun Nah, Guilin Liu, Tyler Poon, Andrew Tao, Bryan Catanzaro, David Jacobs, Jia-Bin Huang, Ming-Yu Liu, Yogesh Balaji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Preserve_Your_Own_Correlation_A_Noise_Prior_for_Video_Diffusion_ICCV_2023_paper.pdf",
        "aff": "University of Maryland; NVIDIA; University of Chicago",
        "project": "https://research.nvidia.com/labs/dir/pyoco/",
        "github": "",
        "arxiv": "2305.10474"
    },
    {
        "title": "Preserving Modality Structure Improves Multi-Modal Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Swetha_Preserving_Modality_Structure_Improves_Multi-Modal_Learning_ICCV_2023_paper.html",
        "author": "Sirnam Swetha, Mamshad Nayeem Rizve, Nina Shvetsova, Hilde Kuehne, Mubarak Shah",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Swetha_Preserving_Modality_Structure_Improves_Multi-Modal_Learning_ICCV_2023_paper.pdf",
        "aff": "Goethe University Frankfurt Germany, University of Bonn Germany, MIT-IBM Watson AI Lab; Goethe University Frankfurt Germany, University of Bonn Germany; CRCV, University of Central Florida",
        "project": "",
        "github": "https://github.com/Swetha5/Multi_Sinkhorn_Knopp",
        "arxiv": "2308.13077"
    },
    {
        "title": "Preserving Tumor Volumes for Unsupervised Medical Image Registration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.html",
        "author": "Qihua Dong, Hao Du, Ying Song, Yan Xu, Jing Liao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, City University of Hong Kong; School of Biological Science and Medical Engineering, Beihang University; National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College",
        "project": "",
        "github": "https://dddraxxx.github.io/Volume-Preserving-Registration/",
        "arxiv": "2309.10153"
    },
    {
        "title": "Pretrained Language Models as Visual Planners for Human Assistance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Patel_Pretrained_Language_Models_as_Visual_Planners_for_Human_Assistance_ICCV_2023_paper.html",
        "author": "Dhruvesh Patel, Hamid Eghbalzadeh, Nitin Kamra, Michael Louis Iuzzolino, Unnat Jain, Ruta Desai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Patel_Pretrained_Language_Models_as_Visual_Planners_for_Human_Assistance_ICCV_2023_paper.pdf",
        "aff": "Meta; UMass Amherst",
        "project": "",
        "github": "https://github.com/facebookresearch/vlamp",
        "arxiv": "2304.09179"
    },
    {
        "title": "Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Preventing_Zero-Shot_Transfer_Degradation_in_Continual_Learning_of_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Zangwei Zheng, Mingyuan Ma, Kai Wang, Ziheng Qin, Xiangyu Yue, Yang You",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Preventing_Zero-Shot_Transfer_Degradation_in_Continual_Learning_of_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; The Chinese University of Hong Kong; National University of Singapore",
        "project": "",
        "github": "https://github.com/Thunderbeee/ZSCL",
        "arxiv": "2303.06628"
    },
    {
        "title": "Prior-guided Source-free Domain Adaptation for Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Raychaudhuri_Prior-guided_Source-free_Domain_Adaptation_for_Human_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Dripta S. Raychaudhuri, Calvin-Khang Ta, Arindam Dutta, Rohit Lal, Amit K. Roy-Chowdhury",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Raychaudhuri_Prior-guided_Source-free_Domain_Adaptation_for_Human_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "University of California, Riverside; University of California, Riverside and AWS AI Labs",
        "project": "",
        "github": "",
        "arxiv": "2308.13954"
    },
    {
        "title": "Priority-Centric Human Motion Generation in Discrete Latent Space",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Priority-Centric_Human_Motion_Generation_in_Discrete_Latent_Space_ICCV_2023_paper.html",
        "author": "Hanyang Kong, Kehong Gong, Dongze Lian, Michael Bi Mi, Xinchao Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Priority-Centric_Human_Motion_Generation_in_Discrete_Latent_Space_ICCV_2023_paper.pdf",
        "aff": "Huawei International Pte Ltd; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": "2308.14480"
    },
    {
        "title": "Privacy Preserving Localization via Coordinate Permutations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Privacy_Preserving_Localization_via_Coordinate_Permutations_ICCV_2023_paper.html",
        "author": "Linfei Pan, Johannes L. Sch\u00f6nberger, Viktor Larsson, Marc Pollefeys",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Privacy_Preserving_Localization_via_Coordinate_Permutations_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; Lund University; Microsoft",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Privacy-Preserving Face Recognition Using Random Frequency Components",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mi_Privacy-Preserving_Face_Recognition_Using_Random_Frequency_Components_ICCV_2023_paper.html",
        "author": "Yuxi Mi, Yuge Huang, Jiazhen Ji, Minyi Zhao, Jiaxiang Wu, Xingkun Xu, Shouhong Ding, Shuigeng Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mi_Privacy-Preserving_Face_Recognition_Using_Random_Frequency_Components_ICCV_2023_paper.pdf",
        "aff": "Fudan University; Tencent Youtu Lab",
        "project": "",
        "github": "https://github.com/Tencent/TFace",
        "arxiv": "2308.10461"
    },
    {
        "title": "ProPainter: Improving Propagation and Transformer for Video Inpainting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_ProPainter_Improving_Propagation_and_Transformer_for_Video_Inpainting_ICCV_2023_paper.html",
        "author": "Shangchen Zhou, Chongyi Li, Kelvin C.K. Chan, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ProPainter_Improving_Propagation_and_Transformer_for_Video_Inpainting_ICCV_2023_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University",
        "project": "https://shangchenzhou.com/projects/ProPainter",
        "github": "",
        "arxiv": "2309.03897"
    },
    {
        "title": "ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Upadhyay_ProbVLM_Probabilistic_Adapter_for_Frozen_Vison-Language_Models_ICCV_2023_paper.html",
        "author": "Uddeshya Upadhyay, Shyamgopal Karthik, Massimiliano Mancini, Zeynep Akata",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Upadhyay_ProbVLM_Probabilistic_Adapter_for_Frozen_Vison-Language_Models_ICCV_2023_paper.pdf",
        "aff": "University of Trento; MPI for Intelligent Systems; University of T\u00fcbingen",
        "project": "",
        "github": "https://github.com/ExplainableML/ProbVLM",
        "arxiv": "2307.00398"
    },
    {
        "title": "Probabilistic Human Mesh Recovery in 3D Scenes from Egocentric Views",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Probabilistic_Human_Mesh_Recovery_in_3D_Scenes_from_Egocentric_Views_ICCV_2023_paper.html",
        "author": "Siwei Zhang, Qianli Ma, Yan Zhang, Sadegh Aliakbarian, Darren Cosker, Siyu Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Probabilistic_Human_Mesh_Recovery_in_3D_Scenes_from_Egocentric_Views_ICCV_2023_paper.pdf",
        "aff": "ETH Z\u00fcrich; Microsoft",
        "project": "",
        "github": "https://sanweiliti.github.io/egohmr/egohmr.html",
        "arxiv": "2304.06024"
    },
    {
        "title": "Probabilistic Modeling of Inter- and Intra-observer Variability in Medical Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.html",
        "author": "Arne Schmidt, Pablo Morales-\u00c1lvarez, Rafael Molina",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.pdf",
        "aff": "Universidad de Granada, Granada, Spain",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Probabilistic Precision and Recall Towards Reliable Evaluation of Generative Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_Probabilistic_Precision_and_Recall_Towards_Reliable_Evaluation_of_Generative_Models_ICCV_2023_paper.html",
        "author": "Dogyun Park, Suhyun Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Probabilistic_Precision_and_Recall_Towards_Reliable_Evaluation_of_Generative_Models_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Korea University, Seoul, South Korea; Korea Institute of Science and Technology, Seoul, South Korea",
        "project": "",
        "github": "https://github.com/kdst-team/Probablistic_precision_recall",
        "arxiv": "2309.01590"
    },
    {
        "title": "Probabilistic Triangulation for Uncalibrated Multi-View 3D Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Probabilistic_Triangulation_for_Uncalibrated_Multi-View_3D_Human_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Boyuan Jiang, Lei Hu, Shihong Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Probabilistic_Triangulation_for_Uncalibrated_Multi-View_3D_Human_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/bymaths/probabilistic_triangulation",
        "arxiv": "2309.04756"
    },
    {
        "title": "Progressive Spatio-Temporal Prototype Matching for Text-Video Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Progressive_Spatio-Temporal_Prototype_Matching_for_Text-Video_Retrieval_ICCV_2023_paper.html",
        "author": "Pandeng Li, Chen-Wei Xie, Liming Zhao, Hongtao Xie, Jiannan Ge, Yun Zheng, Deli Zhao, Yongdong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Progressive_Spatio-Temporal_Prototype_Matching_for_Text-Video_Retrieval_ICCV_2023_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/IMCCretrieval/ProST",
        "arxiv": ""
    },
    {
        "title": "Prompt Switch: Efficient CLIP Adaptation for Text-Video Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Prompt_Switch_Efficient_CLIP_Adaptation_for_Text-Video_Retrieval_ICCV_2023_paper.html",
        "author": "Chaorui Deng, Qi Chen, Pengda Qin, Da Chen, Qi Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Prompt_Switch_Efficient_CLIP_Adaptation_for_Text-Video_Retrieval_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, University of Bath; Alibaba Group; Australia Institute of Machine Learning, University of Adelaide",
        "project": "",
        "github": "https://github.com/bladewaltz1/PromptSwitch",
        "arxiv": "2308.07648"
    },
    {
        "title": "Prompt Tuning Inversion for Text-driven Image Editing Using Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Wenkai Dong, Song Xue, Xiaoyue Duan, Shumin Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Baidu VIS; Baidu VIS, Beihang University",
        "project": "",
        "github": "",
        "arxiv": "2305.04441"
    },
    {
        "title": "Prompt-aligned Gradient for Prompt Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Prompt-aligned_Gradient_for_Prompt_Tuning_ICCV_2023_paper.html",
        "author": "Beier Zhu, Yulei Niu, Yucheng Han, Yue Wu, Hanwang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Prompt-aligned_Gradient_for_Prompt_Tuning_ICCV_2023_paper.pdf",
        "aff": "Damo Academy, Alibaba Group; Nanyang Technological University; Columbia University",
        "project": "",
        "github": "",
        "arxiv": "2205.14865"
    },
    {
        "title": "PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_PromptCap_Prompt-Guided_Image_Captioning_for_VQA_with_GPT-3_ICCV_2023_paper.html",
        "author": "Yushi Hu, Hang Hua, Zhengyuan Yang, Weijia Shi, Noah A. Smith, Jiebo Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PromptCap_Prompt-Guided_Image_Captioning_for_VQA_with_GPT-3_ICCV_2023_paper.pdf",
        "aff": "University of Washington, Allen Institute for AI; University of Rochester; University of Washington; Microsoft",
        "project": "https://yushi-hu.github.io/promptcap_demo/",
        "github": "https://huggingface.co/tifa-benchmark/promptcap-coco-vqa",
        "arxiv": ""
    },
    {
        "title": "PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cho_PromptStyler_Prompt-driven_Style_Generation_for_Source-free_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Junhyeong Cho, Gilhyun Nam, Sungyeon Kim, Hunmin Yang, Suha Kwak",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_PromptStyler_Prompt-driven_Style_Generation_for_Source-free_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "KAIST; ADD; POSTECH",
        "project": "",
        "github": "https://PromptStyler.github.io",
        "arxiv": "2307.15199"
    },
    {
        "title": "ProtoFL: Unsupervised Federated Learning via Prototypical Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_ProtoFL_Unsupervised_Federated_Learning_via_Prototypical_Distillation_ICCV_2023_paper.html",
        "author": "Hansol Kim, Youngjun Kwak, Minyoung Jung, Jinho Shin, Youngsung Kim, Changick Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_ProtoFL_Unsupervised_Federated_Learning_via_Prototypical_Distillation_ICCV_2023_paper.pdf",
        "aff": "Inha University, South Korea; KETI, Korea Electronics Technology Institute, South Korea; KakaoBank Corp., South Korea; Department of Electrical Engineering, KAIST, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2307.12450"
    },
    {
        "title": "ProtoTransfer: Cross-Modal Prototype Transfer for Point Cloud Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_ProtoTransfer_Cross-Modal_Prototype_Transfer_for_Point_Cloud_Segmentation_ICCV_2023_paper.html",
        "author": "Pin Tang, Hai-Ming Xu, Chao Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_ProtoTransfer_Cross-Modal_Prototype_Transfer_for_Point_Cloud_Segmentation_ICCV_2023_paper.pdf",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Australian Institute for Machine Learning, University of Adelaide",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Prototype Reminiscence and Augmented Asymmetric Knowledge Aggregation for Non-Exemplar Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Prototype_Reminiscence_and_Augmented_Asymmetric_Knowledge_Aggregation_for_Non-Exemplar_Class-Incremental_ICCV_2023_paper.html",
        "author": "Wuxuan Shi, Mang Ye",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Prototype_Reminiscence_and_Augmented_Asymmetric_Knowledge_Aggregation_for_Non-Exemplar_Class-Incremental_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; Hubei Luojia Laboratory, Wuhan, China",
        "project": "https://shiwuxuan.github.io/PRAKA-project",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Prototype-based Dataset Comparison",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/van_Noord_Protoype-based_Dataset_Comparison_ICCV_2023_paper.html",
        "author": "Nanne van Noord",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/van_Noord_Protoype-based_Dataset_Comparison_ICCV_2023_paper.pdf",
        "aff": "University of Amsterdam",
        "project": "",
        "github": "https://github.com/Nanne/ProtoSim",
        "arxiv": ""
    },
    {
        "title": "Prototypes-oriented Transductive Few-shot Learning with Conditional Transport",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Prototypes-oriented_Transductive_Few-shot_Learning_with_Conditional_Transport_ICCV_2023_paper.html",
        "author": "Long Tian, Jingyi Feng, Xiaoqiang Chai, Wenchao Chen, Liming Wang, Xiyang Liu, Bo Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Prototypes-oriented_Transductive_Few-shot_Learning_with_Conditional_Transport_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory of Radar Signal Processing, Xidian University, Xi'an, Shanxi 710071, China; National Pilot School of Software Engineering, Xidian University, Xi'an, Shanxi 710071, China",
        "project": "",
        "github": "https://github.com/RashLog/PUTM",
        "arxiv": "2308.03047"
    },
    {
        "title": "Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.html",
        "author": "Kai Huang, Feigege Wang, Ye Xi, Yutao Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": "2308.04952"
    },
    {
        "title": "Prototypical Mixing and Retrieval-Based Refinement for Label Noise-Resistant Image Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.html",
        "author": "Xinlong Yang, Haixin Wang, Jinan Sun, Shikun Zhang, Chong Chen, Xian-Sheng Hua, Xiao Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.pdf",
        "aff": "Peking University; University of California, Los Angeles; Terminus Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized_Category_Discovery_ICCV_2023_paper.html",
        "author": "Hyungmin Kim, Sungho Suh, Daehwan Kim, Daun Jeong, Hansang Cho, Junmo Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized_Category_Discovery_ICCV_2023_paper.pdf",
        "aff": "German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Department of Computer Science, RPTU Kaiserslautern-Landau, Kaiserslautern, Germany; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Samsung Electro-Mechanics, Suwon, South Korea; Samsung Electro-Mechanics, Suwon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2307.10943"
    },
    {
        "title": "Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Prune_Spatio-temporal_Tokens_by_Semantic-aware_Temporal_Accumulation_ICCV_2023_paper.html",
        "author": "Shuangrui Ding, Peisen Zhao, Xiaopeng Zhang, Rui Qian, Hongkai Xiong, Qi Tian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Prune_Spatio-temporal_Tokens_by_Semantic-aware_Temporal_Accumulation_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; Shanghai Jiao Tong University; Huawei Cloud",
        "project": "",
        "github": "https://github.com/Mark12Ding/STA",
        "arxiv": "2308.04549"
    },
    {
        "title": "Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hai_Pseudo_Flow_Consistency_for_Self-Supervised_6D_Object_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Yang Hai, Rui Song, Jiaojiao Li, David Ferstl, Yinlin Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hai_Pseudo_Flow_Consistency_for_Self-Supervised_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of ISN, Xidian University; MagicLeap",
        "project": "",
        "github": "",
        "arxiv": "2308.10016"
    },
    {
        "title": "Pseudo-label Alignment for Semi-supervised Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Pseudo-label_Alignment_for_Semi-supervised_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Jie Hu, Chen Chen, Liujuan Cao, Shengchuan Zhang, Annan Shu, Guannan Jiang, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Pseudo-label_Alignment_for_Semi-supervised_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Contemporary Amperex Technology Co. Limited; Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University",
        "project": "",
        "github": "https://github.com/hujiecpp/PAIS",
        "arxiv": "2308.05359"
    },
    {
        "title": "Pyramid Dual Domain Injection Network for Pan-sharpening",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Pyramid_Dual_Domain_Injection_Network_for_Pan-sharpening_ICCV_2023_paper.html",
        "author": "Xuanhua He, Keyu Yan, Rui Li, Chengjun Xie, Jie Zhang, Man Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Pyramid_Dual_Domain_Injection_Network_for_Pan-sharpening_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, China; Hefei Institute of Physical Science, Chinese Academy of Sciences, China; Nanyang Technological University, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Q-Diffusion: Quantizing Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Q-Diffusion_Quantizing_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Xiuyu Li, Yijiang Liu, Long Lian, Huanrui Yang, Zhen Dong, Daniel Kang, Shanghang Zhang, Kurt Keutzer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Q-Diffusion_Quantizing_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; Peking University; University of Illinois Urbana-Champaign; Nanjing University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "QD-BEV : Quantization-aware View-guided Distillation for Multi-view 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_QD-BEV__Quantization-aware_View-guided_Distillation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Yifan Zhang, Zhen Dong, Huanrui Yang, Ming Lu, Cheng-Ching Tseng, Yuan Du, Kurt Keutzer, Li Du, Shanghang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_QD-BEV__Quantization-aware_View-guided_Distillation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Nanjing University; University of California, Berkeley; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2308.10515"
    },
    {
        "title": "Quality Diversity for Visual Pre-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chavhan_Quality_Diversity_for_Visual_Pre-Training_ICCV_2023_paper.html",
        "author": "Ruchika Chavhan, Henry Gouk, Da Li, Timothy Hospedales",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chavhan_Quality_Diversity_for_Visual_Pre-Training_ICCV_2023_paper.pdf",
        "aff": "The University of Edinburgh; Samsung AI Center, Cambridge",
        "project": "",
        "github": "https://github.com/ruchikachavhan/quality-diversity-pretraining.git",
        "arxiv": ""
    },
    {
        "title": "Quality-Agnostic Deepfake Detection with Intra-model Collaborative Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Le_Quality-Agnostic_Deepfake_Detection_with_Intra-model_Collaborative_Learning_ICCV_2023_paper.html",
        "author": "Binh M. Le, Simon S. Woo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Le_Quality-Agnostic_Deepfake_Detection_with_Intra-model_Collaborative_Learning_ICCV_2023_paper.pdf",
        "aff": "Dept. of Computer Science & Engineering, Sungkyunkwan University, Suwon, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2309.05911"
    },
    {
        "title": "Query Refinement Transformer for 3D Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Query_Refinement_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Jiahao Lu, Jiacheng Deng, Chuxin Wang, Jianfeng He, Tianzhu Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Query_Refinement_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Deep Space Exploration Lab; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Query6DoF: Learning Sparse Queries as Implicit Shape Prior for Category-Level 6DoF Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Query6DoF_Learning_Sparse_Queries_as_Implicit_Shape_Prior_for_Category-Level_ICCV_2023_paper.html",
        "author": "Ruiqi Wang, Xinggang Wang, Te Li, Rong Yang, Minhong Wan, Wenyu Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Query6DoF_Learning_Sparse_Queries_as_Implicit_Shape_Prior_for_Category-Level_ICCV_2023_paper.pdf",
        "aff": "Zhejiang Engineering Research Center for Intelligent Robotics, China; Research Center for Intelligent Robotics, Research Institute of Interdisciplinary Innovation, Zhejiang Lab, China; Hubei Key Laboratory of Smart Internet Technology, School of Electronic Information and Communications, Huazhong University of Science and Technology",
        "project": "",
        "github": "https://github.com/hustvl/Query6DoF",
        "arxiv": ""
    },
    {
        "title": "R-Pred: Two-Stage Motion Prediction Via Tube-Query Attention-Based Trajectory Refinement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Choi_R-Pred_Two-Stage_Motion_Prediction_Via_Tube-Query_Attention-Based_Trajectory_Refinement_ICCV_2023_paper.html",
        "author": "Sehwan Choi, Jungho Kim, Junyong Yun, Jun Won Choi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_R-Pred_Two-Stage_Motion_Prediction_Via_Tube-Query_Attention-Based_Trajectory_Refinement_ICCV_2023_paper.pdf",
        "aff": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n8525\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Schmied_R3D3_Dense_3D_Reconstruction_of_Dynamic_Scenes_from_Multiple_Cameras_ICCV_2023_paper.html",
        "author": "Aron Schmied, Tobias Fischer, Martin Danelljan, Marc Pollefeys, Fisher Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Schmied_R3D3_Dense_3D_Reconstruction_of_Dynamic_Scenes_from_Multiple_Cameras_ICCV_2023_paper.pdf",
        "aff": "ETH Z\u00fcrich, Microsoft; ETH Z\u00fcrich",
        "project": "https://www.vis.xyz/pub/r3d3/",
        "github": "",
        "arxiv": "2308.14713"
    },
    {
        "title": "RANA: Relightable Articulated Neural Avatars",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Iqbal_RANA_Relightable_Articulated_Neural_Avatars_ICCV_2023_paper.html",
        "author": "Umar Iqbal, Akin Caliskan, Koki Nagano, Sameh Khamis, Pavlo Molchanov, Jan Kautz",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Iqbal_RANA_Relightable_Articulated_Neural_Avatars_ICCV_2023_paper.pdf",
        "aff": "Flawless AI; NVIDIA",
        "project": "https://nvlabs.github.io/RANA/",
        "github": "https://github.com/nvlabs/RANA",
        "arxiv": "2212.03237"
    },
    {
        "title": "RCA-NOC: Relative Contrastive Alignment for Novel Object Captioning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_RCA-NOC_Relative_Contrastive_Alignment_for_Novel_Object_Captioning_ICCV_2023_paper.html",
        "author": "Jiashuo Fan, Yaoyuan Liang, Leyao Liu, Shaolun Huang, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_RCA-NOC_Relative_Contrastive_Alignment_for_Novel_Object_Captioning_ICCV_2023_paper.pdf",
        "aff": "International Digital Economy Academy; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "REAP: A Large-Scale Realistic Adversarial Patch Benchmark",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hingun_REAP_A_Large-Scale_Realistic_Adversarial_Patch_Benchmark_ICCV_2023_paper.html",
        "author": "Nabeel Hingun, Chawin Sitawarin, Jerry Li, David Wagner",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hingun_REAP_A_Large-Scale_Realistic_Adversarial_Patch_Benchmark_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; Microsoft",
        "project": "",
        "github": "https://github.com/wagner-group/reap-benchmark",
        "arxiv": "2212.05680"
    },
    {
        "title": "RED-PSM: Regularization by Denoising of Partially Separable Models for Dynamic Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Iskender_RED-PSM_Regularization_by_Denoising_of_Partially_Separable_Models_for_Dynamic_ICCV_2023_paper.html",
        "author": "Berk Iskender, Marc L. Klasky, Yoram Bresler",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Iskender_RED-PSM_Regularization_by_Denoising_of_Partially_Separable_Models_for_Dynamic_ICCV_2023_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign, USA; Los Alamos National Laboratory, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RFD-ECNet: Extreme Underwater Image Compression with Reference to Feature Dictionary",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.html",
        "author": "Mengyao Li, Liquan Shen, Peng Ye, Guorui Feng, Zheyin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.pdf",
        "aff": "Shanghai University, Shanghai, China; Fudan University, Shanghai, China",
        "project": "",
        "github": "https://github.com/lilala0/RFD-ECNet",
        "arxiv": ""
    },
    {
        "title": "RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical World",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_RFLA_A_Stealthy_Reflected_Light_Adversarial_Attack_in_the_Physical_ICCV_2023_paper.html",
        "author": "Donghua Wang, Wen Yao, Tingsong Jiang, Chao Li, Xiaoqian Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_RFLA_A_Stealthy_Reflected_Light_Adversarial_Attack_in_the_Physical_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence, Xidian University; Defense Innovation Institute, Chinese Academy of Military Science; College of Computer Science and Technology, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2307.07653"
    },
    {
        "title": "RICO: Regularizing the Unobservable for Indoor Compositional Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_RICO_Regularizing_the_Unobservable_for_Indoor_Compositional_Reconstruction_ICCV_2023_paper.html",
        "author": "Zizhang Li, Xiaoyang Lyu, Yuanyuan Ding, Mengmeng Wang, Yiyi Liao, Yong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RICO_Regularizing_the_Unobservable_for_Indoor_Compositional_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "The University of Hong Kong; Zhejiang University",
        "project": "",
        "github": "https://github.com/kyleleey/RICO",
        "arxiv": "2303.08605"
    },
    {
        "title": "RIGID: Recurrent GAN Inversion and Editing of Real Face Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_RIGID_Recurrent_GAN_Inversion_and_Editing_of_Real_Face_Videos_ICCV_2023_paper.html",
        "author": "Yangyang Xu, Shengfeng He, Kwan-Yee K. Wong, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_RIGID_Recurrent_GAN_Inversion_and_Editing_of_Real_Face_Videos_ICCV_2023_paper.pdf",
        "aff": "Deapartment of Computer Science, The University of Hong Kong and Shanghai AI Laboratory; Deapartment of Computer Science, The University of Hong Kong; School of Computing and Information Systems, Singapore Management University",
        "project": "https://cnnlstm.github.io/RIGID",
        "github": "https://github.com/cnnlstm/RIGID",
        "arxiv": "2308.06097"
    },
    {
        "title": "RLIPv2: Fast Scaling of Relational Language-Image Pre-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.html",
        "author": "Hangjie Yuan, Shiwei Zhang, Xiang Wang, Samuel Albanie, Yining Pan, Tao Feng, Jianwen Jiang, Dong Ni, Yingya Zhang, Deli Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group; CAML Lab, University of Cambridge; Zhejiang University; Huazhong University of Science and Technology; Singapore University of Technology and Design",
        "project": "",
        "github": "https://github.com/JacobYuan7/RLIPv2",
        "arxiv": "2308.09351"
    },
    {
        "title": "RLSAC: Reinforcement Learning Enhanced Sample Consensus for End-to-End Robust Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nie_RLSAC_Reinforcement_Learning_Enhanced_Sample_Consensus_for_End-to-End_Robust_Estimation_ICCV_2023_paper.html",
        "author": "Chang Nie, Guangming Wang, Zhe Liu, Luca Cavalli, Marc Pollefeys, Hesheng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_RLSAC_Reinforcement_Learning_Enhanced_Sample_Consensus_for_End-to-End_Robust_Estimation_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, ETH Z\u00fcrich; Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Shanghai Jiao Tong University; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Department of Computer Science, ETH Z\u00fcrich4Microsoft Mixed Reality and AI Z\u00fcrich Lab",
        "project": "",
        "github": "https://github.com/IRMVLab/RLSAC",
        "arxiv": "2308.05318"
    },
    {
        "title": "RMP-Loss: Regularizing Membrane Potential Distribution for Spiking Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_RMP-Loss_Regularizing_Membrane_Potential_Distribution_for_Spiking_Neural_Networks_ICCV_2023_paper.html",
        "author": "Yufei Guo, Xiaode Liu, Yuanpei Chen, Liwen Zhang, Weihang Peng, Yuhan Zhang, Xuhui Huang, Zhe Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_RMP-Loss_Regularizing_Membrane_Potential_Distribution_for_Spiking_Neural_Networks_ICCV_2023_paper.pdf",
        "aff": "Intelligent Science & Technology Academy of CASIC, China; Scientific Research Laboratory of Aerospace Intelligent Systems and Technology, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ROME: Robustifying Memory-Efficient NAS via Topology Disentanglement and Gradient Accumulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ROME_Robustifying_Memory-Efficient_NAS_via_Topology_Disentanglement_and_Gradient_Accumulation_ICCV_2023_paper.html",
        "author": "Xiaoxing Wang, Xiangxiang Chu, Yuda Fan, Zhexi Zhang, Bo Zhang, Xiaokang Yang, Junchi Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ROME_Robustifying_Memory-Efficient_NAS_via_Topology_Disentanglement_and_Gradient_Accumulation_ICCV_2023_paper.pdf",
        "aff": "Meituan; Dep. of Computer Science and Engineering & MoE Key Lab of AI, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2011.11233"
    },
    {
        "title": "RPEFlow: Multimodal Fusion of RGB-PointCloud-Event for Joint Optical Flow and Scene Flow Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wan_RPEFlow_Multimodal_Fusion_of_RGB-PointCloud-Event_for_Joint_Optical_Flow_and_ICCV_2023_paper.html",
        "author": "Zhexiong Wan, Yuxin Mao, Jing Zhang, Yuchao Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_RPEFlow_Multimodal_Fusion_of_RGB-PointCloud-Event_for_Joint_Optical_Flow_and_ICCV_2023_paper.pdf",
        "aff": "Northwestern Polytechnical University & Shaanxi Key Laboratory of Information Acquisition and Processing; Australian National University",
        "project": "",
        "github": "https://npucvr.github.io/RPEFlow",
        "arxiv": ""
    },
    {
        "title": "RPG-Palm: Realistic Pseudo-data Generation for Palmprint Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shen_RPG-Palm_Realistic_Pseudo-data_Generation_for_Palmprint_Recognition_ICCV_2023_paper.html",
        "author": "Lei Shen, Jianlong Jin, Ruixin Zhang, Huaen Li, Kai Zhao, Yingyi Zhang, Jingyun Zhang, Shouhong Ding, Yang Zhao, Wei Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_RPG-Palm_Realistic_Pseudo-data_Generation_for_Palmprint_Recognition_ICCV_2023_paper.pdf",
        "aff": "WeChat Pay Lab33, Tencent, Shenzhen, China; Youtu Lab, Tencent, Shanghai, China; Hefei University of Technology, Hefei, China; UCLA, California, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RSFNet: A White-Box Image Retouching Approach using Region-Specific Color Filters",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ouyang_RSFNet_A_White-Box_Image_Retouching_Approach_using_Region-Specific_Color_Filters_ICCV_2023_paper.html",
        "author": "Wenqi Ouyang, Yi Dong, Xiaoyang Kang, Peiran Ren, Xin Xu, Xuansong Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ouyang_RSFNet_A_White-Box_Image_Retouching_Approach_using_Region-Specific_Color_Filters_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/Vicky0522/RSFNet",
        "arxiv": "2303.08682"
    },
    {
        "title": "Random Boxes Are Open-world Object Detectors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Random_Boxes_Are_Open-world_Object_Detectors_ICCV_2023_paper.html",
        "author": "Yanghao Wang, Zhongqi Yue, Xian-Sheng Hua, Hanwang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Random_Boxes_Are_Open-world_Object_Detectors_ICCV_2023_paper.pdf",
        "aff": "Terminus Group; Nanyang Technological University; Nanyang Technological University, Damo Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/scuwyh2000/RandBox",
        "arxiv": "2307.08249"
    },
    {
        "title": "Random Sub-Samples Generation for Self-Supervised Real Image Denoising",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Random_Sub-Samples_Generation_for_Self-Supervised_Real_Image_Denoising_ICCV_2023_paper.html",
        "author": "Yizhong Pan, Xiao Liu, Xiangyu Liao, Yuanzhouhan Cao, Chao Ren",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Random_Sub-Samples_Generation_for_Self-Supervised_Real_Image_Denoising_ICCV_2023_paper.pdf",
        "aff": "College of Electronics and Information Engineering, Sichuan University, China; School of Computer and Information Technology, Beijing Jiaotong University, China",
        "project": "",
        "github": "https://github.com/p1y2z3/SDAP",
        "arxiv": "2307.16825"
    },
    {
        "title": "Randomized Quantization: A Generic Augmentation for Data Agnostic Self-supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Randomized_Quantization_A_Generic_Augmentation_for_Data_Agnostic_Self-supervised_Learning_ICCV_2023_paper.html",
        "author": "Huimin Wu, Chenyang Lei, Xiao Sun, Peng-Shuai Wang, Qifeng Chen, Kwang-Ting Cheng, Stephen Lin, Zhirong Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Randomized_Quantization_A_Generic_Augmentation_for_Data_Agnostic_Self-supervised_Learning_ICCV_2023_paper.pdf",
        "aff": "HKUST; Shanghai AI Lab; CAIR, HKISI CAS; Microsoft Research Asia; Peking University",
        "project": "",
        "github": "https://github.com/microsoft/random_quantize",
        "arxiv": "2212.08663"
    },
    {
        "title": "RankMatch: Fostering Confidence and Consistency in Learning with Noisy Labels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_RankMatch_Fostering_Confidence_and_Consistency_in_Learning_with_Noisy_Labels_ICCV_2023_paper.html",
        "author": "Ziyi Zhang, Weikai Chen, Chaowei Fang, Zhen Li, Lechao Chen, Liang Lin, Guanbin Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_RankMatch_Fostering_Confidence_and_Consistency_in_Learning_with_Noisy_Labels_ICCV_2023_paper.pdf",
        "aff": "Xidian University; Tencent America; National Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China; Sun Yat-sen University, Guangzhou, China; Zhejiang Lab; Sun Yat-sen University, Guangzhou, China; Sun Yat-sen University, Guangzhou, China; Research Institute, Sun Yat-sen University, Shenzhen, China; The Chinese University of Hong Kong (Shenzhen)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RankMixup: Ranking-Based Mixup Training for Network Calibration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Noh_RankMixup_Ranking-Based_Mixup_Training_for_Network_Calibration_ICCV_2023_paper.html",
        "author": "Jongyoun Noh, Hyekang Park, Junghyup Lee, Bumsub Ham",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Noh_RankMixup_Ranking-Based_Mixup_Training_for_Network_Calibration_ICCV_2023_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University",
        "project": "https://cvlab.yonsei.ac.kr/projects/RankMixup",
        "github": "",
        "arxiv": "2308.11990"
    },
    {
        "title": "Rapid Adaptation in Online Continual Learning: Are We Evaluating It Right?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Al_Kader_Hammoud_Rapid_Adaptation_in_Online_Continual_Learning_Are_We_Evaluating_It_ICCV_2023_paper.html",
        "author": "Hasan Abed Al Kader Hammoud, Ameya Prabhu, Ser-Nam Lim, Philip H.S. Torr, Adel Bibi, Bernard Ghanem",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Al_Kader_Hammoud_Rapid_Adaptation_in_Online_Continual_Learning_Are_We_Evaluating_It_ICCV_2023_paper.pdf",
        "aff": "Meta AI; University of Oxford; KAUST",
        "project": "",
        "github": "https://github.com/drimpossible/EvalOCL",
        "arxiv": "2305.09275"
    },
    {
        "title": "Rapid Network Adaptation: Learning to Adapt Neural Networks Using Test-Time Feedback",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yeo_Rapid_Network_Adaptation_Learning_to_Adapt_Neural_Networks_Using_Test-Time_ICCV_2023_paper.html",
        "author": "Teresa Yeo, O\u011fuzhan Fatih Kar, Zahra Sodagar, Amir Zamir",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yeo_Rapid_Network_Adaptation_Learning_to_Adapt_Neural_Networks_Using_Test-Time_ICCV_2023_paper.pdf",
        "aff": "Swiss Federal Institute of Technology Lausanne (EPFL)",
        "project": "https://rapid-network-adaptation.epfl.ch/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RawHDR: High Dynamic Range Image Reconstruction from a Single Raw Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.html",
        "author": "Yunhao Zou, Chenggang Yan, Ying Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of Technology; Hangzhou Dianzi University",
        "project": "",
        "github": "",
        "arxiv": "2309.02020"
    },
    {
        "title": "Ray Conditioning: Trading Photo-consistency for Photo-realism in Multi-view Image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.html",
        "author": "Eric Ming Chen, Sidhanth Holalkere, Ruyu Yan, Kai Zhang, Abe Davis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.pdf",
        "aff": "Cornell University; Adobe Research",
        "project": "https://ray-cond.github.io",
        "github": "",
        "arxiv": "2304.13681"
    },
    {
        "title": "RbA: Segmenting Unknown Regions Rejected by All",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nayal_RbA_Segmenting_Unknown_Regions_Rejected_by_All_ICCV_2023_paper.html",
        "author": "Nazir Nayal, Misra Yavuz, Jo\u00e3o F. Henriques, Fatma G\u00fcney",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nayal_RbA_Segmenting_Unknown_Regions_Rejected_by_All_ICCV_2023_paper.pdf",
        "aff": "KUIS AI Center and Department of Computer Engineering, Koc University; University of Oxford",
        "project": "https://kuis-ai.github.io/RbA",
        "github": "",
        "arxiv": "2211.14293"
    },
    {
        "title": "Re-ReND: Real-Time Rendering of NeRFs across Devices",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rojas_Re-ReND_Real-Time_Rendering_of_NeRFs_across_Devices_ICCV_2023_paper.html",
        "author": "Sara Rojas, Jesus Zarzar, Juan C. P\u00e9rez, Artsiom Sanakoyeu, Ali Thabet, Albert Pumarola, Bernard Ghanem",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rojas_Re-ReND_Real-Time_Rendering_of_NeRFs_across_Devices_ICCV_2023_paper.pdf",
        "aff": "Meta Research; King Abdullah University of Science and Technology (KAUST)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Re-mine, Learn and Reason: Exploring the Cross-modal Semantic Correlations for Language-guided HOI detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Re-mine_Learn_and_Reason_Exploring_the_Cross-modal_Semantic_Correlations_for_ICCV_2023_paper.html",
        "author": "Yichao Cao, Qingfei Tang, Feng Yang, Xiu Su, Shan You, Xiaobo Lu, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Re-mine_Learn_and_Reason_Exploring_the_Cross-modal_Semantic_Correlations_for_ICCV_2023_paper.pdf",
        "aff": "Southeast University; University of Sydney; Nanjing Enbo Tech.; SenseTime",
        "project": "",
        "github": "",
        "arxiv": "2307.13529"
    },
    {
        "title": "Re:PolyWorld - A Graph Neural Network for Polygonal Scene Parsing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zorzi_RePolyWorld_-_A_Graph_Neural_Network_for_Polygonal_Scene_Parsing_ICCV_2023_paper.html",
        "author": "Stefano Zorzi, Friedrich Fraundorfer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zorzi_RePolyWorld_-_A_Graph_Neural_Network_for_Polygonal_Scene_Parsing_ICCV_2023_paper.pdf",
        "aff": "Graz University of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ReFit: Recurrent Fitting Network for 3D Human Recovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ReFit_Recurrent_Fitting_Network_for_3D_Human_Recovery_ICCV_2023_paper.html",
        "author": "Yufu Wang, Kostas Daniilidis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ReFit_Recurrent_Fitting_Network_for_3D_Human_Recovery_ICCV_2023_paper.pdf",
        "aff": "University of Pennsylvania",
        "project": "https://yufu-wang.github.io/refit-humans/",
        "github": "",
        "arxiv": "2308.11184"
    },
    {
        "title": "ReGen: A good Generative Zero-Shot Video Classifier Should be Rewarded",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bulat_ReGen_A_good_Generative_Zero-Shot_Video_Classifier_Should_be_Rewarded_ICCV_2023_paper.html",
        "author": "Adrian Bulat, Enrique Sanchez, Brais Martinez, Georgios Tzimiropoulos",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_ReGen_A_good_Generative_Zero-Shot_Video_Classifier_Should_be_Rewarded_ICCV_2023_paper.pdf",
        "aff": "Samsung AI Cambridge, Queen Mary University of London; Samsung AI Cambridge",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ReLeaPS : Reinforcement Learning-based Illumination Planning for Generalized Photometric Stereo",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chan_ReLeaPS__Reinforcement_Learning-based_Illumination_Planning_for_Generalized_Photometric_Stereo_ICCV_2023_paper.html",
        "author": "Jun Hoong Chan, Bohan Yu, Heng Guo, Jieji Ren, Zongqing Lu, Boxin Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_ReLeaPS__Reinforcement_Learning-based_Illumination_Planning_for_Generalized_Photometric_Stereo_ICCV_2023_paper.pdf",
        "aff": "School of Mechanical Engineering, Shanghai Jiao Tong University; School of Artificial Intelligence, Beijing University of Posts and Telecommunications; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University",
        "project": "https://jhchan0805.github.io/ReLeaPS",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ReMoDiffuse_Retrieval-Augmented_Motion_Diffusion_Model_ICCV_2023_paper.html",
        "author": "Mingyuan Zhang, Xinying Guo, Liang Pan, Zhongang Cai, Fangzhou Hong, Huirong Li, Lei Yang, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ReMoDiffuse_Retrieval-Augmented_Motion_Diffusion_Model_ICCV_2023_paper.pdf",
        "aff": "Sensetime, China; S-Lab, Nanyang Technological University, Singapore; S-Lab, Nanyang Technological University, Singapore and Sensetime, China",
        "project": "https://mingyuan-zhang.github.io/projects/ReMoDiffuse.html",
        "github": "",
        "arxiv": "2304.01116"
    },
    {
        "title": "ReNeRF: Relightable Neural Radiance Fields with Nearfield Lighting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ReNeRF_Relightable_Neural_Radiance_Fields_with_Nearfield_Lighting_ICCV_2023_paper.html",
        "author": "Yingyan Xu, Gaspard Zoss, Prashanth Chandran, Markus Gross, Derek Bradley, Paulo Gotardo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ReNeRF_Relightable_Neural_Radiance_Fields_with_Nearfield_Lighting_ICCV_2023_paper.pdf",
        "aff": "DisneyResearch|Studios; ETH Z\u00fcrich, DisneyResearch|Studios",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ReST: A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera Multi-Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_ReST_A_Reconfigurable_Spatial-Temporal_Graph_Model_for_Multi-Camera_Multi-Object_Tracking_ICCV_2023_paper.html",
        "author": "Cheng-Che Cheng, Min-Xuan Qiu, Chen-Kuo Chiang, Shang-Hong Lai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_ReST_A_Reconfigurable_Spatial-Temporal_Graph_Model_for_Multi-Camera_Multi-Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "National Chung Cheng University, Taiwan; National Tsing Hua University, Taiwan",
        "project": "",
        "github": "https://github.com/chengche6230/ReST",
        "arxiv": "2308.13229"
    },
    {
        "title": "ReactioNet: Learning High-Order Facial Behavior from Universal Stimulus-Reaction by Dyadic Relation Reasoning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_ReactioNet_Learning_High-Order_Facial_Behavior_from_Universal_Stimulus-Reaction_by_Dyadic_ICCV_2023_paper.html",
        "author": "Xiaotian Li, Taoyue Wang, Geran Zhao, Xiang Zhang, Xi Kang, Lijun Yin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_ReactioNet_Learning_High-Order_Facial_Behavior_from_Universal_Stimulus-Reaction_by_Dyadic_ICCV_2023_paper.pdf",
        "aff": "State University of New York at Binghamton",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Read-only Prompt Optimization for Vision-Language Few-shot Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Read-only_Prompt_Optimization_for_Vision-Language_Few-shot_Learning_ICCV_2023_paper.html",
        "author": "Dongjun Lee, Seokwon Song, Jihee Suh, Joonmyeong Choi, Sanghyeok Lee, Hyunwoo J. Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Read-only_Prompt_Optimization_for_Vision-Language_Few-shot_Learning_ICCV_2023_paper.pdf",
        "aff": "Korea University",
        "project": "",
        "github": "https://github.com/mlvlab/RPO",
        "arxiv": "2308.14960"
    },
    {
        "title": "Real-Time Neural Rasterization for Large Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Real-Time_Neural_Rasterization_for_Large_Scenes_ICCV_2023_paper.html",
        "author": "Jeffrey Yunfan Liu, Yun Chen, Ze Yang, Jingkang Wang, Sivabalan Manivasagam, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Real-Time_Neural_Rasterization_for_Large_Scenes_ICCV_2023_paper.pdf",
        "aff": "Waabi, University of Toronto, University of Waterloo; Waabi, University of Toronto",
        "project": "https://waabi.ai/neuras/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RealGraph: A Multiview Dataset for 4D Real-world Context Graph Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_RealGraph_A_Multiview_Dataset_for_4D_Real-world_Context_Graph_Generation_ICCV_2023_paper.html",
        "author": "Haozhe Lin, Zequn Chen, Jinzhi Zhang, Bing Bai, Yu Wang, Ruqi Huang, Lu Fang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_RealGraph_A_Multiview_Dataset_for_4D_Real-world_Context_Graph_Generation_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University",
        "project": "",
        "github": "https://github.com/THU-luvision/RealGraph",
        "arxiv": ""
    },
    {
        "title": "Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Realistic_Full-Body_Tracking_from_Sparse_Observations_via_Joint-Level_Modeling_ICCV_2023_paper.html",
        "author": "Xiaozheng Zheng, Zhuo Su, Chao Wen, Zhou Xue, Xiaojie Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Realistic_Full-Body_Tracking_from_Sparse_Observations_via_Joint-Level_Modeling_ICCV_2023_paper.pdf",
        "aff": "ByteDance Inc",
        "project": "https://zxz267.github.io/AvatarJLM",
        "github": "",
        "arxiv": "2308.08855"
    },
    {
        "title": "RecRecNet: Rectangling Rectified Wide-Angle Images by Thin-Plate Spline Model and DoF-based Curriculum Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liao_RecRecNet_Rectangling_Rectified_Wide-Angle_Images_by_Thin-Plate_Spline_Model_and_ICCV_2023_paper.html",
        "author": "Kang Liao, Lang Nie, Chunyu Lin, Zishuo Zheng, Yao Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_RecRecNet_Rectangling_Rectified_Wide-Angle_Images_by_Thin-Plate_Spline_Model_and_ICCV_2023_paper.pdf",
        "aff": "Institute of Information Science, Beijing Jiaotong University",
        "project": "",
        "github": "https://github.com/KangLiao929/RecRecNet",
        "arxiv": "2301.01661"
    },
    {
        "title": "Reconciling Object-Level and Global-Level Objectives for Long-Tail Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Reconciling_Object-Level_and_Global-Level_Objectives_for_Long-Tail_Detection_ICCV_2023_paper.html",
        "author": "Shaoyu Zhang, Chen Chen, Silong Peng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Reconciling_Object-Level_and_Global-Level_Objectives_for_Long-Tail_Detection_ICCV_2023_paper.pdf",
        "aff": "Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Beijing Visystem Co. Ltd, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "https://github.com/EricZsy/ROG",
        "arxiv": ""
    },
    {
        "title": "Reconstructed Convolution Module Based Look-Up Tables for Efficient Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html",
        "author": "Guandu Liu, Yukang Ding, Mading Li, Ming Sun, Xing Wen, Bin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "School of Software, Tsinghua University; Beijing National Research Center for Information Science and Technology (BNRist), China; Kuaishou Technology",
        "project": "",
        "github": "https://github.com/liuguandu/RC-LUT",
        "arxiv": "2307.08544"
    },
    {
        "title": "Reconstructing Groups of People with Hypergraph Relational Reasoning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Reconstructing_Groups_of_People_with_Hypergraph_Relational_Reasoning_ICCV_2023_paper.html",
        "author": "Buzhen Huang, Jingyi Ju, Zhihao Li, Yangang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Reconstructing_Groups_of_People_with_Hypergraph_Relational_Reasoning_ICCV_2023_paper.pdf",
        "aff": "Southeast University, China; Huawei Noah\u2019s Ark Lab",
        "project": "",
        "github": "https://github.com/boycehbz/GroupRec",
        "arxiv": "2308.15844"
    },
    {
        "title": "Reconstructing Interacting Hands with Interaction Prior from Monocular Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zuo_Reconstructing_Interacting_Hands_with_Interaction_Prior_from_Monocular_Images_ICCV_2023_paper.html",
        "author": "Binghui Zuo, Zimeng Zhao, Wenqian Sun, Wei Xie, Zhou Xue, Yangang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zuo_Reconstructing_Interacting_Hands_with_Interaction_Prior_from_Monocular_Images_ICCV_2023_paper.pdf",
        "aff": "Southeast University, China; Pico IDL, ByteDance, Beijing",
        "project": "",
        "github": "https://github.com/binghui-z/InterPrior_pytorch",
        "arxiv": "2308.14082"
    },
    {
        "title": "Recovering a Molecule's 3D Dynamics from Liquid-phase Electron Microscopy Movies",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Recovering_a_Molecules_3D_Dynamics_from_Liquid-phase_Electron_Microscopy_Movies_ICCV_2023_paper.html",
        "author": "Enze Ye, Yuhang Wang, Hong Zhang, Yiqin Gao, Huan Wang, He Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Recovering_a_Molecules_3D_Dynamics_from_Liquid-phase_Electron_Microscopy_Movies_ICCV_2023_paper.pdf",
        "aff": "College of Chemistry and Molecular Engineering, Peking University, Beijing, China.; National Biomedical Imaging Center, Peking University, Beijing, China.; National Biomedical Imaging Center, Peking University, Beijing, China.; College of Chemistry and Molecular Engineering, Peking University, Beijing, China.; DP Technology, Ltd., Beijing, China.; National Biomedical Imaging Center, Peking University, Beijing, China.; College of Future Technology, Peking University, Beijing, China.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Recursive Video Lane Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Recursive_Video_Lane_Detection_ICCV_2023_paper.html",
        "author": "Dongkwon Jin, Dahyun Kim, Chang-Su Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Recursive_Video_Lane_Detection_ICCV_2023_paper.pdf",
        "aff": "Korea University",
        "project": "",
        "github": "https://github.com/dongkwonjin/RVLD",
        "arxiv": "2308.11106"
    },
    {
        "title": "RecursiveDet: End-to-End Region-Based Recursive Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_RecursiveDet_End-to-End_Region-Based_Recursive_Object_Detection_ICCV_2023_paper.html",
        "author": "Jing Zhao, Li Sun, Qingli Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_RecursiveDet_End-to-End_Region-Based_Recursive_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, Key Laboratory of Advanced Theory and Application in Statistics and Data Science, East China Normal University, Shanghai, China",
        "project": "",
        "github": "https://github.com/bravezzzzzz/RecursiveDet",
        "arxiv": "2307.13619"
    },
    {
        "title": "Reducing Training Time in Cross-Silo Federated Learning Using Multigraph Topology",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Do_Reducing_Training_Time_in_Cross-Silo_Federated_Learning_Using_Multigraph_Topology_ICCV_2023_paper.html",
        "author": "Tuong Do, Binh X. Nguyen, Vuong Pham, Toan Tran, Erman Tjiputra, Quang D. Tran, Anh Nguyen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Do_Reducing_Training_Time_in_Cross-Silo_Federated_Learning_Using_Multigraph_Topology_ICCV_2023_paper.pdf",
        "aff": "University of Liverpool, UK; AIOZ, Singapore; VinAI Research, Vietnam",
        "project": "",
        "github": "https://github.com/aioz-ai/MultigraphFL",
        "arxiv": "2207.09657"
    },
    {
        "title": "Ref-NeuS: Ambiguity-Reduced Neural Implicit Surface Learning for Multi-View Reconstruction with Reflection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Ref-NeuS_Ambiguity-Reduced_Neural_Implicit_Surface_Learning_for_Multi-View_Reconstruction_with_ICCV_2023_paper.html",
        "author": "Wenhang Ge, Tao Hu, Haoyu Zhao, Shu Liu, Ying-Cong Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Ref-NeuS_Ambiguity-Reduced_Neural_Implicit_Surface_Learning_for_Multi-View_Reconstruction_with_ICCV_2023_paper.pdf",
        "aff": "1HKUST(GZ); 1HKUST(GZ)2HKUST(GZ)-SmartMore Joint Lab; 4CUHK; 1HKUST(GZ)2HKUST(GZ)-SmartMore Joint Lab3HKUST; 5SmartMore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RefEgo: Referring Expression Comprehension Dataset from First-Person Perception of Ego4D",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kurita_RefEgo_Referring_Expression_Comprehension_Dataset_from_First-Person_Perception_of_Ego4D_ICCV_2023_paper.html",
        "author": "Shuhei Kurita, Naoki Katsura, Eri Onami",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kurita_RefEgo_Referring_Expression_Comprehension_Dataset_from_First-Person_Perception_of_Ego4D_ICCV_2023_paper.pdf",
        "aff": "University of Tsukuba; RIKEN; Nara Institute of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2308.12035"
    },
    {
        "title": "Reference-guided Controllable Inpainting of Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mirzaei_Reference-guided_Controllable_Inpainting_of_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Ashkan Mirzaei, Tristan Aumentado-Armstrong, Marcus A. Brubaker, Jonathan Kelly, Alex Levinshtein, Konstantinos G. Derpanis, Igor Gilitschenski",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mirzaei_Reference-guided_Controllable_Inpainting_of_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "University of Toronto; York University; Samsung AI Centre Toronto; Vector Institute for AI",
        "project": "Please visit our project page.",
        "github": "",
        "arxiv": "2304.09677"
    },
    {
        "title": "Referring Image Segmentation Using Text Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Referring_Image_Segmentation_Using_Text_Supervision_ICCV_2023_paper.html",
        "author": "Fang Liu, Yuhao Liu, Yuqiu Kong, Ke Xu, Lihe Zhang, Baocai Yin, Gerhard Hancke, Rynson Lau",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Referring_Image_Segmentation_Using_Text_Supervision_ICCV_2023_paper.pdf",
        "aff": "Dalian University of Technology; City University of Hong Kong",
        "project": "",
        "github": "https://github.com/fawnliu/TRIS",
        "arxiv": "2308.14575"
    },
    {
        "title": "RegFormer: An Efficient Projection-Aware Transformer Network for Large-Scale Point Cloud Registration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_RegFormer_An_Efficient_Projection-Aware_Transformer_Network_for_Large-Scale_Point_Cloud_ICCV_2023_paper.html",
        "author": "Jiuming Liu, Guangming Wang, Zhe Liu, Chaokang Jiang, Marc Pollefeys, Hesheng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_RegFormer_An_Efficient_Projection-Aware_Transformer_Network_for_Large-Scale_Point_Cloud_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Shanghai Jiao Tong University; China University of Mining and Technology; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; ETH Z\u00fcrich",
        "project": "",
        "github": "https://github.com/IRMVLab/RegFormer",
        "arxiv": "2303.12384"
    },
    {
        "title": "Regularized Mask Tuning: Uncovering Hidden Knowledge in Pre-Trained Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Regularized_Mask_Tuning_Uncovering_Hidden_Knowledge_in_Pre-Trained_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Kecheng Zheng, Wei Wu, Ruili Feng, Kai Zhu, Jiawei Liu, Deli Zhao, Zheng-Jun Zha, Wei Chen, Yujun Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Regularized_Mask_Tuning_Uncovering_Hidden_Knowledge_in_Pre-Trained_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "Regularized Mask Tuning: Uncovering Hidden Knowledge\nin Pre-trained Vision-Language Models\nKecheng Zheng\u2020,1,2Wei Wu\u2020,4Ruili Feng4Kai Zhu4Jiawei Liu4\nDeli Zhao3Zheng-Jun Zha4Wei Chen1Yujun Shen2\n1State Key Lab of CAD&CG, Zhejiang University2Ant Group3Alibaba Group4USTC\nAbstract\nPrompt tuning and adapter tuning have shown great po-\ntential in transferring pre-trained vision-language models\n(VLMs) to various downstream tasks. In this work, we\ndesign a new type of tuning method, termed as regularized\nmask tuning , which masks the network parameters through\na learnable selection. Inspired by neural pathways, we\nargue that the knowledge required by a downstream task\nalready exists in the pre-trained weights but just gets\nconcealed in the upstream pre-training stage. To bring the\nuseful knowledge back into light, we first identify a set of\nparameters that are important to a given downstream task,\nthen attach a binary mask to each parameter, and finally\noptimize these masks on the downstream data with the\nparameters frozen. When updating the mask, we introduce a\nnovel gradient dropout strategy to regularize the parameter\nselection, in order to prevent the model from forgetting old\nknowledge and overfitting the downstream data. Experi-\nmental results on 11 datasets demonstrate the consistent\nsuperiority of our method over previous alternatives. It is\nnoteworthy that we manage to deliver 18.73% performance\nimprovement compared to the zero-shot CLIP via masking\nan average of only 2.56% parameters. Furthermore, our\nmethod is synergistic with most existing parameter-efficient\ntuning methods and can boost the performance on top of\nthem. Project page can be found here.\n1. Introduction\nThe advent of large-scale pre-trained vision-language\nmodels (VLMs) [30] has ushered in a new era of incor-\nporating language features to supervise the image encoder\nfor a wide range of downstream visual tasks, such as few-\nshot learning [47] and open-world detection [8]. Thanks\nto the multimodal architecture and millions of text-image\npairs from the web, VLMs exhibit exceptional zero-shot\ntransferability in downstream tasks. To further enhance\n\u2020indicates equal contribution.\nMask\nText  Encoder\nImage Encoder\nLearnable Text\n [CLASS]\nLearnable Image\n(a) Prompt Tuning\n(c) Regularized Mask Tuning  - Ours\nText  Encoder\nImage Encoder\n(b) Adapter  Tuning\nExtra \nArchitecture\u201ca photo of a \n[CLASS] \u201d\nText  Encoder\nImage Encoder\n\u201ca photo of a \n[CLASS] \u201d\nKey \nPara.\nInference \nTimeAccuracyCoop\nTip-\nAdapter\nR-AMTInference \nTimeAccuracyInference \nTimeAccuracy7.45 FPS\n51.81 FPS\n62.11 FPS\n83.96%81.24%79.90%7.45 FPS\n83.16%\n(+3.26% )+R-AMT\n+R-AMT\n51.81 FPS\n84.37%\n(+3.13% )Figure 1. Concept diagrams of (a) prompt tuning [47, 39], (b)\nadapter tuning [12, 43], and (c) our regularized mask tuning . The\ntables on the right of (a)(b) demonstrate the inference time and\naccuracy of the existing tuning method before and after combining\nwith our regularized mask tuning method (R-AMT). The R-\nAMT significantly boosts their performance without introducing\nadditional inference time. \u201cKey Para.\u201d refers to the identified\nkey parameters ( e.g., multi-head self-attetnion). Flames and\nsnowflakes refer to learnable and frozen parameters, respectively.\nthe transferability of VLMs, researchers have proposed\nefficient tuning methods, such as adapter tuning [12, 43] or\nprompt tuning [47, 39, 24]. These techniques incorporate\na small number of task-specific parameters and train them\nsolely on the downstream task, thus significantly improving\nthe performance and reducing computational requirements.\nThe essence of efficient tuning methods lies in two\nfundamental components, i.e. leveraging the well-learned\nknowledge structure of VLMs and efficiently exploring the\ntask-specific knowledge given few-shot data. Despite its\npotential, however, most existing efficient transfer learn-\ning approaches direct utilize all parameters of pre-trained\nVLMs and do not consider further unleashing the potential\n1\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n11663\n",
        "project": "",
        "github": "",
        "arxiv": "2307.15049"
    },
    {
        "title": "Regularized Primitive Graph Learning for Unified Vector Mapping",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Regularized_Primitive_Graph_Learning_for_Unified_Vector_Mapping_ICCV_2023_paper.html",
        "author": "Lei Wang, Min Dai, Jianan He, Jingwei Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Regularized_Primitive_Graph_Learning_for_Unified_Vector_Mapping_ICCV_2023_paper.pdf",
        "aff": "Riemann Lab, Huawei Technologies",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Rehearsal-Free Domain Continual Face Anti-Spoofing: Generalize More and Forget Less",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Rehearsal-Free_Domain_Continual_Face_Anti-Spoofing_Generalize_More_and_Forget_Less_ICCV_2023_paper.html",
        "author": "Rizhao Cai, Yawen Cui, Zhi Li, Zitong Yu, Haoliang Li, Yongjian Hu, Alex Kot",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Rehearsal-Free_Domain_Continual_Face_Anti-Spoofing_Generalize_More_and_Forget_Less_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; School of Computing and Information Technology, Great Bay University; Rapid-Rich Object Search (ROSE) Lab, NTU-PKU Joint Research Institute, Nanyang Technological University; South China University of Technology; Bytedance Ltd.; University of Oulu",
        "project": "",
        "github": "https://github.com/RizhaoCai/DCL-FAS-ICCV2023",
        "arxiv": ""
    },
    {
        "title": "Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Faghri_Reinforce_Data_Multiply_Impact_Improved_Model_Accuracy_and_Robustness_with_ICCV_2023_paper.html",
        "author": "Fartash Faghri, Hadi Pouransari, Sachin Mehta, Mehrdad Farajtabar, Ali Farhadi, Mohammad Rastegari, Oncel Tuzel",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Faghri_Reinforce_Data_Multiply_Impact_Improved_Model_Accuracy_and_Robustness_with_ICCV_2023_paper.pdf",
        "aff": "Apple",
        "project": "",
        "github": "https://github.com/apple/ml-dr",
        "arxiv": "2303.08983"
    },
    {
        "title": "Reinforced Disentanglement for Face Swapping without Skip Connection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Reinforced_Disentanglement_for_Face_Swapping_without_Skip_Connection_ICCV_2023_paper.html",
        "author": "Xiaohang Ren, Xingyu Chen, Pengfei Yao, Heung-Yeung Shum, Baoyuan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Reinforced_Disentanglement_for_Face_Swapping_without_Skip_Connection_ICCV_2023_paper.pdf",
        "aff": "Xiaobing.AI",
        "project": "",
        "github": "",
        "arxiv": "2307.07928"
    },
    {
        "title": "Relightify: Relightable 3D Faces from a Single Image via Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.html",
        "author": "Foivos Paraperas Papantoniou, Alexandros Lattas, Stylianos Moschoglou, Stefanos Zafeiriou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.pdf",
        "aff": "Imperial College London, Huawei Noah\u2019s Ark Lab",
        "project": "",
        "github": "",
        "arxiv": "2305.06077"
    },
    {
        "title": "Remembering Normality: Memory-guided Knowledge Distillation for Unsupervised Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Remembering_Normality_Memory-guided_Knowledge_Distillation_for_Unsupervised_Anomaly_Detection_ICCV_2023_paper.html",
        "author": "Zhihao Gu, Liang Liu, Xu Chen, Ran Yi, Jiangning Zhang, Yabiao Wang, Chengjie Wang, Annan Shu, Guannan Jiang, Lizhuang Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Remembering_Normality_Memory-guided_Knowledge_Distillation_for_Unsupervised_Anomaly_Detection_ICCV_2023_paper.pdf",
        "aff": "CATL, China; Shanghai Jiao Tong University, China; Tencent YouTu Lab, China; Shanghai Jiao Tong University, China and Tencent YouTu Lab, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Removing Anomalies as Noises for Industrial Defect Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Removing_Anomalies_as_Noises_for_Industrial_Defect_Localization_ICCV_2023_paper.html",
        "author": "Fanbin Lu, Xufeng Yao, Chi-Wing Fu, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Removing_Anomalies_as_Noises_for_Industrial_Defect_Localization_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong and SmartMore; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RenderIH: A Large-Scale Synthetic Dataset for 3D Interacting Hand Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_RenderIH_A_Large-Scale_Synthetic_Dataset_for_3D_Interacting_Hand_Pose_ICCV_2023_paper.html",
        "author": "Lijun Li, Linrui Tian, Xindi Zhang, Qi Wang, Bang Zhang, Liefeng Bo, Mengyuan Liu, Chen Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RenderIH_A_Large-Scale_Synthetic_Dataset_for_3D_Interacting_Hand_Pose_ICCV_2023_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida; Key Laboratory of Machine Perception, Shenzhen Graduate School, Peking University; Alibaba Group; Alibaba Group, Shanghai Artificial Intelligence Laboratory",
        "project": "",
        "github": "https://github.com/adwardlee/RenderIH",
        "arxiv": "2309.09301"
    },
    {
        "title": "Rendering Humans from Object-Occluded Monocular Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Rendering_Humans_from_Object-Occluded_Monocular_Videos_ICCV_2023_paper.html",
        "author": "Tiange Xiang, Adam Sun, Jiajun Wu, Ehsan Adeli, Li Fei-Fei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Rendering_Humans_from_Object-Occluded_Monocular_Videos_ICCV_2023_paper.pdf",
        "aff": "Stanford University",
        "project": "https://cs.stanford.edu/~xtiange/projects/occnerf/",
        "github": "",
        "arxiv": "2308.04622"
    },
    {
        "title": "RepQ-ViT: Scale Reparameterization for Post-Training Quantization of Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_RepQ-ViT_Scale_Reparameterization_for_Post-Training_Quantization_of_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Zhikai Li, Junrui Xiao, Lianwei Yang, Qingyi Gu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RepQ-ViT_Scale_Reparameterization_for_Post-Training_Quantization_of_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "Institute of Automation, Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/zkkli/RepQ-ViT",
        "arxiv": ""
    },
    {
        "title": "Replay: Multi-modal Multi-view Acted Videos for Casual Holography",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shapovalov_Replay_Multi-modal_Multi-view_Acted_Videos_for_Casual_Holography_ICCV_2023_paper.html",
        "author": "Roman Shapovalov, Yanir Kleiman, Ignacio Rocco, David Novotny, Andrea Vedaldi, Changan Chen, Filippos Kokkinos, Ben Graham, Natalia Neverova",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shapovalov_Replay_Multi-modal_Multi-view_Acted_Videos_for_Casual_Holography_ICCV_2023_paper.pdf",
        "aff": "\u2020; Not provided; Meta UT Austin\u2020\u21e4equal contribution",
        "project": "https://replay-dataset.github.io/",
        "github": "https://github.com/replay-dataset",
        "arxiv": "2307.12067"
    },
    {
        "title": "Representation Disparity-aware Distillation for 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Representation_Disparity-aware_Distillation_for_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Yanjing Li, Sheng Xu, Mingbao Lin, Jihao Yin, Baochang Zhang, Xianbin Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Representation_Disparity-aware_Distillation_for_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Beihang University, Zhongguancun Laboratory, Nanchang Institute of Technology; Tencent; Beihang University",
        "project": "",
        "github": "https://github.com/YanjingLi0202/RDD",
        "arxiv": "2308.10308"
    },
    {
        "title": "Representation Uncertainty in Self-Supervised Learning as Variational Inference",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nakamura_Representation_Uncertainty_in_Self-Supervised_Learning_as_Variational_Inference_ICCV_2023_paper.html",
        "author": "Hiroki Nakamura, Masashi Okada, Tadahiro Taniguchi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_Representation_Uncertainty_in_Self-Supervised_Learning_as_Variational_Inference_ICCV_2023_paper.pdf",
        "aff": "Ritsumeikan University; Panasonic Holdings Corp.",
        "project": "",
        "github": "",
        "arxiv": "2203.11437"
    },
    {
        "title": "ResQ: Residual Quantization for Video Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Abati_ResQ_Residual_Quantization_for_Video_Perception_ICCV_2023_paper.html",
        "author": "Davide Abati, Haitam Ben Yahia, Markus Nagel, Amirhossein Habibian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Abati_ResQ_Residual_Quantization_for_Video_Perception_ICCV_2023_paper.pdf",
        "aff": "Qualcomm AI Research",
        "project": "",
        "github": "",
        "arxiv": "2308.09511"
    },
    {
        "title": "Residual Pattern Learning for Pixel-Wise Out-of-Distribution Detection in Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Yuyuan Liu, Choubo Ding, Yu Tian, Guansong Pang, Vasileios Belagiannis, Ian Reid, Gustavo Carneiro",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Harvard University; Singapore Management University; University of Surrey; Friedrich-Alexander-Universit \u00a8at Erlangen-N \u00a8urnberg; Australian Institute for Machine Learning, University of Adelaide",
        "project": "",
        "github": "https://github.com/yyliu01/RPL",
        "arxiv": "2211.14512"
    },
    {
        "title": "Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-centric Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Rethinking_Amodal_Video_Segmentation_from_Learning_Supervised_Signals_with_Object-centric_ICCV_2023_paper.html",
        "author": "Ke Fan, Jingshi Lei, Xuelin Qian, Miaopeng Yu, Tianjun Xiao, Tong He, Zheng Zhang, Yanwei Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Rethinking_Amodal_Video_Segmentation_from_Learning_Supervised_Signals_with_Object-centric_ICCV_2023_paper.pdf",
        "aff": "Fudan University; Amazon Web Service",
        "project": "",
        "github": "https://github.com/kfan21/EoRaS",
        "arxiv": "2309.13248"
    },
    {
        "title": "Rethinking Data Distillation: Do Not Overlook Calibration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Rethinking_Data_Distillation_Do_Not_Overlook_Calibration_ICCV_2023_paper.html",
        "author": "Dongyao Zhu, Bowen Lei, Jie Zhang, Yanbo Fang, Yiqun Xie, Ruqi Zhang, Dongkuan Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Rethinking_Data_Distillation_Do_Not_Overlook_Calibration_ICCV_2023_paper.pdf",
        "aff": "North Carolina State University; University of Maryland, College Park; Purdue University; University of California, San Diego; Zhejiang University; Texas A&M University; Certik",
        "project": "",
        "github": "https://github.com/DongyaoZhu/calibrate-networks-trained-on-distilled-datasets",
        "arxiv": "2307.12463"
    },
    {
        "title": "Rethinking Fast Fourier Convolution in Image Inpainting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.html",
        "author": "Tianyi Chu, Jiafu Chen, Jiakai Sun, Shuobin Lian, Zhizhong Wang, Zhiwen Zuo, Lei Zhao, Wei Xing, Dongming Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.pdf",
        "aff": "College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Zhejiang Gongshang University, Hangzhou, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Rethinking Mobile Block for Efficient Attention-based Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Rethinking_Mobile_Block_for_Efficient_Attention-based_Models_ICCV_2023_paper.html",
        "author": "Jiangning Zhang, Xiangtai Li, Jian Li, Liang Liu, Zhucun Xue, Boshen Zhang, Zhengkai Jiang, Tianxin Huang, Yabiao Wang, Chengjie Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Rethinking_Mobile_Block_for_Efficient_Attention-based_Models_ICCV_2023_paper.pdf",
        "aff": "Peking University; Wuhan University; Zhejiang University; Youtu Lab, Tencent",
        "project": "",
        "github": "https://github.com/zhangzjn/EMO",
        "arxiv": "2301.01146"
    },
    {
        "title": "Rethinking Multi-Contrast MRI Super-Resolution: Rectangle-Window Cross-Attention Transformer and Arbitrary-Scale Upsampling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.html",
        "author": "Guangyuan Li, Lei Zhao, Jiakai Sun, Zehua Lan, Zhanjie Zhang, Jiafu Chen, Zhijie Lin, Huaizhong Lin, Wei Xing",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University of Science and Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",
        "project": "",
        "github": "https://github.com/GuangYuanKK/McASSR",
        "arxiv": ""
    },
    {
        "title": "Rethinking Point Cloud Registration as Masking and Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Rethinking_Point_Cloud_Registration_as_Masking_and_Reconstruction_ICCV_2023_paper.html",
        "author": "Guangyan Chen, Meiling Wang, Li Yuan, Yi Yang, Yufeng Yue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Rethinking_Point_Cloud_Registration_as_Masking_and_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Peking University; Beijing Institute of Technology",
        "project": "",
        "github": "https://github.com/CGuangyan-BIT/MRA",
        "arxiv": ""
    },
    {
        "title": "Rethinking Pose Estimation in Crowds: Overcoming the Detection Information Bottleneck and Ambiguity",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.html",
        "author": "Mu Zhou, Lucas Stoffl, Mackenzie Weygandt Mathis, Alexander Mathis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.pdf",
        "aff": "\u00b4Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne (EPFL)",
        "project": "",
        "github": "https://github.com/amathislab/BUCTD",
        "arxiv": "2306.07879"
    },
    {
        "title": "Rethinking Range View Representation for LiDAR Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Rethinking_Range_View_Representation_for_LiDAR_Segmentation_ICCV_2023_paper.html",
        "author": "Lingdong Kong, Youquan Liu, Runnan Chen, Yuexin Ma, Xinge Zhu, Yikang Li, Yuenan Hou, Yu Qiao, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Rethinking_Range_View_Representation_for_LiDAR_Segmentation_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; Shanghai AI Laboratory; S-Lab, Nanyang Technological University; Shanghai AI Laboratory, National University of Singapore; Shanghai AI Laboratory, Hochschule Bremerhaven; ShanghaiTech University; Shanghai AI Laboratory, The University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2303.05367"
    },
    {
        "title": "Rethinking Safe Semi-supervised Learning: Transferring the Open-set Problem to A Close-set One",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Rethinking_Safe_Semi-supervised_Learning_Transferring_the_Open-set_Problem_to_A_ICCV_2023_paper.html",
        "author": "Qiankun Ma, Jiyao Gao, Bo Zhan, Yunpeng Guo, Jiliu Zhou, Yan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Rethinking_Safe_Semi-supervised_Learning_Transferring_the_Open-set_Problem_to_A_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Sichuan University, Chengdu, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Rethinking Video Frame Interpolation from Shutter Mode Induced Degradation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.html",
        "author": "Xiang Ji, Zhixiang Wang, Zhihang Zhong, Yinqiang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.pdf",
        "aff": "The University of Tokyo, Japan; National Institute of Informatics, Japan; The University of Tokyo, Japan",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Rethinking Vision Transformers for MobileNet Size and Speed",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Rethinking_Vision_Transformers_for_MobileNet_Size_and_Speed_ICCV_2023_paper.html",
        "author": "Yanyu Li, Ju Hu, Yang Wen, Georgios Evangelidis, Kamyar Salahi, Yanzhi Wang, Sergey Tulyakov, Jian Ren",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Vision_Transformers_for_MobileNet_Size_and_Speed_ICCV_2023_paper.pdf",
        "aff": "Snap Inc., Northeastern University; Northeastern University; UC Berkeley; Snap Inc.",
        "project": "",
        "github": "https://github.com/snap-research/EfficientFormer",
        "arxiv": "2212.08059"
    },
    {
        "title": "Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Rethinking_the_Role_of_Pre-Trained_Networks_in_Source-Free_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Wenyu Zhang, Li Shen, Chuan-Sheng Foo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Rethinking_the_Role_of_Pre-Trained_Networks_in_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR); Centre for Frontier AI Research (CFAR), Agency for Science, Technology and Research (A*STAR); Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR)",
        "project": "",
        "github": "",
        "arxiv": "2212.07585"
    },
    {
        "title": "Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Retinexformer_One-stage_Retinex-based_Transformer_for_Low-light_Image_Enhancement_ICCV_2023_paper.html",
        "author": "Yuanhao Cai, Hao Bian, Jing Lin, Haoqian Wang, Radu Timofte, Yulun Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Retinexformer_One-stage_Retinex-based_Transformer_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf",
        "aff": "University of W\u00fcrzburg; Tsinghua University; ETH Z\u00fcrich",
        "project": "",
        "github": "https://github.com/caiyuanhao1998/Retinexformer",
        "arxiv": "2303.06705"
    },
    {
        "title": "Retro-FPN: Retrospective Feature Pyramid Network for Point Cloud Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Peng Xiang, Xin Wen, Yu-Shen Liu, Hui Zhang, Yi Fang, Zhizhong Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Wayne State University; New York University Abu Dhabi; JD.com, Beijing, China; School of Software, Tsinghua University, Beijing, China",
        "project": "",
        "github": "https://github.com/AllenXiangX/Retro-FPN",
        "arxiv": ""
    },
    {
        "title": "Revisit PCA-based Technique for Out-of-Distribution Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guan_Revisit_PCA-based_Technique_for_Out-of-Distribution_Detection_ICCV_2023_paper.html",
        "author": "Xiaoyuan Guan, Zhouwu Liu, Wei-Shi Zheng, Yuren Zhou, Ruixuan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_Revisit_PCA-based_Technique_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen Univerisity, Guangzhou, China; Peng Cheng Laboratory, Shenzhen, China; School of Computer Science and Engineering, Sun Yat-sen Univerisity, Guangzhou, China",
        "project": "",
        "github": "https://github.com/SYSU-MIA-GROUP/pca-based-out-of-distribution-detection",
        "arxiv": ""
    },
    {
        "title": "Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Revisiting_Domain-Adaptive_3D_Object_Detection_by_Reliable_Diverse_and_Class-balanced_ICCV_2023_paper.html",
        "author": "Zhuoxiao Chen, Yadan Luo, Zheng Wang, Mahsa Baktashmotlagh, Zi Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Revisiting_Domain-Adaptive_3D_Object_Detection_by_Reliable_Diverse_and_Class-balanced_ICCV_2023_paper.pdf",
        "aff": "The University of Queensland; University of Electronic Science and Technology of China",
        "project": "",
        "github": "https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet",
        "arxiv": "2307.07944"
    },
    {
        "title": "Revisiting Foreground and Background Separation in Weakly-supervised Temporal Action Localization: A Clustering-based Approach",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Revisiting_Foreground_and_Background_Separation_in_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.html",
        "author": "Qinying Liu, Zilei Wang, Shenghai Rong, Junjie Li, Yixin Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Revisiting_Foreground_and_Background_Separation_in_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/Qinying-Liu/CASE",
        "arxiv": ""
    },
    {
        "title": "Revisiting Scene Text Recognition: A Data Perspective",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Revisiting_Scene_Text_Recognition_A_Data_Perspective_ICCV_2023_paper.html",
        "author": "Qing Jiang, Jiapeng Wang, Dezhi Peng, Chongyu Liu, Lianwen Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Revisiting_Scene_Text_Recognition_A_Data_Perspective_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology",
        "project": "https://union14m.github.io/",
        "github": "https://github.com/Mountchicken/Union14M",
        "arxiv": "2307.08723"
    },
    {
        "title": "Revisiting Vision Transformer from the View of Path Ensemble",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chang_Revisiting_Vision_Transformer_from_the_View_of_Path_Ensemble_ICCV_2023_paper.html",
        "author": "Shuning Chang, Pichao Wang, Hao Luo, Fan Wang, Mike Zheng Shou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Revisiting_Vision_Transformer_from_the_View_of_Path_Ensemble_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group; Show Lab, National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": "2308.06548"
    },
    {
        "title": "Revisiting the Parameter Efficiency of Adapters from the Perspective of Precision Redundancy",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jie_Revisiting_the_Parameter_Efficiency_of_Adapters_from_the_Perspective_of_ICCV_2023_paper.html",
        "author": "Shibo Jie, Haoqing Wang, Zhi-Hong Deng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jie_Revisiting_the_Parameter_Efficiency_of_Adapters_from_the_Perspective_of_ICCV_2023_paper.pdf",
        "aff": "School of Intelligence Science and Technology, Peking University",
        "project": "",
        "github": "https://github.com/JieShibo/PETL-ViT",
        "arxiv": "2307.16867"
    },
    {
        "title": "Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.html",
        "author": "Lukas Struppek, Dominik Hintersdorf, Kristian Kersting",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.pdf",
        "aff": "Technical University of Darmstadt, Centre for Cognitive Science, Hessian Center for AI (hessian.AI), German Research Center for Artificial Intelligence (DFKI)",
        "project": "",
        "github": "https://github.com/LukasStruppek/Rickrolling-the-Artist",
        "arxiv": "2211.02408"
    },
    {
        "title": "Robo3D: Towards Robust and Reliable 3D Perception against Corruptions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Robo3D_Towards_Robust_and_Reliable_3D_Perception_against_Corruptions_ICCV_2023_paper.html",
        "author": "Lingdong Kong, Youquan Liu, Xin Li, Runnan Chen, Wenwei Zhang, Jiawei Ren, Liang Pan, Kai Chen, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Robo3D_Towards_Robust_and_Reliable_3D_Perception_against_Corruptions_ICCV_2023_paper.pdf",
        "aff": "Shanghai AI Laboratory; Shanghai AI Laboratory, National University of Singapore, CNRS@CREATE; S-Lab, Nanyang Technological University; Shanghai AI Laboratory, Hochschule Bremerhaven; Shanghai AI Laboratory, East China Normal University; Shanghai AI Laboratory, The University of Hong Kong",
        "project": "",
        "github": "https://github.com/ldkong1205/Robo3D",
        "arxiv": "2303.17597"
    },
    {
        "title": "Robust Evaluation of Diffusion-Based Adversarial Purification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Robust_Evaluation_of_Diffusion-Based_Adversarial_Purification_ICCV_2023_paper.html",
        "author": "Minjong Lee, Dongwoo Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Robust_Evaluation_of_Diffusion-Based_Adversarial_Purification_ICCV_2023_paper.pdf",
        "aff": "CSED POSTECH; CSED, GSAI POSTECH",
        "project": "",
        "github": "",
        "arxiv": "2303.09051"
    },
    {
        "title": "Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Delattre_Robust_Frame-to-Frame_Camera_Rotation_Estimation_in_Crowded_Scenes_ICCV_2023_paper.html",
        "author": "Fabien Delattre, David Dirnfeld, Phat Nguyen, Stephen K Scarano, Michael J Jones, Pedro Miraldo, Erik Learned-Miller",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Delattre_Robust_Frame-to-Frame_Camera_Rotation_Estimation_in_Crowded_Scenes_ICCV_2023_paper.pdf",
        "aff": "University of Massachusetts Amherst; Mitsubishi Electric Research Laboratories (MERL)",
        "project": "",
        "github": "https://fabiendelattre.com/robust-rotation-estimation",
        "arxiv": "2309.08588"
    },
    {
        "title": "Robust Geometry-Preserving Depth Estimation Using Differentiable Rendering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Robust_Geometry-Preserving_Depth_Estimation_Using_Differentiable_Rendering_ICCV_2023_paper.html",
        "author": "Chi Zhang, Wei Yin, Gang Yu, Zhibin Wang, Tao Chen, Bin Fu, Joey Tianyi Zhou, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Geometry-Preserving_Depth_Estimation_Using_Differentiable_Rendering_ICCV_2023_paper.pdf",
        "aff": "Centre for Frontier AI Research, A\u2217STAR, Institute of High Performance Computing, A\u2217STAR; Fudan University; DJI Technology; Tencent; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2309.09724"
    },
    {
        "title": "Robust Heterogeneous Federated Learning under Data Corruption",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Robust_Heterogeneous_Federated_Learning_under_Data_Corruption_ICCV_2023_paper.html",
        "author": "Xiuwen Fang, Mang Ye, Xiyuan Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Robust_Heterogeneous_Federated_Learning_under_Data_Corruption_ICCV_2023_paper.pdf",
        "aff": "National Engineering Research Center for Multimedia Software, Institute of Artificial Intelligence, Hubei Key Laboratory of Multimedia and Network Communication Engineering, School of Computer Science, Hubei Luojia Laboratory, Wuhan University, Wuhan, China",
        "project": "",
        "github": "https://github.com/FangXiuwen/AugHFL",
        "arxiv": ""
    },
    {
        "title": "Robust Mixture-of-Expert Training for Convolutional Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.html",
        "author": "Yihua Zhang, Ruisi Cai, Tianlong Chen, Guanhua Zhang, Huan Zhang, Pin-Yu Chen, Shiyu Chang, Zhangyang Wang, Sijia Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University; IBM Research; University of Texas at Austin; Michigan State University; UC Santa Barbara",
        "project": "",
        "github": "https://github.com/OPTML-Group/Robust-MoE-CNN",
        "arxiv": "2308.10110"
    },
    {
        "title": "Robust Monocular Depth Estimation under Challenging Conditions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gasperini_Robust_Monocular_Depth_Estimation_under_Challenging_Conditions_ICCV_2023_paper.html",
        "author": "Stefano Gasperini, Nils Morbitzer, HyunJun Jung, Nassir Navab, Federico Tombari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gasperini_Robust_Monocular_Depth_Estimation_under_Challenging_Conditions_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich; Technical University of Munich, Google",
        "project": "",
        "github": "https://md4all.github.io",
        "arxiv": "2308.09711"
    },
    {
        "title": "Robust Object Modeling for Visual Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Robust_Object_Modeling_for_Visual_Tracking_ICCV_2023_paper.html",
        "author": "Yidong Cai, Jie Liu, Jie Tang, Gangshan Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Robust_Object_Modeling_for_Visual_Tracking_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "project": "",
        "github": "",
        "arxiv": "2308.05140"
    },
    {
        "title": "Robust One-Shot Face Video Re-enactment using Hybrid Latent Spaces of StyleGAN2",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Oorloff_Robust_One-Shot_Face_Video_Re-enactment_using_Hybrid_Latent_Spaces_of_ICCV_2023_paper.html",
        "author": "Trevine Oorloff, Yaser Yacoob",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Oorloff_Robust_One-Shot_Face_Video_Re-enactment_using_Hybrid_Latent_Spaces_of_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park, Maryland, USA",
        "project": "https://trevineoorloff.github.io/FaceVideoReenactment_HybridLatents.io/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Robust Referring Video Object Segmentation with Cyclic Structural Consensus",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Robust_Referring_Video_Object_Segmentation_with_Cyclic_Structural_Consensus_ICCV_2023_paper.html",
        "author": "Xiang Li, Jinglu Wang, Xiaohao Xu, Xiao Li, Bhiksha Raj, Yan Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Robust_Referring_Video_Object_Segmentation_with_Cyclic_Structural_Consensus_ICCV_2023_paper.pdf",
        "aff": "University of Michigan; Microsoft Research Asia; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Robust e-NeRF: NeRF from Sparse & Noisy Events under Non-Uniform Motion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Low_Robust_e-NeRF_NeRF_from_Sparse__Noisy_Events_under_Non-Uniform_ICCV_2023_paper.html",
        "author": "Weng Fei Low, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Low_Robust_e-NeRF_NeRF_from_Sparse__Noisy_Events_under_Non-Uniform_ICCV_2023_paper.pdf",
        "aff": "The NUS Graduate School\u2019s Integrative Sciences and Engineering Programme (ISEP), Institute of Data Science (IDS), National University of Singapore, Department of Computer Science, National University of Singapore",
        "project": "https://wengflow.github.io/robust-e-nerf",
        "github": "https://github.com/wengflow/robust-e-nerf",
        "arxiv": ""
    },
    {
        "title": "Robustifying Token Attention for Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Robustifying_Token_Attention_for_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Yong Guo, David Stutz, Bernt Schiele",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Robustifying_Token_Attention_for_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Informatics, Saarland Informatics Campus",
        "project": "",
        "github": "https://github.com/guoyongcs/TAPADL",
        "arxiv": "2303.11126"
    },
    {
        "title": "Role-Aware Interaction Generation from Textual Description",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tanaka_Role-Aware_Interaction_Generation_from_Textual_Description_ICCV_2023_paper.html",
        "author": "Mikihiro Tanaka, Kent Fujiwara",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tanaka_Role-Aware_Interaction_Generation_from_Textual_Description_ICCV_2023_paper.pdf",
        "aff": "LINE Corporation",
        "project": "",
        "github": "https://github.com/line/Human-Interaction-Generation",
        "arxiv": ""
    },
    {
        "title": "Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with Monocular Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Root_Pose_Decomposition_Towards_Generic_Non-rigid_3D_Reconstruction_with_Monocular_ICCV_2023_paper.html",
        "author": "Yikai Wang, Yinpeng Dong, Fuchun Sun, Xiao Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Root_Pose_Decomposition_Towards_Generic_Non-rigid_3D_Reconstruction_with_Monocular_ICCV_2023_paper.pdf",
        "aff": "Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University; RealAI; Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University",
        "project": "https://rpd-share.github.io",
        "github": "https://github.com/rpd-share",
        "arxiv": "2308.10089"
    },
    {
        "title": "Rosetta Neurons: Mining the Common Units in a Model Zoo",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dravid_Rosetta_Neurons_Mining_the_Common_Units_in_a_Model_Zoo_ICCV_2023_paper.html",
        "author": "Amil Dravid, Yossi Gandelsman, Alexei A. Efros, Assaf Shocher",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dravid_Rosetta_Neurons_Mining_the_Common_Units_in_a_Model_Zoo_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; Northwestern; UC Berkeley, Google",
        "project": "",
        "github": "https://yossigandelsman.github.io/rosetta_neurons",
        "arxiv": "2306.09346"
    },
    {
        "title": "S-TREK: Sequential Translation and Rotation Equivariant Keypoints for Local Feature Extraction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Santellani_S-TREK_Sequential_Translation_and_Rotation_Equivariant_Keypoints_for_Local_Feature_ICCV_2023_paper.html",
        "author": "Emanuele Santellani, Christian Sormann, Mattia Rossi, Andreas Kuhn, Friedrich Fraundorfer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Santellani_S-TREK_Sequential_Translation_and_Rotation_Equivariant_Keypoints_for_Local_Feature_ICCV_2023_paper.pdf",
        "aff": "Stuttgart Laboratory 1, SSS-EU, Sony Europe B.V.; Graz University of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit Surfaces",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_S-VolSDF_Sparse_Multi-View_Stereo_Regularization_of_Neural_Implicit_Surfaces_ICCV_2023_paper.html",
        "author": "Haoyu Wu, Alexandros Graikos, Dimitris Samaras",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_S-VolSDF_Sparse_Multi-View_Stereo_Regularization_of_Neural_Implicit_Surfaces_ICCV_2023_paper.pdf",
        "aff": "Stony Brook University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_S3IM_Stochastic_Structural_SIMilarity_and_Its_Unreasonable_Effectiveness_for_Neural_ICCV_2023_paper.html",
        "author": "Zeke Xie, Xindi Yang, Yujie Yang, Qi Sun, Yixiang Jiang, Haoran Wang, Yunfeng Cai, Mingming Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_S3IM_Stochastic_Structural_SIMilarity_and_Its_Unreasonable_Effectiveness_for_Neural_ICCV_2023_paper.pdf",
        "aff": "Baidu Research",
        "project": "",
        "github": "",
        "arxiv": "2308.07032"
    },
    {
        "title": "SA-BEV: Generating Semantic-Aware Bird's-Eye-View Feature for Multi-view 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_SA-BEV_Generating_Semantic-Aware_Birds-Eye-View_Feature_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Jinqing Zhang, Yanan Zhang, Qingjie Liu, Yunhong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SA-BEV_Generating_Semantic-Aware_Birds-Eye-View_Feature_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Zhongguancun Laboratory, Beijing, China; Hangzhou Innovation Institute, Beihang University, Hangzhou, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Hangzhou Innovation Institute, Beihang University, Hangzhou, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China",
        "project": "",
        "github": "https://github.com/mengtan00/SA-BEV.git",
        "arxiv": ""
    },
    {
        "title": "SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_SAFARI_Versatile_and_Efficient_Evaluations_for_Robustness_of_Interpretability_ICCV_2023_paper.html",
        "author": "Wei Huang, Xingyu Zhao, Gaojie Jin, Xiaowei Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_SAFARI_Versatile_and_Efficient_Evaluations_for_Robustness_of_Interpretability_ICCV_2023_paper.pdf",
        "aff": "University of Liverpool; University of Liverpool, Institute of Software, CAS; Purple Mountain Laboratories, University of Liverpool; University of Liverpool, WMG, University of Warwick",
        "project": "",
        "github": "",
        "arxiv": "2208.09418"
    },
    {
        "title": "SAFE: Machine Unlearning With Shard Graphs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dukler_SAFE_Machine_Unlearning_With_Shard_Graphs_ICCV_2023_paper.html",
        "author": "Yonatan Dukler, Benjamin Bowman, Alessandro Achille, Aditya Golatkar, Ashwin Swaminathan, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dukler_SAFE_Machine_Unlearning_With_Shard_Graphs_ICCV_2023_paper.pdf",
        "aff": "AWS AI Labs; AWS AI Labs, UCLA",
        "project": "",
        "github": "",
        "arxiv": "2304.13169"
    },
    {
        "title": "SAFE: Sensitivity-Aware Features for Out-of-Distribution Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wilson_SAFE_Sensitivity-Aware_Features_for_Out-of-Distribution_Object_Detection_ICCV_2023_paper.html",
        "author": "Samuel Wilson, Tobias Fischer, Feras Dayoub, Dimity Miller, Niko S\u00fcnderhauf",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wilson_SAFE_Sensitivity-Aware_Features_for_Out-of-Distribution_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "QUT Centre for Robotics, Queensland University of Technology; Australian Institute for Machine Learning, University of Adelaide",
        "project": "",
        "github": "",
        "arxiv": "2208.13930"
    },
    {
        "title": "SAFL-Net: Semantic-Agnostic Feature Learning Network with Auxiliary Plugins for Image Manipulation Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_SAFL-Net_Semantic-Agnostic_Feature_Learning_Network_with_Auxiliary_Plugins_for_Image_ICCV_2023_paper.html",
        "author": "Zhihao Sun, Haoran Jiang, Danding Wang, Xirong Li, Juan Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_SAFL-Net_Semantic-Agnostic_Feature_Learning_Network_with_Auxiliary_Plugins_for_Image_ICCV_2023_paper.pdf",
        "aff": "School of Mathematics Science, University of Chinese Academy of Sciences; MoE Key Lab of Data Engineering and Knowledge Engineering, Renmin University of China; Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SAGA: Spectral Adversarial Geometric Attack on 3D Meshes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Stolik_SAGA_Spectral_Adversarial_Geometric_Attack_on_3D_Meshes_ICCV_2023_paper.html",
        "author": "Tomer Stolik, Itai Lang, Shai Avidan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Stolik_SAGA_Spectral_Adversarial_Geometric_Attack_on_3D_Meshes_ICCV_2023_paper.pdf",
        "aff": "Tel Aviv University",
        "project": "",
        "github": "https://github.com/StolikTomer/SAGA",
        "arxiv": "2211.13775"
    },
    {
        "title": "SAL-ViT: Towards Latency Efficient Private Inference on ViT using Selective Attention Search with a Learnable Softmax Approximation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_SAL-ViT_Towards_Latency_Efficient_Private_Inference_on_ViT_using_Selective_ICCV_2023_paper.html",
        "author": "Yuke Zhang, Dake Chen, Souvik Kundu, Chenghao Li, Peter A. Beerel",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SAL-ViT_Towards_Latency_Efficient_Private_Inference_on_ViT_using_Selective_ICCV_2023_paper.pdf",
        "aff": "University of Southern California, Los Angeles, CA, USA; Intel Labs, San Diego, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Koo_SALAD_Part-Level_Latent_Diffusion_for_3D_Shape_Generation_and_Manipulation_ICCV_2023_paper.html",
        "author": "Juil Koo, Seungwoo Yoo, Minh Hieu Nguyen, Minhyuk Sung",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Koo_SALAD_Part-Level_Latent_Diffusion_for_3D_Shape_Generation_and_Manipulation_ICCV_2023_paper.pdf",
        "aff": "KAIST",
        "project": "https://salad3d.github.io",
        "github": "",
        "arxiv": "2303.12236"
    },
    {
        "title": "SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.html",
        "author": "Xiaoyu Zhou, Zhiwei Lin, Xiaojun Shan, Yongtao Wang, Deqing Sun, Ming-Hsuan Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University; University of California, Merced; Google Research",
        "project": "",
        "github": "https://pkuvdig.github.io/SAMPLING/",
        "arxiv": "2309.06323"
    },
    {
        "title": "SATR: Zero-Shot Semantic Segmentation of 3D Shapes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Abdelreheem_SATR_Zero-Shot_Semantic_Segmentation_of_3D_Shapes_ICCV_2023_paper.html",
        "author": "Ahmed Abdelreheem, Ivan Skorokhodov, Maks Ovsjanikov, Peter Wonka",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelreheem_SATR_Zero-Shot_Semantic_Segmentation_of_3D_Shapes_ICCV_2023_paper.pdf",
        "aff": "LIX, Ecole Polytechnique; KAUST",
        "project": "https://samir55.github.io/SATR/",
        "github": "",
        "arxiv": "2304.04909"
    },
    {
        "title": "SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zohaib_SC3K_Self-supervised_and_Coherent_3D_Keypoints_Estimation_from_Rotated_Noisy_ICCV_2023_paper.html",
        "author": "Mohammad Zohaib, Alessio Del Bue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zohaib_SC3K_Self-supervised_and_Coherent_3D_Keypoints_Estimation_from_Rotated_Noisy_ICCV_2023_paper.pdf",
        "aff": "Pattern Analysis & Computer Vision (PAVIS), Italian Institute of Technology (IIT), Genoa, Italy",
        "project": "",
        "github": "https://github.com/IIT-PAVIS/SC3K",
        "arxiv": "2308.05410"
    },
    {
        "title": "SCANet: Scene Complexity Aware Network for Weakly-Supervised Video Moment Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.html",
        "author": "Sunjae Yoon, Gwanhyeong Koo, Dahyun Kim, Chang D. Yoo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SCOB: Universal Text Understanding via Character-wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_SCOB_Universal_Text_Understanding_via_Character-wise_Supervised_Contrastive_Learning_with_ICCV_2023_paper.html",
        "author": "Daehee Kim, Yoonsik Kim, DongHyun Kim, Yumin Lim, Geewook Kim, Taeho Kil",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_SCOB_Universal_Text_Understanding_via_Character-wise_Supervised_Contrastive_Learning_with_ICCV_2023_paper.pdf",
        "aff": "Seoul National University; NAVER Cloud AI",
        "project": "",
        "github": "https://github.com/naver-ai/scob",
        "arxiv": "2309.12382"
    },
    {
        "title": "SEFD: Learning to Distill Complex Pose and Occlusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_SEFD_Learning_to_Distill_Complex_Pose_and_Occlusion_ICCV_2023_paper.html",
        "author": "ChangHee Yang, Kyeongbo Kong, SungJun Min, Dongyoon Wee, Ho-Deok Jang, Geonho Cha, SukJu Kang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SEFD_Learning_to_Distill_Complex_Pose_and_Occlusion_ICCV_2023_paper.pdf",
        "aff": "Samsung Electronics3; NAVER Cloud Corp4; Pusan National University2; Sogang University1",
        "project": "",
        "github": "https://github.com/YangChangHee/ICCV2023_SEFD_RELEASE/",
        "arxiv": ""
    },
    {
        "title": "SEMPART: Self-supervised Multi-resolution Partitioning of Image Semantics",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.html",
        "author": "Sriram Ravindran, Debraj Basu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.pdf",
        "aff": "Adobe",
        "project": "",
        "github": "",
        "arxiv": "2309.10972"
    },
    {
        "title": "SFHarmony: Source Free Domain Adaptation for Distributed Neuroimaging Analysis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dinsdale_SFHarmony_Source_Free_Domain_Adaptation_for_Distributed_Neuroimaging_Analysis_ICCV_2023_paper.html",
        "author": "Nicola K Dinsdale, Mark Jenkinson, Ana IL Namburete",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dinsdale_SFHarmony_Source_Free_Domain_Adaptation_for_Distributed_Neuroimaging_Analysis_ICCV_2023_paper.pdf",
        "aff": "Wellcome Centre for Integrative Neuroimaging, FMRIB, University of Oxford, Oxford, UK; Australian Institute for Machine Learning (AIML), Department of Computer Science, University of Adelaide, Adelaide, Australia; South Australian Health and Medical Research Institute (SAHMRI), North Terrace, Adelaide, Australia; Oxford Machine Learning in NeuroImaging (OMNI) Lab, Department of Computer Science, University of Oxford, UK; Oxford Machine Learning in NeuroImaging (OMNI) Lab, Department of Computer Science, University of Oxford, UK; Wellcome Centre for Integrative Neuroimaging, FMRIB, University of Oxford, Oxford, UK",
        "project": "",
        "github": "https://github.com/nkdinsdale/SFHarmony",
        "arxiv": "2303.15965"
    },
    {
        "title": "SG-Former: Self-guided Transformer with Evolving Token Reallocation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ren_SG-Former_Self-guided_Transformer_with_Evolving_Token_Reallocation_ICCV_2023_paper.html",
        "author": "Sucheng Ren, Xingyi Yang, Songhua Liu, Xinchao Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_SG-Former_Self-guided_Transformer_with_Evolving_Token_Reallocation_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore",
        "project": "",
        "github": "https://github.com/OliverRensu/SG-Former",
        "arxiv": ""
    },
    {
        "title": "SGAligner: 3D Scene Alignment with Scene Graphs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sarkar_SGAligner_3D_Scene_Alignment_with_Scene_Graphs_ICCV_2023_paper.html",
        "author": "Sayan Deb Sarkar, Ondrej Miksik, Marc Pollefeys, Daniel Barath, Iro Armeni",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sarkar_SGAligner_3D_Scene_Alignment_with_Scene_Graphs_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich, Switzerland; Microsoft Mixed Reality & AI Lab, Zurich, Switzerland",
        "project": "sgaligner.github.io",
        "github": "https://github.com/sgaligner",
        "arxiv": "2304.14880"
    },
    {
        "title": "SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Girish_SHACIRA_Scalable_HAsh-grid_Compression_for_Implicit_Neural_Representations_ICCV_2023_paper.html",
        "author": "Sharath Girish, Abhinav Shrivastava, Kamal Gupta",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Girish_SHACIRA_Scalable_HAsh-grid_Compression_for_Implicit_Neural_Representations_ICCV_2023_paper.pdf",
        "aff": "University of Maryland",
        "project": "https://shacira.github.io",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SHERF: Generalizable Human NeRF from a Single Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.html",
        "author": "Shoukang Hu, Fangzhou Hong, Liang Pan, Haiyi Mei, Lei Yang, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.pdf",
        "aff": "SenseTime Research; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/skhu101/SHERF",
        "arxiv": "2303.12791"
    },
    {
        "title": "SHIFT3D: Synthesizing Hard Inputs For Tricking 3D Detectors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SHIFT3D_Synthesizing_Hard_Inputs_For_Tricking_3D_Detectors_ICCV_2023_paper.html",
        "author": "Hongge Chen, Zhao Chen, Gregory P. Meyer, Dennis Park, Carl Vondrick, Ashish Shrivastava, Yuning Chai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SHIFT3D_Synthesizing_Hard_Inputs_For_Tricking_3D_Detectors_ICCV_2023_paper.pdf",
        "aff": "Cruise LLC",
        "project": "",
        "github": "",
        "arxiv": "2309.05810"
    },
    {
        "title": "SIDGAN: High-Resolution Dubbed Video Generation via Shift-Invariant Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_paper.html",
        "author": "Urwa Muaz, Wondong Jang, Rohun Tripathi, Santhosh Mani, Wenbin Ouyang, Ravi Teja Gadde, Baris Gecer, Sergio Elizondo, Reza Madad, Naveen Nair",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_paper.pdf",
        "aff": "Amazon Prime Video",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SIGMA: Scale-Invariant Global Sparse Shape Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_SIGMA_Scale-Invariant_Global_Sparse_Shape_Matching_ICCV_2023_paper.html",
        "author": "Maolin Gao, Paul Roetzer, Marvin Eisenberger, Zorah L\u00e4hner, Michael Moeller, Daniel Cremers, Florian Bernard",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_SIGMA_Scale-Invariant_Global_Sparse_Shape_Matching_ICCV_2023_paper.pdf",
        "aff": "University of Siegen; Technical University of Munich; University of Bonn",
        "project": "",
        "github": "",
        "arxiv": "2308.08393"
    },
    {
        "title": "SILT: Shadow-Aware Iterative Label Tuning for Learning to Detect Shadows from Noisy Labels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_SILT_Shadow-Aware_Iterative_Label_Tuning_for_Learning_to_Detect_Shadows_ICCV_2023_paper.html",
        "author": "Han Yang, Tianyu Wang, Xiaowei Hu, Chi-Wing Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SILT_Shadow-Aware_Iterative_Label_Tuning_for_Learning_to_Detect_Shadows_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong, The Shun Hing Institute of Advanced Engineering; The Chinese University of Hong Kong; Shanghai Artificial Intelligence Laboratory, The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2308.12064"
    },
    {
        "title": "SINC: Self-Supervised In-Context Learning for Vision-Language Tasks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SINC_Self-Supervised_In-Context_Learning_for_Vision-Language_Tasks_ICCV_2023_paper.html",
        "author": "Yi-Syuan Chen, Yun-Zhu Song, Cheng Yu Yeo, Bei Liu, Jianlong Fu, Hong-Han Shuai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SINC_Self-Supervised_In-Context_Learning_for_Vision-Language_Tasks_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; National Yang Ming Chiao Tung University",
        "project": "",
        "github": "",
        "arxiv": "2307.07742"
    },
    {
        "title": "SINC: Spatial Composition of 3D Human Motions for Simultaneous Action Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.html",
        "author": "Nikos Athanasiou, Mathis Petrovich, Michael J. Black, G\u00fcl Varol",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.pdf",
        "aff": "LIGM, \u00c9cole des Ponts, Univ Gustave Eiffel, CNRS, France; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; LIGM, \u00c9cole des Ponts, Univ Gustave Eiffel, CNRS, France",
        "project": "",
        "github": "https://sinc.is.tue.mpg.de",
        "arxiv": "2304.10417"
    },
    {
        "title": "SIRA-PCR: Sim-to-Real Adaptation for 3D Point Cloud Registration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SIRA-PCR_Sim-to-Real_Adaptation_for_3D_Point_Cloud_Registration_ICCV_2023_paper.html",
        "author": "Suyi Chen, Hao Xu, Ru Li, Guanghui Liu, Chi-Wing Fu, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SIRA-PCR_Sim-to-Real_Adaptation_for_3D_Point_Cloud_Registration_ICCV_2023_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; Harbin Institute of Technology; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/Chen-Suyi/SIRA_Pytorch",
        "arxiv": ""
    },
    {
        "title": "SKED: Sketch-guided Text-based 3D Editing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mikaeili_SKED_Sketch-guided_Text-based_3D_Editing_ICCV_2023_paper.html",
        "author": "Aryan Mikaeili, Or Perel, Mehdi Safaee, Daniel Cohen-Or, Ali Mahdavi-Amiri",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mikaeili_SKED_Sketch-guided_Text-based_3D_Editing_ICCV_2023_paper.pdf",
        "aff": "Simon Fraser University; Tel Aviv University; NVIDIA",
        "project": "",
        "github": "https://sked-paper.github.io/",
        "arxiv": "2303.10735"
    },
    {
        "title": "SKiT: a Fast Key Information Video Transformer for Online Surgical Phase Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SKiT_a_Fast_Key_Information_Video_Transformer_for_Online_Surgical_ICCV_2023_paper.html",
        "author": "Yang Liu, Jiayu Huo, Jingjing Peng, Rachel Sparks, Prokar Dasgupta, Alejandro Granados, Sebastien Ourselin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SKiT_a_Fast_Key_Information_Video_Transformer_for_Online_Surgical_ICCV_2023_paper.pdf",
        "aff": "King\u2019s College London",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SLAN: Self-Locator Aided Network for Vision-Language Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_SLAN_Self-Locator_Aided_Network_for_Vision-Language_Understanding_ICCV_2023_paper.html",
        "author": "Jiang-Tian Zhai, Qi Zhang, Tong Wu, Xing-Yu Chen, Jiang-Jiang Liu, Ming-Ming Cheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_SLAN_Self-Locator_Aided_Network_for_Vision-Language_Understanding_ICCV_2023_paper.pdf",
        "aff": "VCIP, CS, Nankai University; Tencent Youtu Lab",
        "project": "",
        "github": "https://github.com/scok30/SLAN",
        "arxiv": ""
    },
    {
        "title": "SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_SLCA_Slow_Learner_with_Classifier_Alignment_for_Continual_Learning_on_ICCV_2023_paper.html",
        "author": "Gengwei Zhang, Liyuan Wang, Guoliang Kang, Ling Chen, Yunchao Wei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SLCA_Slow_Learner_with_Classifier_Alignment_for_Continual_Learning_on_ICCV_2023_paper.pdf",
        "aff": "Institute of Information Science, Beijing Jiaotong University; Beihang University; Tsinghua University; University of Technology Sydney",
        "project": "",
        "github": "https://github.com/GengDavid/SLCA",
        "arxiv": "2303.05118"
    },
    {
        "title": "SMAUG: Sparse Masked Autoencoder for Efficient Video-Language Pre-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_SMAUG_Sparse_Masked_Autoencoder_for_Efficient_Video-Language_Pre-Training_ICCV_2023_paper.html",
        "author": "Yuanze Lin, Chen Wei, Huiyu Wang, Alan Yuille, Cihang Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_SMAUG_Sparse_Masked_Autoencoder_for_Efficient_Video-Language_Pre-Training_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; UC Santa Cruz; University of Washington",
        "project": "",
        "github": "",
        "arxiv": "2211.11446"
    },
    {
        "title": "SMMix: Self-Motivated Image Mixing for Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SMMix_Self-Motivated_Image_Mixing_for_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Mengzhao Chen, Mingbao Lin, Zhihang Lin, Yuxin Zhang, Fei Chao, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SMMix_Self-Motivated_Image_Mixing_for_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "Tencent Youtu Lab; Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, School of Informatics, Xiamen University",
        "project": "",
        "github": "https://github.com/ChenMnZ/SMMix",
        "arxiv": "2212.12977"
    },
    {
        "title": "SOAR: Scene-debiasing Open-set Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_SOAR_Scene-debiasing_Open-set_Action_Recognition_ICCV_2023_paper.html",
        "author": "Yuanhao Zhai, Ziyi Liu, Zhenyu Wu, Yi Wu, Chunluan Zhou, David Doermann, Junsong Yuan, Gang Hua",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_SOAR_Scene-debiasing_Open-set_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "University at Buffalo; Wormpex AI Research",
        "project": "",
        "github": "",
        "arxiv": "2309.01265"
    },
    {
        "title": "SOCS: Semantically-Aware Object Coordinate Space for Category-Level 6D Object Pose Estimation under Large Shape Variations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wan_SOCS_Semantically-Aware_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_ICCV_2023_paper.html",
        "author": "Boyan Wan, Yifei Shi, Kai Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_SOCS_Semantically-Aware_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_ICCV_2023_paper.pdf",
        "aff": "National University of Defense Technology",
        "project": "",
        "github": "https://github.com/wanboyan/SOCS",
        "arxiv": "2303.10346"
    },
    {
        "title": "SPACE: Speech-driven Portrait Animation with Controllable Expression",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gururani_SPACE_Speech-driven_Portrait_Animation_with_Controllable_Expression_ICCV_2023_paper.html",
        "author": "Siddharth Gururani, Arun Mallya, Ting-Chun Wang, Rafael Valle, Ming-Yu Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gururani_SPACE_Speech-driven_Portrait_Animation_with_Controllable_Expression_ICCV_2023_paper.pdf",
        "aff": "NVIDIA",
        "project": "https://research.nvidia.com/labs/dir/space/",
        "github": "",
        "arxiv": "2211.09809"
    },
    {
        "title": "SPANet: Frequency-balancing Token Mixer using Spectral Pooling Aggregation Modulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yun_SPANet_Frequency-balancing_Token_Mixer_using_Spectral_Pooling_Aggregation_Modulation_ICCV_2023_paper.html",
        "author": "Guhnoo Yun, Juhan Yoo, Kijung Kim, Jeongho Lee, Dong Hwan Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_SPANet_Frequency-balancing_Token_Mixer_using_Spectral_Pooling_Aggregation_Modulation_ICCV_2023_paper.pdf",
        "aff": "Semyung University; Korea Institute of Science and Technology, Korea University",
        "project": "",
        "github": "https://doranlyong.github.io/projects/spanet/",
        "arxiv": "2308.11568"
    },
    {
        "title": "SQAD: Automatic Smartphone Camera Quality Assessment and Benchmarking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fang_SQAD_Automatic_Smartphone_Camera_Quality_Assessment_and_Benchmarking_ICCV_2023_paper.html",
        "author": "Zilin Fang, Andrey Ignatov, Eduard Zamfir, Radu Timofte",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_SQAD_Automatic_Smartphone_Camera_Quality_Assessment_and_Benchmarking_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; National University of Singapore; University of Wurzburg",
        "project": "",
        "github": "https://github.com/aiff22/SQAD",
        "arxiv": ""
    },
    {
        "title": "SRFormer: Permuted Self-Attention for Single Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.html",
        "author": "Yupeng Zhou, Zhen Li, Chun-Le Guo, Song Bai, Ming-Ming Cheng, Qibin Hou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "ByteDance, Singapore; VCIP, School of Computer Science, Nankai University",
        "project": "",
        "github": "https://github.com/HVision-NKU/SRFormer",
        "arxiv": "2303.09735"
    },
    {
        "title": "SSB: Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_SSB_Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_ICCV_2023_paper.html",
        "author": "Yue Fan, Anna Kukleva, Dengxin Dai, Bernt Schiele",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_SSB_Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Informatics, Saarbr\u00fccken, Germany",
        "project": "",
        "github": "https://github.com/YUE-FAN/SSB",
        "arxiv": ""
    },
    {
        "title": "SSDA: Secure Source-Free Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Sabbir Ahmed, Abdullah Al Arafat, Mamshad Nayeem Rizve, Rahim Hossain, Zhishan Guo, Adnan Siraj Rakin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "North Carolina State University; Binghamton University (SUNY); University of Central Florida",
        "project": "",
        "github": "https://github.com/ML-Security-Research-LAB/SSDA",
        "arxiv": ""
    },
    {
        "title": "SSF: Accelerating Training of Spiking Neural Networks with Stabilized Spiking Flow",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SSF_Accelerating_Training_of_Spiking_Neural_Networks_with_Stabilized_Spiking_ICCV_2023_paper.html",
        "author": "Jingtao Wang, Zengjie Song, Yuxi Wang, Jun Xiao, Yuran Yang, Shuqi Mei, Zhaoxiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SSF_Accelerating_Training_of_Spiking_Neural_Networks_with_Stabilized_Spiking_ICCV_2023_paper.pdf",
        "aff": "University of Chinese Academy of Sciences, Centre for Arti\ufb01cial Intelligence and Robotics, HKISI-CAS, Institute of Automation, Chinese Academy of Sciences, State Key Laboratory of Multimodal Arti\ufb01cial Intelligence Systems; Tencent; Centre for Arti\ufb01cial Intelligence and Robotics, HKISI-CAS; Xi\u2019an Jiaotong University; University of Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "STEERER: Resolving Scale Variations for Counting and Localization via Selective Inheritance Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_STEERER_Resolving_Scale_Variations_for_Counting_and_Localization_via_Selective_ICCV_2023_paper.html",
        "author": "Tao Han, Lei Bai, Lingbo Liu, Wanli Ouyang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_STEERER_Resolving_Scale_Variations_for_Counting_and_Localization_via_Selective_ICCV_2023_paper.pdf",
        "aff": "Shanghai Artificial Intelligence Laboratory; The Hong Kong Polytechnic University",
        "project": "",
        "github": "https://github.com/taohan10200/STEERER",
        "arxiv": "2308.10468"
    },
    {
        "title": "STEPs: Self-Supervised Key Step Extraction and Localization from Unlabeled Procedural Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shah_STEPs_Self-Supervised_Key_Step_Extraction_and_Localization_from_Unlabeled_Procedural_ICCV_2023_paper.html",
        "author": "Anshul Shah, Benjamin Lundell, Harpreet Sawhney, Rama Chellappa",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shah_STEPs_Self-Supervised_Key_Step_Extraction_and_Localization_from_Unlabeled_Procedural_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; Microsoft Mixed Reality",
        "project": "",
        "github": "https://github.com/anshulbshah/STEPs",
        "arxiv": "2301.00794"
    },
    {
        "title": "STPrivacy: Spatio-Temporal Privacy-Preserving Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_STPrivacy_Spatio-Temporal_Privacy-Preserving_Action_Recognition_ICCV_2023_paper.html",
        "author": "Ming Li, Xiangyu Xu, Hehe Fan, Pan Zhou, Jun Liu, Jia-Wei Liu, Jiahe Li, Jussi Keppo, Mike Zheng Shou, Shuicheng Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_STPrivacy_Spatio-Temporal_Privacy-Preserving_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "National University of Singapore; Sea AI Lab; Zhejiang University; Xi\u2019an Jiaotong University; Singapore University of Technology and Design",
        "project": "",
        "github": "",
        "arxiv": "2301.03046"
    },
    {
        "title": "SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Simons_SUMMIT_Source-Free_Adaptation_of_Uni-Modal_Models_to_Multi-Modal_Targets_ICCV_2023_paper.html",
        "author": "Cody Simons, Dripta S. Raychaudhuri, Sk Miraj Ahmed, Suya You, Konstantinos Karydis, Amit K. Roy-Chowdhury",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Simons_SUMMIT_Source-Free_Adaptation_of_Uni-Modal_Models_to_Multi-Modal_Targets_ICCV_2023_paper.pdf",
        "aff": "DEVCOM Army Research Laboratory; University of California, Riverside; University of California, Riverside and AWS AI Labs",
        "project": "",
        "github": "https://github.com/csimo005/SUMMIT",
        "arxiv": "2308.11880"
    },
    {
        "title": "SVDFormer: Complementing Point Cloud via Self-view Augmentation and Self-structure Dual-generator",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_SVDFormer_Complementing_Point_Cloud_via_Self-view_Augmentation_and_Self-structure_Dual-generator_ICCV_2023_paper.html",
        "author": "Zhe Zhu, Honghua Chen, Xing He, Weiming Wang, Jing Qin, Mingqiang Wei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_SVDFormer_Complementing_Point_Cloud_via_Self-view_Augmentation_and_Self-structure_Dual-generator_ICCV_2023_paper.pdf",
        "aff": "Nanjing University of Aeronautics and Astronautics; The Hong Kong Polytechnic University; Hong Kong Metropolitan University",
        "project": "",
        "github": "https://github.com/czvvd/SVDFormer",
        "arxiv": "2307.08492"
    },
    {
        "title": "SVDiff: Compact Parameter Space for Diffusion Fine-Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_SVDiff_Compact_Parameter_Space_for_Diffusion_Fine-Tuning_ICCV_2023_paper.html",
        "author": "Ligong Han, Yinxiao Li, Han Zhang, Peyman Milanfar, Dimitris Metaxas, Feng Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_SVDiff_Compact_Parameter_Space_for_Diffusion_Fine-Tuning_ICCV_2023_paper.pdf",
        "aff": "Rutgers University; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2303.11305"
    },
    {
        "title": "SVQNet: Sparse Voxel-Adjacent Query Network for 4D Spatio-Temporal LiDAR Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SVQNet_Sparse_Voxel-Adjacent_Query_Network_for_4D_Spatio-Temporal_LiDAR_Semantic_ICCV_2023_paper.html",
        "author": "Xuechao Chen, Shuangjie Xu, Xiaoyi Zou, Tongyi Cao, Dit-Yan Yeung, Lu Fang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SVQNet_Sparse_Voxel-Adjacent_Query_Network_for_4D_Spatio-Temporal_LiDAR_Semantic_ICCV_2023_paper.pdf",
        "aff": "SVQNet: Sparse Voxel-Adjacent Query Network\nfor 4D Spatio-Temporal LiDAR Semantic Segmentation\nXuechao Chen1*Shuangjie Xu2*Xiaoyi Zou3Tongyi Cao3Dit-Yan Yeung2 \u2020Lu Fang1 \u2020\n1Tsinghua University2Hong Kong University of Science and Technology3Deeproute.ai\nAbstract\nLiDAR-based semantic perception tasks are critical yet\nchallenging for autonomous driving. Due to the motion of\nobjects and static/dynamic occlusion, temporal information\nplays an essential role in reinforcing perception by enhanc-\ning and completing single-frame knowledge. Previous ap-\nproaches either directly stack historical frames to the cur-\nrent frame or build a 4D spatio-temporal neighborhood us-\ning KNN, which duplicates computation and hinders real-\ntime performance. Based on our observation that stacking\nall the historical points would damage performance due\nto a large amount of redundant and misleading informa-\ntion, we propose the Sparse Voxel-Adjacent Query Network\n(SVQNet) for 4D LiDAR semantic segmentation. To take\nfull advantage of the historical frames high-efficiently, we\nshunt the historical points into two groups with reference to\nthe current points. One is the Voxel-Adjacent Neighborhood\ncarrying local enhancing knowledge. The other is the His-\ntorical Context completing the global knowledge. Then we\npropose new modules to select and extract the instructive\nfeatures from the two groups. Our SVQNet achieves state-\nof-the-art performance in LiDAR semantic segmentation of\nthe SemanticKITTI benchmark and the nuScenes dataset.\n1. Introduction\nServing as a robust 3D perception solution, LiDAR-\nbased perception is under enthusiastic exploration by re-\nsearchers, among which 3D LiDAR semantic segmentation,\naiming at assigning a category label to each point in the\nwhole LiDAR scene at the semantic level, is of great signifi-\ncance in autonomous driving and robotics. Recently, a large\nnumber of literature [33, 43, 45, 28, 13, 19] concentrates on\nsemantic segmentation within a single frame. However, the\ninformation in a single frame is affected by multiple factors:\n1) occlusion problems caused by obstacles or the move-\nment of ego-car, leading to incomplete information of the\n*Equal contribution\n\u2020Corresponding authors\nCurrent\u00a0 frame\u00a0Points\nVoxel\u2010Adjacent \u00a0Historical \u00a0Points\nHistorical \u00a0Context\u00a0 PointsHistorical \u00a0\nContext \u00a0\nVoxel\u2010Adjacent \u00a0\nNeighborhood\nVoxel\u2010 Adjacent\nFigure 1. 4D spatio-temporal LiDAR points for a truck. We shunt\nthe historical points into 1) Voxel-Adjacent points that lie in the\nvoxel containing current frame points; 2) The remaining points\nnamed Historical Context points whose features will be adaptively\nfused to complete the missing features in the current frame.\noccluded objects; and 2) ambiguity between similar point\nclusters, for example, the fence looks similar to one side\nof a big truck, which severely degrades the performance of\nsingle-frame based LiDAR semantic segmentation.\nTo eliminate the distortion within the single frame, the\nuse of sequential knowledge has attracted widespread at-\ntention [24, 44, 42, 1, 39] as the LiDAR continuously trans-\nmits and receives sensory data. Therefore, 4D Spatio-\ntemporal information (LiDAR video) is increasingly play-\ning an essential role in reinforcing perception by enhancing\nand completing single-frame knowledge. Classic temporal\nmethods [1, 48] directly stack frames in the last few times-\ntamps by adding additional channel tto the coordinates\nxyzof each point, which is quite straightforward but super-\nimposing all historical points without any selection brings\nredundancy, masking the useful temporal knowledge and\nweakens the benefits of the time series.\nTo model spatio-temporal relationship instead of stack-\ning all frames, approaches based on KNN or radius neigh-\nbors query [21, 4, 31, 37] apply point-wise nearest neighbor\nsearch methods to extract instructive features across time\nand space. However, these approaches will not only fail\nwhen the target object is moving at high speed but also bear\nthe high complexity of searching algorithms that lead to the\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n8569\n",
        "project": "",
        "github": "",
        "arxiv": "2308.13323"
    },
    {
        "title": "SYENet: A Simple Yet Effective Network for Multiple Low-Level Vision Tasks with Real-Time Performance on Mobile Device",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gou_SYENet_A_Simple_Yet_Effective_Network_for_Multiple_Low-Level_Vision_ICCV_2023_paper.html",
        "author": "Weiran Gou, Ziyao Yi, Yan Xiang, Shaoqing Li, Zibin Liu, Dehui Kong, Ke Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gou_SYENet_A_Simple_Yet_Effective_Network_for_Multiple_Low-Level_Vision_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Mobile Network and Mobile Multimedia Technology, Sanechips Technology, Chengdu, China",
        "project": "",
        "github": "https://github.com/sanechips-multimedia/syenet",
        "arxiv": "2308.08137"
    },
    {
        "title": "Saliency Regularization for Self-Training with Partial Annotations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Saliency_Regularization_for_Self-Training_with_Partial_Annotations_ICCV_2023_paper.html",
        "author": "Shouwen Wang, Qian Wan, Xiang Xiang, Zhigang Zeng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Saliency_Regularization_for_Self-Training_with_Partial_Annotations_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence and Automation, Huazhong University of Science and Technology; Key Laboratory of Image Processing and Intelligent Control, Ministry of Education; Wuhan Research Institute of Posts and Telecommunications",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Sample-adaptive Augmentation for Point Cloud Recognition Against Real-world Corruptions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Sample-adaptive_Augmentation_for_Point_Cloud_Recognition_Against_Real-world_Corruptions_ICCV_2023_paper.html",
        "author": "Jie Wang, Lihe Ding, Tingfa Xu, Shaocong Dong, Xinli Xu, Long Bai, Jianan Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Sample-adaptive_Augmentation_for_Point_Cloud_Recognition_Against_Real-world_Corruptions_ICCV_2023_paper.pdf",
        "aff": "Beijing Institute of Technology; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/Roywangj/AdaptPoint",
        "arxiv": "2309.10431"
    },
    {
        "title": "Sample-wise Label Confidence Incorporation for Learning with Noisy Labels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ahn_Sample-wise_Label_Confidence_Incorporation_for_Learning_with_Noisy_Labels_ICCV_2023_paper.html",
        "author": "Chanho Ahn, Kikyung Kim, Ji-won Baek, Jongin Lim, Seungju Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ahn_Sample-wise_Label_Confidence_Incorporation_for_Learning_with_Noisy_Labels_ICCV_2023_paper.pdf",
        "aff": "Samsung Advanced Institute of Technology (SAIT), Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Sample4Geo: Hard Negative Sampling For Cross-View Geo-Localisation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deuser_Sample4Geo_Hard_Negative_Sampling_For_Cross-View_Geo-Localisation_ICCV_2023_paper.html",
        "author": "Fabian Deuser, Konrad Habel, Norbert Oswald",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deuser_Sample4Geo_Hard_Negative_Sampling_For_Cross-View_Geo-Localisation_ICCV_2023_paper.pdf",
        "aff": "Institute for Distributed Intelligent Systems, University of the Bundeswehr Munich, Munich, Germany",
        "project": "",
        "github": "",
        "arxiv": "2303.11851"
    },
    {
        "title": "Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.html",
        "author": "Ming Qian, Jincheng Xiong, Gui-Song Xia, Nan Xue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.pdf",
        "aff": "Ant Group; LIESMARS, Wuhan University",
        "project": "https://sat2density.github.io",
        "github": "",
        "arxiv": "2303.14672"
    },
    {
        "title": "SatlasPretrain: A Large-Scale Dataset for Remote Sensing Image Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.html",
        "author": "Favyen Bastani, Piper Wolters, Ritwik Gupta, Joe Ferdinando, Aniruddha Kembhavi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.pdf",
        "aff": "Allen Institute for AI",
        "project": "https://satlas-pretrain.allen.ai/",
        "github": "",
        "arxiv": "2211.15660"
    },
    {
        "title": "Scalable Diffusion Models with Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.html",
        "author": "William Peebles, Saining Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.pdf",
        "aff": "UC Berkeley; Work done during an internship at Meta AI, FAIR Team; New York University",
        "project": "Available here (\u7684\u5177\u4f53\u94fe\u63a5\u672a\u63d0\u4f9b)",
        "github": "",
        "arxiv": "2212.09748"
    },
    {
        "title": "Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating Stochastic Change Process",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Scalable_Multi-Temporal_Remote_Sensing_Change_Data_Generation_via_Simulating_Stochastic_ICCV_2023_paper.html",
        "author": "Zhuo Zheng, Shiqi Tian, Ailong Ma, Liangpei Zhang, Yanfei Zhong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Scalable_Multi-Temporal_Remote_Sensing_Change_Data_Generation_via_Simulating_Stochastic_ICCV_2023_paper.pdf",
        "aff": "Wuhan University; Wuhan University, Stanford University",
        "project": "",
        "github": "https://github.com/Z-Zheng/Changen",
        "arxiv": ""
    },
    {
        "title": "Scalable Video Object Segmentation with Simplified Framework",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Scalable_Video_Object_Segmentation_with_Simplified_Framework_ICCV_2023_paper.html",
        "author": "Qiangqiang Wu, Tianyu Yang, Wei Wu, Antoni B. Chan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Scalable_Video_Object_Segmentation_with_Simplified_Framework_ICCV_2023_paper.pdf",
        "aff": "International Digital Economy Academy; Department of Computer Science, City University of Hong Kong",
        "project": "",
        "github": "https://github.com/jimmy-dq/SimVOS.git",
        "arxiv": "2308.09903"
    },
    {
        "title": "Scale-Aware Modulation Meet Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Scale-Aware_Modulation_Meet_Transformer_ICCV_2023_paper.html",
        "author": "Weifeng Lin, Ziheng Wu, Jiayu Chen, Jun Huang, Lianwen Jin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Scale-Aware_Modulation_Meet_Transformer_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology; Platform of AI (PAI), Alibaba Group",
        "project": "",
        "github": "https://github.com/AFeng-x/SMT",
        "arxiv": "2307.08579"
    },
    {
        "title": "Scale-MAE: A Scale-Aware Masked Autoencoder for Multiscale Geospatial Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Reed_Scale-MAE_A_Scale-Aware_Masked_Autoencoder_for_Multiscale_Geospatial_Representation_Learning_ICCV_2023_paper.html",
        "author": "Colorado J Reed, Ritwik Gupta, Shufan Li, Sarah Brockman, Christopher Funk, Brian Clipp, Kurt Keutzer, Salvatore Candido, Matt Uyttendaele, Trevor Darrell",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Reed_Scale-MAE_A_Scale-Aware_Masked_Autoencoder_for_Multiscale_Geospatial_Representation_Learning_ICCV_2023_paper.pdf",
        "aff": "Meta AI, FAIR; Kitware Inc.; Berkeley AI Research; Berkeley AI Research; Meta AI, FAIR",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scaling Data Generation in Vision-and-Language Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Scaling_Data_Generation_in_Vision-and-Language_Navigation_ICCV_2023_paper.html",
        "author": "Zun Wang, Jialu Li, Yicong Hong, Yi Wang, Qi Wu, Mohit Bansal, Stephen Gould, Hao Tan, Yu Qiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Scaling_Data_Generation_in_Vision-and-Language_Navigation_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; The Australian National University; University of Adelaide; UNC, Chapel Hill; OpenGVLab, Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/wz0919/ScaleVLN",
        "arxiv": "2307.15644"
    },
    {
        "title": "ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yeshwanth_ScanNet_A_High-Fidelity_Dataset_of_3D_Indoor_Scenes_ICCV_2023_paper.html",
        "author": "Chandan Yeshwanth, Yueh-Cheng Liu, Matthias Nie\u00dfner, Angela Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yeshwanth_ScanNet_A_High-Fidelity_Dataset_of_3D_Indoor_Scenes_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich",
        "project": "https://cy94.github.io/scannetpp/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scanning Only Once: An End-to-end Framework for Fast Temporal Grounding in Long Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Scanning_Only_Once_An_End-to-end_Framework_for_Fast_Temporal_Grounding_ICCV_2023_paper.html",
        "author": "Yulin Pan, Xiangteng He, Biao Gong, Yiliang Lv, Yujun Shen, Yuxin Peng, Deli Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Scanning_Only_Once_An_End-to-end_Framework_for_Fast_Temporal_Grounding_ICCV_2023_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University; Alibaba Group; Ant Group",
        "project": "",
        "github": "https://github.com/afcedf/SOONet.git",
        "arxiv": "2303.08345"
    },
    {
        "title": "ScatterNeRF: Seeing Through Fog with Physically-Based Inverse Neural Rendering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ramazzina_ScatterNeRF_Seeing_Through_Fog_with_Physically-Based_Inverse_Neural_Rendering_ICCV_2023_paper.html",
        "author": "Andrea Ramazzina, Mario Bijelic, Stefanie Walz, Alessandro Sanvito, Dominik Scheuble, Felix Heide",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ramazzina_ScatterNeRF_Seeing_Through_Fog_with_Physically-Based_Inverse_Neural_Rendering_ICCV_2023_paper.pdf",
        "aff": "Mercedes-Benz; Princeton University",
        "project": "",
        "github": "https://light.princeton.edu/scatternerf",
        "arxiv": "2305.02103"
    },
    {
        "title": "Scene Graph Contrastive Learning for Embodied Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Singh_Scene_Graph_Contrastive_Learning_for_Embodied_Navigation_ICCV_2023_paper.html",
        "author": "Kunal Pratap Singh, Jordi Salvador, Luca Weihs, Aniruddha Kembhavi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Scene_Graph_Contrastive_Learning_for_Embodied_Navigation_ICCV_2023_paper.pdf",
        "aff": "Allen Institute for AI",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scene Matters: Model-based Deep Video Compression",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Scene_Matters_Model-based_Deep_Video_Compression_ICCV_2023_paper.html",
        "author": "Lv Tang, Xinfeng Zhang, Gai Zhang, Xiaoqi Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Scene_Matters_Model-based_Deep_Video_Compression_ICCV_2023_paper.pdf",
        "aff": "University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": "2303.04557"
    },
    {
        "title": "Scene as Occupancy",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tong_Scene_as_Occupancy_ICCV_2023_paper.html",
        "author": "Wenwen Tong, Chonghao Sima, Tai Wang, Li Chen, Silei Wu, Hanming Deng, Yi Gu, Lewei Lu, Ping Luo, Dahua Lin, Hongyang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tong_Scene_as_Occupancy_ICCV_2023_paper.pdf",
        "aff": "The University of Hong Kong; Shanghai AI Laboratory, The University of Hong Kong; Shanghai AI Laboratory; Shanghai AI Laboratory, The Chinese University of Hong Kong; Shanghai AI Laboratory, SenseTime Research; SenseTime Research",
        "project": "https://github.com/OpenDriveLab/OpenScene",
        "github": "https://github.com/OpenDriveLab/OccNet",
        "arxiv": "2306.02851"
    },
    {
        "title": "Scene-Aware Feature Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Scene-Aware_Feature_Matching_ICCV_2023_paper.html",
        "author": "Xiaoyong Lu, Yaping Yan, Tong Wei, Songlin Du",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Scene-Aware_Feature_Matching_ICCV_2023_paper.pdf",
        "aff": "Southeast University, Nanjing, China",
        "project": "",
        "github": "",
        "arxiv": "2308.09949"
    },
    {
        "title": "Scene-Aware Label Graph Learning for Multi-Label Image Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Scene-Aware_Label_Graph_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.html",
        "author": "Xuelin Zhu, Jian Liu, Weijia Liu, Jiawei Ge, Bo Liu, Jiuxin Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Scene-Aware_Label_Graph_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Southeast University; School of Cyber Science and Engineering, Southeast University; Ant Group, Hangzhou, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SceneRF: Self-Supervised Monocular 3D Scene Reconstruction with Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_SceneRF_Self-Supervised_Monocular_3D_Scene_Reconstruction_with_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Anh-Quan Cao, Raoul de Charette",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_SceneRF_Self-Supervised_Monocular_3D_Scene_Reconstruction_with_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "Inria",
        "project": "",
        "github": "https://astra-vision.github.io/SceneRF",
        "arxiv": "2212.02501"
    },
    {
        "title": "Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.html",
        "author": "Yuxin Jiang, Liming Jiang, Shuai Yang, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University",
        "project": "https://yuxinn-j.github.io/projects/Scenimefy.html",
        "github": "",
        "arxiv": "2308.12968"
    },
    {
        "title": "Score Priors Guided Deep Variational Inference for Unsupervised Real-World Single Image Denoising",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Score_Priors_Guided_Deep_Variational_Inference_for_Unsupervised_Real-World_Single_ICCV_2023_paper.html",
        "author": "Jun Cheng, Tao Liu, Shan Tan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Score_Priors_Guided_Deep_Variational_Inference_for_Unsupervised_Real-World_Single_ICCV_2023_paper.pdf",
        "aff": "Huazhong University of Science and Technology, Wuhan, China",
        "project": "",
        "github": "",
        "arxiv": "2308.04682"
    },
    {
        "title": "Score-Based Diffusion Models as Principled Priors for Inverse Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Score-Based_Diffusion_Models_as_Principled_Priors_for_Inverse_Imaging_ICCV_2023_paper.html",
        "author": "Berthy T. Feng, Jamie Smith, Michael Rubinstein, Huiwen Chang, Katherine L. Bouman, William T. Freeman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Score-Based_Diffusion_Models_as_Principled_Priors_for_Inverse_Imaging_ICCV_2023_paper.pdf",
        "aff": "California Institute of Technology; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2304.11751"
    },
    {
        "title": "Scratch Each Other's Back: Incomplete Multi-Modal Brain Tumor Segmentation via Category Aware Group Self-Support Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_Scratch_Each_Others_Back_Incomplete_Multi-Modal_Brain_Tumor_Segmentation_via_ICCV_2023_paper.html",
        "author": "Yansheng Qiu, Delin Chen, Hongdou Yao, Yongchao Xu, Zheng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Scratch_Each_Others_Back_Incomplete_Multi-Modal_Brain_Tumor_Segmentation_via_ICCV_2023_paper.pdf",
        "aff": "National Engineering Research Center for Multimedia Software, Institute of Arti\ufb01cial Intelligence, School of Computer Science, Wuhan University; Hubei Key Laboratory of Multimedia and Network Communication Engineering",
        "project": "",
        "github": "https://github.com/qysgithubopen/GSS",
        "arxiv": ""
    },
    {
        "title": "Scratching Visual Transformer's Back with Uniform Attention",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hyeon-Woo_Scratching_Visual_Transformers_Back_with_Uniform_Attention_ICCV_2023_paper.html",
        "author": "Nam Hyeon-Woo, Kim Yu-Ji, Byeongho Heo, Dongyoon Han, Seong Joon Oh, Tae-Hyun Oh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hyeon-Woo_Scratching_Visual_Transformers_Back_with_Uniform_Attention_ICCV_2023_paper.pdf",
        "aff": "NAVER AI Lab; T\u00fcbingen University; POSTECH",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Seal-3D_Interactive_Pixel-Level_Editing_for_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Xiangyu Wang, Jingsen Zhu, Qi Ye, Yuchi Huo, Yunlong Ran, Zhihua Zhong, Jiming Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Seal-3D_Interactive_Pixel-Level_Editing_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "Zhejiang Lab, State Key Lab of CAD&CG, Zhejiang University; Zhejiang University, Key Lab of CS&AUS of Zhejiang Province; State Key Lab of CAD&CG, Zhejiang University",
        "project": "https://windingwind.github.io/seal-3d/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Search for or Navigate to? Dual Adaptive Thinking for Object Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dang_Search_for_or_Navigate_to_Dual_Adaptive_Thinking_for_Object_ICCV_2023_paper.html",
        "author": "Ronghao Dang, Liuyi Wang, Zongtao He, Shuai Su, Jiagui Tang, Chengju Liu, Qijun Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dang_Search_for_or_Navigate_to_Dual_Adaptive_Thinking_for_Object_ICCV_2023_paper.pdf",
        "aff": "Tongji University; Tongji University, Tongji Artificial Intelligence (Suzhou) Research Institute",
        "project": "",
        "github": "",
        "arxiv": "2208.00553"
    },
    {
        "title": "See More and Know More: Zero-shot Point Cloud Segmentation via Multi-modal Visual Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_See_More_and_Know_More_Zero-shot_Point_Cloud_Segmentation_via_ICCV_2023_paper.html",
        "author": "Yuhang Lu, Qi Jiang, Runnan Chen, Yuenan Hou, Xinge Zhu, Yuexin Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_See_More_and_Know_More_Zero-shot_Point_Cloud_Segmentation_via_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; The University of Hong Kong; Shanghai AI Laboratory; ShanghaiTech University",
        "project": "",
        "github": "",
        "arxiv": "2307.10782"
    },
    {
        "title": "SeeABLE: Soft Discrepancies and Bounded Contrastive Learning for Exposing Deepfakes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Larue_SeeABLE_Soft_Discrepancies_and_Bounded_Contrastive_Learning_for_Exposing_Deepfakes_ICCV_2023_paper.html",
        "author": "Nicolas Larue, Ngoc-Son Vu, Vitomir Struc, Peter Peer, Vassilis Christophides",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Larue_SeeABLE_Soft_Discrepancies_and_Bounded_Contrastive_Learning_for_Exposing_Deepfakes_ICCV_2023_paper.pdf",
        "aff": "ETIS - CY Cergy Paris University, ENSEA, CNRS, France; University of Ljubljana, Slovenia",
        "project": "",
        "github": "https://github.com/anonymous-author-sub/seeable",
        "arxiv": "2211.11296"
    },
    {
        "title": "Seeing Beyond the Patch: Scale-Adaptive Semantic Segmentation of High-resolution Remote Sensing Imagery based on Reinforcement Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.html",
        "author": "Yinhe Liu, Sunan Shi, Junjue Wang, Yanfei Zhong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.pdf",
        "aff": "Wuhan University, Wuhan, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SegGPT: Towards Segmenting Everything in Context",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SegGPT_Towards_Segmenting_Everything_in_Context_ICCV_2023_paper.html",
        "author": "Xinlong Wang, Xiaosong Zhang, Yue Cao, Wen Wang, Chunhua Shen, Tiejun Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SegGPT_Towards_Segmenting_Everything_in_Context_ICCV_2023_paper.pdf",
        "aff": "Peking University; Beijing Academy of Artificial Intelligence; Zhejiang University",
        "project": "",
        "github": "https://github.com/baaivision/Painter",
        "arxiv": ""
    },
    {
        "title": "SegPrompt: Boosting Open-World Segmentation via Category-Level Prompt Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_SegPrompt_Boosting_Open-World_Segmentation_via_Category-Level_Prompt_Learning_ICCV_2023_paper.html",
        "author": "Muzhi Zhu, Hengtao Li, Hao Chen, Chengxiang Fan, Weian Mao, Chenchen Jing, Yifan Liu, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_SegPrompt_Boosting_Open-World_Segmentation_via_Category-Level_Prompt_Learning_ICCV_2023_paper.pdf",
        "aff": "The University of Adelaide, Australia; Zhejiang University, China; Zhejiang University, China; Ant Group; Zhejiang University, China; The University of Adelaide, Australia",
        "project": "",
        "github": "https://github.com/aim-uofa/SegPrompt",
        "arxiv": "2308.06531"
    },
    {
        "title": "SegRCDB: Semantic Segmentation via Formula-Driven Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shinoda_SegRCDB_Semantic_Segmentation_via_Formula-Driven_Supervised_Learning_ICCV_2023_paper.html",
        "author": "Risa Shinoda, Ryo Hayamizu, Kodai Nakashima, Nakamasa Inoue, Rio Yokota, Hirokatsu Kataoka",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shinoda_SegRCDB_Semantic_Segmentation_via_Formula-Driven_Supervised_Learning_ICCV_2023_paper.pdf",
        "aff": "Tokyo Institute of Technology; National Institute of Advanced Industrial Science and Technology (AIST)",
        "project": "",
        "github": "https://github.com/dahlian00/SegRCDB",
        "arxiv": ""
    },
    {
        "title": "Segment Anything",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kirillov_Segment_Anything_ICCV_2023_paper.html",
        "author": "Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kirillov_Segment_Anything_ICCV_2023_paper.pdf",
        "aff": "Meta AI Research, FAIR",
        "project": "https://segment-anything.com",
        "github": "",
        "arxiv": "2304.02643"
    },
    {
        "title": "Segment Every Reference Object in Spatial and Temporal Spaces",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Segment_Every_Reference_Object_in_Spatial_and_Temporal_Spaces_ICCV_2023_paper.html",
        "author": "Jiannan Wu, Yi Jiang, Bin Yan, Huchuan Lu, Zehuan Yuan, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Segment_Every_Reference_Object_in_Spatial_and_Temporal_Spaces_ICCV_2023_paper.pdf",
        "aff": "Dalian University of Technology; The University of Hong Kong; Shanghai AI Laboratory; ByteDance",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Segmentation of Tubular Structures Using Iterative Training with Tailored Samples",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.html",
        "author": "Wei Liao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.pdf",
        "aff": "Independent Researcher",
        "project": "",
        "github": "",
        "arxiv": "2309.08727"
    },
    {
        "title": "Segmenting Known Objects and Unseen Unknowns without Prior Knowledge",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gasperini_Segmenting_Known_Objects_and_Unseen_Unknowns_without_Prior_Knowledge_ICCV_2023_paper.html",
        "author": "Stefano Gasperini, Alvaro Marcos-Ramiro, Michael Schmidt, Nassir Navab, Benjamin Busam, Federico Tombari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gasperini_Segmenting_Known_Objects_and_Unseen_Unknowns_without_Prior_Knowledge_ICCV_2023_paper.pdf",
        "aff": "BMW Group; Technical University of Munich; Google",
        "project": "https://holisticseg.github.io",
        "github": "",
        "arxiv": "2209.05407"
    },
    {
        "title": "SeiT: Storage-Efficient Vision Training with Tokens Using 1% of Pixel Storage",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_SeiT_Storage-Efficient_Vision_Training_with_Tokens_Using_1_of_Pixel_ICCV_2023_paper.html",
        "author": "Song Park, Sanghyuk Chun, Byeongho Heo, Wonjae Kim, Sangdoo Yun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_SeiT_Storage-Efficient_Vision_Training_with_Tokens_Using_1_of_Pixel_ICCV_2023_paper.pdf",
        "aff": "NAVER AI Lab",
        "project": "",
        "github": "https://github.com/naver-ai/seit",
        "arxiv": "2303.11114"
    },
    {
        "title": "Self-Calibrated Cross Attention Network for Few-Shot Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Self-Calibrated_Cross_Attention_Network_for_Few-Shot_Segmentation_ICCV_2023_paper.html",
        "author": "Qianxiong Xu, Wenting Zhao, Guosheng Lin, Cheng Long",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Self-Calibrated_Cross_Attention_Network_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Nanjing University of Science and Technology; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/Sam1224/SCCAN",
        "arxiv": "2308.09294"
    },
    {
        "title": "Self-Evolved Dynamic Expansion Model for Task-Free Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Self-Evolved_Dynamic_Expansion_Model_for_Task-Free_Continual_Learning_ICCV_2023_paper.html",
        "author": "Fei Ye, Adrian G. Bors",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Self-Evolved_Dynamic_Expansion_Model_for_Task-Free_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, University of York, York YO10 5GH, UK",
        "project": "",
        "github": "https://github.com/dtuzi123/SEDEM/",
        "arxiv": ""
    },
    {
        "title": "Self-Feedback DETR for Temporal Action Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Self-Feedback_DETR_for_Temporal_Action_Detection_ICCV_2023_paper.html",
        "author": "Jihwan Kim, Miso Lee, Jae-Pil Heo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Self-Feedback_DETR_for_Temporal_Action_Detection_ICCV_2023_paper.pdf",
        "aff": "Sungkyunkwan University",
        "project": "",
        "github": "",
        "arxiv": "2308.10570"
    },
    {
        "title": "Self-Ordering Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Self-Ordering_Point_Clouds_ICCV_2023_paper.html",
        "author": "Pengwan Yang, Cees G. M. Snoek, Yuki M. Asano",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Self-Ordering_Point_Clouds_ICCV_2023_paper.pdf",
        "aff": "University of Amsterdam",
        "project": "",
        "github": "",
        "arxiv": "2304.00961"
    },
    {
        "title": "Self-Organizing Pathway Expansion for Non-Exemplar Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Self-Organizing_Pathway_Expansion_for_Non-Exemplar_Class-Incremental_Learning_ICCV_2023_paper.html",
        "author": "Kai Zhu, Kecheng Zheng, Ruili Feng, Deli Zhao, Yang Cao, Zheng-Jun Zha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Self-Organizing_Pathway_Expansion_for_Non-Exemplar_Class-Incremental_Learning_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; Alibaba Group, University of Science and Technology of China; University of Science and Technology of China; Alibaba Group; Zhejiang University, Ant Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-Supervised Burst Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_paper.html",
        "author": "Goutam Bhat, Micha\u00ebl Gharbi, Jiawen Chen, Luc Van Gool, Zhihao Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "Adobe; CVL, ETH Zurich",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-Supervised Character-to-Character Distillation for Text Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guan_Self-Supervised_Character-to-Character_Distillation_for_Text_Recognition_ICCV_2023_paper.html",
        "author": "Tongkun Guan, Wei Shen, Xue Yang, Qi Feng, Zekun Jiang, Xiaokang Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_Self-Supervised_Character-to-Character_Distillation_for_Text_Recognition_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, Shanghai Jiao Tong University; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/TongkunGuan/CCD",
        "arxiv": "2211.00288"
    },
    {
        "title": "Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative Convolution Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_Self-Supervised_Monocular_Depth_Estimation_by_Direction-aware_Cumulative_Convolution_Network_ICCV_2023_paper.html",
        "author": "Wencheng Han, Junbo Yin, Jianbing Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Self-Supervised_Monocular_Depth_Estimation_by_Direction-aware_Cumulative_Convolution_Network_ICCV_2023_paper.pdf",
        "aff": "SKL-IOTSC, CIS, University of Macau; Beijing Institute of Technology",
        "project": "",
        "github": "https://github.com/wencheng256/DaCCN",
        "arxiv": "2308.05605"
    },
    {
        "title": "Self-Supervised Object Detection from Egocentric Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Akiva_Self-Supervised_Object_Detection_from_Egocentric_Videos_ICCV_2023_paper.html",
        "author": "Peri Akiva, Jing Huang, Kevin J Liang, Rama Kovvuri, Xingyu Chen, Matt Feiszli, Kristin Dana, Tal Hassner",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Akiva_Self-Supervised_Object_Detection_from_Egocentric_Videos_ICCV_2023_paper.pdf",
        "aff": "Rutgers University; Meta AI",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-regulating Prompts: Foundational Model Adaptation without Forgetting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Khattak_Self-regulating_Prompts_Foundational_Model_Adaptation_without_Forgetting_ICCV_2023_paper.html",
        "author": "Muhammad Uzair Khattak, Syed Talal Wasim, Muzammal Naseer, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Khattak_Self-regulating_Prompts_Foundational_Model_Adaptation_without_Forgetting_ICCV_2023_paper.pdf",
        "aff": "Link\u00f6ping University; University of California, Merced; Mohamed bin Zayed University of AI; Australian National University",
        "project": "",
        "github": "https://github.com/muzairkhattak/PromptSRC",
        "arxiv": "2307.06948"
    },
    {
        "title": "Self-similarity Driven Scale-invariant Learning for Weakly Supervised Person Search",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Self-similarity_Driven_Scale-invariant_Learning_for_Weakly_Supervised_Person_Search_ICCV_2023_paper.html",
        "author": "Benzhi Wang, Yang Yang, Jinlin Wu, Guo-jun Qi, Zhen Lei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Self-similarity_Driven_Scale-invariant_Learning_for_Weakly_Supervised_Person_Search_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences; OPPO Research; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences; Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/Wangbenzhi/SSL.git",
        "arxiv": "2302.12986"
    },
    {
        "title": "Self-supervised Cross-view Representation Reconstruction for Change Captioning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tu_Self-supervised_Cross-view_Representation_Reconstruction_for_Change_Captioning_ICCV_2023_paper.html",
        "author": "Yunbin Tu, Liang Li, Li Su, Zheng-Jun Zha, Chenggang Yan, Qingming Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Self-supervised_Cross-view_Representation_Reconstruction_for_Change_Captioning_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Hefei, China; Hangzhou Dianzi University, Hangzhou, China; Key Lab of Intelligent Information Processing, ICT, CAS, Beijing, China; University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "https://github.com/tuyunbin/SCORER",
        "arxiv": ""
    },
    {
        "title": "Self-supervised Image Denoising with Downsampled Invariance Loss and Conditional Blind-Spot Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Self-supervised_Image_Denoising_with_Downsampled_Invariance_Loss_and_Conditional_Blind-Spot_ICCV_2023_paper.html",
        "author": "Yeong Il Jang, Keuntek Lee, Gu Yong Park, Seyun Kim, Nam Ik Cho",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Self-supervised_Image_Denoising_with_Downsampled_Invariance_Loss_and_Conditional_Blind-Spot_ICCV_2023_paper.pdf",
        "aff": "IPAI, Seoul National University, Seoul, Korea; Gauss Labs Inc.; Department of ECE, INMC, Seoul National University, Seoul, Korea",
        "project": "",
        "github": "",
        "arxiv": "2304.09507"
    },
    {
        "title": "Self-supervised Learning of Implicit Shape Representation with Dense Correspondence for Deformable Objects",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Self-supervised_Learning_of_Implicit_Shape_Representation_with_Dense_Correspondence_for_ICCV_2023_paper.html",
        "author": "Baowen Zhang, Jiahe Li, Xiaoming Deng, Yinda Zhang, Cuixia Ma, Hongan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Self-supervised_Learning_of_Implicit_Shape_Representation_with_Dense_Correspondence_for_ICCV_2023_paper.pdf",
        "aff": "Google; Institute of Software, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://iscas3dv.github.io/deformshape",
        "arxiv": "2308.12590"
    },
    {
        "title": "Self-supervised Learning to Bring Dual Reversed Rolling Shutter Images Alive",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shang_Self-supervised_Learning_to_Bring_Dual_Reversed_Rolling_Shutter_Images_Alive_ICCV_2023_paper.html",
        "author": "Wei Shang, Dongwei Ren, Chaoyu Feng, Xiaotao Wang, Lei Lei, Wangmeng Zuo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shang_Self-supervised_Learning_to_Bring_Dual_Reversed_Rolling_Shutter_Images_Alive_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Technology, Harbin Institute of Technology; Peng Cheng Laboratory, Shenzhen; Not provided in the text; School of Computer Science and Technology, Harbin Institute of Technology",
        "project": "",
        "github": "https://github.com/shangwei5/SelfDRSC",
        "arxiv": "2305.19862"
    },
    {
        "title": "Self-supervised Monocular Depth Estimation: Let's Talk About The Weather",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Saunders_Self-supervised_Monocular_Depth_Estimation_Lets_Talk_About_The_Weather_ICCV_2023_paper.html",
        "author": "Kieran Saunders, George Vogiatzis, Luis J. Manso",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Saunders_Self-supervised_Monocular_Depth_Estimation_Lets_Talk_About_The_Weather_ICCV_2023_paper.pdf",
        "aff": "Aston University, Birmingham, UK; Loughborough University, Leicestershire, UK",
        "project": "https://kieran514.github.io/Robust-Depth-Project/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-supervised Monocular Underwater Depth Recovery, Image Restoration, and a Real-sea Video Dataset",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.html",
        "author": "Nisha Varghese, Ashish Kumar, A. N. Rajagopalan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.pdf",
        "aff": "Indian Institute of Technology Madras, India",
        "project": "",
        "github": "https://github.com/nishavarghese15/DRUVA",
        "arxiv": ""
    },
    {
        "title": "Self-supervised Pre-training for Mirror Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Self-supervised_Pre-training_for_Mirror_Detection_ICCV_2023_paper.html",
        "author": "Jiaying Lin, Rynson W.H. Lau",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Self-supervised_Pre-training_for_Mirror_Detection_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong",
        "project": "",
        "github": "https://jiaying.link/iccv2023-sslmirror/",
        "arxiv": ""
    },
    {
        "title": "SemARFlow: Injecting Semantics into Unsupervised Optical Flow Estimation for Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_SemARFlow_Injecting_Semantics_into_Unsupervised_Optical_Flow_Estimation_for_Autonomous_ICCV_2023_paper.html",
        "author": "Shuai Yuan, Shuzhi Yu, Hannah Kim, Carlo Tomasi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_SemARFlow_Injecting_Semantics_into_Unsupervised_Optical_Flow_Estimation_for_Autonomous_ICCV_2023_paper.pdf",
        "aff": "Duke University",
        "project": "",
        "github": "https://github.com/duke-vision/semantic-unsup-flow-release",
        "arxiv": "2303.06209"
    },
    {
        "title": "Semantic Attention Flow Fields for Monocular Dynamic Scene Decomposition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Semantic_Attention_Flow_Fields_for_Monocular_Dynamic_Scene_Decomposition_ICCV_2023_paper.html",
        "author": "Yiqing Liang, Eliot Laidlaw, Alexander Meyerowitz, Srinath Sridhar, James Tompkin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Semantic_Attention_Flow_Fields_for_Monocular_Dynamic_Scene_Decomposition_ICCV_2023_paper.pdf",
        "aff": "Brown University",
        "project": "https://visual.cs.brown.edu/saff",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Semantic Information in Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Semantic_Information_in_Contrastive_Learning_ICCV_2023_paper.html",
        "author": "Shengjiang Quan, Masahiro Hirano, Yuji Yamakawa",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Semantic_Information_in_Contrastive_Learning_ICCV_2023_paper.pdf",
        "aff": "Institute of Industrial Science, The University of Tokyo, Japan; Interfaculty Initiative in Information Studies, The University of Tokyo, Japan; Graduate School of Engineering, The University of Tokyo, Japan",
        "project": "",
        "github": "https://github.com/sjiang95/semcl",
        "arxiv": ""
    },
    {
        "title": "Semantic-Aware Dynamic Parameter for Video Inpainting Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Semantic-Aware_Dynamic_Parameter_for_Video_Inpainting_Transformer_ICCV_2023_paper.html",
        "author": "Eunhye Lee, Jinsu Yoo, Yunjeong Yang, Sungyong Baik, Tae Hyun Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Semantic-Aware_Dynamic_Parameter_for_Video_Inpainting_Transformer_ICCV_2023_paper.pdf",
        "aff": "Dept. of Computer Science, Hanyang University; Dept. of Data Science, Hanyang University; Dept. of Artificial Intelligence, Hanyang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Semantic-Aware Implicit Template Learning via Part Deformation Consistency",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Semantic-Aware_Implicit_Template_Learning_via_Part_Deformation_Consistency_ICCV_2023_paper.html",
        "author": "Sihyeon Kim, Minseok Joo, Jaewon Lee, Juyeon Ko, Juhan Cha, Hyunwoo J. Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Semantic-Aware_Implicit_Template_Learning_via_Part_Deformation_Consistency_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, Korea University",
        "project": "",
        "github": "https://github.com/mlvlab/PDC",
        "arxiv": "2308.11916"
    },
    {
        "title": "Semantically Structured Image Compression via Irregular Group-Based Decoupling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.html",
        "author": "Ruoyu Feng, Yixin Gao, Xin Jin, Runsen Feng, Zhibo Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.pdf",
        "aff": "Eastern Institute of Technology, Ningbo; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2305.02586"
    },
    {
        "title": "Semantics Meets Temporal Correspondence: Self-supervised Object-centric Learning in Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Semantics_Meets_Temporal_Correspondence_Self-supervised_Object-centric_Learning_in_Videos_ICCV_2023_paper.html",
        "author": "Rui Qian, Shuangrui Ding, Xian Liu, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Semantics_Meets_Temporal_Correspondence_Self-supervised_Object-centric_Learning_in_Videos_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; The Chinese University of Hong Kong, Shanghai Artificial Intelligence Laboratory",
        "project": "",
        "github": "https://github.com/shvdiwnkozbw/SMTC",
        "arxiv": "2308.09951"
    },
    {
        "title": "Semantics-Consistent Feature Search for Self-Supervised Visual Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_Semantics-Consistent_Feature_Search_for_Self-Supervised_Visual_Representation_Learning_ICCV_2023_paper.html",
        "author": "Kaiyou Song, Shan Zhang, Zimeng Luo, Tong Wang, Jin Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Semantics-Consistent_Feature_Search_for_Self-Supervised_Visual_Representation_Learning_ICCV_2023_paper.pdf",
        "aff": "Megvii Technology",
        "project": "",
        "github": "https://github.com/skyoux/scfs",
        "arxiv": "2212.06486"
    },
    {
        "title": "Semantify: Simplifying the Control of 3D Morphable Models Using CLIP",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gralnik_Semantify_Simplifying_the_Control_of_3D_Morphable_Models_Using_CLIP_ICCV_2023_paper.html",
        "author": "Omer Gralnik, Guy Gafni, Ariel Shamir",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gralnik_Semantify_Simplifying_the_Control_of_3D_Morphable_Models_Using_CLIP_ICCV_2023_paper.pdf",
        "aff": "Reichman University; Technical University of Munich",
        "project": "https://omergral.github.io/Semantify/",
        "github": "https://github.com/omergral/Semantify",
        "arxiv": "2308.07415"
    },
    {
        "title": "Semi-Supervised Learning via Weight-Aware Distillation under Class Distribution Mismatch",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Du_Semi-Supervised_Learning_via_Weight-Aware_Distillation_under_Class_Distribution_Mismatch_ICCV_2023_paper.html",
        "author": "Pan Du, Suyun Zhao, Zisen Sheng, Cuiping Li, Hong Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Du_Semi-Supervised_Learning_via_Weight-Aware_Distillation_under_Class_Distribution_Mismatch_ICCV_2023_paper.pdf",
        "aff": "Key Lab of Data Engineering and Knowledge Engineering of MOE Renmin University of China, Renmin University of China, Beijing, China",
        "project": "",
        "github": "https://github.com/RUC-DWBI-ML/research/tree/main/WAD-master",
        "arxiv": "2308.11874"
    },
    {
        "title": "Semi-Supervised Semantic Segmentation under Label Noise via Diverse Learning Groups",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Semi-Supervised_Semantic_Segmentation_under_Label_Noise_via_Diverse_Learning_Groups_ICCV_2023_paper.html",
        "author": "Peixia Li, Pulak Purkait, Thalaiyasingam Ajanthan, Majid Abdolshah, Ravi Garg, Hisham Husain, Chenchen Xu, Stephen Gould, Wanli Ouyang, Anton van den Hengel",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Semi-Supervised_Semantic_Segmentation_under_Label_Noise_via_Diverse_Learning_Groups_ICCV_2023_paper.pdf",
        "aff": "Amazon; The University of Adelaide; Australian National University; The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Semi-supervised Semantics-guided Adversarial Training for Robust Trajectory Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiao_Semi-supervised_Semantics-guided_Adversarial_Training_for_Robust_Trajectory_Prediction_ICCV_2023_paper.html",
        "author": "Ruochen Jiao, Xiangguo Liu, Takami Sato, Qi Alfred Chen, Qi Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiao_Semi-supervised_Semantics-guided_Adversarial_Training_for_Robust_Trajectory_Prediction_ICCV_2023_paper.pdf",
        "aff": "Northwestern University; University of California, Irvine",
        "project": "",
        "github": "https://github.com/jrcblue/SSAT-for-Motion-Prediction",
        "arxiv": ""
    },
    {
        "title": "Semi-supervised Speech-driven 3D Facial Animation via Cross-modal Encoding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Semi-supervised_Speech-driven_3D_Facial_Animation_via_Cross-modal_Encoding_ICCV_2023_paper.html",
        "author": "Peiji Yang, Huawei Wei, Yicheng Zhong, Zhisheng Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Semi-supervised_Speech-driven_3D_Facial_Animation_via_Cross-modal_Encoding_ICCV_2023_paper.pdf",
        "aff": "Tencent, Shenzhen, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Sensitivity-Aware Visual Parameter-Efficient Fine-Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.html",
        "author": "Haoyu He, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.pdf",
        "aff": "ZIP Lab, Monash University; The University of Sydney",
        "project": "",
        "github": "https://github.com/ziplab/SPT",
        "arxiv": "2303.08566"
    },
    {
        "title": "Sentence Attention Blocks for Answer Grounding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Khoshsirat_Sentence_Attention_Blocks_for_Answer_Grounding_ICCV_2023_paper.html",
        "author": "Seyedalireza Khoshsirat, Chandra Kambhamettu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Khoshsirat_Sentence_Attention_Blocks_for_Answer_Grounding_ICCV_2023_paper.pdf",
        "aff": "Video/Image Modeling and Synthesis (VIMS) Lab, University of Delaware",
        "project": "",
        "github": "",
        "arxiv": "2309.11593"
    },
    {
        "title": "Sequential Texts Driven Cohesive Motions Synthesis with Natural Transitions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Sequential_Texts_Driven_Cohesive_Motions_Synthesis_with_Natural_Transitions_ICCV_2023_paper.html",
        "author": "Shuai Li, Sisi Zhuang, Wenfeng Song, Xinyu Zhang, Hejia Chen, Aimin Hao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Sequential_Texts_Driven_Cohesive_Motions_Synthesis_with_Natural_Transitions_ICCV_2023_paper.pdf",
        "aff": "Computer School, Beijing Information Science and Technology University, P.R. China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, P.R. China",
        "project": "https://druthrie.github.io/sequential-texts-to-motion/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Set-level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-training Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Set-level_Guidance_Attack_Boosting_Adversarial_Transferability_of_Vision-Language_Pre-training_Models_ICCV_2023_paper.html",
        "author": "Dong Lu, Zhiqiang Wang, Teng Wang, Weili Guan, Hongchang Gao, Feng Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Set-level_Guidance_Attack_Boosting_Adversarial_Transferability_of_Vision-Language_Pre-training_Models_ICCV_2023_paper.pdf",
        "aff": "Temple University; The University of Hong Kong; Monash University; Southern University of Science and Technology; Peng Cheng Laboratory",
        "project": "",
        "github": "https://github.com/Zoky-2020/SGA",
        "arxiv": "2307.14061"
    },
    {
        "title": "Shape Analysis of Euclidean Curves under Frenet-Serret Framework",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chassat_Shape_Analysis_of_Euclidean_Curves_under_Frenet-Serret_Framework_ICCV_2023_paper.html",
        "author": "Perrine Chassat, Juhyun Park, Nicolas Brunel",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chassat_Shape_Analysis_of_Euclidean_Curves_under_Frenet-Serret_Framework_ICCV_2023_paper.pdf",
        "aff": "ENSIIE, Evry; LaMME, University of Paris-Saclay; Quantmetry, Paris",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Shape Anchor Guided Holistic Indoor Scene Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Shape_Anchor_Guided_Holistic_Indoor_Scene_Understanding_ICCV_2023_paper.html",
        "author": "Mingyue Dong, Linxi Huan, Hanjiang Xiong, Shuhan Shen, Xianwei Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Shape_Anchor_Guided_Holistic_Indoor_Scene_Understanding_ICCV_2023_paper.pdf",
        "aff": "Institute of Automation, Chinese Academy of Sciences; The State Key Lab. LIESMARS, Wuhan University",
        "project": "",
        "github": "https://github.com/Geo-Tell/AncRec",
        "arxiv": "2309.11133"
    },
    {
        "title": "ShapeScaffolder: Structure-Aware 3D Shape Generation from Text",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tian_ShapeScaffolder_Structure-Aware_3D_Shape_Generation_from_Text_ICCV_2023_paper.html",
        "author": "Xi Tian, Yong-Liang Yang, Qi Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_ShapeScaffolder_Structure-Aware_3D_Shape_Generation_from_Text_ICCV_2023_paper.pdf",
        "aff": "University of Bath, Bath, UK; University of Adelaide, Adelaide, Australia",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Shatter and Gather: Learning Referring Image Segmentation with Text Supervision",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_paper.html",
        "author": "Dongwon Kim, Namyup Kim, Cuiling Lan, Suha Kwak",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; POSTECH",
        "project": "http://cvlab.postech.ac.kr/research/sag",
        "github": "",
        "arxiv": "2308.15512"
    },
    {
        "title": "Shift from Texture-bias to Shape-bias: Edge Deformation-based Augmentation for Robust Object Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Shift_from_Texture-bias_to_Shape-bias_Edge_Deformation-based_Augmentation_for_Robust_ICCV_2023_paper.html",
        "author": "Xilin He, Qinliang Lin, Cheng Luo, Weicheng Xie, Siyang Song, Feng Liu, Linlin Shen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Shift_from_Texture-bias_to_Shape-bias_Edge_Deformation-based_Augmentation_for_Robust_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Institute, School of Computer Science & Software Engineering, Shenzhen University; Guangdong Key Laboratory of intelligent Information Processing; University of Leicester; Shenzhen Institue of Artificial Intelligence & Robotics for Society",
        "project": "",
        "github": "https://github.com/C0notSilly/-ICCV-23-Edge-Deformation-based-Online-Augmentation",
        "arxiv": ""
    },
    {
        "title": "ShiftNAS: Improving One-shot NAS via Probability Shift",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ShiftNAS_Improving_One-shot_NAS_via_Probability_Shift_ICCV_2023_paper.html",
        "author": "Mingyang Zhang, Xinyi Yu, Haodong Zhao, Linlin Ou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ShiftNAS_Improving_One-shot_NAS_via_Probability_Shift_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University of Technology, Hangzhou, Zhejiang, China",
        "project": "",
        "github": "Available at GitHub (exact link not provided in text)",
        "arxiv": "2307.08300"
    },
    {
        "title": "Shortcut-V2V: Compression Framework for Video-to-Video Translation Based on Temporal Redundancy Reduction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chung_Shortcut-V2V_Compression_Framework_for_Video-to-Video_Translation_Based_on_Temporal_Redundancy_ICCV_2023_paper.html",
        "author": "Chaeyeon Chung, Yeojeong Park, Seunghwan Choi, Munkhsoyol Ganbat, Jaegul Choo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_Shortcut-V2V_Compression_Framework_for_Video-to-Video_Translation_Based_on_Temporal_Redundancy_ICCV_2023_paper.pdf",
        "aff": "KAIST AI, KT Research & Development Center, KT Corporation; KAIST AI",
        "project": "",
        "github": "https://shortcut-v2v.github.io/",
        "arxiv": ""
    },
    {
        "title": "Shrinking Class Space for Enhanced Certainty in Semi-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Shrinking_Class_Space_for_Enhanced_Certainty_in_Semi-Supervised_Learning_ICCV_2023_paper.html",
        "author": "Lihe Yang, Zhen Zhao, Lei Qi, Yu Qiao, Yinghuan Shi, Hengshuang Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Shrinking_Class_Space_for_Enhanced_Certainty_in_Semi-Supervised_Learning_ICCV_2023_paper.pdf",
        "aff": "The University of Hong Kong; Southeast University; The University of Sydney; Nanjing University; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/LiheYoung/ShrinkMatch",
        "arxiv": "2308.06777"
    },
    {
        "title": "SiLK: Simple Learned Keypoints",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gleize_SiLK_Simple_Learned_Keypoints_ICCV_2023_paper.html",
        "author": "Pierre Gleize, Weiyao Wang, Matt Feiszli",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gleize_SiLK_Simple_Learned_Keypoints_ICCV_2023_paper.pdf",
        "aff": "Meta AI",
        "project": "",
        "github": "https://github.com/facebookresearch/silk",
        "arxiv": ""
    },
    {
        "title": "Sigmoid Loss for Language Image Pre-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.html",
        "author": "Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, Lucas Beyer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.pdf",
        "aff": "Google DeepMind, Z\u00fcrich, Switzerland",
        "project": "",
        "github": "",
        "arxiv": "2303.15343"
    },
    {
        "title": "Sign Language Translation with Iterative Prototype",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Sign_Language_Translation_with_Iterative_Prototype_ICCV_2023_paper.html",
        "author": "Huijie Yao, Wengang Zhou, Hao Feng, Hezhen Hu, Hao Zhou, Houqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Sign_Language_Translation_with_Iterative_Prototype_ICCV_2023_paper.pdf",
        "aff": "CAS Key Laboratory of Technology in GIPAS, EEIS Department, University of Science and Technology of China; CAS Key Laboratory of Technology in GIPAS, EEIS Department, University of Science and Technology of China; Institute of Artificial Intelligence, Hefei Comprehensive National Science Center",
        "project": "",
        "github": "",
        "arxiv": "2308.12191"
    },
    {
        "title": "SimFIR: A Simple Framework for Fisheye Image Rectification with Self-supervised Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_SimFIR_A_Simple_Framework_for_Fisheye_Image_Rectification_with_Self-supervised_ICCV_2023_paper.html",
        "author": "Hao Feng, Wendi Wang, Jiajun Deng, Wengang Zhou, Li Li, Houqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_SimFIR_A_Simple_Framework_for_Fisheye_Image_Rectification_with_Self-supervised_ICCV_2023_paper.pdf",
        "aff": "CAS Key Laboratory of Technology in GIPAS, EEIS Department, University of Science and Technology of China; CAS Key Laboratory of Technology in GIPAS, EEIS Department, University of Science and Technology of China; Zhangjiang Laboratory, Shanghai, China; CAS Key Laboratory of Technology in GIPAS, EEIS Department, University of Science and Technology of China; Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": "2308.09040"
    },
    {
        "title": "SimMatchV2: Semi-Supervised Learning with Graph Consistency",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_SimMatchV2_Semi-Supervised_Learning_with_Graph_Consistency_ICCV_2023_paper.html",
        "author": "Mingkai Zheng, Shan You, Lang Huang, Chen Luo, Fei Wang, Chen Qian, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_SimMatchV2_Semi-Supervised_Learning_with_Graph_Consistency_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Faculty of Engineering, The University of Sydney; State Grid Anhui Electric Power Research Institute; University of Science and Technology of China; The University of Tokyo; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2308.06692"
    },
    {
        "title": "SimNP: Learning Self-Similarity Priors Between Neural Points",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wewer_SimNP_Learning_Self-Similarity_Priors_Between_Neural_Points_ICCV_2023_paper.html",
        "author": "Christopher Wewer, Eddy Ilg, Bernt Schiele, Jan Eric Lenssen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wewer_SimNP_Learning_Self-Similarity_Priors_Between_Neural_Points_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Informatics, Saarland Informatics Campus, Germany; Saarland University, Saarland Informatics Campus, Germany",
        "project": "",
        "github": "",
        "arxiv": "2309.03809"
    },
    {
        "title": "Similarity Min-Max: Zero-Shot Day-Night Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Similarity_Min-Max_Zero-Shot_Day-Night_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Rundong Luo, Wenjing Wang, Wenhan Yang, Jiaying Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Similarity_Min-Max_Zero-Shot_Day-Night_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University; Peng Cheng Laboratory",
        "project": "https://red-fairy.github.io/ZeroShotDayNightDA-Webpage/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Simoun: Synergizing Interactive Motion-appearance Understanding for Vision-based Reinforcement Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Simoun_Synergizing_Interactive_Motion-appearance_Understanding_for_Vision-based_Reinforcement_Learning_ICCV_2023_paper.html",
        "author": "Yangru Huang, Peixi Peng, Yifan Zhao, Yunpeng Zhai, Haoran Xu, Yonghong Tian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Simoun_Synergizing_Interactive_Motion-appearance_Understanding_for_Vision-based_Reinforcement_Learning_ICCV_2023_paper.pdf",
        "aff": "Actor\nCritic\nActor\nCriticActor\nCritic\nActor\nCritic(a) Individual Frame (b)Stacked Frames\n(c) Latent Flow (d) Ours \nInteractive\nConcatenation Appearance-related encoder/feature\nMotion-related encoder/feature\n Motion-appearance mixed encoder/feature\n\u0001\u0002\u0003\u0004\n\u0001\u0002\u0001\u0002\u0003\u0005\n\u0001\u0002\u0003\u0004\n\u0001\u0002\u0001\u0002\u0003\u0005\u0001\u0002\u0003\u0005\u2212\u0001\u0002\u0003\u0004\n\u0001\u0002\u0001\u0002\u0003\u0004\n\u0001\u0002\u0001\u0002\u0003\u0005\n\u0001\u0002\u2212\u0001\u0002\u0003\u0005\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n176\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Simple Baselines for Interactive Video Retrieval with Questions and Answers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Simple_Baselines_for_Interactive_Video_Retrieval_with_Questions_and_Answers_ICCV_2023_paper.html",
        "author": "Kaiqu Liang, Samuel Albanie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Simple_Baselines_for_Interactive_Video_Retrieval_with_Questions_and_Answers_ICCV_2023_paper.pdf",
        "aff": "University of Cambridge; Princeton University",
        "project": "",
        "github": "https://github.com/kevinliang888/IVR-QA-baselines",
        "arxiv": "2308.10402"
    },
    {
        "title": "Simple and Effective Out-of-Distribution Detection via Cosine-based Softmax Loss",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Noh_Simple_and_Effective_Out-of-Distribution_Detection_via_Cosine-based_Softmax_Loss_ICCV_2023_paper.html",
        "author": "SoonCheol Noh, DongEon Jeong, Jee-Hyong Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Noh_Simple_and_Effective_Out-of-Distribution_Detection_via_Cosine-based_Softmax_Loss_ICCV_2023_paper.pdf",
        "aff": "Sungkyunkwan University, Suwon, Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SimpleClick: Interactive Image Segmentation with Simple Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Qin Liu, Zhenlin Xu, Gedas Bertasius, Marc Niethammer",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "University of North Carolina at Chapel Hill",
        "project": "",
        "github": "https://github.com/uncbiag/SimpleClick",
        "arxiv": "2210.11006"
    },
    {
        "title": "Simulating Fluids in Real-World Still Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Simulating_Fluids_in_Real-World_Still_Images_ICCV_2023_paper.html",
        "author": "Siming Fan, Jingtan Piao, Chen Qian, Hongsheng Li, Kwan-Yee Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Simulating_Fluids_in_Real-World_Still_Images_ICCV_2023_paper.pdf",
        "aff": "Shanghai AI Laboratory, The Chinese University of Hong Kong; SenseTime Research, The Chinese University of Hong Kong; Shanghai AI Laboratory, The Chinese University of Hong Kong, CPII; SenseTime Research",
        "project": "https://slr-sfs.github.io/",
        "github": "",
        "arxiv": "2204.11335"
    },
    {
        "title": "Single Depth-image 3D Reflection Symmetry and Shape Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.html",
        "author": "Zhaoxuan Zhang, Bo Dong, Tong Li, Felix Heide, Pieter Peers, Baocai Yin, Xin Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.pdf",
        "aff": "",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Single Image Deblurring with Row-dependent Blur Magnitude",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Single_Image_Deblurring_with_Row-dependent_Blur_Magnitude_ICCV_2023_paper.html",
        "author": "Xiang Ji, Zhixiang Wang, Shin'ichi Satoh, Yinqiang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Single_Image_Deblurring_with_Row-dependent_Blur_Magnitude_ICCV_2023_paper.pdf",
        "aff": "National Institute of Informatics, Japan/The University of Tokyo, Japan; The University of Tokyo, Japan/National Institute of Informatics, Japan; The University of Tokyo, Japan",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Single Image Defocus Deblurring via Implicit Neural Inverse Kernels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Single_Image_Defocus_Deblurring_via_Implicit_Neural_Inverse_Kernels_ICCV_2023_paper.html",
        "author": "Yuhui Quan, Xin Yao, Hui Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Single_Image_Defocus_Deblurring_via_Implicit_Neural_Inverse_Kernels_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China; Pazhou Lab, Guangzhou 510335, China; Department of Mathematics, National University of Singapore, 119076, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Single Image Reflection Separation via Component Synergy",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Single_Image_Reflection_Separation_via_Component_Synergy_ICCV_2023_paper.html",
        "author": "Qiming Hu, Xiaojie Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Single_Image_Reflection_Separation_via_Component_Synergy_ICCV_2023_paper.pdf",
        "aff": "College of Intelligence and Computing, Tianjin University, Tianjin, China",
        "project": "",
        "github": "https://github.com/mingcv/DSRNet",
        "arxiv": "2308.10027"
    },
    {
        "title": "Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.html",
        "author": "Hansheng Chen, Jiatao Gu, Anpei Chen, Wei Tian, Zhuowen Tu, Lingjie Liu, Hao Su",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.pdf",
        "aff": "University of Pennsylvania; Tongji University; ETH Z\u00fcrich; Apple; University of California, San Diego",
        "project": "https://lakonik.github.io/ssdnerf",
        "github": "",
        "arxiv": "2304.06714"
    },
    {
        "title": "Size Does Matter: Size-aware Virtual Try-on via Clothing-oriented Transformation Try-on Network",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Size_Does_Matter_Size-aware_Virtual_Try-on_via_Clothing-oriented_Transformation_Try-on_ICCV_2023_paper.html",
        "author": "Chieh-Yun Chen, Yi-Chung Chen, Hong-Han Shuai, Wen-Huang Cheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Size_Does_Matter_Size-aware_Virtual_Try-on_via_Clothing-oriented_Transformation_Try-on_ICCV_2023_paper.pdf",
        "aff": "National Taiwan University, Stylins.ai; Stylins.ai, National Yang Ming Chiao Tung University; National Taiwan University; National Yang Ming Chiao Tung University",
        "project": "",
        "github": "https://github.com/cotton6/COTTON-size-does-matter",
        "arxiv": ""
    },
    {
        "title": "SkeleTR: Towards Skeleton-based Action Recognition in the Wild",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Duan_SkeleTR_Towards_Skeleton-based_Action_Recognition_in_the_Wild_ICCV_2023_paper.html",
        "author": "Haodong Duan, Mingze Xu, Bing Shuai, Davide Modolo, Zhuowen Tu, Joseph Tighe, Alessandro Bergamo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_SkeleTR_Towards_Skeleton-based_Action_Recognition_in_the_Wild_ICCV_2023_paper.pdf",
        "aff": "AWS AI Labs; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SkeletonMAE: Graph-based Masked Autoencoder for Skeleton Sequence Pre-training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_SkeletonMAE_Graph-based_Masked_Autoencoder_for_Skeleton_Sequence_Pre-training_ICCV_2023_paper.html",
        "author": "Hong Yan, Yang Liu, Yushen Wei, Zhen Li, Guanbin Li, Liang Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_SkeletonMAE_Graph-based_Masked_Autoencoder_for_Skeleton_Sequence_Pre-training_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong, Shenzhen, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
        "project": "",
        "github": "https://github.com/HongYan1123/SkeletonMAE",
        "arxiv": "2307.08476"
    },
    {
        "title": "Sketch and Text Guided Diffusion Model for Colored Point Cloud Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Sketch_and_Text_Guided_Diffusion_Model_for_Colored_Point_Cloud_ICCV_2023_paper.html",
        "author": "Zijie Wu, Yaonan Wang, Mingtao Feng, He Xie, Ajmal Mian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Sketch_and_Text_Guided_Diffusion_Model_for_Colored_Point_Cloud_ICCV_2023_paper.pdf",
        "aff": "The University of Western Australia; Xidian University; Hunan University",
        "project": "",
        "github": "",
        "arxiv": "2308.02874"
    },
    {
        "title": "Skill Transformer: A Monolithic Policy for Mobile Manipulation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Skill_Transformer_A_Monolithic_Policy_for_Mobile_Manipulation_ICCV_2023_paper.html",
        "author": "Xiaoyu Huang, Dhruv Batra, Akshara Rai, Andrew Szot",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Skill_Transformer_A_Monolithic_Policy_for_Mobile_Manipulation_ICCV_2023_paper.pdf",
        "aff": "Georgia Tech; Meta AI (FAIR); Meta AI (FAIR), Georgia Tech",
        "project": "",
        "github": "",
        "arxiv": "2308.09873"
    },
    {
        "title": "Skip-Plan: Procedure Planning in Instructional Videos via Condensed Action Space Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Skip-Plan_Procedure_Planning_in_Instructional_Videos_via_Condensed_Action_Space_ICCV_2023_paper.html",
        "author": "Zhiheng Li, Wenjia Geng, Muheng Li, Lei Chen, Yansong Tang, Jiwen Lu, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Skip-Plan_Procedure_Planning_in_Instructional_Videos_via_Condensed_Action_Space_ICCV_2023_paper.pdf",
        "aff": "Shenzhen International Graduate School, Tsinghua University; Beijing University of Science and Technology; Department of Automation, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SlaBins: Fisheye Depth Estimation using Slanted Bins on Road Environments",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_SlaBins_Fisheye_Depth_Estimation_using_Slanted_Bins_on_Road_Environments_ICCV_2023_paper.html",
        "author": "Jongsung Lee, Gyeongsu Cho, Jeongin Park, Kyongjun Kim, Seongoh Lee, Jung-Hee Kim, Seong-Gyun Jeong, Kyungdon Joo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_SlaBins_Fisheye_Depth_Estimation_using_Slanted_Bins_on_Road_Environments_ICCV_2023_paper.pdf",
        "aff": "242dot Inc.; Artificial Intelligence Graduate School, UNIST, 242dot Inc.",
        "project": "https://syniez.github.io/SlaBins/",
        "github": "https://github.com/syniez/SlaBins",
        "arxiv": ""
    },
    {
        "title": "Small Object Detection via Coarse-to-fine Proposal Generation and Imitation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Small_Object_Detection_via_Coarse-to-fine_Proposal_Generation_and_Imitation_Learning_ICCV_2023_paper.html",
        "author": "Xiang Yuan, Gong Cheng, Kebing Yan, Qinghua Zeng, Junwei Han",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Small_Object_Detection_via_Coarse-to-fine_Proposal_Generation_and_Imitation_Learning_ICCV_2023_paper.pdf",
        "aff": "School of Automation, Northwestern Polytechnical University, Xi'an, China",
        "project": "",
        "github": "https://github.com/shaunyuan22/CFINet",
        "arxiv": "2308.09534"
    },
    {
        "title": "Smoothness Similarity Regularization for Few-Shot GAN Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sushko_Smoothness_Similarity_Regularization_for_Few-Shot_GAN_Adaptation_ICCV_2023_paper.html",
        "author": "Vadim Sushko, Ruyu Wang, Juergen Gall",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sushko_Smoothness_Similarity_Regularization_for_Few-Shot_GAN_Adaptation_ICCV_2023_paper.pdf",
        "aff": "University of Bonn, Lamarr Institute for Machine Learning and Artificial Intelligence; Bosch Center for Artificial Intelligence, University of Bonn; Bosch Center for Artificial Intelligence",
        "project": "",
        "github": "",
        "arxiv": "2308.09717"
    },
    {
        "title": "Snow Removal in Video: A New Dataset and A Novel Method",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Snow_Removal_in_Video_A_New_Dataset_and_A_Novel_ICCV_2023_paper.html",
        "author": "Haoyu Chen, Jingjing Ren, Jinjin Gu, Hongtao Wu, Xuequan Lu, Haoming Cai, Lei Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Snow_Removal_in_Video_A_New_Dataset_and_A_Novel_ICCV_2023_paper.pdf",
        "aff": "La Trobe University; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology (Guangzhou); The University of Maryland; The University of Sydney",
        "project": "https://haoyuchen.com/VideoDesnowing",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SoDaCam: Software-defined Cameras via Single-Photon Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sundar_SoDaCam_Software-defined_Cameras_via_Single-Photon_Imaging_ICCV_2023_paper.html",
        "author": "Varun Sundar, Andrei Ardelean, Tristan Swedish, Claudio Bruschini, Edoardo Charbon, Mohit Gupta",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sundar_SoDaCam_Software-defined_Cameras_via_Single-Photon_Imaging_ICCV_2023_paper.pdf",
        "aff": "University of Wisconsin-Madison, Ubicept; Ubicept; University of Wisconsin-Madison; \u00b4Ecole polytechnique f \u00b4ed\u00b4erale de Lausanne",
        "project": "",
        "github": "",
        "arxiv": "2309.00066"
    },
    {
        "title": "Social Diffusion: Long-term Multiple Human Motion Anticipation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tanke_Social_Diffusion_Long-term_Multiple_Human_Motion_Anticipation_ICCV_2023_paper.html",
        "author": "Julian Tanke, Linguang Zhang, Amy Zhao, Chengcheng Tang, Yujun Cai, Lezi Wang, Po-Chen Wu, Juergen Gall, Cem Keskin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tanke_Social_Diffusion_Long-term_Multiple_Human_Motion_Anticipation_ICCV_2023_paper.pdf",
        "aff": "University of Bonn, Lamarr Institute for Machine Learning and Artificial Intelligence; Reality Labs Research; University of Bonn",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Sound Localization from Motion: Jointly Learning Sound Direction and Camera Rotation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Sound_Localization_from_Motion_Jointly_Learning_Sound_Direction_and_Camera_ICCV_2023_paper.html",
        "author": "Ziyang Chen, Shengyi Qian, Andrew Owens",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Sound_Localization_from_Motion_Jointly_Learning_Sound_Direction_and_Camera_ICCV_2023_paper.pdf",
        "aff": "University of Michigan",
        "project": "https://ificl.github.io/SLfM",
        "github": "",
        "arxiv": "2303.11329"
    },
    {
        "title": "Sound Source Localization is All about Cross-Modal Alignment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Senocak_Sound_Source_Localization_is_All_about_Cross-Modal_Alignment_ICCV_2023_paper.html",
        "author": "Arda Senocak, Hyeonggon Ryu, Junsik Kim, Tae-Hyun Oh, Hanspeter Pfister, Joon Son Chung",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Senocak_Sound_Source_Localization_is_All_about_Cross-Modal_Alignment_ICCV_2023_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology; Dept. of Electrical Engineering and Grad. School of Artificial Intelligence, POSTECH; Harvard University",
        "project": "",
        "github": "",
        "arxiv": "2309.10724"
    },
    {
        "title": "Source-free Depth for Object Pop-out",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/WU_Source-free_Depth_for_Object_Pop-out_ICCV_2023_paper.html",
        "author": "Zongwei WU, Danda Pani Paudel, Deng-Ping Fan, Jingjing Wang, Shuo Wang, C\u00e9dric Demonceaux, Radu Timofte, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/WU_Source-free_Depth_for_Object_Pop-out_ICCV_2023_paper.pdf",
        "aff": "AUST; Computer Vision Lab, CAIDAS & IFI, University of Wurzburg; CVL, ETH Zurich; University of Burgundy, CNRS, ICB",
        "project": "",
        "github": "https://github.com/Zongwei97/PopNet",
        "arxiv": "2212.05370"
    },
    {
        "title": "Source-free Domain Adaptive Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Peng_Source-free_Domain_Adaptive_Human_Pose_Estimation_ICCV_2023_paper.html",
        "author": "Qucheng Peng, Ce Zheng, Chen Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_Source-free_Domain_Adaptive_Human_Pose_Estimation_ICCV_2023_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida",
        "project": "",
        "github": "https://github.com/davidpengucf/SFDAHPE",
        "arxiv": "2308.03202"
    },
    {
        "title": "Space Engage: Collaborative Space Supervision for Contrastive-Based Semi-Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Space_Engage_Collaborative_Space_Supervision_for_Contrastive-Based_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Changqi Wang, Haoyu Xie, Yuhui Yuan, Chong Fu, Xiangyu Yue",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Space_Engage_Collaborative_Space_Supervision_for_Contrastive-Based_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Northeastern University, Shenyang, China; Key Laboratory of Intelligent Computing in Medical Image, Ministry of Education, NEU, China; Microsoft Research Asia; The Chinese University of Hong Kong; School of Computer Science and Engineering, Northeastern University, Shenyang, China",
        "project": "",
        "github": "",
        "arxiv": "2307.09755"
    },
    {
        "title": "Space-time Prompting for Video Class-incremental Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pei_Space-time_Prompting_for_Video_Class-incremental_Learning_ICCV_2023_paper.html",
        "author": "Yixuan Pei, Zhiwu Qing, Shiwei Zhang, Xiang Wang, Yingya Zhang, Deli Zhao, Xueming Qian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pei_Space-time_Prompting_for_Video_Class-incremental_Learning_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group; Huazhong University of Science and Technology; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SpaceEvo: Hardware-Friendly Search Space Design for Efficient INT8 Inference",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SpaceEvo_Hardware-Friendly_Search_Space_Design_for_Efficient_INT8_Inference_ICCV_2023_paper.html",
        "author": "Xudong Wang, Li Lyna Zhang, Jiahang Xu, Quanlu Zhang, Yujing Wang, Yuqing Yang, Ningxin Zheng, Ting Cao, Mao Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SpaceEvo_Hardware-Friendly_Search_Space_Design_for_Efficient_INT8_Inference_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research; Shanghai Jiao Tong University; Microsoft",
        "project": "",
        "github": "https://github.com/microsoft/Moonlit/tree/main/SpaceEvo",
        "arxiv": "2303.08308"
    },
    {
        "title": "Spacetime Surface Regularization for Neural Dynamic Scene Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Choe_Spacetime_Surface_Regularization_for_Neural_Dynamic_Scene_Reconstruction_ICCV_2023_paper.html",
        "author": "Jaesung Choe, Christopher Choy, Jaesik Park, In So Kweon, Anima Anandkumar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Choe_Spacetime_Surface_Regularization_for_Neural_Dynamic_Scene_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "Seoul National University; KAIST; NVIDIA; NVIDIA, Caltech; NVIDIA, KAIST",
        "project": "",
        "github": "https://4dregsdf.github.io/",
        "arxiv": ""
    },
    {
        "title": "Sparse Instance Conditioned Multimodal Trajectory Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Sparse_Instance_Conditioned_Multimodal_Trajectory_Prediction_ICCV_2023_paper.html",
        "author": "Yonghao Dong, Le Wang, Sanping Zhou, Gang Hua",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Sparse_Instance_Conditioned_Multimodal_Trajectory_Prediction_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Applications, and Institute of Arti\ufb01cial Intelligence and Robotics, Xi\u2019an Jiaotong University; Wormpex AI Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Sparse Point Guided 3D Lane Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Sparse_Point_Guided_3D_Lane_Detection_ICCV_2023_paper.html",
        "author": "Chengtang Yao, Lidong Yu, Yuwei Wu, Yunde Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Sparse_Point_Guided_3D_Lane_Detection_ICCV_2023_paper.pdf",
        "aff": "Autonomous Driving Algorithm, DeepRoute; Guangdong Laboratory of Machine Perception and Intelligent Computing, Shenzhen MSU-BIT University, China; Beijing Key Laboratory of Intelligent Information Technology, School of Computer Science & Technology, Beijing Institute of Technology, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Sparse Sampling Transformer with Uncertainty-Driven Ranking for Unified Removal of Raindrops and Rain Streaks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Sparse_Sampling_Transformer_with_Uncertainty-Driven_Ranking_for_Unified_Removal_of_ICCV_2023_paper.html",
        "author": "Sixiang Chen, Tian Ye, Jinbin Bai, Erkang Chen, Jun Shi, Lei Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Sparse_Sampling_Transformer_with_Uncertainty-Driven_Ranking_for_Unified_Removal_of_ICCV_2023_paper.pdf",
        "aff": "School of Ocean Information Engineering, Jimei University; National University of Singapore; Xinjiang University; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology (Guangzhou)",
        "project": "https://ephemeral182.github.io/UDR_S2Former_deraining",
        "github": "",
        "arxiv": "2308.14153"
    },
    {
        "title": "SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SparseBEV_High-Performance_Sparse_3D_Object_Detection_from_Multi-Camera_Videos_ICCV_2023_paper.html",
        "author": "Haisong Liu, Yao Teng, Tao Lu, Haiguang Wang, Limin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SparseBEV_High-Performance_Sparse_3D_Object_Detection_from_Multi-Camera_Videos_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University/Shanghai AI Lab",
        "project": "",
        "github": "https://github.com/MCG-NJU/SparseBEV",
        "arxiv": "2308.09244"
    },
    {
        "title": "SparseDet: Improving Sparsely Annotated Object Detection with Pseudo-positive Mining",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Suri_SparseDet_Improving_Sparsely_Annotated_Object_Detection_with_Pseudo-positive_Mining_ICCV_2023_paper.html",
        "author": "Saksham Suri, Saketh Rambhatla, Rama Chellappa, Abhinav Shrivastava",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Suri_SparseDet_Improving_Sparsely_Annotated_Object_Detection_with_Pseudo-positive_Mining_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park; Johns Hopkins University",
        "project": "http://cs.umd.edu/~sakshams/SparseDet",
        "github": "",
        "arxiv": "2201.04620"
    },
    {
        "title": "SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xie_SparseFusion_Fusing_Multi-Modal_Sparse_Representations_for_Multi-Sensor_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Yichen Xie, Chenfeng Xu, Marie-Julie Rakotosaona, Patrick Rim, Federico Tombari, Kurt Keutzer, Masayoshi Tomizuka, Wei Zhan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_SparseFusion_Fusing_Multi-Modal_Sparse_Representations_for_Multi-Sensor_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "California Institute of Technology; Google; University of California, Berkeley",
        "project": "",
        "github": "https://github.com/yichen928/SparseFusion",
        "arxiv": "2304.14340"
    },
    {
        "title": "SparseMAE: Sparse Training Meets Masked Autoencoders",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SparseMAE_Sparse_Training_Meets_Masked_Autoencoders_ICCV_2023_paper.html",
        "author": "Aojun Zhou, Yang Li, Zipeng Qin, Jianbo Liu, Junting Pan, Renrui Zhang, Rui Zhao, Peng Gao, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SparseMAE_Sparse_Training_Meets_Masked_Autoencoders_ICCV_2023_paper.pdf",
        "aff": "Shanghai AI Lab; SenseTime Research; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/aojunzz/SparseMAE",
        "arxiv": ""
    },
    {
        "title": "SparseNeRF: Distilling Depth Ranking for Few-shot Novel View Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SparseNeRF_Distilling_Depth_Ranking_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.html",
        "author": "Guangcong Wang, Zhaoxi Chen, Chen Change Loy, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SparseNeRF_Distilling_Depth_Ranking_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://sparsenerf.github.io/",
        "arxiv": "2303.16196"
    },
    {
        "title": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding Boxes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Spatial_Self-Distillation_for_Object_Detection_with_Inaccurate_Bounding_Boxes_ICCV_2023_paper.html",
        "author": "Di Wu, Pengfei Chen, Xuehui Yu, Guorong Li, Zhenjun Han, Jianbin Jiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial_Self-Distillation_for_Object_Detection_with_Inaccurate_Bounding_Boxes_ICCV_2023_paper.pdf",
        "aff": "University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det",
        "arxiv": "2307.12101"
    },
    {
        "title": "Spatial-Aware Token for Weakly Supervised Object Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Spatial-Aware_Token_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html",
        "author": "Pingyu Wu, Wei Zhai, Yang Cao, Jiebo Luo, Zheng-Jun Zha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial-Aware_Token_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China, Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; University of Rochester; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/wpy1999/SAT",
        "arxiv": "2303.10438"
    },
    {
        "title": "Spatially and Spectrally Consistent Deep Functional Maps",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatially_and_Spectrally_Consistent_Deep_Functional_Maps_ICCV_2023_paper.html",
        "author": "Mingze Sun, Shiwei Mao, Puhua Jiang, Maks Ovsjanikov, Ruqi Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially_and_Spectrally_Consistent_Deep_Functional_Maps_ICCV_2023_paper.pdf",
        "aff": "LIX, Ecole polytechnique, IP Paris, France; Tsinghua Shenzhen International Graduate School, China",
        "project": "",
        "github": "https://github.com/rqhuang88/Spatially-and-Spectrally-Consistent-Deep-Functional-Maps",
        "arxiv": "2308.08871"
    },
    {
        "title": "Spatially-Adaptive Feature Modulation for Efficient Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html",
        "author": "Long Sun, Jiangxin Dong, Jinhui Tang, Jinshan Pan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology",
        "project": "",
        "github": "https://github.com/sunny2109/SAFMN",
        "arxiv": "2302.13800"
    },
    {
        "title": "Spatio-Temporal Crop Aggregation for Video Representation Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sameni_Spatio-Temporal_Crop_Aggregation_for_Video_Representation_Learning_ICCV_2023_paper.html",
        "author": "Sepehr Sameni, Simon Jenni, Paolo Favaro",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sameni_Spatio-Temporal_Crop_Aggregation_for_Video_Representation_Learning_ICCV_2023_paper.pdf",
        "aff": "University of Bern; Adobe Research",
        "project": "",
        "github": "",
        "arxiv": "2211.17042"
    },
    {
        "title": "Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.html",
        "author": "Kun Yang, Dingkang Yang, Jingyu Zhang, Mingcheng Li, Yang Liu, Jing Liu, Hanqi Wang, Peng Sun, Liang Song",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.pdf",
        "aff": "Duke Kunshan University; Institute of Meta-Medical, IPASS (at the time of the work); Academy for Engineering and Technology, Fudan University",
        "project": "https://ydk122024.github.io/SCOPE/",
        "github": "",
        "arxiv": "2307.13929"
    },
    {
        "title": "Spatio-temporal Prompting Network for Robust Video Feature Extraction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatio-temporal_Prompting_Network_for_Robust_Video_Feature_Extraction_ICCV_2023_paper.html",
        "author": "Guanxiong Sun, Chi Wang, Zhaoyu Zhang, Jiankang Deng, Stefanos Zafeiriou, Yang Hua",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatio-temporal_Prompting_Network_for_Robust_Video_Feature_Extraction_ICCV_2023_paper.pdf",
        "aff": "Queen\u2019s University Belfast, Huawei UKRD; Queen\u2019s University Belfast; Imperial College London; Huawei UKRD, Imperial College London",
        "project": "",
        "github": "https://github.com/guanxiongsun/STPN",
        "arxiv": ""
    },
    {
        "title": "Spectral Graphormer: Spectral Graph-Based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tse_Spectral_Graphormer_Spectral_Graph-Based_Transformer_for_Egocentric_Two-Hand_Reconstruction_using_ICCV_2023_paper.html",
        "author": "Tze Ho Elden Tse, Franziska Mueller, Zhengyang Shen, Danhang Tang, Thabo Beeler, Mingsong Dou, Yinda Zhang, Sasa Petrovic, Hyung Jin Chang, Jonathan Taylor, Bardia Doosti",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tse_Spectral_Graphormer_Spectral_Graph-Based_Transformer_for_Egocentric_Two-Hand_Reconstruction_using_ICCV_2023_paper.pdf",
        "aff": "Google; University of Birmingham",
        "project": "",
        "github": "",
        "arxiv": "2308.11015"
    },
    {
        "title": "Spectrum-guided Multi-granularity Referring Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Miao_Spectrum-guided_Multi-granularity_Referring_Video_Object_Segmentation_ICCV_2023_paper.html",
        "author": "Bo Miao, Mohammed Bennamoun, Yongsheng Gao, Ajmal Mian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_Spectrum-guided_Multi-granularity_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf",
        "aff": "The University of Western Australia; Grif\ufb01th University",
        "project": "",
        "github": "https://github.com/bo-miao/SgMg",
        "arxiv": "2307.13537"
    },
    {
        "title": "Speech2Lip: High-fidelity Speech to Lip Generation by Learning from a Short Video",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Speech2Lip_High-fidelity_Speech_to_Lip_Generation_by_Learning_from_a_ICCV_2023_paper.html",
        "author": "Xiuzhe Wu, Pengfei Hu, Yang Wu, Xiaoyang Lyu, Yan-Pei Cao, Ying Shan, Wenming Yang, Zhongqian Sun, Xiaojuan Qi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Speech2Lip_High-fidelity_Speech_to_Lip_Generation_by_Learning_from_a_ICCV_2023_paper.pdf",
        "aff": "Tencent AI Lab; The University of Hong Kong; ARC Lab, Tencent PCG; Tsinghua University",
        "project": "",
        "github": "https://github.com/CVMI-Lab/Speech2Lip",
        "arxiv": "2309.04814"
    },
    {
        "title": "Speech4Mesh: Speech-Assisted Monocular 3D Facial Reconstruction for Speech-Driven 3D Facial Animation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Speech4Mesh_Speech-Assisted_Monocular_3D_Facial_Reconstruction_for_Speech-Driven_3D_Facial_ICCV_2023_paper.html",
        "author": "Shan He, Haonan He, Shuo Yang, Xiaoyan Wu, Pengcheng Xia, Bing Yin, Cong Liu, Lirong Dai, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Speech4Mesh_Speech-Assisted_Monocular_3D_Facial_Reconstruction_for_Speech-Driven_3D_Facial_ICCV_2023_paper.pdf",
        "aff": "University of Sydney; iFLYTEK Research; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Spherical Space Feature Decomposition for Guided Depth Map Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_paper.html",
        "author": "Zixiang Zhao, Jiangshe Zhang, Xiang Gu, Chengli Tan, Shuang Xu, Yulun Zhang, Radu Timofte, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Lab, ETH Z\u00fcrich; Northwestern Polytechnical University; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "https://github.com/Zhaozixiang1228/GDSR-SSDNet",
        "arxiv": "2303.08942"
    },
    {
        "title": "SpinCam: High-Speed Imaging via a Rotating Point-Spread Function",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chan_SpinCam_High-Speed_Imaging_via_a_Rotating_Point-Spread_Function_ICCV_2023_paper.html",
        "author": "Dorian Chan, Mark Sheinin, Matthew O'Toole",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_SpinCam_High-Speed_Imaging_via_a_Rotating_Point-Spread_Function_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University, Pittsburgh, PA 15213, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SportsMOT: A Large Multi-Object Tracking Dataset in Multiple Sports Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cui_SportsMOT_A_Large_Multi-Object_Tracking_Dataset_in_Multiple_Sports_Scenes_ICCV_2023_paper.html",
        "author": "Yutao Cui, Chenkai Zeng, Xiaoyu Zhao, Yichun Yang, Gangshan Wu, Limin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_SportsMOT_A_Large_Multi-Object_Tracking_Dataset_in_Multiple_Sports_Scenes_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "project": "",
        "github": "https://github.com/MCG-NJU/SportsMOT",
        "arxiv": "2304.05170"
    },
    {
        "title": "Spurious Features Everywhere - Large-Scale Detection of Harmful Spurious Features in ImageNet",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Neuhaus_Spurious_Features_Everywhere_-_Large-Scale_Detection_of_Harmful_Spurious_Features_ICCV_2023_paper.html",
        "author": "Yannic Neuhaus, Maximilian Augustin, Valentyn Boreiko, Matthias Hein",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Neuhaus_Spurious_Features_Everywhere_-_Large-Scale_Detection_of_Harmful_Spurious_Features_ICCV_2023_paper.pdf",
        "aff": "T\u00a8ubingen AI Center \u2013 University of T \u00a8ubingen",
        "project": "",
        "github": "https://github.com/YanNeu/spurious_imagenet",
        "arxiv": ""
    },
    {
        "title": "Stabilizing Visual Reinforcement Learning via Asymmetric Interactive Cooperation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Stabilizing_Visual_Reinforcement_Learning_via_Asymmetric_Interactive_Cooperation_ICCV_2023_paper.html",
        "author": "Yunpeng Zhai, Peixi Peng, Yifan Zhao, Yangru Huang, Yonghong Tian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Stabilizing_Visual_Reinforcement_Learning_via_Asymmetric_Interactive_Cooperation_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University, Beijing, China; School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Stable Cluster Discrimination for Deep Clustering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Stable_Cluster_Discrimination_for_Deep_Clustering_ICCV_2023_paper.html",
        "author": "Qi Qian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Stable_Cluster_Discrimination_for_Deep_Clustering_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group, Bellevue, WA 98004, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Stable and Causal Inference for Discriminative Self-supervised Deep Visual Representations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Stable_and_Causal_Inference_for_Discriminative_Self-supervised_Deep_Visual_Representations_ICCV_2023_paper.html",
        "author": "Yuewei Yang, Hai Li, Yiran Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Stable_and_Causal_Inference_for_Discriminative_Self-supervised_Deep_Visual_Representations_ICCV_2023_paper.pdf",
        "aff": "Duke University, Durham, USA",
        "project": "",
        "github": "",
        "arxiv": "2308.08321"
    },
    {
        "title": "StableVideo: Text-driven Consistency-aware Diffusion Video Editing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chai_StableVideo_Text-driven_Consistency-aware_Diffusion_Video_Editing_ICCV_2023_paper.html",
        "author": "Wenhao Chai, Xun Guo, Gaoang Wang, Yan Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_StableVideo_Text-driven_Consistency-aware_Diffusion_Video_Editing_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; Zhejiang University",
        "project": "",
        "github": "https URL provided in the paper",
        "arxiv": "2308.09592"
    },
    {
        "title": "StageInteractor: Query-based Object Detector with Cross-stage Interaction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Teng_StageInteractor_Query-based_Object_Detector_with_Cross-stage_Interaction_ICCV_2023_paper.html",
        "author": "Yao Teng, Haisong Liu, Sheng Guo, Limin Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Teng_StageInteractor_Query-based_Object_Detector_with_Cross-stage_Interaction_ICCV_2023_paper.pdf",
        "aff": "MYbank, Ant Group, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; Shanghai AI Lab, China",
        "project": "",
        "github": "https://github.com/MCG-NJU/StageInteractor",
        "arxiv": "2304.04978"
    },
    {
        "title": "Steered Diffusion: A Generalized Framework for Plug-and-Play Conditional Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_paper.html",
        "author": "Nithin Gopalakrishnan Nair, Anoop Cherian, Suhas Lohit, Ye Wang, Toshiaki Koike-Akino, Vishal M. Patel, Tim K. Marks",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; Mitsubishi Electric Research Laboratories (MERL)",
        "project": "https://merl.com/demos/steered-diffusion",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "StegaNeRF: Embedding Invisible Information within Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_StegaNeRF_Embedding_Invisible_Information_within_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Chenxin Li, Brandon Y. Feng, Zhiwen Fan, Panwang Pan, Zhangyang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_StegaNeRF_Embedding_Invisible_Information_within_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "University of Maryland; University of Texas at Austin; Chinese University of Hong Kong; ByteDance",
        "project": "https://xggnet.github.io/StegaNeRF/",
        "github": "",
        "arxiv": "2212.01602"
    },
    {
        "title": "Stochastic Segmentation with Conditional Categorical Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zbinden_Stochastic_Segmentation_with_Conditional_Categorical_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Lukas Zbinden, Lars Doorenbos, Theodoros Pissas, Adrian Thomas Huber, Raphael Sznitman, Pablo M\u00e1rquez-Neila",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zbinden_Stochastic_Segmentation_with_Conditional_Categorical_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "University of Bern, Bern, Switzerland",
        "project": "",
        "github": "",
        "arxiv": "2303.08888"
    },
    {
        "title": "Story Visualization by Online Text Augmentation with Context Memory",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ahn_Story_Visualization_by_Online_Text_Augmentation_with_Context_Memory_ICCV_2023_paper.html",
        "author": "Daechul Ahn, Daneul Kim, Gwangmo Song, Seung Hwan Kim, Honglak Lee, Dongyeop Kang, Jonghyun Choi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ahn_Story_Visualization_by_Online_Text_Augmentation_with_Context_Memory_ICCV_2023_paper.pdf",
        "aff": "LG AI Research; GIST; University of Michigan; Yonsei University; University of Minnesota",
        "project": "",
        "github": "https://github.com/yonseivnl/cmota",
        "arxiv": "2308.07575"
    },
    {
        "title": "Strata-NeRF : Neural Radiance Fields for Stratified Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dhiman_Strata-NeRF__Neural_Radiance_Fields_for_Stratified_Scenes_ICCV_2023_paper.html",
        "author": "Ankit Dhiman, R Srinath, Harsh Rangwani, Rishubh Parihar, Lokesh R Boregowda, Srinath Sridhar, R Venkatesh Babu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dhiman_Strata-NeRF__Neural_Radiance_Fields_for_Stratified_Scenes_ICCV_2023_paper.pdf",
        "aff": "Brown University; Samsung R & D Institute India - Bangalore; Vision and AI Lab, IISc Bangalore",
        "project": "https://ankitatiisc.github.io/Strata-NeRF/",
        "github": "https://github.com/ankitatiisc/Strata-NeRF",
        "arxiv": "2308.10337"
    },
    {
        "title": "Strip-MLP: Efficient Token Interaction for Vision MLP",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Strip-MLP_Efficient_Token_Interaction_for_Vision_MLP_ICCV_2023_paper.html",
        "author": "Guiping Cao, Shengda Luo, Wenjian Huang, Xiangyuan Lan, Dongmei Jiang, Yaowei Wang, Jianguo Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Strip-MLP_Efficient_Token_Interaction_for_Vision_MLP_ICCV_2023_paper.pdf",
        "aff": "Southern University of Science and Technology, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China",
        "project": "",
        "github": "https://github.com/MedProcess/Strip-MLP",
        "arxiv": ""
    },
    {
        "title": "Strivec: Sparse Tri-Vector Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Strivec_Sparse_Tri-Vector_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Quankai Gao, Qiangeng Xu, Hao Su, Ulrich Neumann, Zexiang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Strivec_Sparse_Tri-Vector_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; UC San Diego; University of Southern California",
        "project": "",
        "github": "https://github.com/Zerg-Overmind/Strivec",
        "arxiv": "2307.13226"
    },
    {
        "title": "Structural Alignment for Network Pruning through Partial Regularization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Structural_Alignment_for_Network_Pruning_through_Partial_Regularization_ICCV_2023_paper.html",
        "author": "Shangqian Gao, Zeyu Zhang, Yanfu Zhang, Feihu Huang, Heng Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Structural_Alignment_for_Network_Pruning_through_Partial_Regularization_ICCV_2023_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, University of Pittsburgh; Department of Computer Science, University of Maryland at College Park; School of Information, University of Arizona",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Structure Invariant Transformation for better Adversarial Transferability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Structure_Invariant_Transformation_for_better_Adversarial_Transferability_ICCV_2023_paper.html",
        "author": "Xiaosen Wang, Zeliang Zhang, Jianping Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Structure_Invariant_Transformation_for_better_Adversarial_Transferability_ICCV_2023_paper.pdf",
        "aff": "HUST; Huawei Singularity Security Lab; Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/xiaosen-wang/SIT",
        "arxiv": ""
    },
    {
        "title": "Structure and Content-Guided Video Synthesis with Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Esser_Structure_and_Content-Guided_Video_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Patrick Esser, Johnathan Chiu, Parmida Atighehchian, Jonathan Granskog, Anastasis Germanidis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Esser_Structure_and_Content-Guided_Video_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Runway",
        "project": "https://research.runwayml.com/gen1",
        "github": "",
        "arxiv": "2302.03011"
    },
    {
        "title": "Structure-Aware Surface Reconstruction via Primitive Assembly",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Structure-Aware_Surface_Reconstruction_via_Primitive_Assembly_ICCV_2023_paper.html",
        "author": "Jingen Jiang, Mingyang Zhao, Shiqing Xin, Yanchao Yang, Hanxiao Wang, Xiaohong Jia, Dong-Ming Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Structure-Aware_Surface_Reconstruction_via_Primitive_Assembly_ICCV_2023_paper.pdf",
        "aff": "Shandong University; KLMM, AMSS, CAS; MAIS & NLPR, CASIA; The University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Studying How to Efficiently and Effectively Guide Models with Explanations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rao_Studying_How_to_Efficiently_and_Effectively_Guide_Models_with_Explanations_ICCV_2023_paper.html",
        "author": "Sukrut Rao, Moritz B\u00f6hle, Amin Parchami-Araghi, Bernt Schiele",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rao_Studying_How_to_Efficiently_and_Effectively_Guide_Models_with_Explanations_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Informatics, Saarland Informatics Campus, Saarbr\u00fccken, Germany",
        "project": "",
        "github": "https://github.com/sukrutrao/Model-Guidance",
        "arxiv": ""
    },
    {
        "title": "StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_StyleDiffusion_Controllable_Disentangled_Style_Transfer_via_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Zhizhong Wang, Lei Zhao, Wei Xing",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleDiffusion_Controllable_Disentangled_Style_Transfer_via_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "College of Computer Science and Technology, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2308.07863"
    },
    {
        "title": "StyleDomain: Efficient and Lightweight Parameterizations of StyleGAN for One-shot and Few-shot Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Alanov_StyleDomain_Efficient_and_Lightweight_Parameterizations_of_StyleGAN_for_One-shot_and_ICCV_2023_paper.html",
        "author": "Aibek Alanov, Vadim Titov, Maksim Nakhodnov, Dmitry Vetrov",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Alanov_StyleDomain_Efficient_and_Lightweight_Parameterizations_of_StyleGAN_for_One-shot_and_ICCV_2023_paper.pdf",
        "aff": "AIRI; HSE University, AIRI; AIRI, Lomonosov Moscow State University",
        "project": "",
        "github": "https://github.com/AIRI-Institute/StyleDomain",
        "arxiv": "2212.10229"
    },
    {
        "title": "StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_StyleGANEX_StyleGAN-Based_Manipulation_Beyond_Cropped_Aligned_Faces_ICCV_2023_paper.html",
        "author": "Shuai Yang, Liming Jiang, Ziwei Liu, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_StyleGANEX_StyleGAN-Based_Manipulation_Beyond_Cropped_Aligned_Faces_ICCV_2023_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University",
        "project": "https://www.mmlab-ntu.com/project/styleganex",
        "github": "",
        "arxiv": "2303.06146"
    },
    {
        "title": "StyleInV: A Temporal Style Modulated Inversion Network for Unconditional Video Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_StyleInV_A_Temporal_Style_Modulated_Inversion_Network_for_Unconditional_Video_ICCV_2023_paper.html",
        "author": "Yuhan Wang, Liming Jiang, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleInV_A_Temporal_Style_Modulated_Inversion_Network_for_Unconditional_Video_ICCV_2023_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/johannwyh/StyleInV",
        "arxiv": "2308.16909"
    },
    {
        "title": "StyleLipSync: Style-based Personalized Lip-sync Video Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ki_StyleLipSync_Style-based_Personalized_Lip-sync_Video_Generation_ICCV_2023_paper.html",
        "author": "Taekyung Ki, Dongchan Min",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ki_StyleLipSync_Style-based_Personalized_Lip-sync_Video_Generation_ICCV_2023_paper.pdf",
        "aff": "Graduate School of AI, KAIST; AITRICS",
        "project": "",
        "github": "https://stylelipsync.github.io",
        "arxiv": "2305.00521"
    },
    {
        "title": "StylerDALLE: Language-Guided Style Transfer Using a Vector-Quantized Tokenizer of a Large-Scale Generative Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_StylerDALLE_Language-Guided_Style_Transfer_Using_a_Vector-Quantized_Tokenizer_of_a_ICCV_2023_paper.html",
        "author": "Zipeng Xu, Enver Sangineto, Nicu Sebe",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_StylerDALLE_Language-Guided_Style_Transfer_Using_a_Vector-Quantized_Tokenizer_of_a_ICCV_2023_paper.pdf",
        "aff": "University of Trento, Italy; University of Modena and Reggio Emilia, Italy",
        "project": "",
        "github": "",
        "arxiv": "2303.09268"
    },
    {
        "title": "SuS-X: Training-Free Name-Only Transfer of Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Udandarao_SuS-X_Training-Free_Name-Only_Transfer_of_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Vishaal Udandarao, Ankush Gupta, Samuel Albanie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Udandarao_SuS-X_Training-Free_Name-Only_Transfer_of_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "University of Cambridge; DeepMind, London",
        "project": "",
        "github": "https://github.com/vishaal27/SuS-X",
        "arxiv": ""
    },
    {
        "title": "Subclass-balancing Contrastive Learning for Long-tailed Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hou_Subclass-balancing_Contrastive_Learning_for_Long-tailed_Recognition_ICCV_2023_paper.html",
        "author": "Chengkai Hou, Jieyu Zhang, Haonan Wang, Tianyi Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hou_Subclass-balancing_Contrastive_Learning_for_Long-tailed_Recognition_ICCV_2023_paper.pdf",
        "aff": "University of Maryland; Jilin University; University of Washington; National University of Singapore",
        "project": "",
        "github": "https://github.com/JackHck/subclass-balancing-contrastive-learning",
        "arxiv": "2306.15925"
    },
    {
        "title": "SupFusion: Supervised LiDAR-Camera Fusion for 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qin_SupFusion_Supervised_LiDAR-Camera_Fusion_for_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Yiran Qin, Chaoqun Wang, Zijian Kang, Ningning Ma, Zhen Li, Ruimao Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_SupFusion_Supervised_LiDAR-Camera_Fusion_for_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "School of Science and Engineering, Future Intelligent Network Research Institute, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; NIO; School of Data Science, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China",
        "project": "",
        "github": "https://github.com/IranQin/SupFusion",
        "arxiv": "2309.07084"
    },
    {
        "title": "Supervised Homography Learning with Realistic Dataset Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Supervised_Homography_Learning_with_Realistic_Dataset_Generation_ICCV_2023_paper.html",
        "author": "Hai Jiang, Haipeng Li, Songchen Han, Haoqiang Fan, Bing Zeng, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Supervised_Homography_Learning_with_Realistic_Dataset_Generation_ICCV_2023_paper.pdf",
        "aff": "Sichuan University; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China, Megvii Technology; Sichuan University, Megvii Technology; Megvii Technology",
        "project": "",
        "github": "https://github.com/JianghaiSCU/RealSH",
        "arxiv": "2307.15353"
    },
    {
        "title": "Surface Extraction from Neural Unsigned Distance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Surface_Extraction_from_Neural_Unsigned_Distance_Fields_ICCV_2023_paper.html",
        "author": "Congyi Zhang, Guying Lin, Lei Yang, Xin Li, Taku Komura, Scott Schaefer, John Keyser, Wenping Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Surface_Extraction_from_Neural_Unsigned_Distance_Fields_ICCV_2023_paper.pdf",
        "aff": "Texas A&M University; The University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2309.08878"
    },
    {
        "title": "Surface Normal Clustering for Implicit Representation of Manhattan Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Popovic_Surface_Normal_Clustering_for_Implicit_Representation_of_Manhattan_Scenes_ICCV_2023_paper.html",
        "author": "Nikola Popovic, Danda Pani Paudel, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Popovic_Surface_Normal_Clustering_for_Implicit_Representation_of_Manhattan_Scenes_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Laboratory, ETH Zurich, Switzerland; Computer Vision Laboratory, ETH Zurich, Switzerland; INSAIT, So\ufb01a University, Bulgaria",
        "project": "",
        "github": "https://github.com/nikola3794/normal-clustering-nerf",
        "arxiv": "2212.01331"
    },
    {
        "title": "SurfsUP: Learning Fluid Simulation for Novel Surfaces",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mani_SurfsUP_Learning_Fluid_Simulation_for_Novel_Surfaces_ICCV_2023_paper.html",
        "author": "Arjun Mani, Ishaan Preetam Chandratreya, Elliot Creager, Carl Vondrick, Richard Zemel",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mani_SurfsUP_Learning_Fluid_Simulation_for_Novel_Surfaces_ICCV_2023_paper.pdf",
        "aff": "University of Toronto, Vector Institute; Columbia University",
        "project": "http://surfsup.cs.columbia.edu",
        "github": "",
        "arxiv": "2304.06197"
    },
    {
        "title": "SurroundOcc: Multi-camera 3D Occupancy Prediction for Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_SurroundOcc_Multi-camera_3D_Occupancy_Prediction_for_Autonomous_Driving_ICCV_2023_paper.html",
        "author": "Yi Wei, Linqing Zhao, Wenzhao Zheng, Zheng Zhu, Jie Zhou, Jiwen Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_SurroundOcc_Multi-camera_3D_Occupancy_Prediction_for_Autonomous_Driving_ICCV_2023_paper.pdf",
        "aff": "PhiGent Robotics; School of Electrical and Information Engineering, Tianjin University, China; Beijing National Research Center for Information Science and Technology, China; Department of Automation, Tsinghua University, China",
        "project": "",
        "github": "https://github.com/weiyithu/SurroundOcc",
        "arxiv": "2303.09551"
    },
    {
        "title": "SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shaker_SwiftFormer_Efficient_Additive_Attention_for_Transformer-based_Real-time_Mobile_Vision_Applications_ICCV_2023_paper.html",
        "author": "Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shaker_SwiftFormer_Efficient_Additive_Attention_for_Transformer-based_Real-time_Mobile_Vision_Applications_ICCV_2023_paper.pdf",
        "aff": "University of California, Merced; Mohamed bin Zayed University of AI; Link\u00f6ping University",
        "project": "",
        "github": "https://tinyurl.com/5ft8v46w",
        "arxiv": "2303.15446"
    },
    {
        "title": "SwinLSTM: Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_SwinLSTM_Improving_Spatiotemporal_Prediction_Accuracy_using_Swin_Transformer_and_LSTM_ICCV_2023_paper.html",
        "author": "Song Tang, Chuang Li, Pu Zhang, RongNian Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_SwinLSTM_Improving_Spatiotemporal_Prediction_Accuracy_using_Swin_Transformer_and_LSTM_ICCV_2023_paper.pdf",
        "aff": "Hainan University",
        "project": "",
        "github": "https://github.com/SongTang-x/SwinLSTM",
        "arxiv": "2308.09891"
    },
    {
        "title": "SynBody: Synthetic Dataset with Layered Human Models for 3D Human Perception and Modeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_SynBody_Synthetic_Dataset_with_Layered_Human_Models_for_3D_Human_ICCV_2023_paper.html",
        "author": "Zhitao Yang, Zhongang Cai, Haiyi Mei, Shuai Liu, Zhaoxi Chen, Weiye Xiao, Yukun Wei, Zhongfei Qing, Chen Wei, Bo Dai, Wayne Wu, Chen Qian, Dahua Lin, Ziwei Liu, Lei Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SynBody_Synthetic_Dataset_with_Layered_Human_Models_for_3D_Human_ICCV_2023_paper.pdf",
        "aff": "SenseTime Research; The Chinese University of Hong Kong; Shanghai AI Laboratory; SenseTime Research, Shanghai AI Laboratory, S-Lab, Nanyang Technological University; SenseTime Research, Shanghai AI Laboratory; S-Lab, Nanyang Technological University",
        "project": "https://synbody.github.io/",
        "github": "https://github.com/SynBody",
        "arxiv": "2303.17368"
    },
    {
        "title": "Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.html",
        "author": "Teli Ma, Mengmeng Wang, Jimin Xiao, Huifeng Wu, Yong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.pdf",
        "aff": "Xi\u2019an Jiaotong-Liverpool University; Zhejiang University; Hangzhou Dianzi University; The Hong Kong University of Science and Technology, Guangzhou",
        "project": "",
        "github": "",
        "arxiv": "2308.12549"
    },
    {
        "title": "Synthesizing Diverse Human Motions in 3D Indoor Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Synthesizing_Diverse_Human_Motions_in_3D_Indoor_Scenes_ICCV_2023_paper.html",
        "author": "Kaifeng Zhao, Yan Zhang, Shaofei Wang, Thabo Beeler, Siyu Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Synthesizing_Diverse_Human_Motions_in_3D_Indoor_Scenes_ICCV_2023_paper.pdf",
        "aff": "Google; ETH Z\u00fcrich",
        "project": "https://zkf1997.github.io/DIMOS",
        "github": "https://github.com/zkf1997/DIMOS",
        "arxiv": "2305.12411"
    },
    {
        "title": "TALL: Thumbnail Layout for Deepfake Video Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_TALL_Thumbnail_Layout_for_Deepfake_Video_Detection_ICCV_2023_paper.html",
        "author": "Yuting Xu, Jian Liang, Gengyun Jia, Ziming Yang, Yanhao Zhang, Ran He",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_TALL_Thumbnail_Layout_for_Deepfake_Video_Detection_ICCV_2023_paper.pdf",
        "aff": "OPPO Research Institute; School of Communications and Information Engineering, NJUPT; CRIPAC & MAIS, Institute of Automation, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/rainy-xu/TALL4Deepfake",
        "arxiv": "2307.07494"
    },
    {
        "title": "TAPIR: Tracking Any Point with Per-Frame Initialization and Temporal Refinement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Doersch_TAPIR_Tracking_Any_Point_with_Per-Frame_Initialization_and_Temporal_Refinement_ICCV_2023_paper.html",
        "author": "Carl Doersch, Yi Yang, Mel Vecerik, Dilara Gokay, Ankush Gupta, Yusuf Aytar, Joao Carreira, Andrew Zisserman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Doersch_TAPIR_Tracking_Any_Point_with_Per-Frame_Initialization_and_Temporal_Refinement_ICCV_2023_paper.pdf",
        "aff": "University College London; VGG, Department of Engineering Science, University of Oxford; Google DeepMind",
        "project": "https://deepmind-tapir.github.io",
        "github": "https://github.com/deepmind-tapir",
        "arxiv": "2306.08637"
    },
    {
        "title": "TARGET: Federated Class-Continual Learning via Exemplar-Free Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_TARGET_Federated_Class-Continual_Learning_via_Exemplar-Free_Distillation_ICCV_2023_paper.html",
        "author": "Jie Zhang, Chen Chen, Weiming Zhuang, Lingjuan Lyu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_TARGET_Federated_Class-Continual_Learning_via_Exemplar-Free_Distillation_ICCV_2023_paper.pdf",
        "aff": "Sony AI; ETH Zurich",
        "project": "",
        "github": "",
        "arxiv": "2303.06937"
    },
    {
        "title": "TCOVIS: Temporally Consistent Online Video Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_TCOVIS_Temporally_Consistent_Online_Video_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Junlong Li, Bingyao Yu, Yongming Rao, Jie Zhou, Jiwen Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_TCOVIS_Temporally_Consistent_Online_Video_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, Tsinghua University, China; Beijing National Research Center for Information Science and Technology, China",
        "project": "",
        "github": "https://github.com/jun-long-li/TCOVIS",
        "arxiv": "2309.11857"
    },
    {
        "title": "TEMPO: Efficient Multi-View Pose Estimation, Tracking, and Forecasting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Choudhury_TEMPO_Efficient_Multi-View_Pose_Estimation_Tracking_and_Forecasting_ICCV_2023_paper.html",
        "author": "Rohan Choudhury, Kris M. Kitani, L\u00e1szl\u00f3 A. Jeni",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Choudhury_TEMPO_Efficient_Multi-View_Pose_Estimation_Tracking_and_Forecasting_ICCV_2023_paper.pdf",
        "aff": "Robotics Institute, Carnegie Mellon University",
        "project": "https://rccchoudhury.github.io/tempo2023/",
        "github": "https://github.com/rccchoudhury/tempo2023",
        "arxiv": "2309.07910"
    },
    {
        "title": "TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.html",
        "author": "Shilin Lu, Yanzhu Liu, Adams Wai-Kin Kong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; Institute for Infocomm Research (I2R) & Centre for Frontier AI Research (CFAR), A*STAR, Singapore",
        "project": "",
        "github": "https://github.com/Shilin-LU/TF-ICON",
        "arxiv": ""
    },
    {
        "title": "TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_TIFA_Accurate_and_Interpretable_Text-to-Image_Faithfulness_Evaluation_with_Question_Answering_ICCV_2023_paper.html",
        "author": "Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari Ostendorf, Ranjay Krishna, Noah A. Smith",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_TIFA_Accurate_and_Interpretable_Text-to-Image_Faithfulness_Evaluation_with_Question_Answering_ICCV_2023_paper.pdf",
        "aff": "TIFA: Accurate and Interpretable Text-to-Image Faithfulness\nEvaluation with Question Answering\nYushi Hu1Benlin Liu1Jungo Kasai1Yizhong Wang1\nMari Ostendorf1Ranjay Krishna1,2Noah A. Smith1,2\n1University of Washington2Allen Institute for AI\nhttps://tifa-benchmark.github.io/\nAbstract\nDespite thousands of researchers, engineers, and artists\nactively working on improving text-to-image generation mod-\nels, systems often fail to produce images that accurately\nalign with the text inputs. We introduce TIFA ( Text-to- Image\nFaithfulness evaluation with question Answering), an auto-\nmatic evaluation metric that measures the faithfulness of a\ngenerated image to its text input via visual question answer-\ning (VQA). Speci\ufb01cally, given a text input, we automatically\ngenerate several question-answer pairs using a language\nmodel. We calculate image faithfulness by checking whether\nexisting VQA models can answer these questions using the\ngenerated image. TIFA is a reference-free metric that allows\nfor \ufb01ne-grained and interpretable evaluations of generated\nimages. TIFA also has better correlations with human judg-\nments than existing metrics. Based on this approach, we\nintroduce TIFA v1.0, a benchmark consisting of 4K diverse\ntext inputs and 25K questions across 12 categories (object,\ncounting, etc.). We present a comprehensive evaluation of ex-\nisting text-to-image models using TIFA v1.0 and highlight the\nlimitations and challenges of current models. For instance,\nwe \ufb01nd that current text-to-image models, despite doing well\non color and material, still struggle in counting, spatial\nrelations, and composing multiple objects. We hope our\nbenchmark will help carefully measure the research progress\nin text-to-image synthesis and provide valuable insights for\nfurther research.1\n1. Introduction\nWhile we welcome artistic freedom when we commis-\nsion art from artists, images produced by deep generative\nmodels [ 44,46,43,47,61] should conform closely to our\nrequests. Despite the advances in generative models, it is\nstill challenging for models to produce images faithful to\nusers\u2019 intentions [ 40,11,30,35,36]. For example, current\n1Correspondance to <Yushi Hu: yushihu@uw.edu >. All data and a\npip-installable evaluation package are available on the project page.\nText Input: A person sitting on a horse in air over gate in grass with people and trees in background.GPT-3 generated + verified QAs (pre-generated in TIFA v1.0 benchmark)Question: what is the animal?     Answer inferred from text: horseVQA:HorseHorse  Question: is there a gate?            Answer inferred from text: yesVQA:NoYes  Question: is the horse in air?      Answer inferred from text: yesVQA:NoYesTIFA71.4100.0v.s. other automatic image-text align metricsCLIPScore\nAccuracy on 14 questions\nCLIP (image)CLIP (text)SPICE\nCaptionsim. (caption, text input)CLIP: 24.3  SPICE: 22.2 CLIP: 21.3  SPICE: 11.8 Stable Diffusion v1.5Stable Diffusion v2.1\n. . .Fine-Grained         Accurate         Interpretable><\nFigure 1. Illustration of how TIFA works, and comparison with the\nwidely-used CLIPScore and SPICE metrics. Given the text input,\nTIFA uses GPT-3 to generate several question-answer pairs, and\na QA model \ufb01lters them (3 out of 14 questions for this text input\nare shown). TIFA measures whether VQA models can accurately\nanswer these questions given the generated image. In this example,\nTIFA indicates that the image generated by Stable Diffusion v2.1 is\nbetter than that by v1.5, while CLIP and SPICE yield the opposite\nresult. The text input is from the MSCOCO validation set.\nmodels often fail to compose multiple objects [ 40,11,35],\nbind attributes to the wrong objects [ 11], and struggle in gen-\nerating visual text [ 36]. Today, there are efforts to address\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n20406\n",
        "project": "",
        "github": "",
        "arxiv": "2303.11897"
    },
    {
        "title": "TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sur_TIJO_Trigger_Inversion_with_Joint_Optimization_for_Defending_Multimodal_Backdoored_ICCV_2023_paper.html",
        "author": "Indranil Sur, Karan Sikka, Matthew Walmer, Kaushik Koneripalli, Anirban Roy, Xiao Lin, Ajay Divakaran, Susmit Jha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sur_TIJO_Trigger_Inversion_with_Joint_Optimization_for_Defending_Multimodal_Backdoored_ICCV_2023_paper.pdf",
        "aff": "University of Maryland; SRI International",
        "project": "",
        "github": "https://github.com/SRI-CSL/TIJO",
        "arxiv": "2308.03906"
    },
    {
        "title": "TM2D: Bimodality Driven 3D Dance Generation via Music-Text Integration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.html",
        "author": "Kehong Gong, Dongze Lian, Heng Chang, Chuan Guo, Zihang Jiang, Xinxin Zuo, Michael Bi Mi, Xinchao Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.pdf",
        "aff": "Huawei Technologies Co., Ltd.; National University of Singapore",
        "project": "",
        "github": "https://garfield-kh.github.io/TM2D/",
        "arxiv": "2304.02419"
    },
    {
        "title": "TMA: Temporal Motion Aggregation for Event-based Optical Flow",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_TMA_Temporal_Motion_Aggregation_for_Event-based_Optical_Flow_ICCV_2023_paper.html",
        "author": "Haotian Liu, Guang Chen, Sanqing Qu, Yanping Zhang, Zhijun Li, Alois Knoll, Changjun Jiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TMA_Temporal_Motion_Aggregation_for_Event-based_Optical_Flow_ICCV_2023_paper.pdf",
        "aff": "Technical University of Munich; Tongji University",
        "project": "",
        "github": "https://github.com/ispc-lab/TMA",
        "arxiv": "2303.11629"
    },
    {
        "title": "TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Petrovich_TMR_Text-to-Motion_Retrieval_Using_Contrastive_3D_Human_Motion_Synthesis_ICCV_2023_paper.html",
        "author": "Mathis Petrovich, Michael J. Black, G\u00fcl Varol",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Petrovich_TMR_Text-to-Motion_Retrieval_Using_Contrastive_3D_Human_Motion_Synthesis_ICCV_2023_paper.pdf",
        "aff": "LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS, France; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "project": "",
        "github": "https://mathis.petrovich.fr/tmr",
        "arxiv": "2305.00976"
    },
    {
        "title": "TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dou_TORE_Token_Reduction_for_Efficient_Human_Mesh_Recovery_with_Transformer_ICCV_2023_paper.html",
        "author": "Zhiyang Dou, Qingxuan Wu, Cheng Lin, Zeyu Cao, Qiangqiang Wu, Weilin Wan, Taku Komura, Wenping Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dou_TORE_Token_Reduction_for_Efficient_Human_Mesh_Recovery_with_Transformer_ICCV_2023_paper.pdf",
        "aff": "City University of Hong Kong; The University of Hong Kong; University of Cambridge; University of Oxford; Tencent Games; Texas A&M University",
        "project": "https://frank-zy-dou.github.io/projects/Tore/index.html",
        "github": "https://github.com/frank-zy-dou",
        "arxiv": "2211.10705"
    },
    {
        "title": "TRM-UAP: Enhancing the Transferability of Data-Free Universal Adversarial Perturbation via Truncated Ratio Maximization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_TRM-UAP_Enhancing_the_Transferability_of_Data-Free_Universal_Adversarial_Perturbation_via_ICCV_2023_paper.html",
        "author": "Yiran Liu, Xin Feng, Yunlong Wang, Wu Yang, Di Ming",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TRM-UAP_Enhancing_the_Transferability_of_Data-Free_Universal_Adversarial_Perturbation_via_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Chongqing University of Technology, Chongqing, China",
        "project": "",
        "github": "https://github.com/RandolphCarter0/TRMUAP",
        "arxiv": ""
    },
    {
        "title": "Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Take-A-Photo_3D-to-2D_Generative_Pre-training_of_Point_Cloud_Models_ICCV_2023_paper.html",
        "author": "Ziyi Wang, Xumin Yu, Yongming Rao, Jie Zhou, Jiwen Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Take-A-Photo_3D-to-2D_Generative_Pre-training_of_Point_Cloud_Models_ICCV_2023_paper.pdf",
        "aff": "Department of Automation, Tsinghua University; BNRist; Department of Automation, Tsinghua University",
        "project": "",
        "github": "https://github.com/wangzy22/TakeAPhoto",
        "arxiv": ""
    },
    {
        "title": "Talking Head Generation with Probabilistic Audio-to-Visual Diffusion Priors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Talking_Head_Generation_with_Probabilistic_Audio-to-Visual_Diffusion_Priors_ICCV_2023_paper.html",
        "author": "Zhentao Yu, Zixin Yin, Deyu Zhou, Duomin Wang, Finn Wong, Baoyuan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Talking_Head_Generation_with_Probabilistic_Audio-to-Visual_Diffusion_Priors_ICCV_2023_paper.pdf",
        "aff": "Xiaobing.AI; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology (Guangzhou)",
        "project": "",
        "github": "",
        "arxiv": "2212.04248"
    },
    {
        "title": "Taming Contrast Maximization for Learning Sequential, Low-latency, Event-based Optical Flow",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Paredes-Valles_Taming_Contrast_Maximization_for_Learning_Sequential_Low-latency_Event-based_Optical_Flow_ICCV_2023_paper.html",
        "author": "Federico Paredes-Vall\u00e9s, Kirk Y. W. Scheper, Christophe De Wagter, Guido C. H. E. de Croon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Paredes-Valles_Taming_Contrast_Maximization_for_Learning_Sequential_Low-latency_Event-based_Optical_Flow_ICCV_2023_paper.pdf",
        "aff": "1. Micro Air Vehicle Laboratory, Delft University of Technology; 2. Stuttgart Laboratory 1, Sony Semiconductor Solutions Europe, Sony Europe B.V.",
        "project": "https://mavlab.tudelft.nl/taming-event-flow/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Tangent Model Composition for Ensembling and Continual Fine-tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Tangent_Model_Composition_for_Ensembling_and_Continual_Fine-tuning_ICCV_2023_paper.html",
        "author": "Tian Yu Liu, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Tangent_Model_Composition_for_Ensembling_and_Continual_Fine-tuning_ICCV_2023_paper.pdf",
        "aff": "University of California, Los Angeles",
        "project": "",
        "github": "https://github.com/tianyu139/tangent-model-composition",
        "arxiv": "2307.08114"
    },
    {
        "title": "Tangent Sampson Error: Fast Approximate Two-view Reprojection Error for Central Camera Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Terekhov_Tangent_Sampson_Error_Fast_Approximate_Two-view_Reprojection_Error_for_Central_ICCV_2023_paper.html",
        "author": "Mikhail Terekhov, Viktor Larsson",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Terekhov_Tangent_Sampson_Error_Fast_Approximate_Two-view_Reprojection_Error_for_Central_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; Lund University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Task Agnostic Restoration of Natural Video Dynamics",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ali_Task_Agnostic_Restoration_of_Natural_Video_Dynamics_ICCV_2023_paper.html",
        "author": "Muhammad Kashif Ali, Dongjin Kim, Tae Hyun Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_Task_Agnostic_Restoration_of_Natural_Video_Dynamics_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Hanyang University, Seoul, Korea",
        "project": "",
        "github": "https://github.com/MKashifAli/TARONVD",
        "arxiv": "2206.03753"
    },
    {
        "title": "Task-Oriented Multi-Modal Mutual Leaning for Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Long_Task-Oriented_Multi-Modal_Mutual_Leaning_for_Vision-Language_Models_ICCV_2023_paper.html",
        "author": "Sifan Long, Zhen Zhao, Junkun Yuan, Zichang Tan, Jiangjiang Liu, Luping Zhou, Shengsheng Wang, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Long_Task-Oriented_Multi-Modal_Mutual_Leaning_for_Vision-Language_Models_ICCV_2023_paper.pdf",
        "aff": "Baidu VIS; College of Computer Science and Technology, Jilin University, Jilin, China; Baidu VIS, Zhejiang University; Baidu VIS, University of Sydney; University of Sydney",
        "project": "",
        "github": "",
        "arxiv": "2303.17169"
    },
    {
        "title": "Task-aware Adaptive Learning for Cross-domain Few-shot Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Task-aware_Adaptive_Learning_for_Cross-domain_Few-shot_Learning_ICCV_2023_paper.html",
        "author": "Yurong Guo, Ruoyi Du, Yuan Dong, Timothy Hospedales, Yi-Zhe Song, Zhanyu Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Task-aware_Adaptive_Learning_for_Cross-domain_Few-shot_Learning_ICCV_2023_paper.pdf",
        "aff": "University of Edinburgh, UK; University of Surrey, UK; Beijing University of Posts and Telecommunications, China",
        "project": "",
        "github": "https://github.com/PRIS-CV/TA2-Net",
        "arxiv": ""
    },
    {
        "title": "TaskExpert: Dynamically Assembling Multi-Task Representations with Memorial Mixture-of-Experts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_TaskExpert_Dynamically_Assembling_Multi-Task_Representations_with_Memorial_Mixture-of-Experts_ICCV_2023_paper.html",
        "author": "Hanrong Ye, Dan Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_TaskExpert_Dynamically_Assembling_Multi-Task_Representations_with_Memorial_Mixture-of-Experts_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science and Engineering, HKUST",
        "project": "",
        "github": "",
        "arxiv": "2307.15324"
    },
    {
        "title": "Taxonomy Adaptive Cross-Domain Adaptation in Medical Imaging via Optimization Trajectory Distillation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Taxonomy_Adaptive_Cross-Domain_Adaptation_in_Medical_Imaging_via_Optimization_Trajectory_ICCV_2023_paper.html",
        "author": "Jianan Fan, Dongnan Liu, Hang Chang, Heng Huang, Mei Chen, Weidong Cai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Taxonomy_Adaptive_Cross-Domain_Adaptation_in_Medical_Imaging_via_Optimization_Trajectory_ICCV_2023_paper.pdf",
        "aff": "Lawrence Berkeley National Laboratory; University of Maryland at College Park; University of Sydney; Microsoft",
        "project": "",
        "github": "https://github.com/camwew/TADA-MI",
        "arxiv": "2307.14709"
    },
    {
        "title": "TeD-SPAD: Temporal Distinctiveness for Self-Supervised Privacy-Preservation for Video Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.html",
        "author": "Joseph Fioresi, Ishan Rajendrakumar Dave, Mubarak Shah",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida, Orlando, USA",
        "project": "https://joefioresi718.github.io/TeD-SPAD_webpage/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Teaching CLIP to Count to Ten",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Paiss_Teaching_CLIP_to_Count_to_Ten_ICCV_2023_paper.html",
        "author": "Roni Paiss, Ariel Ephrat, Omer Tov, Shiran Zada, Inbar Mosseri, Michal Irani, Tali Dekel",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Paiss_Teaching_CLIP_to_Count_to_Ten_ICCV_2023_paper.pdf",
        "aff": "Google Research, Weizmann Institute of Science; Google Research, Tel Aviv University; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2302.12066"
    },
    {
        "title": "Tem-Adapter: Adapting Image-Text Pretraining for Video Question Answer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_paper.html",
        "author": "Guangyi Chen, Xiao Liu, Guangrun Wang, Kun Zhang, Philip H.S. Torr, Xiao-Ping Zhang, Yansong Tang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_paper.pdf",
        "aff": "Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer\nGuangyi Chen1,2*, Xiao Liu5*, Guangrun Wang4, Kun Zhang1,2, Philip H.S. Torr4,\nXiao-Ping Zhang3,6, Yansong Tang3\u2020\n1Carnegie Mellon University, Pittsburgh PA, USA\n2Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE\n3Shenzhen International Graduate School, Tsinghua University, China\n4University of Oxford, UK\n5Eindhoven University of Technology, NL\n6Toronto Metropolitan University, Canada\nCLIP\n$500 fine for running a red light!ContrastiveLearningVideoQA\nQuestion: What would be considered a high potential traffic hazard?A: Narrow roads.   B: Not obeying the traffic rules and regulations.C: Speeding vehicles.   D: Theviewofdriverisblockedbyothers.\nInput ImageInput Video FramesInput TextInput Question-Answer PairTemporal GapSemantic Gap\u2026\nFigure 1: Illustration of the domain gaps between the pre-trained CLIP and the downstream VideoQA. CLIP is trained to align\nvisual and textual domains, while VideoQA requires understanding the temporal dynamics and complex semantics of videos.\nAbstract\nVideo-language pre-trained models have shown remark-\nable success in guiding video question-answering (VideoQA)\ntasks. However, due to the length of video sequences, train-\ning large-scale video-based models incurs considerably\nhigher costs than training image-based ones. This moti-\nvates us to leverage the knowledge from image-based pre-\ntraining, despite the obvious gaps between image and video\ndomains. To bridge these gaps, in this paper, we propose\nTem-Adapter , which enables the learning of temporal dy-\nnamics and complex semantics by a visual Temporal Aligner\nand a textual Semantic Aligner. Unlike conventional pre-\ntrained knowledge adaptation methods that only concentrate\non the downstream task objective, the Temporal Aligner in-\ntroduces an extra language-guided autoregressive task aimed\nat facilitating the learning of temporal dependencies, with\nthe objective of predicting future states based on historical\nclues and language guidance that describes event progres-\nsion. Besides, to reduce the semantic gap and adapt the\ntextual representation for better event description, we intro-\nduce a Semantic Aligner that first designs a template to fusequestion and answer pairs as event descriptions and then\nlearns a Transformer decoder with the whole video sequence\nas guidance for refinement. We evaluate Tem-Adapter\nand different pre-train transferring methods on two VideoQA\nbenchmarks, and the significant performance improvement\ndemonstrates the effectiveness of our method.1\n1. Introduction\nVideo Question Answering (VideoQA) is a task that aims\nto answer natural language questions based on the infor-\nmation available in observed videos. It has attracted con-\nsiderable attention recently due to its promise to develop\ninteractive AI systems capable of communicating with the\ndynamic visual environment using natural language. Despite\nsignificant advancements in recent years, VideoQA remains\na challenging problem that requires models to comprehen-\nsively understand and dynamically align the semantics of\nboth the visual world and natural language.\n1Our code can be found at: https://github.com/XLiu443/Tem-adapter\n*Equal contribution.\n\u2020Corresponding author.\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n13945\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Template Inversion Attack against Face Recognition Systems using 3D Face Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shahreza_Template_Inversion_Attack_against_Face_Recognition_Systems_using_3D_Face_ICCV_2023_paper.html",
        "author": "Hatef Otroshi Shahreza, S\u00e9bastien Marcel",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shahreza_Template_Inversion_Attack_against_Face_Recognition_Systems_using_3D_Face_ICCV_2023_paper.pdf",
        "aff": "Idiap Research Institute, Martigny, Switzerland and Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Idiap Research Institute, Martigny, Switzerland and Universit\u00e9 de Lausanne (UNIL), Lausanne, Switzerland",
        "project": "https://www.idiap.ch/paper/gafar",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Template-guided Hierarchical Feature Restoration for Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Template-guided_Hierarchical_Feature_Restoration_for_Anomaly_Detection_ICCV_2023_paper.html",
        "author": "Hewei Guo, Liping Ren, Jingjing Fu, Yuwang Wang, Zhizheng Zhang, Cuiling Lan, Haoqian Wang, Xinwen Hou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Template-guided_Hierarchical_Feature_Restoration_for_Anomaly_Detection_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Microsoft Research Asia; Institute of Automation, Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Temporal Collection and Distribution for Referring Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Temporal_Collection_and_Distribution_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.html",
        "author": "Jiajin Tang, Ge Zheng, Sibei Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Temporal_Collection_and_Distribution_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf",
        "aff": "School of Information Science and Technology, ShanghaiTech University",
        "project": "https://toneyaya.github.io/tempcd",
        "github": "https://github.com/toneyaya",
        "arxiv": "2309.03473"
    },
    {
        "title": "Temporal Enhanced Training of Multi-view 3D Object Detector via Historical Object Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zong_Temporal_Enhanced_Training_of_Multi-view_3D_Object_Detector_via_Historical_ICCV_2023_paper.html",
        "author": "Zhuofan Zong, Dongzhi Jiang, Guanglu Song, Zeyue Xue, Jingyong Su, Hongsheng Li, Yu Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_Temporal_Enhanced_Training_of_Multi-view_3D_Object_Detector_via_Historical_ICCV_2023_paper.pdf",
        "aff": "SenseTime Research, CUHK MMLAB; HITSZ; CUHK MMLAB, CPII, Shanghai AI Laboratory; SenseTime Research; HKU",
        "project": "",
        "github": "https://github.com/Sense-X/HoP",
        "arxiv": "2304.00967"
    },
    {
        "title": "Temporal-Coded Spiking Neural Networks with Dynamic Firing Threshold: Learning with Event-Driven Backpropagation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Temporal-Coded_Spiking_Neural_Networks_with_Dynamic_Firing_Threshold_Learning_with_ICCV_2023_paper.html",
        "author": "Wenjie Wei, Malu Zhang, Hong Qu, Ammar Belatreche, Jian Zhang, Hong Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Temporal-Coded_Spiking_Neural_Networks_with_Dynamic_Firing_Threshold_Learning_with_ICCV_2023_paper.pdf",
        "aff": "Northumbria University; University of Electronic Science and Technology of China; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Test Time Adaptation for Blind Image Quality Assessment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Roy_Test_Time_Adaptation_for_Blind_Image_Quality_Assessment_ICCV_2023_paper.html",
        "author": "Subhadeep Roy, Shankhanil Mitra, Soma Biswas, Rajiv Soundararajan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Roy_Test_Time_Adaptation_for_Blind_Image_Quality_Assessment_ICCV_2023_paper.pdf",
        "aff": "Indian Institute of Science, Bengaluru, India",
        "project": "",
        "github": "https://github.com/subhadeeproy2000/TTA-IQA",
        "arxiv": "2307.14735"
    },
    {
        "title": "Test-time Personalizable Forecasting of 3D Human Poses",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Test-time_Personalizable_Forecasting_of_3D_Human_Poses_ICCV_2023_paper.html",
        "author": "Qiongjie Cui, Huaijiang Sun, Jianfeng Lu, Weiqing Li, Bin Li, Hongwei Yi, Haofan Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Test-time_Personalizable_Forecasting_of_3D_Human_Poses_ICCV_2023_paper.pdf",
        "aff": "Xiaohongshu Inc; Tianjin AiForward Science and Technology Co., Ltd., China; Nanjing University of Science and Technology, Nanjing, China; Max Planck Institute for Intelligent Systems, Tubingen, Germany",
        "project": "https://sites.google.com/view/hp-ttp",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Tetra-NeRF: Representing Neural Radiance Fields Using Tetrahedra",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kulhanek_Tetra-NeRF_Representing_Neural_Radiance_Fields_Using_Tetrahedra_ICCV_2023_paper.html",
        "author": "Jonas Kulhanek, Torsten Sattler",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kulhanek_Tetra-NeRF_Representing_Neural_Radiance_Fields_Using_Tetrahedra_ICCV_2023_paper.pdf",
        "aff": "Czech Technical University in Prague",
        "project": "",
        "github": "https://jkulhanek.com/tetra-nerf",
        "arxiv": ""
    },
    {
        "title": "TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Tianshi Cao, Karsten Kreis, Sanja Fidler, Nicholas Sharp, Kangxue Yin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "NVIDIA, University of Toronto, Vector Institute; NVIDIA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Text-Conditioned Sampling Framework for Text-to-Image Generation with Masked Generative Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.html",
        "author": "Jaewoong Lee, Sangwon Jang, Jaehyeong Jo, Jaehong Yoon, Yunji Kim, Jin-Hwa Kim, Jung-Woo Ha, Sung Ju Hwang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.pdf",
        "aff": "NAVER AI Lab, Republic of Korea; Yonsei University, Republic of Korea; KAIST, Republic of Korea",
        "project": "",
        "github": "",
        "arxiv": "2304.01515"
    },
    {
        "title": "Text-Driven Generative Domain Adaptation with Spectral Consistency Regularization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Text-Driven_Generative_Domain_Adaptation_with_Spectral_Consistency_Regularization_ICCV_2023_paper.html",
        "author": "Zhenhuan Liu, Liang Li, Jiayu Xiao, Zheng-Jun Zha, Qingming Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Text-Driven_Generative_Domain_Adaptation_with_Spectral_Consistency_Regularization_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, CAS; University of Chinese Academy of Sciences; Institute of Computing Technology, CAS; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, CAS; University of Chinese Academy of Sciences; Peng Cheng Laboratory; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/Victarry/Adaptation-SCR",
        "arxiv": ""
    },
    {
        "title": "Text2Performer: Text-Driven Human Video Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Text2Performer_Text-Driven_Human_Video_Generation_ICCV_2023_paper.html",
        "author": "Yuming Jiang, Shuai Yang, Tong Liang Koh, Wayne Wu, Chen Change Loy, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Text2Performer_Text-Driven_Human_Video_Generation_ICCV_2023_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University; Shanghai AI Laboratory",
        "project": "https://yumingj.github.io/projects/Text2Performer.html",
        "github": "",
        "arxiv": "2304.08483"
    },
    {
        "title": "Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.html",
        "author": "Lukas H\u00f6llein, Ang Cao, Andrew Owens, Justin Johnson, Matthias Nie\u00dfner",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.pdf",
        "aff": "University of Michigan; Technical University of Munich",
        "project": "",
        "github": "https://lukashoel.github.io/text-to-room",
        "arxiv": ""
    },
    {
        "title": "Text2Tex: Text-driven Texture Synthesis via Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Text2Tex_Text-driven_Texture_Synthesis_via_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Dave Zhenyu Chen, Yawar Siddiqui, Hsin-Ying Lee, Sergey Tulyakov, Matthias Nie\u00dfner",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Text2Tex_Text-driven_Texture_Synthesis_via_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Snap Research; Technical University of Munich",
        "project": "https://daveredrum.github.io/Text2Tex/",
        "github": "",
        "arxiv": "2303.11396"
    },
    {
        "title": "Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.html",
        "author": "Levon Khachatryan, Andranik Movsisyan, Vahram Tadevosyan, Roberto Henschel, Zhangyang Wang, Shant Navasardyan, Humphrey Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.pdf",
        "aff": "Picsart AI Resarch (PAIR); Picsart AI Resarch (PAIR), UT Austin; Picsart AI Resarch (PAIR), SHI Labs @ Georgia Tech, Oregon & UIUC",
        "project": "",
        "github": "https://github.com/Picsart-AI-Research/Text2Video-Zero",
        "arxiv": ""
    },
    {
        "title": "TextManiA: Enriching Visual Feature by Text-driven Manifold Augmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye-Bin_TextManiA_Enriching_Visual_Feature_by_Text-driven_Manifold_Augmentation_ICCV_2023_paper.html",
        "author": "Moon Ye-Bin, Jisoo Kim, Hongyeob Kim, Kilho Son, Tae-Hyun Oh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye-Bin_TextManiA_Enriching_Visual_Feature_by_Text-driven_Manifold_Augmentation_ICCV_2023_paper.pdf",
        "aff": "Columbia University; Sungkyunkwan University; Dept. of Electrical Engineering and Grad. School of Artificial Intelligence, POSTECH; Microsoft Azure; Dept. of Electrical Engineering and Grad. School of Artificial Intelligence, POSTECH; Institute for Convergence Research and Education in Advanced Technology, Yonsei University",
        "project": "https://textmania.github.io/",
        "github": "https://github.com/TextManiA",
        "arxiv": "2307.14611"
    },
    {
        "title": "TextPSG: Panoptic Scene Graph Generation from Textual Descriptions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_TextPSG_Panoptic_Scene_Graph_Generation_from_Textual_Descriptions_ICCV_2023_paper.html",
        "author": "Chengyang Zhao, Yikang Shen, Zhenfang Chen, Mingyu Ding, Chuang Gan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_TextPSG_Panoptic_Scene_Graph_Generation_from_Textual_Descriptions_ICCV_2023_paper.pdf",
        "aff": "Peking University; MIT-IBM Watson AI Lab, UMass Amherst; UC Berkley; MIT-IBM Watson AI Lab",
        "project": "https://vis-www.cs.umass.edu/TextPSG",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Texture Generation on 3D Meshes with Point-UV Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.html",
        "author": "Xin Yu, Peng Dai, Wenbo Li, Lan Ma, Zhengzhe Liu, Xiaojuan Qi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.pdf",
        "aff": "TCL Corporate Research; The University of Hong Kong; The Chinese University of Hong Kong",
        "project": "https://cvmi-lab.github.io/Point-UV-Diffusion",
        "github": "https://github.com/cvmi-lab/Point-UV-Diffusion",
        "arxiv": "2308.10490"
    },
    {
        "title": "Texture Learning Domain Randomization for Domain Generalized Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Texture_Learning_Domain_Randomization_for_Domain_Generalized_Segmentation_ICCV_2023_paper.html",
        "author": "Sunghwan Kim, Dae-hwan Kim, Hoseong Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Texture_Learning_Domain_Randomization_for_Domain_Generalized_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Agency for Defense Development (ADD)",
        "project": "",
        "github": "https://github.com/ssssshwan/TLDR",
        "arxiv": "2303.11546"
    },
    {
        "title": "The Devil is in the Crack Orientation: A New Perspective for Crack Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_The_Devil_is_in_the_Crack_Orientation_A_New_Perspective_ICCV_2023_paper.html",
        "author": "Zhuangzhuang Chen, Jin Zhang, Zhuonan Lai, Guanming Zhu, Zun Liu, Jie Chen, Jianqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_The_Devil_is_in_the_Crack_Orientation_A_New_Perspective_ICCV_2023_paper.pdf",
        "aff": "Shenzhen University, Shenzhen, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "The Devil is in the Upsampling: Architectural Decisions Made Simpler for Denoising with Deep Image Prior",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.html",
        "author": "Yilin Liu, Jiang Li, Yunkui Pang, Dong Nie, Pew-Thian Yap",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.pdf",
        "aff": "University of North Carolina at Chapel Hill",
        "project": "",
        "github": "https://github.com/YilinLiu97/FasterDIP-devil-in-upsampling.git",
        "arxiv": "2304.11409"
    },
    {
        "title": "The Effectiveness of MAE Pre-Pretraining for Billion-Scale Pretraining",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Singh_The_Effectiveness_of_MAE_Pre-Pretraining_for_Billion-Scale_Pretraining_ICCV_2023_paper.html",
        "author": "Mannat Singh, Quentin Duval, Kalyan Vasudev Alwala, Haoqi Fan, Vaibhav Aggarwal, Aaron Adcock, Armand Joulin, Piotr Dollar, Christoph Feichtenhofer, Ross Girshick, Rohit Girdhar, Ishan Misra",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_The_Effectiveness_of_MAE_Pre-Pretraining_for_Billion-Scale_Pretraining_ICCV_2023_paper.pdf",
        "aff": "Meta AI",
        "project": "",
        "github": "",
        "arxiv": "2303.13496"
    },
    {
        "title": "The Euclidean Space is Evil: Hyperbolic Attribute Editing for Few-shot Image Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.html",
        "author": "Lingxiao Li, Yi Zhang, Shuhui Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.pdf",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; University of Oxford; Columbia University",
        "project": "",
        "github": "https://github.com/lingxiao-li/HAE",
        "arxiv": "2211.12347"
    },
    {
        "title": "The Making and Breaking of Camouflage",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lamdouar_The_Making_and_Breaking_of_Camouflage_ICCV_2023_paper.html",
        "author": "Hala Lamdouar, Weidi Xie, Andrew Zisserman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lamdouar_The_Making_and_Breaking_of_Camouflage_ICCV_2023_paper.pdf",
        "aff": "Visual Geometry Group, University of Oxford; Visual Geometry Group, University of Oxford and CMIC, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2309.03899"
    },
    {
        "title": "The Perils of Learning From Unlabeled Data: Backdoor Attacks on Semi-supervised Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shejwalkar_The_Perils_of_Learning_From_Unlabeled_Data_Backdoor_Attacks_on_ICCV_2023_paper.html",
        "author": "Virat Shejwalkar, Lingjuan Lyu, Amir Houmansadr",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shejwalkar_The_Perils_of_Learning_From_Unlabeled_Data_Backdoor_Attacks_on_ICCV_2023_paper.pdf",
        "aff": "Sony AI; UMass Amherst",
        "project": "",
        "github": "",
        "arxiv": "2211.00453"
    },
    {
        "title": "The Power of Sound (TPoS): Audio Reactive Video Generation with Stable Diffusion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jeong_The_Power_of_Sound_TPoS_Audio_Reactive_Video_Generation_with_ICCV_2023_paper.html",
        "author": "Yujin Jeong, Wonjeong Ryoo, Seunghyun Lee, Dabin Seo, Wonmin Byeon, Sangpil Kim, Jinkyu Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jeong_The_Power_of_Sound_TPoS_Audio_Reactive_Video_Generation_with_ICCV_2023_paper.pdf",
        "aff": "NVIDIA Research, Santa Clara 95050, USA; Department of Computer Science and Engineering, Korea University, Seoul 02841, Korea; Department of Arti\ufb01cial Intelligence, Korea University, Seoul 02841, Korea",
        "project": "",
        "github": "",
        "arxiv": "2309.04509"
    },
    {
        "title": "The Stable Signature: Rooting Watermarks in Latent Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fernandez_The_Stable_Signature_Rooting_Watermarks_in_Latent_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Pierre Fernandez, Guillaume Couairon, Herv\u00e9 J\u00e9gou, Matthijs Douze, Teddy Furon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fernandez_The_Stable_Signature_Rooting_Watermarks_in_Latent_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "Meta AI; Centre Inria de l\u2019Universit \u00b4e de Rennes",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "The Unreasonable Effectiveness of Large Language-Vision Models for Source-Free Video Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zara_The_Unreasonable_Effectiveness_of_Large_Language-Vision_Models_for_Source-Free_Video_ICCV_2023_paper.html",
        "author": "Giacomo Zara, Alessandro Conti, Subhankar Roy, St\u00e9phane Lathuili\u00e8re, Paolo Rota, Elisa Ricci",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zara_The_Unreasonable_Effectiveness_of_Large_Language-Vision_Models_for_Source-Free_Video_ICCV_2023_paper.pdf",
        "aff": "University of Trento, Italy; Fondazione Bruno Kessler, Italy; University of Trento, Italy; LTCI, T\u00e9l\u00e9com Paris, Institut polytechnique de Paris, France",
        "project": "",
        "github": "https://github.com/giaczara/dallv",
        "arxiv": "2308.09139"
    },
    {
        "title": "The Victim and The Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_The_Victim_and_The_Beneficiary_Exploiting_a_Poisoned_Model_to_ICCV_2023_paper.html",
        "author": "Zixuan Zhu, Rui Wang, Cong Zou, Lihua Jing",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_The_Victim_and_The_Beneficiary_Exploiting_a_Poisoned_Model_to_ICCV_2023_paper.pdf",
        "aff": "SKLOIS, Institute of Information Engineering, CAS, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "https://github.com/Zixuan-Zhu/VaB",
        "arxiv": ""
    },
    {
        "title": "Theoretical and Numerical Analysis of 3D Reconstruction Using Point and Line Incidences",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rydell_Theoretical_and_Numerical_Analysis_of_3D_Reconstruction_Using_Point_and_ICCV_2023_paper.html",
        "author": "Felix Rydell, Elima Shehu, Ang\u00e9lica Torres",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rydell_Theoretical_and_Numerical_Analysis_of_3D_Reconstruction_Using_Point_and_ICCV_2023_paper.pdf",
        "aff": "Centre de Recerca Matem`atica, Edifici C, Campus UAB, Bellaterra, Spain; University of Osnabruck and MPI MiS, Albrechtstrasse 28a, Osnabruck, Germany; Inselstrasse 22, Leipzig, Germany; KTH Royal Institute of Technology, Lindstedtsvagen 25, Stockholm, Sweden",
        "project": "",
        "github": "",
        "arxiv": "2303.13593"
    },
    {
        "title": "Thinking Image Color Aesthetics Assessment: Models, Datasets and Benchmarks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Thinking_Image_Color_Aesthetics_Assessment_Models_Datasets_and_Benchmarks_ICCV_2023_paper.html",
        "author": "Shuai He, Anlong Ming, Yaqi Li, Jinyuan Sun, ShunTian Zheng, Huadong Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Thinking_Image_Color_Aesthetics_Assessment_Models_Datasets_and_Benchmarks_ICCV_2023_paper.pdf",
        "aff": "Beijing University of Posts and Telecommunications",
        "project": "",
        "github": "https://github.com/woshidandan/Image-Color-Aesthetics-Assessment",
        "arxiv": ""
    },
    {
        "title": "TiDAL: Learning Training Dynamics for Active Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kye_TiDAL_Learning_Training_Dynamics_for_Active_Learning_ICCV_2023_paper.html",
        "author": "Seong Min Kye, Kwanghee Choi, Hyeongmin Byun, Buru Chang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kye_TiDAL_Learning_Training_Dynamics_for_Active_Learning_ICCV_2023_paper.pdf",
        "aff": "Sogang University; Hyperconnect; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2210.06788"
    },
    {
        "title": "TiDy-PSFs: Computational Imaging with Time-Averaged Dynamic Point-Spread-Functions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shah_TiDy-PSFs_Computational_Imaging_with_Time-Averaged_Dynamic_Point-Spread-Functions_ICCV_2023_paper.html",
        "author": "Sachin Shah, Sakshum Kulshrestha, Christopher A. Metzler",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shah_TiDy-PSFs_Computational_Imaging_with_Time-Averaged_Dynamic_Point-Spread-Functions_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Tiled Multiplane Images for Practical 3D Photography",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Khan_Tiled_Multiplane_Images_for_Practical_3D_Photography_ICCV_2023_paper.html",
        "author": "Numair Khan, Lei Xiao, Douglas Lanman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Tiled_Multiplane_Images_for_Practical_3D_Photography_ICCV_2023_paper.pdf",
        "aff": "Meta",
        "project": "",
        "github": "",
        "arxiv": "2309.14291"
    },
    {
        "title": "Time Does Tell: Self-Supervised Time-Tuning of Dense Image Representations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Salehi_Time_Does_Tell_Self-Supervised_Time-Tuning_of_Dense_Image_Representations_ICCV_2023_paper.html",
        "author": "Mohammadreza Salehi, Efstratios Gavves, Cees G.M. Snoek, Yuki M. Asano",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Salehi_Time_Does_Tell_Self-Supervised_Time-Tuning_of_Dense_Image_Representations_ICCV_2023_paper.pdf",
        "aff": "QUV A Lab, University of Amsterdam",
        "project": "",
        "github": "https://github.com/SMSD75/Timetuning",
        "arxiv": "2308.11796"
    },
    {
        "title": "Time-to-Contact Map by Joint Estimation of Up-to-Scale Inverse Depth and Global Motion using a Single Event Camera",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.html",
        "author": "Urbano Miguel Nunes, Laurent Udo Perrinet, Sio-Hoi Ieng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.pdf",
        "aff": "Aix Marseille Univ, CNRS, INT, Institut de Neurosciences de la Timone; Sorbonne University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Tiny Updater: Towards Efficient Neural Network-Driven Software Updating",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Tiny_Updater_Towards_Efficient_Neural_Network-Driven_Software_Updating_ICCV_2023_paper.html",
        "author": "Linfeng Zhang, Kaisheng Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Tiny_Updater_Towards_Efficient_Neural_Network-Driven_Software_Updating_ICCV_2023_paper.pdf",
        "aff": "Institute for Interdisciplinary Information Sciences, Tsinghua University",
        "project": "",
        "github": "https://github.com/ArchipLab-LinfengZhang/TinyUpdater",
        "arxiv": ""
    },
    {
        "title": "TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_TinyCLIP_CLIP_Distillation_via_Affinity_Mimicking_and_Weight_Inheritance_ICCV_2023_paper.html",
        "author": "Kan Wu, Houwen Peng, Zhenghong Zhou, Bin Xiao, Mengchen Liu, Lu Yuan, Hong Xuan, Michael Valenzuela, Xi (Stephen) Chen, Xinggang Wang, Hongyang Chao, Han Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_TinyCLIP_CLIP_Distillation_via_Affinity_Mimicking_and_Weight_Inheritance_ICCV_2023_paper.pdf",
        "aff": "Huazhong University of Science & Technology; Sun Yat-sen University; Microsoft",
        "project": "aka.ms/tinyclip",
        "github": "",
        "arxiv": "2309.12314"
    },
    {
        "title": "To Adapt or Not to Adapt? Real-Time Adaptation for Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Colomer_To_Adapt_or_Not_to_Adapt_Real-Time_Adaptation_for_Semantic_ICCV_2023_paper.html",
        "author": "Marc Botet Colomer, Pier Luigi Dovesi, Theodoros Panagiotakopoulos, Joao Frederico Carvalho, Linus H\u00e4renstam-Nielsen, Hossein Azizpour, Hedvig Kjellstr\u00f6m, Daniel Cremers, Matteo Poggi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Colomer_To_Adapt_or_Not_to_Adapt_Real-Time_Adaptation_for_Semantic_ICCV_2023_paper.pdf",
        "aff": "KTH, Silo AI; Technical University of Munich, Munich Center for Machine Learning, University of Oxford; Univrses, KTH; KTH; Univrses; University of Bologna; Technical University of Munich, Munich Center for Machine Learning; King; Silo AI, Technical University of Munich",
        "project": "https://marcbotet.github.io/hamlet-web/",
        "github": "",
        "arxiv": "2307.15063"
    },
    {
        "title": "Token-Label Alignment for Vision Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xiao_Token-Label_Alignment_for_Vision_Transformers_ICCV_2023_paper.html",
        "author": "Han Xiao, Wenzhao Zheng, Zheng Zhu, Jie Zhou, Jiwen Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_Token-Label_Alignment_for_Vision_Transformers_ICCV_2023_paper.pdf",
        "aff": "PhiGent Robotics; Beijing National Research Center for Information Science and Technology, China; Department of Automation, Tsinghua University, China",
        "project": "",
        "github": "https://github.com/Euphoria16/TL-Align",
        "arxiv": "2210.06455"
    },
    {
        "title": "Too Large; Data Reduction for Vision-Language Pre-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Too_Large_Data_Reduction_for_Vision-Language_Pre-Training_ICCV_2023_paper.html",
        "author": "Alex Jinpeng Wang, Kevin Qinghong Lin, David Junhao Zhang, Stan Weixian Lei, Mike Zheng Shou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Too_Large_Data_Reduction_for_Vision-Language_Pre-Training_ICCV_2023_paper.pdf",
        "aff": "Show Lab, National University of Singapore",
        "project": "",
        "github": "https://github.com/showlab/datacentric.vlp",
        "arxiv": "2305.20087"
    },
    {
        "title": "ToonTalker: Cross-Domain Face Reenactment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gong_ToonTalker_Cross-Domain_Face_Reenactment_ICCV_2023_paper.html",
        "author": "Yuan Gong, Yong Zhang, Xiaodong Cun, Fei Yin, Yanbo Fan, Xuan Wang, Baoyuan Wu, Yujiu Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ToonTalker_Cross-Domain_Face_Reenactment_ICCV_2023_paper.pdf",
        "aff": "Shenzhen International Graduate School, Tsinghua University; The School of Data Science, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen); Tencent AI Lab; Ant Group",
        "project": "",
        "github": "",
        "arxiv": "2308.12866"
    },
    {
        "title": "TopoSeg: Topology-Aware Nuclear Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_TopoSeg_Topology-Aware_Nuclear_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Hongliang He, Jun Wang, Pengxu Wei, Fan Xu, Xiangyang Ji, Chang Liu, Jie Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_TopoSeg_Topology-Aware_Nuclear_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Department of Automation and BNRist, Tsinghua University, Beijing, China; Sun Yat-sen University, Guangzhou, China; Peng Cheng Laboratory, Shenzhen, China; School of Electronic and Computer Engineering, Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Peking University, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China",
        "project": "",
        "github": "https://github.com/hhlisme/toposeg",
        "arxiv": ""
    },
    {
        "title": "Total-Recon: Deformable Scene Reconstruction for Embodied View Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_Total-Recon_Deformable_Scene_Reconstruction_for_Embodied_View_Synthesis_ICCV_2023_paper.html",
        "author": "Chonghyuk Song, Gengshan Yang, Kangle Deng, Jun-Yan Zhu, Deva Ramanan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Total-Recon_Deformable_Scene_Reconstruction_for_Embodied_View_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Toward Multi-Granularity Decision-Making: Explicit Visual Reasoning with Hierarchical Knowledge",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Toward_Multi-Granularity_Decision-Making_Explicit_Visual_Reasoning_with_Hierarchical_Knowledge_ICCV_2023_paper.html",
        "author": "Yifeng Zhang, Shi Chen, Qi Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Toward_Multi-Granularity_Decision-Making_Explicit_Visual_Reasoning_with_Hierarchical_Knowledge_ICCV_2023_paper.pdf",
        "aff": "University of Minnesota",
        "project": "",
        "github": "https://github.com/SuperJohnZhang/HCNMN",
        "arxiv": ""
    },
    {
        "title": "Toward Unsupervised Realistic Visual Question Answering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Toward_Unsupervised_Realistic_Visual_Question_Answering_ICCV_2023_paper.html",
        "author": "Yuwei Zhang, Chih-Hui Ho, Nuno Vasconcelos",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Toward_Unsupervised_Realistic_Visual_Question_Answering_ICCV_2023_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, University of California, San Diego",
        "project": "",
        "github": "https://github.com/chihhuiho/RGQA",
        "arxiv": "2303.05068"
    },
    {
        "title": "Towards Attack-tolerant Federated Learning via Critical Parameter Analysis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_Towards_Attack-tolerant_Federated_Learning_via_Critical_Parameter_Analysis_ICCV_2023_paper.html",
        "author": "Sungwon Han, Sungwon Park, Fangzhao Wu, Sundong Kim, Bin Zhu, Xing Xie, Meeyoung Cha",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Towards_Attack-tolerant_Federated_Learning_via_Critical_Parameter_Analysis_ICCV_2023_paper.pdf",
        "aff": "Microsoft Research Asia; KAIST; GIST; KAIST, Institute for Basic Science",
        "project": "",
        "github": "",
        "arxiv": "2308.09318"
    },
    {
        "title": "Towards Authentic Face Restoration with Iterative Diffusion Models and Beyond",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Towards_Authentic_Face_Restoration_with_Iterative_Diffusion_Models_and_Beyond_ICCV_2023_paper.html",
        "author": "Yang Zhao, Tingbo Hou, Yu-Chuan Su, Xuhui Jia, Yandong Li, Matthias Grundmann",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Towards_Authentic_Face_Restoration_with_Iterative_Diffusion_Models_and_Beyond_ICCV_2023_paper.pdf",
        "aff": "Google",
        "project": "",
        "github": "",
        "arxiv": "2307.08996"
    },
    {
        "title": "Towards Better Robustness against Common Corruptions for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Towards_Better_Robustness_against_Common_Corruptions_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Zhiqiang Gao, Kaizhu Huang, Rui Zhang, Dawei Liu, Jieming Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Towards_Better_Robustness_against_Common_Corruptions_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Duke Kunshan University, Kunshan, China; Xi\u2019an Jiatong-Liverpool University, Suzhou, China",
        "project": "",
        "github": "https://github.com/gzqhappy/DDAR",
        "arxiv": ""
    },
    {
        "title": "Towards Building More Robust Models with Frequency Bias",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bu_Towards_Building_More_Robust_Models_with_Frequency_Bias_ICCV_2023_paper.html",
        "author": "Qingwen Bu, Dong Huang, Heming Cui",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bu_Towards_Building_More_Robust_Models_with_Frequency_Bias_ICCV_2023_paper.pdf",
        "aff": "Shanghai Artificial Intelligence Laboratory, Shanghai Jiao Tong University; Shanghai Artificial Intelligence Laboratory, The University of Hong Kong; The University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2307.09763"
    },
    {
        "title": "Towards Content-based Pixel Retrieval in Revisited Oxford and Paris",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/An_Towards_Content-based_Pixel_Retrieval_in_Revisited_Oxford_and_Paris_ICCV_2023_paper.html",
        "author": "Guoyuan An, Woo Jae Kim, Saelyne Yang, Rong Li, Yuchi Huo, Sun-Eui Yoon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/An_Towards_Content-based_Pixel_Retrieval_in_Revisited_Oxford_and_Paris_ICCV_2023_paper.pdf",
        "aff": "School of Computing, KAIST; Zhejiang Lab; State Key Lab of CAD&CG, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2309.05438"
    },
    {
        "title": "Towards Deeply Unified Depth-aware Panoptic Segmentation with Bi-directional Guidance Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Towards_Deeply_Unified_Depth-aware_Panoptic_Segmentation_with_Bi-directional_Guidance_Learning_ICCV_2023_paper.html",
        "author": "Junwen He, Yifan Wang, Lijun Wang, Huchuan Lu, Bin Luo, Jun-Yan He, Jin-Peng Lan, Yifeng Geng, Xuansong Xie",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Towards_Deeply_Unified_Depth-aware_Panoptic_Segmentation_with_Bi-directional_Guidance_Learning_ICCV_2023_paper.pdf",
        "aff": "Dalian University of Technology; DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/jwh97nn/DeepDPS",
        "arxiv": "2307.14786"
    },
    {
        "title": "Towards Effective Instance Discrimination Contrastive Loss for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html",
        "author": "Yixin Zhang, Zilei Wang, Junjie Li, Jiafan Zhuang, Zihan Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf",
        "aff": "Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; Shantou University; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/zhyx12/EIDCo",
        "arxiv": ""
    },
    {
        "title": "Towards Fair and Comprehensive Comparisons for Image-Based 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.html",
        "author": "Xinzhu Ma, Yongtao Wang, Yinmin Zhang, Zhiyi Xia, Yuan Meng, Zhihui Wang, Haojie Li, Wanli Ouyang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Dalian University of Technology; Shanghai AI Lab; Shanghai AI Lab, University of Sydney; Tsinghua University",
        "project": "",
        "github": "https://github.com/OpenGVLab/3dodi",
        "arxiv": ""
    },
    {
        "title": "Towards Fairness-aware Adversarial Network Pruning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.html",
        "author": "Lei Zhang, Zhibo Wang, Xiaowei Dong, Yunhe Feng, Xiaoyi Pang, Zhifei Zhang, Kui Ren",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.pdf",
        "aff": "Wuhan University; Adobe Research; University of North Texas; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards General Low-Light Raw Noise Synthesis and Modeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_General_Low-Light_Raw_Noise_Synthesis_and_Modeling_ICCV_2023_paper.html",
        "author": "Feng Zhang, Bin Xu, Zhiqiang Li, Xinran Liu, Qingbo Lu, Changxin Gao, Nong Sang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_General_Low-Light_Raw_Noise_Synthesis_and_Modeling_ICCV_2023_paper.pdf",
        "aff": "DJI Technology Co., Ltd; National Key Laboratory of Multispectral Information Intelligent Processing Technology, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology; DJI Technology Co., Ltd; National Key Laboratory of Multispectral Information Intelligent Processing Technology, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2307.16508"
    },
    {
        "title": "Towards Generic Image Manipulation Detection with Weakly-Supervised Self-Consistency Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Towards_Generic_Image_Manipulation_Detection_with_Weakly-Supervised_Self-Consistency_Learning_ICCV_2023_paper.html",
        "author": "Yuanhao Zhai, Tianyu Luan, David Doermann, Junsong Yuan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Towards_Generic_Image_Manipulation_Detection_with_Weakly-Supervised_Self-Consistency_Learning_ICCV_2023_paper.pdf",
        "aff": "University at Buffalo",
        "project": "",
        "github": "",
        "arxiv": "2309.01246"
    },
    {
        "title": "Towards Geospatial Foundation Models via Continual Pretraining",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mendieta_Towards_Geospatial_Foundation_Models_via_Continual_Pretraining_ICCV_2023_paper.html",
        "author": "Mat\u00edas Mendieta, Boran Han, Xingjian Shi, Yi Zhu, Chen Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mendieta_Towards_Geospatial_Foundation_Models_via_Continual_Pretraining_ICCV_2023_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida; Amazon Web Services; Boson AI",
        "project": "",
        "github": "https://github.com/mmendiet/GFM",
        "arxiv": "2302.04476"
    },
    {
        "title": "Towards Grand Unified Representation Learning for Unsupervised Visible-Infrared Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Towards_Grand_Unified_Representation_Learning_for_Unsupervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.html",
        "author": "Bin Yang, Jun Chen, Mang Ye",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Towards_Grand_Unified_Representation_Learning_for_Unsupervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf",
        "aff": "National Engineering Research Center for Multimedia Software, School of Computer Science, Hubei Luojia Laboratory, Wuhan University, Wuhan, China",
        "project": "",
        "github": "https://github.com/yangbincv/GUR",
        "arxiv": ""
    },
    {
        "title": "Towards High-Fidelity Text-Guided 3D Face Generation and Manipulation Using only Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Towards_High-Fidelity_Text-Guided_3D_Face_Generation_and_Manipulation_Using_only_ICCV_2023_paper.html",
        "author": "Cuican Yu, Guansong Lu, Yihan Zeng, Jian Sun, Xiaodan Liang, Huibin Li, Zongben Xu, Songcen Xu, Wei Zhang, Hang Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Towards_High-Fidelity_Text-Guided_3D_Face_Generation_and_Manipulation_Using_only_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; Sun Yat-sen University; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": "2308.16758"
    },
    {
        "title": "Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fu_Towards_High-Quality_Specular_Highlight_Removal_by_Leveraging_Large-Scale_Synthetic_Data_ICCV_2023_paper.html",
        "author": "Gang Fu, Qing Zhang, Lei Zhu, Chunxia Xiao, Ping Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Towards_High-Quality_Specular_Highlight_Removal_by_Leveraging_Large-Scale_Synthetic_Data_ICCV_2023_paper.pdf",
        "aff": "Sun Yat-sen University, Guangzhou, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; The Hong Kong Polytechnic University, Hong Kong; School of Computer Science, Wuhan University, Wuhan, China",
        "project": "",
        "github": "",
        "arxiv": "2309.06302"
    },
    {
        "title": "Towards Improved Input Masking for Convolutional Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Balasubramanian_Towards_Improved_Input_Masking_for_Convolutional_Neural_Networks_ICCV_2023_paper.html",
        "author": "Sriram Balasubramanian, Soheil Feizi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Balasubramanian_Towards_Improved_Input_Masking_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf",
        "aff": "University of Maryland, College Park",
        "project": "",
        "github": "",
        "arxiv": "2211.14646"
    },
    {
        "title": "Towards Inadequately Pre-trained Models in Transfer Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Towards_Inadequately_Pre-trained_Models_in_Transfer_Learning_ICCV_2023_paper.html",
        "author": "Andong Deng, Xingjian Li, Di Hu, Tianyang Wang, Haoyi Xiong, Cheng-Zhong Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Towards_Inadequately_Pre-trained_Models_in_Transfer_Learning_ICCV_2023_paper.pdf",
        "aff": "Renmin University of China; University of Macau; University of Alabama at Birmingham; University of Central Florida; Baidu Research",
        "project": "",
        "github": "",
        "arxiv": "2203.04668"
    },
    {
        "title": "Towards Instance-adaptive Inference for Federated Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.html",
        "author": "Chun-Mei Feng, Kai Yu, Nian Liu, Xinxing Xu, Salman Khan, Wangmeng Zuo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.pdf",
        "aff": "Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR), Singapore; Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), UAE; Harbin Institute of Technology, Harbin, China; Australian National University, Canberra ACT, Australia",
        "project": "",
        "github": "https://github.com/chunmeifeng/FedIns",
        "arxiv": "2308.06051"
    },
    {
        "title": "Towards Memory- and Time-Efficient Backpropagation for Training Spiking Neural Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Meng_Towards_Memory-_and_Time-Efficient_Backpropagation_for_Training_Spiking_Neural_Networks_ICCV_2023_paper.html",
        "author": "Qingyan Meng, Mingqing Xiao, Shen Yan, Yisen Wang, Zhouchen Lin, Zhi-Quan Luo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Meng_Towards_Memory-_and_Time-Efficient_Backpropagation_for_Training_Spiking_Neural_Networks_ICCV_2023_paper.pdf",
        "aff": "National Key Lab. of General AI, School of Intelligence Science and Technology, Peking University; The Chinese University of Hong Kong, Shenzhen; Shenzhen Research Institute of Big Data; Institute for Artificial Intelligence, Peking University; National Key Lab. of General AI, School of Intelligence Science and Technology, Peking University; Peng Cheng Laboratory; Institute for Artificial Intelligence, Peking University; National Key Lab. of General AI, School of Intelligence Science and Technology, Peking University; Center for Data Science, Peking University",
        "project": "",
        "github": "https://github.com/qymeng94/SLTT",
        "arxiv": ""
    },
    {
        "title": "Towards Models that Can See and Read",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ganz_Towards_Models_that_Can_See_and_Read_ICCV_2023_paper.html",
        "author": "Roy Ganz, Oren Nuriel, Aviad Aberdam, Yair Kittenplon, Shai Mazor, Ron Litman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ganz_Towards_Models_that_Can_See_and_Read_ICCV_2023_paper.pdf",
        "aff": "AWS AI Labs; Technion, Israel",
        "project": "",
        "github": "",
        "arxiv": "2301.07389"
    },
    {
        "title": "Towards Multi-Layered 3D Garments Animation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Towards_Multi-Layered_3D_Garments_Animation_ICCV_2023_paper.html",
        "author": "Yidi Shao, Chen Change Loy, Bo Dai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Towards_Multi-Layered_3D_Garments_Animation_ICCV_2023_paper.pdf",
        "aff": "S-Lab for Advanced Intelligence, Nanyang Technological University; Shanghai AI Laboratory",
        "project": "www.mmlab-ntu.com/project/layersnet/index.html",
        "github": "",
        "arxiv": "2305.10418"
    },
    {
        "title": "Towards Nonlinear-Motion-Aware and Occlusion-Robust Rolling Shutter Correction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Towards_Nonlinear-Motion-Aware_and_Occlusion-Robust_Rolling_Shutter_Correction_ICCV_2023_paper.html",
        "author": "Delin Qu, Yizhen Lao, Zhigang Wang, Dong Wang, Bin Zhao, Xuelong Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Towards_Nonlinear-Motion-Aware_and_Occlusion-Robust_Rolling_Shutter_Correction_ICCV_2023_paper.pdf",
        "aff": "Fudan University, Shanghai AI Laboratory; Shanghai AI Laboratory, Northwestern Polytechnical University; Hunan University; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/DelinQu/qrsc",
        "arxiv": "2303.18125"
    },
    {
        "title": "Towards Open-Set Test-Time Adaptation Utilizing the Wisdom of Crowds in Entropy Minimization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Towards_Open-Set_Test-Time_Adaptation_Utilizing_the_Wisdom_of_Crowds_in_ICCV_2023_paper.html",
        "author": "Jungsoo Lee, Debasmit Das, Jaegul Choo, Sungha Choi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Towards_Open-Set_Test-Time_Adaptation_Utilizing_the_Wisdom_of_Crowds_in_ICCV_2023_paper.pdf",
        "aff": "KAIST; Qualcomm AI Research; Qualcomm AI Research, KAIST",
        "project": "",
        "github": "",
        "arxiv": "2308.06879"
    },
    {
        "title": "Towards Open-Vocabulary Video Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Towards_Open-Vocabulary_Video_Instance_Segmentation_ICCV_2023_paper.html",
        "author": "Haochen Wang, Cilin Yan, Shuai Wang, Xiaolong Jiang, Xu Tang, Yao Hu, Weidi Xie, Efstratios Gavves",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Towards_Open-Vocabulary_Video_Instance_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Xiaohongshu Inc.; University of Amsterdam; Shanghai Jiao Tong University; Beihang University",
        "project": "",
        "github": "https://github.com/haochenheheda/LVVIS",
        "arxiv": "2304.01715"
    },
    {
        "title": "Towards Real-World Burst Image Super-Resolution: Benchmark and Method",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.html",
        "author": "Pengxu Wei, Yujing Sun, Xingbei Guo, Chang Liu, Guanbin Li, Jie Chen, Xiangyang Ji, Liang Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.pdf",
        "aff": "Sun Yat-sen University; School of Electronic and Computer Engineering, Peking University, Shenzhen, China; Tsinghua University",
        "project": "",
        "github": "https://github.com/yjsunnn/FBANet",
        "arxiv": ""
    },
    {
        "title": "Towards Realistic Evaluation of Industrial Continual Learning Scenarios with an Emphasis on Energy Consumption and Computational Footprint",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chavan_Towards_Realistic_Evaluation_of_Industrial_Continual_Learning_Scenarios_with_an_ICCV_2023_paper.html",
        "author": "Vivek Chavan, Paul Koch, Marian Schl\u00fcter, Clemens Briese",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chavan_Towards_Realistic_Evaluation_of_Industrial_Continual_Learning_Scenarios_with_an_ICCV_2023_paper.pdf",
        "aff": "Fraunhofer IPK, Berlin, Germany",
        "project": "http://dx.doi.org/10.24406/fordatis/266.2",
        "github": "https://github.com/Vivek9Chavan/RECILPODNet",
        "arxiv": ""
    },
    {
        "title": "Towards Robust Model Watermark via Reducing Parametric Vulnerability",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gan_Towards_Robust_Model_Watermark_via_Reducing_Parametric_Vulnerability_ICCV_2023_paper.html",
        "author": "Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Towards_Robust_Model_Watermark_via_Reducing_Parametric_Vulnerability_ICCV_2023_paper.pdf",
        "aff": "The University of Tokyo, Japan; Tsinghua Shenzhen International Graduate School, Tsinghua University, China; Research Center of Artificial Intelligence, Peng Cheng Laboratory, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, China; Ant Group, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, China",
        "project": "",
        "github": "https://github.com/GuanhaoGan/robust-model-watermarking",
        "arxiv": "2309.04777"
    },
    {
        "title": "Towards Robust and Smooth 3D Multi-Person Pose Estimation from Monocular Videos in the Wild",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_Towards_Robust_and_Smooth_3D_Multi-Person_Pose_Estimation_from_Monocular_ICCV_2023_paper.html",
        "author": "Sungchan Park, Eunyi You, Inhoe Lee, Joonseok Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Towards_Robust_and_Smooth_3D_Multi-Person_Pose_Estimation_from_Monocular_ICCV_2023_paper.pdf",
        "aff": "Seoul National University",
        "project": "https://www.youtube.com/@potr3d",
        "github": "",
        "arxiv": "2309.08644"
    },
    {
        "title": "Towards Saner Deep Image Registration",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Duan_Towards_Saner_Deep_Image_Registration_ICCV_2023_paper.html",
        "author": "Bin Duan, Ming Zhong, Yan Yan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_Towards_Saner_Deep_Image_Registration_ICCV_2023_paper.pdf",
        "aff": "Illinois Tech, Chicago, IL 60616, USA",
        "project": "",
        "github": "https://github.com/tuffr5/Saner-deep-registration",
        "arxiv": "2307.09696"
    },
    {
        "title": "Towards Semi-supervised Learning with Non-random Missing Labels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Duan_Towards_Semi-supervised_Learning_with_Non-random_Missing_Labels_ICCV_2023_paper.html",
        "author": "Yue Duan, Zhen Zhao, Lei Qi, Luping Zhou, Lei Wang, Yinghuan Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_Towards_Semi-supervised_Learning_with_Non-random_Missing_Labels_ICCV_2023_paper.pdf",
        "aff": "University of Sydney; Southeast University; Nanjing University; University of Wollongong",
        "project": "",
        "github": "https://github.com/NJUyued/PRG4SSL-MNAR",
        "arxiv": "2308.08872"
    },
    {
        "title": "Towards Understanding the Generalization of Deepfake Detectors from a Game-Theoretical View",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Towards_Understanding_the_Generalization_of_Deepfake_Detectors_from_a_Game-Theoretical_ICCV_2023_paper.html",
        "author": "Kelu Yao, Jin Wang, Boyu Diao, Chao Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Towards_Understanding_the_Generalization_of_Deepfake_Detectors_from_a_Game-Theoretical_ICCV_2023_paper.pdf",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Zhejiang Laboratory, Hangzhou 311100, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Unifying Medical Vision-and-Language Pre-Training via Soft Prompts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Towards_Unifying_Medical_Vision-and-Language_Pre-Training_via_Soft_Prompts_ICCV_2023_paper.html",
        "author": "Zhihong Chen, Shizhe Diao, Benyou Wang, Guanbin Li, Xiang Wan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Towards_Unifying_Medical_Vision-and-Language_Pre-Training_via_Soft_Prompts_ICCV_2023_paper.pdf",
        "aff": "Shenzhen Research Institute of Big Data; The Hong Kong University of Science and Technology; The Chinese University of Hong Kong, Shenzhen; Sun Yat-sen University",
        "project": "",
        "github": "https://github.com/zhjohnchan/ptunifier",
        "arxiv": "2302.08958"
    },
    {
        "title": "Towards Universal Image Embeddings: A Large-Scale Dataset and Challenge for Generic Image Representations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ypsilantis_Towards_Universal_Image_Embeddings_A_Large-Scale_Dataset_and_Challenge_for_ICCV_2023_paper.html",
        "author": "Nikolaos-Antonios Ypsilantis, Kaifeng Chen, Bingyi Cao, M\u00e1rio Lipovsk\u00fd, Pelin Dogan-Sch\u00f6nberger, Grzegorz Makosa, Boris Bluntschli, Mojtaba Seyedhosseini, Ond\u0159ej Chum, Andr\u00e9 Araujo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ypsilantis_Towards_Universal_Image_Embeddings_A_Large-Scale_Dataset_and_Challenge_for_ICCV_2023_paper.pdf",
        "aff": "Google; VRG, FEE, Czech Technical University in Prague",
        "project": "https://cmp.felk.cvut.cz/univ_emb/",
        "github": "",
        "arxiv": "2309.01858"
    },
    {
        "title": "Towards Universal LiDAR-Based 3D Object Detection by Multi-Domain Knowledge Transfer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Towards_Universal_LiDAR-Based_3D_Object_Detection_by_Multi-Domain_Knowledge_Transfer_ICCV_2023_paper.html",
        "author": "Guile Wu, Tongtong Cao, Bingbing Liu, Xingxin Chen, Yuan Ren",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Towards_Universal_LiDAR-Based_3D_Object_Detection_by_Multi-Domain_Knowledge_Transfer_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Unsupervised Domain Generalization for Face Anti-Spoofing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Towards_Unsupervised_Domain_Generalization_for_Face_Anti-Spoofing_ICCV_2023_paper.html",
        "author": "Yuchen Liu, Yabo Chen, Mengran Gou, Chun-Ting Huang, Yaoming Wang, Wenrui Dai, Hongkai Xiong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Towards_Unsupervised_Domain_Generalization_for_Face_Anti-Spoofing_ICCV_2023_paper.pdf",
        "aff": "Department of Electronic Engineering, Shanghai Jiao Tong University, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Qualcomm AI Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Viewpoint Robustness in Bird's Eye View Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Klinghoffer_Towards_Viewpoint_Robustness_in_Birds_Eye_View_Segmentation_ICCV_2023_paper.html",
        "author": "Tzofi Klinghoffer, Jonah Philion, Wenzheng Chen, Or Litany, Zan Gojcic, Jungseock Joo, Ramesh Raskar, Sanja Fidler, Jose M. Alvarez",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_Towards_Viewpoint_Robustness_in_Birds_Eye_View_Segmentation_ICCV_2023_paper.pdf",
        "aff": "University of Toronto; NVIDIA; UCLA; MIT",
        "project": "https://nvlabs.github.io/viewpoint-robustness",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Viewpoint-Invariant Visual Recognition via Adversarial Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ruan_Towards_Viewpoint-Invariant_Visual_Recognition_via_Adversarial_Training_ICCV_2023_paper.html",
        "author": "Shouwei Ruan, Yinpeng Dong, Hang Su, Jianteng Peng, Ning Chen, Xingxing Wei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ruan_Towards_Viewpoint-Invariant_Visual_Recognition_via_Adversarial_Training_ICCV_2023_paper.pdf",
        "aff": "Dept. of Comp. Sci. and Tech., Institute for AI, Tsinghua-Bosch Joint ML Center, THBI Lab, BNRist Center, Tsinghua University, Beijing 100084, China; Institute of Artificial Intelligence, Beihang University, Beijing 100191, China; OPPO",
        "project": "",
        "github": "",
        "arxiv": "2307.10235"
    },
    {
        "title": "Towards Zero Domain Gap: A Comprehensive Study of Realistic LiDAR Simulation for Autonomy Testing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Manivasagam_Towards_Zero_Domain_Gap_A_Comprehensive_Study_of_Realistic_LiDAR_ICCV_2023_paper.html",
        "author": "Sivabalan Manivasagam, Ioan Andrei B\u00e2rsan, Jingkang Wang, Ze Yang, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Manivasagam_Towards_Zero_Domain_Gap_A_Comprehensive_Study_of_Realistic_LiDAR_ICCV_2023_paper.pdf",
        "aff": "Waabi, University of Toronto",
        "project": "https://waabi.ai/lidar-dg",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Zero-Shot Scale-Aware Monocular Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guizilini_Towards_Zero-Shot_Scale-Aware_Monocular_Depth_Estimation_ICCV_2023_paper.html",
        "author": "Vitor Guizilini, Igor Vasiljevic, Dian Chen, Rare\u0219 Ambru\u0219, Adrien Gaidon",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_Towards_Zero-Shot_Scale-Aware_Monocular_Depth_Estimation_ICCV_2023_paper.pdf",
        "aff": "Toyota Research Institute (TRI), Los Altos, CA",
        "project": "https://sites.google.com/view/tri-zerodepth",
        "github": "",
        "arxiv": "2306.17253"
    },
    {
        "title": "Tracing the Origin of Adversarial Attack for Forensic Investigation and Deterrence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Tracing_the_Origin_of_Adversarial_Attack_for_Forensic_Investigation_and_ICCV_2023_paper.html",
        "author": "Han Fang, Jiyi Zhang, Yupeng Qiu, Jiayang Liu, Ke Xu, Chengfang Fang, Ee-Chien Chang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Tracing_the_Origin_of_Adversarial_Attack_for_Forensic_Investigation_and_ICCV_2023_paper.pdf",
        "aff": "Huawei International; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": "2301.01218"
    },
    {
        "title": "TrackFlow: Multi-Object tracking with Normalizing Flows",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Mancusi_TrackFlow_Multi-Object_tracking_with_Normalizing_Flows_ICCV_2023_paper.html",
        "author": "Gianluca Mancusi, Aniello Panariello, Angelo Porrello, Matteo Fabbri, Simone Calderara, Rita Cucchiara",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mancusi_TrackFlow_Multi-Object_tracking_with_Normalizing_Flows_ICCV_2023_paper.pdf",
        "aff": "University of Modena and Reggio Emilia, Italy; GoatAI S.r.l.; University of Modena and Reggio Emilia, Italy and IIT-CNR, Italy",
        "project": "",
        "github": "",
        "arxiv": "2308.11513"
    },
    {
        "title": "Tracking Anything with Decoupled Video Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Tracking_Anything_with_Decoupled_Video_Segmentation_ICCV_2023_paper.html",
        "author": "Ho Kei Cheng, Seoung Wug Oh, Brian Price, Alexander Schwing, Joon-Young Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Tracking_Anything_with_Decoupled_Video_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; University of Illinois Urbana-Champaign",
        "project": "hkchengrex.github.io/Tracking-Anything-with-DEVA",
        "github": "https://github.com/hkchengrex/Tracking-Anything-with-DEVA",
        "arxiv": "2309.03903"
    },
    {
        "title": "Tracking Everything Everywhere All at Once",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Tracking_Everything_Everywhere_All_at_Once_ICCV_2023_paper.html",
        "author": "Qianqian Wang, Yen-Yu Chang, Ruojin Cai, Zhengqi Li, Bharath Hariharan, Aleksander Holynski, Noah Snavely",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Tracking_Everything_Everywhere_All_at_Once_ICCV_2023_paper.pdf",
        "aff": "Cornell University; Google Research",
        "project": "https://omnimotion.github.io",
        "github": "",
        "arxiv": "2306.05422"
    },
    {
        "title": "Tracking by 3D Model Estimation of Unknown Objects in Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rozumnyi_Tracking_by_3D_Model_Estimation_of_Unknown_Objects_in_Videos_ICCV_2023_paper.html",
        "author": "Denys Rozumnyi, Ji\u0159\u00ed Matas, Marc Pollefeys, Vittorio Ferrari, Martin R. Oswald",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rozumnyi_Tracking_by_3D_Model_Estimation_of_Unknown_Objects_in_Videos_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich; University of Amsterdam; Department of Computer Science, ETH Zurich; Czech Technical University in Prague; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2304.06419"
    },
    {
        "title": "Tracking by Natural Language Specification with Long Short-term Context Decoupling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.html",
        "author": "Ding Ma, Xiangqian Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Technology, Harbin Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Tracking without Label: Unsupervised Multiple Object Tracking via Contrastive Similarity Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Meng_Tracking_without_Label_Unsupervised_Multiple_Object_Tracking_via_Contrastive_Similarity_ICCV_2023_paper.html",
        "author": "Sha Meng, Dian Shao, Jiacheng Guo, Shan Gao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Meng_Tracking_without_Label_Unsupervised_Multiple_Object_Tracking_via_Contrastive_Similarity_ICCV_2023_paper.pdf",
        "aff": "Northwestern Polytechnical University, Xi\u2019an, China",
        "project": "",
        "github": "",
        "arxiv": "2309.00942"
    },
    {
        "title": "Traj-MAE: Masked Autoencoders for Trajectory Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Traj-MAE_Masked_Autoencoders_for_Trajectory_Prediction_ICCV_2023_paper.html",
        "author": "Hao Chen, Jiaze Wang, Kun Shao, Furui Liu, Jianye Hao, Chenyong Guan, Guangyong Chen, Pheng-Ann Heng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Traj-MAE_Masked_Autoencoders_for_Trajectory_Prediction_ICCV_2023_paper.pdf",
        "aff": "Institute of Medical Intelligence and XR, The Chinese University of Hong Kong; Gudsen Technology Co. Ltd; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Zhejiang Lab; Huawei Noah\u2019s Ark Lab; Tianjin University",
        "project": "https://jiazewang.com/projects/trajmae.html",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "TrajPAC: Towards Robustness Verification of Pedestrian Trajectory Prediction Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_TrajPAC_Towards_Robustness_Verification_of_Pedestrian_Trajectory_Prediction_Models_ICCV_2023_paper.html",
        "author": "Liang Zhang, Nathaniel Xu, Pengfei Yang, Gaojie Jin, Cheng-Chao Huang, Lijun Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_TrajPAC_Towards_Robustness_Verification_of_Pedestrian_Trajectory_Prediction_Models_ICCV_2023_paper.pdf",
        "aff": "Nanjing Institute of Software Technology, ISCAS, Nanjing, China; State Key Laboratory of Computer Science, Institute of Software, CAS, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, CAS, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": "2308.05985"
    },
    {
        "title": "Trajectory Unified Transformer for Pedestrian Trajectory Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Trajectory_Unified_Transformer_for_Pedestrian_Trajectory_Prediction_ICCV_2023_paper.html",
        "author": "Liushuai Shi, Le Wang, Sanping Zhou, Gang Hua",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Trajectory_Unified_Transformer_for_Pedestrian_Trajectory_Prediction_ICCV_2023_paper.pdf",
        "aff": "National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Applications, Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University; Wormpex AI Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "TrajectoryFormer: 3D Object Tracking Transformer with Predictive Trajectory Hypotheses",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TrajectoryFormer_3D_Object_Tracking_Transformer_with_Predictive_Trajectory_Hypotheses_ICCV_2023_paper.html",
        "author": "Xuesong Chen, Shaoshuai Shi, Chao Zhang, Benjin Zhu, Qiang Wang, Ka Chun Cheung, Simon See, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TrajectoryFormer_3D_Object_Tracking_Transformer_with_Predictive_Trajectory_Hypotheses_ICCV_2023_paper.pdf",
        "aff": "Max Planck Institute for Informatics; NVIDIA AI Technology Center; MMLab, CUHK; Samsung Telecommunication Research",
        "project": "",
        "github": "https://github.com/poodarchu/EFG",
        "arxiv": "2306.05888"
    },
    {
        "title": "TransFace: Calibrating Transformer Training for Face Recognition from a Data-Centric Perspective",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.html",
        "author": "Jun Dan, Yang Liu, Haoyu Xie, Jiankang Deng, Haoran Xie, Xuansong Xie, Baigui Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Alibaba DAMO Academy; Imperial College London; Zhejiang University",
        "project": "",
        "github": "https://github.com/DanJun6737/TransFace",
        "arxiv": "2308.10133"
    },
    {
        "title": "TransHuman: A Transformer-based Human Representation for Generalizable Neural Human Rendering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_TransHuman_A_Transformer-based_Human_Representation_for_Generalizable_Neural_Human_Rendering_ICCV_2023_paper.html",
        "author": "Xiao Pan, Zongxin Yang, Jianxin Ma, Chang Zhou, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_TransHuman_A_Transformer-based_Human_Representation_for_Generalizable_Neural_Human_Rendering_ICCV_2023_paper.pdf",
        "aff": "Alibaba DAMO Academy, China; ReLER Lab, CCAI, Zhejiang University, China",
        "project": "https://pansanity666.github.io/TransHuman/",
        "github": "https://github.com/pansanity666/TransHuman",
        "arxiv": "2307.12291"
    },
    {
        "title": "TransIFF: An Instance-Level Feature Fusion Framework for Vehicle-Infrastructure Cooperative 3D Detection with Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TransIFF_An_Instance-Level_Feature_Fusion_Framework_for_Vehicle-Infrastructure_Cooperative_3D_ICCV_2023_paper.html",
        "author": "Ziming Chen, Yifeng Shi, Jinrang Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransIFF_An_Instance-Level_Feature_Fusion_Framework_for_Vehicle-Infrastructure_Cooperative_3D_ICCV_2023_paper.pdf",
        "aff": "Baidu Inc.; Beihang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "TransTIC: Transferring Transformer-based Image Compression from Human Perception to Machine Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.html",
        "author": "Yi-Hsin Chen, Ying-Chieh Weng, Chia-Hao Kao, Cheng Chien, Wei-Chen Chiu, Wen-Hsiao Peng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.pdf",
        "aff": "wpeng@cs.nctu.edu.tw; walon@cs.nctu.edu.tw; National Yang Ming Chiao Tung University, Taiwan",
        "project": "",
        "github": "",
        "arxiv": "2306.05085"
    },
    {
        "title": "Transferable Adversarial Attack for Both Vision Transformers and Convolutional Networks via Momentum Integrated Gradients",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Transferable_Adversarial_Attack_for_Both_Vision_Transformers_and_Convolutional_Networks_ICCV_2023_paper.html",
        "author": "Wenshuo Ma, Yidong Li, Xiaofeng Jia, Wei Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Transferable_Adversarial_Attack_for_Both_Vision_Transformers_and_Convolutional_Networks_ICCV_2023_paper.pdf",
        "aff": "Beijing Big Data Centre; Beijing Jiaotong University; IIIS, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Transferable Decoding with Visual Entities for Zero-Shot Image Captioning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.html",
        "author": "Junjie Fei, Teng Wang, Jinrui Zhang, Zhenyu He, Chengjie Wang, Feng Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.pdf",
        "aff": "Harbin Institute of Technology (Shenzhen); Southern University of Science and Technology; The University of Hong Kong; Tencent",
        "project": "",
        "github": "https://github.com/FeiElysia/ViECap",
        "arxiv": "2307.16525"
    },
    {
        "title": "Translating Images to Road Network: A Non-Autoregressive Sequence-to-Sequence Approach",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Translating_Images_to_Road_Network_A_Non-Autoregressive_Sequence-to-Sequence_Approach_ICCV_2023_paper.html",
        "author": "Jiachen Lu, Renyuan Peng, Xinyue Cai, Hang Xu, Hongyang Li, Feng Wen, Wei Zhang, Li Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Translating_Images_to_Road_Network_A_Non-Autoregressive_Sequence-to-Sequence_Approach_ICCV_2023_paper.pdf",
        "aff": "Fudan University; Huawei Noah\u2019s Ark Lab; Shanghai AI Lab",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Transparent Shape from a Single View Polarization Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.html",
        "author": "Mingqi Shao, Chongkun Xia, Zhendong Yang, Junnan Huang, Xueqian Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.pdf",
        "aff": "Tsinghua Shenzhen International Graduate School",
        "project": "",
        "github": "https://github.com/shaomq2187/TransSfP",
        "arxiv": "2204.06331"
    },
    {
        "title": "Treating Pseudo-labels Generation as Image Matting for Weakly Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Treating_Pseudo-labels_Generation_as_Image_Matting_for_Weakly_Supervised_Semantic_ICCV_2023_paper.html",
        "author": "Changwei Wang, Rongtao Xu, Shibiao Xu, Weiliang Meng, Xiaopeng Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Treating_Pseudo-labels_Generation_as_Image_Matting_for_Weakly_Supervised_Semantic_ICCV_2023_paper.pdf",
        "aff": "The State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Tree-Structured Shading Decomposition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Geng_Tree-Structured_Shading_Decomposition_ICCV_2023_paper.html",
        "author": "Chen Geng, Hong-Xing Yu, Sharon Zhang, Maneesh Agrawala, Jiajun Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Geng_Tree-Structured_Shading_Decomposition_ICCV_2023_paper.pdf",
        "aff": "Stanford University",
        "project": "https://chen-geng.com/inv-shade-trees",
        "github": "",
        "arxiv": "2309.07122"
    },
    {
        "title": "Tri-MipRF: Tri-Mip Representation for Efficient Anti-Aliasing Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Tri-MipRF_Tri-Mip_Representation_for_Efficient_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Wenbo Hu, Yuling Wang, Lin Ma, Bangbang Yang, Lin Gao, Xiao Liu, Yuewen Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Tri-MipRF_Tri-Mip_Representation_for_Efficient_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Institute of Computing Technology, CAS; PICO, ByteDance, Beijing",
        "project": "https://wbhu.github.io/projects/Tri-MipRF",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "TripLe: Revisiting Pretrained Model Reuse and Progressive Learning for Efficient Vision Transformer Scaling and Searching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fu_TripLe_Revisiting_Pretrained_Model_Reuse_and_Progressive_Learning_for_Efficient_ICCV_2023_paper.html",
        "author": "Cheng Fu, Hanxian Huang, Zixuan Jiang, Yun Ni, Lifeng Nai, Gang Wu, Liqun Cheng, Yanqi Zhou, Sheng Li, Andrew Li, Jishen Zhao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_TripLe_Revisiting_Pretrained_Model_Reuse_and_Progressive_Learning_for_Efficient_ICCV_2023_paper.pdf",
        "aff": "Google; UC San Diego",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Troubleshooting Ethnic Quality Bias with Curriculum Domain Adaptation for Face Image Quality Assessment",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ou_Troubleshooting_Ethnic_Quality_Bias_with_Curriculum_Domain_Adaptation_for_Face_ICCV_2023_paper.html",
        "author": "Fu-Zhao Ou, Baoliang Chen, Chongyi Li, Shiqi Wang, Sam Kwong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ou_Troubleshooting_Ethnic_Quality_Bias_with_Curriculum_Domain_Adaptation_for_Face_ICCV_2023_paper.pdf",
        "aff": "Nankai University, Tianjin, China; City University of Hong Kong, Hong Kong SAR, China; City University of Hong Kong, Hong Kong SAR, China; Lingnan University, Hong Kong SAR, China",
        "project": "",
        "github": "https://github.com/oufuzhao/EQBM",
        "arxiv": ""
    },
    {
        "title": "Tube-Link: A Flexible Cross Tube Framework for Universal Video Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Tube-Link_A_Flexible_Cross_Tube_Framework_for_Universal_Video_Segmentation_ICCV_2023_paper.html",
        "author": "Xiangtai Li, Haobo Yuan, Wenwei Zhang, Guangliang Cheng, Jiangmiao Pang, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Tube-Link_A_Flexible_Cross_Tube_Framework_for_Universal_Video_Segmentation_ICCV_2023_paper.pdf",
        "aff": "University of Liverpool; Shanghai AI Lab; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/lxtGH/Tube-Link",
        "arxiv": ""
    },
    {
        "title": "Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Thoker_Tubelet-Contrastive_Self-Supervision_for_Video-Efficient_Generalization_ICCV_2023_paper.html",
        "author": "Fida Mohammad Thoker, Hazel Doughty, Cees G. M. Snoek",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Thoker_Tubelet-Contrastive_Self-Supervision_for_Video-Efficient_Generalization_ICCV_2023_paper.pdf",
        "aff": "University of Amsterdam",
        "project": "",
        "github": "https://github.com/fmthoker/tubelet-contrast",
        "arxiv": "2303.11003"
    },
    {
        "title": "Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.html",
        "author": "Jay Zhangjie Wu, Yixiao Ge, Xintao Wang, Stan Weixian Lei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan, Xiaohu Qie, Mike Zheng Shou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.pdf",
        "aff": "Tencent PCG; ARC Lab; Show Lab; National University of Singapore",
        "project": "https://tuneavideo.github.io",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Tuning Pre-trained Model via Moment Probing",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Tuning_Pre-trained_Model_via_Moment_Probing_ICCV_2023_paper.html",
        "author": "Mingze Gao, Qilong Wang, Zhenyi Lin, Pengfei Zhu, Qinghua Hu, Jingbo Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Tuning_Pre-trained_Model_via_Moment_Probing_ICCV_2023_paper.pdf",
        "aff": "Tianjin Key Lab of Machine Learning, College of Intelligence and Computing, Tianjin University, China; Business Intelligence Lab, Baidu Research, China",
        "project": "",
        "github": "",
        "arxiv": "2307.11342"
    },
    {
        "title": "Two Birds, One Stone: A Unified Framework for Joint Learning of Image and Video Style Transfers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.html",
        "author": "Bohai Gu, Heng Fan, Libo Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.pdf",
        "aff": "Institute of Software Chinese Academy of Sciences, Beijing, China; Institute of Software Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Department of Computer Science and Engineering, University of North Texas, Denton TX, USA",
        "project": "",
        "github": "https://github.com/NevSNev/UniST",
        "arxiv": "2304.11335"
    },
    {
        "title": "Two-in-One Depth: Bridging the Gap Between Monocular and Binocular Self-Supervised Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Two-in-One_Depth_Bridging_the_Gap_Between_Monocular_and_Binocular_Self-Supervised_ICCV_2023_paper.html",
        "author": "Zhengming Zhou, Qiulei Dong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Two-in-One_Depth_Bridging_the_Gap_Between_Monocular_and_Binocular_Self-Supervised_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Multimodal Artificial Intelligence Systems, CASIA; School of Artificial Intelligence, UCAS",
        "project": "",
        "github": "https://github.com/ZM-Zhou/TiO-Depth-pytorch",
        "arxiv": "2309.00933"
    },
    {
        "title": "U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point Clouds",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Di_U-RED_Unsupervised_3D_Shape_Retrieval_and_Deformation_for_Partial_Point_ICCV_2023_paper.html",
        "author": "Yan Di, Chenyangguang Zhang, Ruida Zhang, Fabian Manhardt, Yongzhi Su, Jason Rambach, Didier Stricker, Xiangyang Ji, Federico Tombari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Di_U-RED_Unsupervised_3D_Shape_Retrieval_and_Deformation_for_Partial_Point_ICCV_2023_paper.pdf",
        "aff": "Google; Technical University of Munich; DFKI; Tsinghua University",
        "project": "",
        "github": "https://github.com/ZhangCYG/U-RED",
        "arxiv": ""
    },
    {
        "title": "UATVR: Uncertainty-Adaptive Text-Video Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fang_UATVR_Uncertainty-Adaptive_Text-Video_Retrieval_ICCV_2023_paper.html",
        "author": "Bo Fang, Wenhao Wu, Chang Liu, Yu Zhou, Yuxin Song, Weiping Wang, Xiangbo Shu, Xiangyang Ji, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_UATVR_Uncertainty-Adaptive_Text-Video_Retrieval_ICCV_2023_paper.pdf",
        "aff": "UATVR: Uncertainty-Adaptive Text-Video Retrieval\nBo Fang1\u2217Wenhao Wu2,3\u2217Chang Liu4\u2217Yu Zhou1\u2020Yuxin Song3\nWeiping Wang1Xiangbo Shu5Xiangyang Ji4Jingdong Wang3\n1Institute of Information Engineering, Chinese Academy of Sciences2The University of Sydney\n3Baidu Inc.4Tsinghua University5Nanjing University of Science and Technology\n{fangbo,zhouyu,wangweiping }@iie.ac.cn, {songyuxin02,wangjingdong }@baidu.com,\n{liuchang2022,xyji }@tsinghua.edu.cn, wenhao.wu@sydney.edu.au, shuxb@njust.edu.cn\nAbstract\nWith the explosive growth of web videos and emerg-\ning large-scale vision-language pre-training models, e.g.,\nCLIP , retrieving videos of interest with text instructions has\nattracted increasing attention. A common practice is to\ntransfer text-video pairs to the same embedding space and\ncraft cross-modal interactions with certain entities in spe-\ncific granularities for semantic correspondence. Unfortu-\nnately, the intrinsic uncertainties of optimal entity combina-\ntions in appropriate granularities for cross-modal queries\nare understudied, which is especially critical for modalities\nwith hierarchical semantics, e.g., video, text, etc. In this\npaper, we propose an Uncertainty-Adaptive Text-Video Re-\ntrieval approach, termed UATVR, which models each look-\nup as a distribution matching procedure. Concretely, we\nadd additional learnable tokens in the encoders to adap-\ntively aggregate multi-grained semantics for flexible high-\nlevel reasoning. In the refined embedding space, we rep-\nresent text-video pairs as probabilistic distributions where\nprototypes are sampled for matching evaluation. Com-\nprehensive experiments on four benchmarks justify the su-\nperiority of our UATVR, which achieves new state-of-the-\nart results on MSR-VTT (50.8%), VATEX (64.5%), MSVD\n(49.7%), and DiDeMo (45.8%). The code is available at\nhttps://github.com/bofang98/UATVR .\n1. Introduction\nWith surging portable filming devices and emerging\nvideo media platforms, searching videos of interest with\nhuman instructions, typically as texts, has been a part of\ndaily lives, which urgently requires effective and robust\n\u2217Co-first authorship. This work was done when Bo Fang was a re-\nsearch intern at Baidu Inc.\n\u2020Corresponding author.\n(a) Uncertainproblem\n132645Textual Queries:\n(Video-Sentence Matching:) various scenes from differentfootball games (Frame-Sentence Matching:)football player scores a touchdown(Frame-Word Matching:)football players celebrateand another player makes an amazing touchdown(b) Ours\n\ud835\udca9!frame embeddingword embeddingRepresentation distribution\n123456\ud835\udca9\"\nFigure 1. Motivation. A video has numerous descriptions con-\ntaining different level information, (a) which shows inconsistent\ntext-video correspondences in the common embedding space. The\nformer three frames depict a \u2018celebrate\u2019 action, while the last three\nframes are about a \u2018touchdown\u2019. This video diversity thus makes\nthe optimal text-video matching in uncertain granularities, which\nwe call an uncertain matching problem. Moreover, previous deter-\nministic works can only handle one-to-one text-video mappings,\nyet a realistic relationship between two modalities is one-to-many.\n(b) The above problems motivate our uncertainty-adaptive model\nthrough distribution matching procedures.\ntext-video retrieval (TVR) techniques. Given a query text\n(video), TVR aims to find the most relevant video (text) in\nthe database, which is typically overwhelmed with sophisti-\ncated vague semantic combinations varying with hierarchi-\ncal text structures or spatiotemporal video spans.\nRecent breakthroughs in the large-scale image and/or\ntext pre-training [48, 22, 61] benefit TVR significantly. A\nserial of seminal works employ a separated encoder archi-\ntecture to respectively project texts and videos into a pre-\ntrained joint embedding space for compact cross-modal in-\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n13723\n",
        "project": "",
        "github": "",
        "arxiv": "2301.06309"
    },
    {
        "title": "UCF: Uncovering Common Features for Generalizable Deepfake Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_UCF_Uncovering_Common_Features_for_Generalizable_Deepfake_Detection_ICCV_2023_paper.html",
        "author": "Zhiyuan Yan, Yong Zhang, Yanbo Fan, Baoyuan Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UCF_Uncovering_Common_Features_for_Generalizable_Deepfake_Detection_ICCV_2023_paper.pdf",
        "aff": "The School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; Tencent AI Lab",
        "project": "",
        "github": "",
        "arxiv": "2304.13949"
    },
    {
        "title": "UGC: Unified GAN Compression for Efficient Image-to-Image Translation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ren_UGC_Unified_GAN_Compression_for_Efficient_Image-to-Image_Translation_ICCV_2023_paper.html",
        "author": "Yuxi Ren, Jie Wu, Peng Zhang, Manlin Zhang, Xuefeng Xiao, Qian He, Rui Wang, Min Zheng, Xin Pan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_UGC_Unified_GAN_Compression_for_Efficient_Image-to-Image_Translation_ICCV_2023_paper.pdf",
        "aff": "ByteDance Inc",
        "project": "",
        "github": "https://github.com/bytedance/UGC",
        "arxiv": "2309.09310"
    },
    {
        "title": "UHDNeRF: Ultra-High-Definition Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_UHDNeRF_Ultra-High-Definition_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Quewei Li, Feichao Li, Jie Guo, Yanwen Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UHDNeRF_Ultra-High-Definition_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "National Key Lab for Novel Software Technology, Nanjing University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "UMC: A Unified Bandwidth-efficient and Multi-resolution based Collaborative Perception Framework",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_UMC_A_Unified_Bandwidth-efficient_and_Multi-resolution_based_Collaborative_Perception_Framework_ICCV_2023_paper.html",
        "author": "Tianhang Wang, Guang Chen, Kai Chen, Zhengfa Liu, Bo Zhang, Alois Knoll, Changjun Jiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UMC_A_Unified_Bandwidth-efficient_and_Multi-resolution_based_Collaborative_Perception_Framework_ICCV_2023_paper.pdf",
        "aff": "Technische Universit\u00a8at M\u00a8unchen; Shanghai Westwell Technology Co., Ltd; Tongji University",
        "project": "",
        "github": "https://github.com/ispc-lab/UMC",
        "arxiv": "2303.12400"
    },
    {
        "title": "UMFuse: Unified Multi View Fusion for Human Editing Applications",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jain_UMFuse_Unified_Multi_View_Fusion_for_Human_Editing_Applications_ICCV_2023_paper.html",
        "author": "Rishabh Jain, Mayur Hemani, Duygu Ceylan, Krishna Kumar Singh, Jingwan Lu, Mausoom Sarkar, Balaji Krishnamurthy",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_UMFuse_Unified_Multi_View_Fusion_for_Human_Editing_Applications_ICCV_2023_paper.pdf",
        "aff": "MDSR Adobe; Adobe Research",
        "project": "Project Webpage (URL not provided in text)",
        "github": "",
        "arxiv": "2211.10157"
    },
    {
        "title": "UMIFormer: Mining the Correlations between Similar Tokens for Multi-View 3D Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_UMIFormer_Mining_the_Correlations_between_Similar_Tokens_for_Multi-View_3D_ICCV_2023_paper.html",
        "author": "Zhenwei Zhu, Liying Yang, Ning Li, Chaohao Jiang, Yanyan Liang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_UMIFormer_Mining_the_Correlations_between_Similar_Tokens_for_Multi-View_3D_ICCV_2023_paper.pdf",
        "aff": "Macau University of Science and Technology",
        "project": "",
        "github": "https://github.com/GaryZhu1996/UMIFormer",
        "arxiv": "2302.13987"
    },
    {
        "title": "USAGE: A Unified Seed Area Generation Paradigm for Weakly Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Peng_USAGE_A_Unified_Seed_Area_Generation_Paradigm_for_Weakly_Supervised_ICCV_2023_paper.html",
        "author": "Zelin Peng, Guanchun Wang, Lingxi Xie, Dongsheng Jiang, Wei Shen, Qi Tian",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_USAGE_A_Unified_Seed_Area_Generation_Paradigm_for_Weakly_Supervised_ICCV_2023_paper.pdf",
        "aff": "School of Artificial Intelligence, Xidian University; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Huawei Inc.",
        "project": "",
        "github": "",
        "arxiv": "2303.07806"
    },
    {
        "title": "UnLoc: A Unified Framework for Video Localization Tasks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_UnLoc_A_Unified_Framework_for_Video_Localization_Tasks_ICCV_2023_paper.html",
        "author": "Shen Yan, Xuehan Xiong, Arsha Nagrani, Anurag Arnab, Zhonghao Wang, Weina Ge, David Ross, Cordelia Schmid",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UnLoc_A_Unified_Framework_for_Video_Localization_Tasks_ICCV_2023_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign; Google Research",
        "project": "",
        "github": "https://github.com/google-research/scenic",
        "arxiv": "2308.11062"
    },
    {
        "title": "Unaligned 2D to 3D Translation with Conditional Vector-Quantized Code Diffusion using Transformers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Corona-Figueroa_Unaligned_2D_to_3D_Translation_with_Conditional_Vector-Quantized_Code_Diffusion_ICCV_2023_paper.html",
        "author": "Abril Corona-Figueroa, Sam Bond-Taylor, Neelanjan Bhowmik, Yona Falinie A. Gaus, Toby P. Breckon, Hubert P. H. Shum, Chris G. Willcocks",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Corona-Figueroa_Unaligned_2D_to_3D_Translation_with_Conditional_Vector-Quantized_Code_Diffusion_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Durham University, Durham, UK; Department of Computer Science | Engineering, Durham University, Durham, UK",
        "project": "https://abrilcf.github.io/publications/CodeDiff3D",
        "github": "",
        "arxiv": "2308.14152"
    },
    {
        "title": "Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jing_Uncertainty_Guided_Adaptive_Warping_for_Robust_and_Efficient_Stereo_Matching_ICCV_2023_paper.html",
        "author": "Junpeng Jing, Jiankun Li, Pengfei Xiong, Jiangyu Liu, Shuaicheng Liu, Yichen Guo, Xin Deng, Mai Xu, Lai Jiang, Leonid Sigal",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Uncertainty_Guided_Adaptive_Warping_for_Robust_and_Efficient_Stereo_Matching_ICCV_2023_paper.pdf",
        "aff": "Megvii Research; University of British Columbia; Beihang University; Shopee",
        "project": "",
        "github": "",
        "arxiv": "2307.14071"
    },
    {
        "title": "Uncertainty-aware State Space Transformer for Egocentric 3D Hand Trajectory Forecasting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.html",
        "author": "Wentao Bao, Lele Chen, Libing Zeng, Zhong Li, Yi Xu, Junsong Yuan, Yu Kong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.pdf",
        "aff": "Texas A&M University; OPPO US Research Center; University at Buffalo; Michigan State University",
        "project": "https://actionlab-cv.github.io/EgoHandTrajPred",
        "github": "https://github.com/actionlab-cv/EgoHandTrajPred",
        "arxiv": "2307.08243"
    },
    {
        "title": "Uncertainty-aware Unsupervised Multi-Object Tracking",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Uncertainty-aware_Unsupervised_Multi-Object_Tracking_ICCV_2023_paper.html",
        "author": "Kai Liu, Sheng Jin, Zhihang Fu, Ze Chen, Rongxin Jiang, Jieping Ye",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Uncertainty-aware_Unsupervised_Multi-Object_Tracking_ICCV_2023_paper.pdf",
        "aff": "Alibaba DAMO Academy; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2307.15409"
    },
    {
        "title": "Uncertainty-guided Learning for Improving Image Manipulation Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.html",
        "author": "Kaixiang Ji, Feng Chen, Xin Guo, Yadong Xu, Jian Wang, Jingdong Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University; Ant Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Under-Display Camera Image Restoration with Scattering Effect",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_Under-Display_Camera_Image_Restoration_with_Scattering_Effect_ICCV_2023_paper.html",
        "author": "Binbin Song, Xiangyu Chen, Shuning Xu, Jiantao Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Under-Display_Camera_Image_Restoration_with_Scattering_Effect_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Internet of Things for Smart City, Department of Computer and Information Science, University of Macau; State Key Laboratory of Internet of Things for Smart City, Department of Computer and Information Science, University of Macau; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/NamecantbeNULL/SRUDC",
        "arxiv": "2308.04163"
    },
    {
        "title": "Understanding 3D Object Interaction from a Single Image",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.html",
        "author": "Shengyi Qian, David F. Fouhey",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.pdf",
        "aff": "University of Michigan; New York University",
        "project": "https://jasonqsy.github.io/3DOI/",
        "github": "",
        "arxiv": "2305.09664"
    },
    {
        "title": "Understanding Hessian Alignment for Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hemati_Understanding_Hessian_Alignment_for_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Sobhan Hemati, Guojun Zhang, Amir Estiri, Xi Chen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hemati_Understanding_Hessian_Alignment_for_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2308.11778"
    },
    {
        "title": "Understanding Self-attention Mechanism via Dynamical System Perspective",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Understanding_Self-attention_Mechanism_via_Dynamical_System_Perspective_ICCV_2023_paper.html",
        "author": "Zhongzhan Huang, Mingfu Liang, Jinghui Qin, Shanshan Zhong, Liang Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Understanding_Self-attention_Mechanism_via_Dynamical_System_Perspective_ICCV_2023_paper.pdf",
        "aff": "Northwestern University, USA; Sun Yat-sen University; Guangdong University of Technology",
        "project": "",
        "github": "",
        "arxiv": "2308.09939"
    },
    {
        "title": "Understanding the Feature Norm for Out-of-Distribution Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Park_Understanding_the_Feature_Norm_for_Out-of-Distribution_Detection_ICCV_2023_paper.html",
        "author": "Jaewoo Park, Jacky Chen Long Chai, Jaeho Yoon, Andrew Beng Jin Teoh",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Understanding_the_Feature_Norm_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf",
        "aff": "Yonsei University; Yonsei University, AiV Co.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Unfolding Framework with Prior of Convolution-Transformer Mixture and Uncertainty Estimation for Video Snapshot Compressive Imaging",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Unfolding_Framework_with_Prior_of_Convolution-Transformer_Mixture_and_Uncertainty_Estimation_ICCV_2023_paper.html",
        "author": "Siming Zheng, Xin Yuan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Unfolding_Framework_with_Prior_of_Convolution-Transformer_Mixture_and_Uncertainty_Estimation_ICCV_2023_paper.pdf",
        "aff": "Computer Network Information Center, Chinese Academy of Science, Beijing, 100190, China; University of Chinese Academy of Sciences, Beijing, 100049, China; School of Engineering, Westlake University, Hangzhou, 310024, China",
        "project": "",
        "github": "https://github.com/zsm1211/CTM-SCI",
        "arxiv": "2306.11316"
    },
    {
        "title": "Uni-3D: A Universal Model for Panoptic 3D Scene Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Uni-3D_A_Universal_Model_for_Panoptic_3D_Scene_Reconstruction_ICCV_2023_paper.html",
        "author": "Xiang Zhang, Zeyuan Chen, Fangyin Wei, Zhuowen Tu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Uni-3D_A_Universal_Model_for_Panoptic_3D_Scene_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "UC San Diego; Princeton University",
        "project": "",
        "github": "https://github.com/mlpc-ucsd/Uni-3D",
        "arxiv": ""
    },
    {
        "title": "UniDexGrasp++: Improving Dexterous Grasping Policy Learning via Geometry-Aware Curriculum and Iterative Generalist-Specialist Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wan_UniDexGrasp_Improving_Dexterous_Grasping_Policy_Learning_via_Geometry-Aware_Curriculum_and_ICCV_2023_paper.html",
        "author": "Weikang Wan, Haoran Geng, Yun Liu, Zikang Shan, Yaodong Yang, Li Yi, He Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_UniDexGrasp_Improving_Dexterous_Grasping_Policy_Learning_via_Geometry-Aware_Curriculum_and_ICCV_2023_paper.pdf",
        "aff": "Peking University; Tsinghua University; Peking University, Beijing Institute for General Artificial Intelligence",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "UniFace: Unified Cross-Entropy Loss for Deep Face Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_UniFace_Unified_Cross-Entropy_Loss_for_Deep_Face_Recognition_ICCV_2023_paper.html",
        "author": "Jiancan Zhou, Xi Jia, Qiufu Li, Linlin Shen, Jinming Duan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_UniFace_Unified_Cross-Entropy_Loss_for_Deep_Face_Recognition_ICCV_2023_paper.pdf",
        "aff": "Computer Vision Institute, Shenzhen University; National Engineering Laboratory for Big Data System Computing Technology, Shenzhen University; School of Computer Science, University of Birmingham, UK",
        "project": "",
        "github": "Code is publicly available, but the link is not provided in the text",
        "arxiv": ""
    },
    {
        "title": "UniFormerV2: Unlocking the Potential of Image ViTs for Video Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.html",
        "author": "Kunchang Li, Yali Wang, Yinan He, Yizhuo Li, Yi Wang, Limin Wang, Yu Qiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.pdf",
        "aff": "Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences; Shanghai AI Laboratory; Shanghai AI Laboratory; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Shanghai AI Laboratory; State Key Laboratory for Novel Software Technology, Nanjing University; Shanghai AI Laboratory; The University of Hong Kong; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/OpenGVLab/UniFormerV2",
        "arxiv": ""
    },
    {
        "title": "UniFusion: Unified Multi-View Fusion Transformer for Spatial-Temporal Representation in Bird's-Eye-View",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qin_UniFusion_Unified_Multi-View_Fusion_Transformer_for_Spatial-Temporal_Representation_in_Birds-Eye-View_ICCV_2023_paper.html",
        "author": "Zequn Qin, Jingyu Chen, Chao Chen, Xiaozhi Chen, Xi Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_UniFusion_Unified_Multi-View_Fusion_Transformer_for_Spatial-Temporal_Representation_in_Birds-Eye-View_ICCV_2023_paper.pdf",
        "aff": "College of Computer Science & Technology, Zhejiang University; College of Computer Science & Technology, Zhejiang University; Shanghai Institute for Advanced Study of Zhejiang University; Zhejiang-Singapore Innovation and AI Joint Research Lab, Hangzhou; DJI",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "UniKD: Universal Knowledge Distillation for Mimicking Homogeneous or Heterogeneous Object Detectors",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lao_UniKD_Universal_Knowledge_Distillation_for_Mimicking_Homogeneous_or_Heterogeneous_Object_ICCV_2023_paper.html",
        "author": "Shanshan Lao, Guanglu Song, Boxiao Liu, Yu Liu, Yujiu Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_UniKD_Universal_Knowledge_Distillation_for_Mimicking_Homogeneous_or_Heterogeneous_Object_ICCV_2023_paper.pdf",
        "aff": "Sensetime Research; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "UniSeg: A Unified Multi-Modal LiDAR Segmentation Network and the OpenPCSeg Codebase",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_UniSeg_A_Unified_Multi-Modal_LiDAR_Segmentation_Network_and_the_OpenPCSeg_ICCV_2023_paper.html",
        "author": "Youquan Liu, Runnan Chen, Xin Li, Lingdong Kong, Yuchen Yang, Zhaoyang Xia, Yeqi Bai, Xinge Zhu, Yuexin Ma, Yikang Li, Yu Qiao, Yuenan Hou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_UniSeg_A_Unified_Multi-Modal_LiDAR_Segmentation_Network_and_the_OpenPCSeg_ICCV_2023_paper.pdf",
        "aff": "The University of Hong Kong; National University of Singapore; The Chinese University of Hong Kong; Fudan University; East China Normal University; Shanghai AI Laboratory, Hochschule Bremerhaven; Shanghai Tech University; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/PJLab-ADG/PCSeg",
        "arxiv": "2309.05573"
    },
    {
        "title": "UniT3D: A Unified Transformer for 3D Dense Captioning and Visual Grounding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_UniT3D_A_Unified_Transformer_for_3D_Dense_Captioning_and_Visual_ICCV_2023_paper.html",
        "author": "Zhenyu Chen, Ronghang Hu, Xinlei Chen, Matthias Nie\u00dfner, Angel X. Chang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_UniT3D_A_Unified_Transformer_for_3D_Dense_Captioning_and_Visual_ICCV_2023_paper.pdf",
        "aff": "Simon Fraser University; Technical University of Munich; Meta AI",
        "project": "",
        "github": "",
        "arxiv": "2212.00836"
    },
    {
        "title": "UniTR: A Unified and Efficient Multi-Modal Transformer for Bird's-Eye-View Representation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_UniTR_A_Unified_and_Efficient_Multi-Modal_Transformer_for_Birds-Eye-View_Representation_ICCV_2023_paper.html",
        "author": "Haiyang Wang, Hao Tang, Shaoshuai Shi, Aoxue Li, Zhenguo Li, Bernt Schiele, Liwei Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UniTR_A_Unified_and_Efficient_Multi-Modal_Transformer_for_Birds-Eye-View_Representation_ICCV_2023_paper.pdf",
        "aff": "Peking University; Max Planck Institute for Informatics; Huawei, China",
        "project": "",
        "github": "https://github.com/Haiyang-W/UniTR",
        "arxiv": ""
    },
    {
        "title": "UniVTG: Towards Unified Video-Language Temporal Grounding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_UniVTG_Towards_Unified_Video-Language_Temporal_Grounding_ICCV_2023_paper.html",
        "author": "Kevin Qinghong Lin, Pengchuan Zhang, Joya Chen, Shraman Pramanick, Difei Gao, Alex Jinpeng Wang, Rui Yan, Mike Zheng Shou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_UniVTG_Towards_Unified_Video-Language_Temporal_Grounding_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; Meta AI; Show Lab, National University of Singapore",
        "project": "",
        "github": "https://github.com/showlab/UniVTG",
        "arxiv": "2307.16715"
    },
    {
        "title": "Unified Adversarial Patch for Cross-Modal Attacks in the Physical World",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Unified_Adversarial_Patch_for_Cross-Modal_Attacks_in_the_Physical_World_ICCV_2023_paper.html",
        "author": "Xingxing Wei, Yao Huang, Yitong Sun, Jie Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Unified_Adversarial_Patch_for_Cross-Modal_Attacks_in_the_Physical_World_ICCV_2023_paper.pdf",
        "aff": "Institute of Artificial Intelligence, Beihang University, Beijing 100191, China; School of Computer Science and Engineering, Beihang University, Beijing 100191, China; Institute of Artificial Intelligence, Beihang University, Beijing 100191, China; Hangzhou Innovation Institute, Beihang University, Hangzhou 311228, China",
        "project": "",
        "github": "",
        "arxiv": "2307.07859"
    },
    {
        "title": "Unified Coarse-to-Fine Alignment for Video-Text Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Unified_Coarse-to-Fine_Alignment_for_Video-Text_Retrieval_ICCV_2023_paper.html",
        "author": "Ziyang Wang, Yi-Lin Sung, Feng Cheng, Gedas Bertasius, Mohit Bansal",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unified_Coarse-to-Fine_Alignment_for_Video-Text_Retrieval_ICCV_2023_paper.pdf",
        "aff": "UNC Chapel Hill",
        "project": "",
        "github": "https://github.com/Ziyang412/UCoFiA",
        "arxiv": "2309.10091"
    },
    {
        "title": "Unified Data-Free Compression: Pruning and Quantization without Fine-Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bai_Unified_Data-Free_Compression_Pruning_and_Quantization_without_Fine-Tuning_ICCV_2023_paper.html",
        "author": "Shipeng Bai, Jun Chen, Xintian Shen, Yixuan Qian, Yong Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Unified_Data-Free_Compression_Pruning_and_Quantization_without_Fine-Tuning_ICCV_2023_paper.pdf",
        "aff": "College of Control Science and Engineering, Zhejiang University",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2308.07209"
    },
    {
        "title": "Unified Out-Of-Distribution Detection: A Model-Specific Perspective",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Averly_Unified_Out-Of-Distribution_Detection_A_Model-Specific_Perspective_ICCV_2023_paper.html",
        "author": "Reza Averly, Wei-Lun Chao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Averly_Unified_Out-Of-Distribution_Detection_A_Model-Specific_Perspective_ICCV_2023_paper.pdf",
        "aff": "The Ohio State University",
        "project": "",
        "github": "",
        "arxiv": "2304.06813"
    },
    {
        "title": "Unified Pre-Training with Pseudo Texts for Text-To-Image Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Unified_Pre-Training_with_Pseudo_Texts_for_Text-To-Image_Person_Re-Identification_ICCV_2023_paper.html",
        "author": "Zhiyin Shao, Xinyu Zhang, Changxing Ding, Jian Wang, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Unified_Pre-Training_with_Pseudo_Texts_for_Text-To-Image_Person_Re-Identification_ICCV_2023_paper.pdf",
        "aff": "Baidu VIS, China; South China University of Technology, China",
        "project": "",
        "github": "https://github.com/ZhiyinShao-H/UniPT",
        "arxiv": "2309.01420"
    },
    {
        "title": "Unified Visual Relationship Detection with Vision and Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Unified_Visual_Relationship_Detection_with_Vision_and_Language_Models_ICCV_2023_paper.html",
        "author": "Long Zhao, Liangzhe Yuan, Boqing Gong, Yin Cui, Florian Schroff, Ming-Hsuan Yang, Hartwig Adam, Ting Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unified_Visual_Relationship_Detection_with_Vision_and_Language_Models_ICCV_2023_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "https://github.com/google-research/scenic/tree/main/scenic/projects/univrd",
        "arxiv": "2303.08998"
    },
    {
        "title": "Unify, Align and Refine: Multi-Level Semantic Alignment for Radiology Report Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Unify_Align_and_Refine_Multi-Level_Semantic_Alignment_for_Radiology_Report_ICCV_2023_paper.html",
        "author": "Yaowei Li, Bang Yang, Xuxin Cheng, Zhihong Zhu, Hongxiang Li, Yuexian Zou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unify_Align_and_Refine_Multi-Level_Semantic_Alignment_for_Radiology_Report_ICCV_2023_paper.pdf",
        "aff": "School of Electronic and Computer Engineering, Peking University; School of Electronic and Computer Engineering, Peking University; Peng Cheng Laboratory",
        "project": "",
        "github": "",
        "arxiv": "2303.15932"
    },
    {
        "title": "Unilaterally Aggregated Contrastive Learning with Hierarchical Augmentation for Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Unilaterally_Aggregated_Contrastive_Learning_with_Hierarchical_Augmentation_for_Anomaly_Detection_ICCV_2023_paper.html",
        "author": "Guodong Wang, Yunhong Wang, Jie Qin, Dongming Zhang, Xiuguo Bao, Di Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unilaterally_Aggregated_Contrastive_Learning_with_Hierarchical_Augmentation_for_Anomaly_Detection_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; Natl. Comp. Net. Emer. Resp. Tech. Team/Coord. Ctr. of China, Beijing, China; College of Computer Science and Technology, NUAA, Nanjing, China",
        "project": "",
        "github": "",
        "arxiv": "2308.10155"
    },
    {
        "title": "UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.html",
        "author": "Jianglin Fu, Shikai Li, Yuming Jiang, Kwan-Yee Lin, Wayne Wu, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.pdf",
        "aff": "Shanghai AI Laboratory, CUHK; S-Lab, Nanyang Technological University; Shanghai AI Laboratory",
        "project": "https://unitedhuman.github.io/",
        "github": "",
        "arxiv": "2309.14335"
    },
    {
        "title": "UniverSeg: Universal Medical Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.html",
        "author": "Victor Ion Butoi, Jose Javier Gonzalez Ortiz, Tianyu Ma, Mert R. Sabuncu, John Guttag, Adrian V. Dalca",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Cornell University; MIT CSAIL & MGH, HMS; MIT CSAIL",
        "project": "",
        "github": "https://universeg.csail.mit.edu",
        "arxiv": "2304.06131"
    },
    {
        "title": "Universal Domain Adaptation via Compressive Attention Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Universal_Domain_Adaptation_via_Compressive_Attention_Matching_ICCV_2023_paper.html",
        "author": "Didi Zhu, Yinchuan Li, Junkun Yuan, Zexi Li, Kun Kuang, Chao Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Universal_Domain_Adaptation_via_Compressive_Attention_Matching_ICCV_2023_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2304.11862"
    },
    {
        "title": "Unleashing Text-to-Image Diffusion Models for Visual Perception",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Unleashing_Text-to-Image_Diffusion_Models_for_Visual_Perception_ICCV_2023_paper.html",
        "author": "Wenliang Zhao, Yongming Rao, Zuyan Liu, Benlin Liu, Jie Zhou, Jiwen Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unleashing_Text-to-Image_Diffusion_Models_for_Visual_Perception_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University, BNRist; University of Washington",
        "project": "",
        "github": "https://github.com/wl-zhao/VPD",
        "arxiv": "2303.02153"
    },
    {
        "title": "Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.html",
        "author": "Yuxin Fang, Shusheng Yang, Shijie Wang, Yixiao Ge, Ying Shan, Xinggang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.pdf",
        "aff": "School of EIC, Huazhong University of Science & Technology; Tencent AI Lab",
        "project": "",
        "github": "https://github.com/hustvl/MIMDet",
        "arxiv": "2204.02964"
    },
    {
        "title": "Unleashing the Potential of Spiking Neural Networks with Dynamic Confidence",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Unleashing_the_Potential_of_Spiking_Neural_Networks_with_Dynamic_Confidence_ICCV_2023_paper.html",
        "author": "Chen Li, Edward G Jones, Steve Furber",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unleashing_the_Potential_of_Spiking_Neural_Networks_with_Dynamic_Confidence_ICCV_2023_paper.pdf",
        "aff": "The University of Manchester, Manchester, United Kingdom",
        "project": "",
        "github": "https://github.com/chenlicodebank/Dynamic-Confidence-in-Spiking-Neural-Networks",
        "arxiv": ""
    },
    {
        "title": "Unleashing the Power of Gradient Signal-to-Noise Ratio for Zero-Shot NAS",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Unleashing_the_Power_of_Gradient_Signal-to-Noise_Ratio_for_Zero-Shot_NAS_ICCV_2023_paper.html",
        "author": "Zihao Sun, Yu Sun, Longxing Yang, Shun Lu, Jilin Mei, Wenxiao Zhao, Yu Hu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Unleashing_the_Power_of_Gradient_Signal-to-Noise_Ratio_for_Zero-Shot_NAS_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Systems and Control, Academy of Mathematics and Systems Science, Chinese Academy of Sciences; Research Center for Intelligent Computing Systems, Institute of Computing Technology, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/Sunzh1996/Xi-GSNR",
        "arxiv": ""
    },
    {
        "title": "Unmasked Teacher: Towards Training-Efficient Video Foundation Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Unmasked_Teacher_Towards_Training-Efficient_Video_Foundation_Models_ICCV_2023_paper.html",
        "author": "Kunchang Li, Yali Wang, Yizhuo Li, Yi Wang, Yinan He, Limin Wang, Yu Qiao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unmasked_Teacher_Towards_Training-Efficient_Video_Foundation_Models_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences; Shanghai AI Laboratory; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Shanghai AI Laboratory; Shanghai AI Laboratory; The University of Hong Kong; Shanghai AI Laboratory",
        "project": "",
        "github": "https://github.com/OpenGVLab/unmasked_teacher",
        "arxiv": "2303.16058"
    },
    {
        "title": "Unmasking Anomalies in Road-Scene Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.html",
        "author": "Shyam Nandan Rai, Fabio Cermelli, Dario Fontanel, Carlo Masone, Barbara Caputo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.pdf",
        "aff": "Politecnico di Torino; Politecnico di Torino, Italian Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": "2307.13316"
    },
    {
        "title": "Unpaired Multi-domain Attribute Translation of 3D Facial Shapes with a Square and Symmetric Geometric Map",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Unpaired_Multi-domain_Attribute_Translation_of_3D_Facial_Shapes_with_a_ICCV_2023_paper.html",
        "author": "Zhenfeng Fan, Zhiheng Zhang, Shuang Yang, Chongyang Zhong, Min Cao, Shihong Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Unpaired_Multi-domain_Attribute_Translation_of_3D_Facial_Shapes_with_a_ICCV_2023_paper.pdf",
        "aff": "Soochow University; Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/NaughtyZZ/3D facial shape attribute translation ssgmap",
        "arxiv": "2308.13245"
    },
    {
        "title": "Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Najibi_Unsupervised_3D_Perception_with_2D_Vision-Language_Distillation_for_Autonomous_Driving_ICCV_2023_paper.html",
        "author": "Mahyar Najibi, Jingwei Ji, Yin Zhou, Charles R. Qi, Xinchen Yan, Scott Ettinger, Dragomir Anguelov",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Najibi_Unsupervised_3D_Perception_with_2D_Vision-Language_Distillation_for_Autonomous_Driving_ICCV_2023_paper.pdf",
        "aff": "Waymo LLC",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Unsupervised Accuracy Estimation of Deep Visual Models using Domain-Adaptive Adversarial Perturbation without Source Samples",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Unsupervised_Accuracy_Estimation_of_Deep_Visual_Models_using_Domain-Adaptive_Adversarial_ICCV_2023_paper.html",
        "author": "JoonHo Lee, Jae Oh Woo, Hankyu Moon, Kwonho Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Unsupervised_Accuracy_Estimation_of_Deep_Visual_Models_using_Domain-Adaptive_Adversarial_ICCV_2023_paper.pdf",
        "aff": "Samsung SDS; Samsung SDS America",
        "project": "",
        "github": "",
        "arxiv": "2307.10062"
    },
    {
        "title": "Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.html",
        "author": "Nan Liu, Yilun Du, Shuang Li, Joshua B. Tenenbaum, Antonio Torralba",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.pdf",
        "aff": "UIUC; MIT",
        "project": "https://energy-based-model.github.io/unsupervised-concept-discovery/",
        "github": "",
        "arxiv": "2306.05357"
    },
    {
        "title": "Unsupervised Domain Adaptation for Training Event-Based Networks Using Contrastive Learning and Uncorrelated Conditioning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jian_Unsupervised_Domain_Adaptation_for_Training_Event-Based_Networks_Using_Contrastive_Learning_ICCV_2023_paper.html",
        "author": "Dayuan Jian, Mohammad Rostami",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_Unsupervised_Domain_Adaptation_for_Training_Event-Based_Networks_Using_Contrastive_Learning_ICCV_2023_paper.pdf",
        "aff": "University of Southern California",
        "project": "",
        "github": "",
        "arxiv": "2303.12424"
    },
    {
        "title": "Unsupervised Domain Adaptive Detection with Network Stability Analysis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Unsupervised_Domain_Adaptive_Detection_with_Network_Stability_Analysis_ICCV_2023_paper.html",
        "author": "Wenzhang Zhou, Heng Fan, Tiejian Luo, Libo Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Unsupervised_Domain_Adaptive_Detection_with_Network_Stability_Analysis_ICCV_2023_paper.pdf",
        "aff": "Institute of Software, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Department of Computer Science and Engineering, University of North Texas, Denton, USA",
        "project": "",
        "github": "https://github.com/tiankongzhang/NSA",
        "arxiv": "2308.08182"
    },
    {
        "title": "Unsupervised Facial Performance Editing via Vector-Quantized StyleGAN Representations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Kicanaoglu_Unsupervised_Facial_Performance_Editing_via_Vector-Quantized_StyleGAN_Representations_ICCV_2023_paper.html",
        "author": "Berkay Kicanaoglu, Pablo Garrido, Gaurav Bharaj",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kicanaoglu_Unsupervised_Facial_Performance_Editing_via_Vector-Quantized_StyleGAN_Representations_ICCV_2023_paper.pdf",
        "aff": "Flawless AI",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Unsupervised Feature Representation Learning for Domain-generalized Cross-domain Image Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Unsupervised_Feature_Representation_Learning_for_Domain-generalized_Cross-domain_Image_Retrieval_ICCV_2023_paper.html",
        "author": "Conghui Hu, Can Zhang, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Unsupervised_Feature_Representation_Learning_for_Domain-generalized_Cross-domain_Image_Retrieval_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, National University of Singapore",
        "project": "",
        "github": "https://github.com/conghui1002/DG-UCDIR",
        "arxiv": ""
    },
    {
        "title": "Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Unsupervised_Image_Denoising_in_Real-World_Scenarios_via_Self-Collaboration_Parallel_Generative_ICCV_2023_paper.html",
        "author": "Xin Lin, Chao Ren, Xiao Liu, Jie Huang, Yinjie Lei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Unsupervised_Image_Denoising_in_Real-World_Scenarios_via_Self-Collaboration_Parallel_Generative_ICCV_2023_paper.pdf",
        "aff": "Sichuan University",
        "project": "",
        "github": "https://github.com/linxin0/SCPGabNet",
        "arxiv": "2308.06776"
    },
    {
        "title": "Unsupervised Learning of Object-Centric Embeddings for Cell Instance Segmentation in Microscopy Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wolf_Unsupervised_Learning_of_Object-Centric_Embeddings_for_Cell_Instance_Segmentation_in_ICCV_2023_paper.html",
        "author": "Steffen Wolf, Manan Lalit, Katie McDole, Jan Funke",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wolf_Unsupervised_Learning_of_Object-Centric_Embeddings_for_Cell_Instance_Segmentation_in_ICCV_2023_paper.pdf",
        "aff": "HHMI Janelia Research Campus; MRC Laboratory of Molecular Biology",
        "project": "",
        "github": "github.com/funkelab/cellulus",
        "arxiv": ""
    },
    {
        "title": "Unsupervised Manifold Linearizing and Clustering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Unsupervised_Manifold_Linearizing_and_Clustering_ICCV_2023_paper.html",
        "author": "Tianjiao Ding, Shengbang Tong, Kwan Ho Ryan Chan, Xili Dai, Yi Ma, Benjamin D. Haeffele",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Unsupervised_Manifold_Linearizing_and_Clustering_ICCV_2023_paper.pdf",
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, USA; The Hong Kong University of Science and Technology (Guangzhou), PRC; Mathematical Institute for Data Science, Johns Hopkins University, USA",
        "project": "",
        "github": "https://github.com/tianjiaoding/mlc",
        "arxiv": "2301.01805"
    },
    {
        "title": "Unsupervised Object Localization with Representer Point Selection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Song_Unsupervised_Object_Localization_with_Representer_Point_Selection_ICCV_2023_paper.html",
        "author": "Yeonghwan Song, Seokwoo Jang, Dina Katabi, Jeany Son",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Unsupervised_Object_Localization_with_Representer_Point_Selection_ICCV_2023_paper.pdf",
        "aff": "AI Graduate School, GIST; MIT CSAIL",
        "project": "",
        "github": "https://github.com/yeonghwansong/UOLwRPS",
        "arxiv": "2309.04172"
    },
    {
        "title": "Unsupervised Open-Vocabulary Object Localization in Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Unsupervised_Open-Vocabulary_Object_Localization_in_Videos_ICCV_2023_paper.html",
        "author": "Ke Fan, Zechen Bai, Tianjun Xiao, Dominik Zietlow, Max Horn, Zixu Zhao, Carl-Johann Simon-Gabriel, Mike Zheng Shou, Francesco Locatello, Bernt Schiele, Thomas Brox, Zheng Zhang, Yanwei Fu, Tong He",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Unsupervised_Open-Vocabulary_Object_Localization_in_Videos_ICCV_2023_paper.pdf",
        "aff": "Fudan University; Amazon Web Services; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": "2309.09858"
    },
    {
        "title": "Unsupervised Prompt Tuning for Text-Driven Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/He_Unsupervised_Prompt_Tuning_for_Text-Driven_Object_Detection_ICCV_2023_paper.html",
        "author": "Weizhen He, Weijie Chen, Binbin Chen, Shicai Yang, Di Xie, Luojun Lin, Donglian Qi, Yueting Zhuang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/He_Unsupervised_Prompt_Tuning_for_Text-Driven_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Hikvision Research Institute, Key Laboratory of Peace-building Big Data of Zhejiang Province; Zhejiang University, Hikvision Research Institute, Key Laboratory of Peace-building Big Data of Zhejiang Province; Hikvision Research Institute; Fuzhou University; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Unsupervised Self-Driving Attention Prediction via Uncertainty Mining and Knowledge Embedding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Unsupervised_Self-Driving_Attention_Prediction_via_Uncertainty_Mining_and_Knowledge_Embedding_ICCV_2023_paper.html",
        "author": "Pengfei Zhu, Mengshi Qi, Xia Li, Weijian Li, Huadong Ma",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Unsupervised_Self-Driving_Attention_Prediction_via_Uncertainty_Mining_and_Knowledge_Embedding_ICCV_2023_paper.pdf",
        "aff": "Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, 100876; Key Laboratory of Artificial Intelligence, Ministry of Education, Shanghai, 200240; Department of Computer Science, University of Rochester; Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, 100876",
        "project": "",
        "github": "https://github.com/zaplm/DriverAttention",
        "arxiv": "2303.09706"
    },
    {
        "title": "Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.html",
        "author": "Xinyi Zhang, Naiqi Li, Jiawei Li, Tao Dai, Yong Jiang, Shu-Tao Xia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.pdf",
        "aff": "Research Center of Artificial Intelligence, Peng Cheng Laboratory; Shenzhen University; Tsinghua Shenzhen International Graduate School, Tsinghua University; Huawei Manufacturing",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Unsupervised Video Deraining with An Event Camera",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Unsupervised_Video_Deraining_with_An_Event_Camera_ICCV_2023_paper.html",
        "author": "Jin Wang, Wenming Weng, Yueyi Zhang, Zhiwei Xiong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unsupervised_Video_Deraining_with_An_Event_Camera_ICCV_2023_paper.pdf",
        "aff": "University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/booker-max/Unsupervised-Deraining-with-Event-Camera",
        "arxiv": ""
    },
    {
        "title": "Unsupervised Video Object Segmentation with Online Adversarial Self-Tuning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Su_Unsupervised_Video_Object_Segmentation_with_Online_Adversarial_Self-Tuning_ICCV_2023_paper.html",
        "author": "Tiankang Su, Huihui Song, Dong Liu, Bo Liu, Qingshan Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Unsupervised_Video_Object_Segmentation_with_Online_Adversarial_Self-Tuning_ICCV_2023_paper.pdf",
        "aff": "Unsupervised Video Object Segmentation with Online Adversarial Self-Tuning\nTiankang Su1Huihui Song1*Dong Liu2Bo Liu3Qingshan Liu4\n1B-DAT and CICAEET, Nanjing University of Information Science and Technology, Nanjing, China\n2Netflix Inc, Los Gatos, CA, 95032, USA\n3Walmart Global Tech, Sunnyvale, CA, 94086, USA\n4School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China\nAbstract\nThe existing unsupervised video object segmentation\nmethods depend heavily on the segmentation model trained\noffline on a labeled training video set, and cannot well gen-\neralize to the test videos from a different domain with pos-\nsible distribution shifts. We propose to perform online fine-\ntuning on the pre-trained segmentation model to adapt to\nany ad-hoc videos at the test time. To achieve this, we\ndesign an offline semi-supervised adversarial training pro-\ncess, which leverages the unlabeled video frames to improve\nthe model generalizability while aligning the features of\nthe labeled video frames with the features of the unlabeled\nvideo frames. With the trained segmentation model, we fur-\nther conduct an online self-supervised adversarial finetun-\ning, in which a teacher model and a student model are first\ninitialized with the pre-trained segmentation model weights,\nand the pseudo label produced by the teacher model is used\nto supervise the student model in an adversarial learning\nframework. Through online finetuning, the student model is\nprogressively updated according to the emerging patterns in\neach test video, which significantly reduces the test-time do-\nmain gap. We integrate our offline training and online fine-\ntuning in a unified framework for unsupervised video object\nsegmentation and dub our method Online Adversarial Self-\nTuning (OAST). The experiments show that our method out-\nperforms the state-of-the-arts with significant gains on the\npopular video object segmentation datasets.\n1. Introduction\nVideo Object Segmentation (VOS) aims to track the\nmoving objects in a video sequence with an accurate seg-\nmentation mask. The existing VOS works can be catego-\n*Corresponding author. Email: songhuihui@nuist.edu.cn .\nThis work is supported in part by National Key Research and Develop-\nment Program of China under Grant No. 2018AAA0100400, in part by\nthe NSFC under Grant Nos. 61825601, U21B2044, 62276141, 61872189,\nin part by the Postgraduate Research&Practice Innovation Program of\nJiangsu Province under Grant Nos. KYCX23 1367.\nFigure 1. Examples of \u201c visual discrepancy \u201d (row (a)-(b)) in\nUVOS, where \u201ctrain\u201d and \u201ctest\u201d indicate where the example im-\nage is drawn from. Our OAST method produces more precise seg-\nmentation masks (third column) comparing to the method without\nOAST (second column).\nrized into two paradigms based on whether the prior knowl-\nedge is provided at the test time. One is the Semi-supervised\nVOS (SVOS), where a model is trained on the training set,\nand at the test time is provided with the ground truth mask\non the first frame as prior to segment the objects in the sub-\nsequent frames. The other is called Unsupervised VOS1\n(UVOS), where no ground-truth mask is provided at the test\ntime and there is no prior to leverage to segment the target.\nWe focus on UVOS since it requires no prior input\nand is closer to the real-world applications. The existing\nUVOS works train a model with a labeled video set, and\nthen directly apply it to the unlabeled videos at the test\ntime [51, 7, 40]. Without any prior as input, the inference\nhas to completely depend on the trained model. This has\nproven to be effective when the test data are drawn from\nthe same domain as the training data [68, 65, 46]. How-\never, the inference result can become degraded when the test\ndata originate from a different domain which is a common\ncase under the zero-shot setting. The main scenario that can\ncause severe domain shifts in the test data is called \u201c visual\n1It is also referred to as \u201czero-shot VOS\u201d or \u201cprimary object segmenta-\ntion\u201d in the literature.\nThis ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore.\n688\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "UpCycling: Semi-supervised 3D Object Detection without Sharing Raw-level Unlabeled Scenes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hwang_UpCycling_Semi-supervised_3D_Object_Detection_without_Sharing_Raw-level_Unlabeled_Scenes_ICCV_2023_paper.html",
        "author": "Sunwook Hwang, Youngseok Kim, Seongwon Kim, Saewoong Bahk, Hyung-Sin Kim",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_UpCycling_Semi-supervised_3D_Object_Detection_without_Sharing_Raw-level_Unlabeled_Scenes_ICCV_2023_paper.pdf",
        "aff": "SK Telecom, Seoul, Korea; Graduate School of Data Science, Seoul National University; Department of Electrical and Computer Engineering, Seoul National University",
        "project": "",
        "github": "",
        "arxiv": "2211.11950"
    },
    {
        "title": "Urban Radiance Field Representation with Deformable Neural Mesh Primitives",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Urban_Radiance_Field_Representation_with_Deformable_Neural_Mesh_Primitives_ICCV_2023_paper.html",
        "author": "Fan Lu, Yan Xu, Guang Chen, Hongsheng Li, Kwan-Yee Lin, Changjun Jiang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Urban_Radiance_Field_Representation_with_Deformable_Neural_Mesh_Primitives_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong, Shanghai AI Laboratory; Tongji University; The Chinese University of Hong Kong; The Chinese University of Hong Kong, Shanghai AI Laboratory, CPII",
        "project": "https://dnmp.github.io/",
        "github": "https://dnmp.github.io/",
        "arxiv": "2307.10776"
    },
    {
        "title": "UrbanGIRAFFE: Representing Urban Scenes as Compositional Generative Neural Feature Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_UrbanGIRAFFE_Representing_Urban_Scenes_as_Compositional_Generative_Neural_Feature_Fields_ICCV_2023_paper.html",
        "author": "Yuanbo Yang, Yifei Yang, Hanlei Guo, Rong Xiong, Yue Wang, Yiyi Liao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_UrbanGIRAFFE_Representing_Urban_Scenes_as_Compositional_Generative_Neural_Feature_Fields_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2303.14167"
    },
    {
        "title": "Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Puy_Using_a_Waffle_Iron_for_Automotive_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html",
        "author": "Gilles Puy, Alexandre Boulch, Renaud Marlet",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Puy_Using_a_Waffle_Iron_for_Automotive_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "aff": "valeo.ai, Paris, France; valeo.ai, Paris, France2LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS, Marne-la-Vall\u00e9e, France",
        "project": "",
        "github": "https://github.com/valeoai/WaffleIron",
        "arxiv": "2301.10100"
    },
    {
        "title": "V-FUSE: Volumetric Depth Map Fusion with Long-Range Constraints",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Burgdorfer_V-FUSE_Volumetric_Depth_Map_Fusion_with_Long-Range_Constraints_ICCV_2023_paper.html",
        "author": "Nathaniel Burgdorfer, Philippos Mordohai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Burgdorfer_V-FUSE_Volumetric_Depth_Map_Fusion_with_Long-Range_Constraints_ICCV_2023_paper.pdf",
        "aff": "Stevens Institute of Technology",
        "project": "",
        "github": "https://github.com/nburgdorfer/V-FUSE",
        "arxiv": ""
    },
    {
        "title": "V3Det: Vast Vocabulary Visual Detection Dataset",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_V3Det_Vast_Vocabulary_Visual_Detection_Dataset_ICCV_2023_paper.html",
        "author": "Jiaqi Wang, Pan Zhang, Tao Chu, Yuhang Cao, Yujie Zhou, Tong Wu, Bin Wang, Conghui He, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_V3Det_Vast_Vocabulary_Visual_Detection_Dataset_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; The Chinese University of Hong Kong, Centre of Perceptual and Interactive Intelligence; Shanghai AI Laboratory",
        "project": "https://v3det.openxlab.org.cn/",
        "github": "",
        "arxiv": "2304.03752"
    },
    {
        "title": "VAD: Vectorized Scene Representation for Efficient Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_VAD_Vectorized_Scene_Representation_for_Efficient_Autonomous_Driving_ICCV_2023_paper.html",
        "author": "Bo Jiang, Shaoyu Chen, Qing Xu, Bencheng Liao, Jiajie Chen, Helong Zhou, Qian Zhang, Wenyu Liu, Chang Huang, Xinggang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_VAD_Vectorized_Scene_Representation_for_Efficient_Autonomous_Driving_ICCV_2023_paper.pdf",
        "aff": "Huazhong University of Science & Technology; Horizon Robotics",
        "project": "",
        "github": "https://github.com/hustvl/VAD",
        "arxiv": "2303.12077"
    },
    {
        "title": "VADER: Video Alignment Differencing and Retrieval",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Black_VADER_Video_Alignment_Differencing_and_Retrieval_ICCV_2023_paper.html",
        "author": "Alexander Black, Simon Jenni, Tu Bui, Md. Mehrab Tanjim, Stefano Petrangeli, Ritwik Sinha, Viswanathan Swaminathan, John Collomosse",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Black_VADER_Video_Alignment_Differencing_and_Retrieval_ICCV_2023_paper.pdf",
        "aff": "Adobe Research; CVSSP, University of Surrey and Adobe Research; CVSSP, University of Surrey",
        "project": "",
        "github": "https://github.com/AlexBlck/vader",
        "arxiv": "2303.13193"
    },
    {
        "title": "VAPCNet: Viewpoint-Aware 3D Point Cloud Completion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fu_VAPCNet_Viewpoint-Aware_3D_Point_Cloud_Completion_ICCV_2023_paper.html",
        "author": "Zhiheng Fu, Longguang Wang, Lian Xu, Zhiyong Wang, Hamid Laga, Yulan Guo, Farid Boussaid, Mohammed Bennamoun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_VAPCNet_Viewpoint-Aware_3D_Point_Cloud_Completion_ICCV_2023_paper.pdf",
        "aff": "National University of Defense Technology; Murdoch University; The Shenzhen Campus of Sun Yat-sen University; The University of Western Australia; The University of Sydney",
        "project": "",
        "github": "https://github.com/FZH92128/VAPCNet",
        "arxiv": ""
    },
    {
        "title": "VI-Net: Boosting Category-level 6D Object Pose Estimation via Learning Decoupled Rotations on the Spherical Representations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_VI-Net_Boosting_Category-level_6D_Object_Pose_Estimation_via_Learning_Decoupled_ICCV_2023_paper.html",
        "author": "Jiehong Lin, Zewei Wei, Yabin Zhang, Kui Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_VI-Net_Boosting_Category-level_6D_Object_Pose_Estimation_via_Learning_Decoupled_ICCV_2023_paper.pdf",
        "aff": "South China University of Technology; Hong Kong Polytechnic University",
        "project": "",
        "github": "https://github.com/JiehongLin/VI-Net",
        "arxiv": ""
    },
    {
        "title": "VL-Match: Enhancing Vision-Language Pretraining with Token-Level and Instance-Level Matching",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.html",
        "author": "Junyu Bi, Daixuan Cheng, Ping Yao, Bochen Pang, Yuefeng Zhan, Chuanguang Yang, Yujing Wang, Hao Sun, Weiwei Deng, Qi Zhang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.pdf",
        "aff": "Microsoft Corporation; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hu_VL-PET_Vision-and-Language_Parameter-Efficient_Tuning_via_Granularity_Control_ICCV_2023_paper.html",
        "author": "Zi-Yuan Hu, Yanyang Li, Michael R. Lyu, Liwei Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_VL-PET_Vision-and-Language_Parameter-Efficient_Tuning_via_Granularity_Control_ICCV_2023_paper.pdf",
        "aff": "The Chinese University of Hong Kong; The Chinese University of Hong Kong, Centre for Perceptual and Interactive Intelligence",
        "project": "",
        "github": "https://github.com/HenryHZY/VL-PET",
        "arxiv": ""
    },
    {
        "title": "VLN-PETL: Parameter-Efficient Transfer Learning for Vision-and-Language Navigation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_VLN-PETL_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Navigation_ICCV_2023_paper.html",
        "author": "Yanyuan Qiao, Zheng Yu, Qi Wu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_VLN-PETL_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf",
        "aff": "Australian Institute for Machine Learning, The University of Adelaide",
        "project": "",
        "github": "https://github.com/YanyuanQiao/VLN-PETL",
        "arxiv": ""
    },
    {
        "title": "VLSlice: Interactive Vision-and-Language Slice Discovery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Slyman_VLSlice_Interactive_Vision-and-Language_Slice_Discovery_ICCV_2023_paper.html",
        "author": "Eric Slyman, Minsuk Kahng, Stefan Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Slyman_VLSlice_Interactive_Vision-and-Language_Slice_Discovery_ICCV_2023_paper.pdf",
        "aff": "Google Research, Atlanta, GA, USA; Oregon State University, Corvallis, OR, USA",
        "project": "",
        "github": "https://github.com/slymane/vlslice",
        "arxiv": "2309.06703"
    },
    {
        "title": "VQ3D: Learning a 3D-Aware Generative Model on ImageNet",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sargent_VQ3D_Learning_a_3D-Aware_Generative_Model_on_ImageNet_ICCV_2023_paper.html",
        "author": "Kyle Sargent, Jing Yu Koh, Han Zhang, Huiwen Chang, Charles Herrmann, Pratul Srinivasan, Jiajun Wu, Deqing Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sargent_VQ3D_Learning_a_3D-Aware_Generative_Model_on_ImageNet_ICCV_2023_paper.pdf",
        "aff": "Stanford University; OpenAI; Carnegie Mellon University; Google Research",
        "project": "this url",
        "github": "",
        "arxiv": "2302.06833"
    },
    {
        "title": "VQA Therapy: Exploring Answer Differences by Visually Grounding Answers",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_VQA_Therapy_Exploring_Answer_Differences_by_Visually_Grounding_Answers_ICCV_2023_paper.html",
        "author": "Chongyan Chen, Samreen Anjum, Danna Gurari",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VQA_Therapy_Exploring_Answer_Differences_by_Visually_Grounding_Answers_ICCV_2023_paper.pdf",
        "aff": "University of Texas at Austin, University of Colorado Boulder; University of Colorado Boulder; University of Texas at Austin",
        "project": "https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/",
        "github": "",
        "arxiv": "2308.11662"
    },
    {
        "title": "VQA-GNN: Reasoning with Multimodal Knowledge via Graph Neural Networks for Visual Question Answering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_VQA-GNN_Reasoning_with_Multimodal_Knowledge_via_Graph_Neural_Networks_for_ICCV_2023_paper.html",
        "author": "Yanan Wang, Michihiro Yasunaga, Hongyu Ren, Shinya Wada, Jure Leskovec",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_VQA-GNN_Reasoning_with_Multimodal_Knowledge_via_Graph_Neural_Networks_for_ICCV_2023_paper.pdf",
        "aff": "KDDI Research; Stanford University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Vanishing Point Estimation in Uncalibrated Images with Prior Gravity Direction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pautrat_Vanishing_Point_Estimation_in_Uncalibrated_Images_with_Prior_Gravity_Direction_ICCV_2023_paper.html",
        "author": "R\u00e9mi Pautrat, Shaohui Liu, Petr Hruby, Marc Pollefeys, Daniel Barath",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_Vanishing_Point_Estimation_in_Uncalibrated_Images_with_Prior_Gravity_Direction_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich and Microsoft Mixed Reality and AI Zurich lab; Department of Computer Science, ETH Zurich",
        "project": "",
        "github": "https://github.com/cvg/VP-Estimation-with-Prior-Gravity",
        "arxiv": "2308.10694"
    },
    {
        "title": "Variational Causal Inference Network for Explanatory Visual Question Answering",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xue_Variational_Causal_Inference_Network_for_Explanatory_Visual_Question_Answering_ICCV_2023_paper.html",
        "author": "Dizhan Xue, Shengsheng Qian, Changsheng Xu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xue_Variational_Causal_Inference_Network_for_Explanatory_Visual_Question_Answering_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Peng Cheng Laboratory",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Variational Degeneration to Structural Refinement: A Unified Framework for Superimposed Image Decomposition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Variational_Degeneration_to_Structural_Refinement_A_Unified_Framework_for_Superimposed_ICCV_2023_paper.html",
        "author": "Wenyu Li, Yan Xu, Yang Yang, Haoran Ji, Yue Lang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Variational_Degeneration_to_Structural_Refinement_A_Unified_Framework_for_Superimposed_ICCV_2023_paper.pdf",
        "aff": "Tianjin University, Tianjin, China.; Hebei University of Technology, Tianjin, China.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable Human Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.html",
        "author": "Xinya Chen, Jiaxin Huang, Yanrui Bin, Lu Yu, Yiyi Liao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.pdf",
        "aff": "Huazhong University of Science and Technology; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2309.04800"
    },
    {
        "title": "Verbs in Action: Improving Verb Understanding in Video-Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Momeni_Verbs_in_Action_Improving_Verb_Understanding_in_Video-Language_Models_ICCV_2023_paper.html",
        "author": "Liliane Momeni, Mathilde Caron, Arsha Nagrani, Andrew Zisserman, Cordelia Schmid",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Momeni_Verbs_in_Action_Improving_Verb_Understanding_in_Video-Language_Models_ICCV_2023_paper.pdf",
        "aff": "Visual Geometry Group, University of Oxford, UK; Google Research",
        "project": "",
        "github": "https://github.com/scenic/projects/verbs-in-action",
        "arxiv": "2304.06708"
    },
    {
        "title": "Versatile Diffusion: Text, Images and Variations All in One Diffusion Model",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Versatile_Diffusion_Text_Images_and_Variations_All_in_One_Diffusion_ICCV_2023_paper.html",
        "author": "Xingqian Xu, Zhangyang Wang, Gong Zhang, Kai Wang, Humphrey Shi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Versatile_Diffusion_Text_Images_and_Variations_All_in_One_Diffusion_ICCV_2023_paper.pdf",
        "aff": "SHI Labs @ Georgia Tech & UIUC & Oregon & Picsart AI Research (PAIR); SHI Labs @ Georgia Tech & UIUC & Oregon; UT Austin",
        "project": "",
        "github": "https://github.com/SHI-Labs/Versatile-Diffusion",
        "arxiv": "2211.08332"
    },
    {
        "title": "VertexSerum: Poisoning Graph Neural Networks for Link Inference",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ding_VertexSerum_Poisoning_Graph_Neural_Networks_for_Link_Inference_ICCV_2023_paper.html",
        "author": "Ruyi Ding, Shijin Duan, Xiaolin Xu, Yunsi Fei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_VertexSerum_Poisoning_Graph_Neural_Networks_for_Link_Inference_ICCV_2023_paper.pdf",
        "aff": "Northeastern University, Boston, MA, USA",
        "project": "",
        "github": "https://github.com/RollinDing/VertexSerum",
        "arxiv": "2308.01469"
    },
    {
        "title": "ViLLA: Fine-Grained Vision-Language Representation Learning from Real-World Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Varma_ViLLA_Fine-Grained_Vision-Language_Representation_Learning_from_Real-World_Data_ICCV_2023_paper.html",
        "author": "Maya Varma, Jean-Benoit Delbrouck, Sarah Hooper, Akshay Chaudhari, Curtis Langlotz",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Varma_ViLLA_Fine-Grained_Vision-Language_Representation_Learning_from_Real-World_Data_ICCV_2023_paper.pdf",
        "aff": "Stanford University",
        "project": "",
        "github": "https://github.com/StanfordMIMI/villa",
        "arxiv": "2308.11194"
    },
    {
        "title": "ViLTA: Enhancing Vision-Language Pre-training through Textual Augmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ViLTA_Enhancing_Vision-Language_Pre-training_through_Textual_Augmentation_ICCV_2023_paper.html",
        "author": "Weihan Wang, Zhen Yang, Bin Xu, Juanzi Li, Yankui Sun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ViLTA_Enhancing_Vision-Language_Pre-training_through_Textual_Augmentation_ICCV_2023_paper.pdf",
        "aff": "Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2308.16689"
    },
    {
        "title": "ViM: Vision Middleware for Unified Downstream Transferring",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_paper.html",
        "author": "Yutong Feng, Biao Gong, Jianwen Jiang, Yiliang Lv, Yujun Shen, Deli Zhao, Jingren Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group; Ant Group",
        "project": "",
        "github": "",
        "arxiv": "2303.06911"
    },
    {
        "title": "VidStyleODE: Disentangled Video Editing via StyleGAN and NeuralODEs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ali_VidStyleODE_Disentangled_Video_Editing_via_StyleGAN_and_NeuralODEs_ICCV_2023_paper.html",
        "author": "Moayed Haji Ali, Andrew Bond, Tolga Birdal, Duygu Ceylan, Levent Karacan, Erkut Erdem, Aykut Erdem",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_VidStyleODE_Disentangled_Video_Editing_via_StyleGAN_and_NeuralODEs_ICCV_2023_paper.pdf",
        "aff": "Iskenderun Technical University; Adobe Research; Koc University; Imperial College London; Hacettepe University",
        "project": "https://cyberiada.github.io/VidStyleODE",
        "github": "",
        "arxiv": "2304.06020"
    },
    {
        "title": "Video Action Recognition with Attentive Semantic Units",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Video_Action_Recognition_with_Attentive_Semantic_Units_ICCV_2023_paper.html",
        "author": "Yifei Chen, Dapeng Chen, Ruijin Liu, Hao Li, Wei Peng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Video_Action_Recognition_with_Attentive_Semantic_Units_ICCV_2023_paper.pdf",
        "aff": "IIRC, Huawei; Xiamen University; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": "2303.09756"
    },
    {
        "title": "Video Action Segmentation via Contextually Refined Temporal Keypoints",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Video_Action_Segmentation_via_Contextually_Refined_Temporal_Keypoints_ICCV_2023_paper.html",
        "author": "Borui Jiang, Yang Jin, Zhentao Tan, Yadong Mu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Video_Action_Segmentation_via_Contextually_Refined_Temporal_Keypoints_ICCV_2023_paper.pdf",
        "aff": "Peking University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Video Adverse-Weather-Component Suppression Network via Weather Messenger and Adversarial Backpropagation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Video_Adverse-Weather-Component_Suppression_Network_via_Weather_Messenger_and_Adversarial_Backpropagation_ICCV_2023_paper.html",
        "author": "Yijun Yang, Angelica I. Aviles-Rivero, Huazhu Fu, Ye Liu, Weiming Wang, Lei Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Video_Adverse-Weather-Component_Suppression_Network_via_Weather_Messenger_and_Adversarial_Backpropagation_ICCV_2023_paper.pdf",
        "aff": "Hong Kong Metropolitan University; The Hong Kong University of Science and Technology (Guangzhou); Tianjin University; Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore; University of Cambridge",
        "project": "",
        "github": "",
        "arxiv": "2309.13700"
    },
    {
        "title": "Video Anomaly Detection via Sequentially Learning Multiple Pretext Tasks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.html",
        "author": "Chenrui Shi, Che Sun, Yuwei Wu, Yunde Jia",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.pdf",
        "aff": "Guangdong Laboratory of Machine Perception and Intelligent Computing, Shenzhen MSU-BIT University, China; Beijing Key Laboratory of Intelligent Information Technology, School of Computer Science & Technology, Beijing Institute of Technology, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Video Background Music Generation: Dataset, Method and Evaluation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhuo_Video_Background_Music_Generation_Dataset_Method_and_Evaluation_ICCV_2023_paper.html",
        "author": "Le Zhuo, Zhaokai Wang, Baisen Wang, Yue Liao, Chenxi Bao, Stanley Peng, Songhao Han, Aixi Zhang, Fei Fang, Si Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhuo_Video_Background_Music_Generation_Dataset_Method_and_Evaluation_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group; Beihang University, Edinburgh College of Art, University of Edinburgh; Beihang University",
        "project": "",
        "github": "https://github.com/zhuole1025/SymMV",
        "arxiv": "2211.11248"
    },
    {
        "title": "Video OWL-ViT: Temporally-consistent Open-world Localization in Video",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Heigold_Video_OWL-ViT_Temporally-consistent_Open-world_Localization_in_Video_ICCV_2023_paper.html",
        "author": "Georg Heigold, Matthias Minderer, Alexey Gritsenko, Alex Bewley, Daniel Keysers, Mario Lu\u010di\u0107, Fisher Yu, Thomas Kipf",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Heigold_Video_OWL-ViT_Temporally-consistent_Open-world_Localization_in_Video_ICCV_2023_paper.pdf",
        "aff": "ETH Zurich; Google DeepMind",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Video Object Segmentation-aware Video Frame Interpolation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yoo_Video_Object_Segmentation-aware_Video_Frame_Interpolation_ICCV_2023_paper.html",
        "author": "Jun-Sang Yoo, Hongjae Lee, Seung-Won Jung",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yoo_Video_Object_Segmentation-aware_Video_Frame_Interpolation_ICCV_2023_paper.pdf",
        "aff": "Korea University",
        "project": "",
        "github": "https://github.com/junsang7777/VOS-VFI",
        "arxiv": ""
    },
    {
        "title": "Video State-Changing Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Video_State-Changing_Object_Segmentation_ICCV_2023_paper.html",
        "author": "Jiangwei Yu, Xiang Li, Xinran Zhao, Hongming Zhang, Yu-Xiong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Video_State-Changing_Object_Segmentation_ICCV_2023_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign; Carnegie Mellon University; Tencent AI Lab, Bellevue",
        "project": "",
        "github": "https://github.com/venom12138/VSCOS",
        "arxiv": ""
    },
    {
        "title": "Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Video_Task_Decathlon_Unifying_Image_and_Video_Tasks_in_Autonomous_ICCV_2023_paper.html",
        "author": "Thomas E. Huang, Yifan Liu, Luc Van Gool, Fisher Yu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Video_Task_Decathlon_Unifying_Image_and_Video_Tasks_in_Autonomous_ICCV_2023_paper.pdf",
        "aff": "ETH Z\u00fcrich, KU Leuven; ETH Z\u00fcrich",
        "project": "https://www.vis.xyz/pub/vtd",
        "github": "",
        "arxiv": "2309.04422"
    },
    {
        "title": "Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wasim_Video-FocalNets_Spatio-Temporal_Focal_Modulation_for_Video_Action_Recognition_ICCV_2023_paper.html",
        "author": "Syed Talal Wasim, Muhammad Uzair Khattak, Muzammal Naseer, Salman Khan, Mubarak Shah, Fahad Shahbaz Khan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wasim_Video-FocalNets_Spatio-Temporal_Focal_Modulation_for_Video_Action_Recognition_ICCV_2023_paper.pdf",
        "aff": "Link\u00f6ping University; Mohamed bin Zayed University of AI; Australian National University; University of Central Florida",
        "project": "",
        "github": "https://github.com/TalalWasim/Video-FocalNets",
        "arxiv": ""
    },
    {
        "title": "VideoFlow: Exploiting Temporal Cues for Multi-frame Optical Flow Estimation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_VideoFlow_Exploiting_Temporal_Cues_for_Multi-frame_Optical_Flow_Estimation_ICCV_2023_paper.html",
        "author": "Xiaoyu Shi, Zhaoyang Huang, Weikang Bian, Dasong Li, Manyuan Zhang, Ka Chun Cheung, Simon See, Hongwei Qin, Jifeng Dai, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_VideoFlow_Exploiting_Temporal_Cues_for_Multi-frame_Optical_Flow_Estimation_ICCV_2023_paper.pdf",
        "aff": "Multimedia Laboratory, The Chinese University of Hong Kong; NVIDIA AI Technology Center; Tsinghua University; Multimedia Laboratory, The Chinese University of Hong Kong; Centre for Perceptual and Interactive Intelligence (CPII); Shanghai AI Laboratory; SenseTime Research",
        "project": "",
        "github": "https://github.com/XiaoyuShi97/VideoFlow",
        "arxiv": "2303.08340"
    },
    {
        "title": "View Consistent Purification for Accurate Cross-View Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_View_Consistent_Purification_for_Accurate_Cross-View_Localization_ICCV_2023_paper.html",
        "author": "Shan Wang, Yanhao Zhang, Akhil Perincherry, Ankit Vora, Hongdong Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_View_Consistent_Purification_for_Accurate_Cross-View_Localization_ICCV_2023_paper.pdf",
        "aff": "Ford Motor Company; Australian National University, Data61, CSIRO; Australian National University",
        "project": "https://shanwang-shan.github.io/PureACL-website/",
        "github": "",
        "arxiv": "2308.08110"
    },
    {
        "title": "ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_ViewRefer_Grasp_the_Multi-view_Knowledge_for_3D_Visual_Grounding_ICCV_2023_paper.html",
        "author": "Zoey Guo, Yiwen Tang, Ray Zhang, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_ViewRefer_Grasp_the_Multi-view_Knowledge_for_3D_Visual_Grounding_ICCV_2023_paper.pdf",
        "aff": "Shanghai Artificial Intelligence Laboratory; Shanghai Artificial Intelligence Laboratory, Northwestern Polytechnical University; Shanghai Artificial Intelligence Laboratory, The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2303.16894"
    },
    {
        "title": "Viewing Graph Solvability in Practice",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Arrigoni_Viewing_Graph_Solvability_in_Practice_ICCV_2023_paper.html",
        "author": "Federica Arrigoni, Tomas Pajdla, Andrea Fusiello",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Arrigoni_Viewing_Graph_Solvability_in_Practice_ICCV_2023_paper.pdf",
        "aff": "University of Udine (Italy); Politecnico di Milano (Italy); CIIRC - CTU in Prague (Czechia)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D Data",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.html",
        "author": "Stanislaw Szymanowicz, Christian Rupprecht, Andrea Vedaldi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.pdf",
        "aff": "Visual Geometry Group \u2014 University of Oxford",
        "project": "szymanowiczs.github.io/viewset-diffusion",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ViperGPT: Visual Inference via Python Execution for Reasoning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Suris_ViperGPT_Visual_Inference_via_Python_Execution_for_Reasoning_ICCV_2023_paper.html",
        "author": "D\u00eddac Sur\u00eds, Sachit Menon, Carl Vondrick",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Suris_ViperGPT_Visual_Inference_via_Python_Execution_for_Reasoning_ICCV_2023_paper.pdf",
        "aff": "Columbia University",
        "project": "viper.cs.columbia.edu",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Virtual Try-On with Pose-Garment Keypoints Guided Inpainting",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Virtual_Try-On_with_Pose-Garment_Keypoints_Guided_Inpainting_ICCV_2023_paper.html",
        "author": "Zhi Li, Pengfei Wei, Xiang Yin, Zejun Ma, Alex C. Kot",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Virtual_Try-On_with_Pose-Garment_Keypoints_Guided_Inpainting_ICCV_2023_paper.pdf",
        "aff": "Nanyang Technological University; Bytedance Ltd.",
        "project": "",
        "github": "https://github.com/lizhi-ntu/KGI",
        "arxiv": ""
    },
    {
        "title": "Visible-Infrared Person Re-Identification via Semantic Alignment and Affinity Inference",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Visible-Infrared_Person_Re-Identification_via_Semantic_Alignment_and_Affinity_Inference_ICCV_2023_paper.html",
        "author": "Xingye Fang, Yang Yang, Ying Fu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Visible-Infrared_Person_Re-Identification_via_Semantic_Alignment_and_Affinity_Inference_ICCV_2023_paper.pdf",
        "aff": "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences; Beijing Institute of Technology",
        "project": "",
        "github": "https://github.com/xiaoye-hhh/SAAI",
        "arxiv": ""
    },
    {
        "title": "Vision Grid Transformer for Document Layout Analysis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Da_Vision_Grid_Transformer_for_Document_Layout_Analysis_ICCV_2023_paper.html",
        "author": "Cheng Da, Chuwei Luo, Qi Zheng, Cong Yao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Da_Vision_Grid_Transformer_for_Document_Layout_Analysis_ICCV_2023_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group, Beijing, China",
        "project": "",
        "github": "https://github.com/AlibabaResearch/AdvancedLiterateMachineryTable",
        "arxiv": "2308.14978"
    },
    {
        "title": "Vision HGNN: An Image is More than a Graph of Nodes",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.html",
        "author": "Yan Han, Peihao Wang, Souvik Kundu, Ying Ding, Zhangyang Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.pdf",
        "aff": "Intel Labs; University of Texas at Austin",
        "project": "",
        "github": "https://github.com/VITA-Group/ViHGNN",
        "arxiv": ""
    },
    {
        "title": "Vision Relation Transformer for Unbiased Scene Graph Generation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sudhakaran_Vision_Relation_Transformer_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.html",
        "author": "Gopika Sudhakaran, Devendra Singh Dhami, Kristian Kersting, Stefan Roth",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakaran_Vision_Relation_Transformer_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, Technical University of Darmstadt, Germany; Hessian Center for AI (hessian.AI); Department of Computer Science, Technical University of Darmstadt, Germany; Centre for Cognitive Science, TU Darmstadt; Hessian Center for AI (hessian.AI)",
        "project": "",
        "github": "https://github.com/visinf/veto",
        "arxiv": "2308.09472"
    },
    {
        "title": "Vision Transformer Adapters for Generalizable Multitask Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bhattacharjee_Vision_Transformer_Adapters_for_Generalizable_Multitask_Learning_ICCV_2023_paper.html",
        "author": "Deblina Bhattacharjee, Sabine S\u00fcsstrunk, Mathieu Salzmann",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bhattacharjee_Vision_Transformer_Adapters_for_Generalizable_Multitask_Learning_ICCV_2023_paper.pdf",
        "aff": "School of Computer and Communication Sciences, EPFL, Switzerland",
        "project": "https://ivrl.github.io/VTAGML",
        "github": "https://github.com/ivrl/VTAGML",
        "arxiv": ""
    },
    {
        "title": "Visual Explanations via Iterated Integrated Attributions",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Barkan_Visual_Explanations_via_Iterated_Integrated_Attributions_ICCV_2023_paper.html",
        "author": "Oren Barkan, \u202aYehonatan Elisha\u202c\u200f, Yuval Asher, Amit Eshel, Noam Koenigstein",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Barkan_Visual_Explanations_via_Iterated_Integrated_Attributions_ICCV_2023_paper.pdf",
        "aff": "The Open University; Tel Aviv University",
        "project": "",
        "github": "https://github.com/iia-iccv23/iia",
        "arxiv": ""
    },
    {
        "title": "Visual Traffic Knowledge Graph Generation from Scene Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Visual_Traffic_Knowledge_Graph_Generation_from_Scene_Images_ICCV_2023_paper.html",
        "author": "Yunfei Guo, Fei Yin, Xiao-hui Li, Xudong Yan, Tao Xue, Shuqi Mei, Cheng-Lin Liu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Visual_Traffic_Knowledge_Graph_Generation_from_Scene_Images_ICCV_2023_paper.pdf",
        "aff": "MAIS, Institute of Automation of Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; T Lab, Tencent Map, Tencent Technology (Beijing) Co., Ltd.",
        "project": "http://www.nlpr.ia.ac.cn/pal/RS10K.html",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Visually-Prompted_Language_Model_for_Fine-Grained_Scene_Graph_Generation_in_an_ICCV_2023_paper.html",
        "author": "Qifan Yu, Juncheng Li, Yu Wu, Siliang Tang, Wei Ji, Yueting Zhuang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Visually-Prompted_Language_Model_for_Fine-Grained_Scene_Graph_Generation_in_an_ICCV_2023_paper.pdf",
        "aff": "Wuhan University; Zhejiang University; National University of Singapore",
        "project": "",
        "github": "https://github.com/Yuqifan1117/CaCao",
        "arxiv": "2303.13233"
    },
    {
        "title": "VoroMesh: Learning Watertight Surface Meshes with Voronoi Diagrams",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Maruani_VoroMesh_Learning_Watertight_Surface_Meshes_with_Voronoi_Diagrams_ICCV_2023_paper.html",
        "author": "Nissim Maruani, Roman Klokov, Maks Ovsjanikov, Pierre Alliez, Mathieu Desbrun",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Maruani_VoroMesh_Learning_Watertight_Surface_Meshes_with_Voronoi_Diagrams_ICCV_2023_paper.pdf",
        "aff": "Inria, Universit\u00e9 C\u00f4te d\u2019Azur; LIX, \u00c9cole Polytechnique, IP Paris; Inria Saclay - \u00c9cole Polytechnique",
        "project": "",
        "github": "",
        "arxiv": "2308.14616"
    },
    {
        "title": "Vox-E: Text-Guided Voxel Editing of 3D Objects",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Sella_Vox-E_Text-Guided_Voxel_Editing_of_3D_Objects_ICCV_2023_paper.html",
        "author": "Etai Sella, Gal Fiebelman, Peter Hedman, Hadar Averbuch-Elor",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sella_Vox-E_Text-Guided_Voxel_Editing_of_3D_Objects_ICCV_2023_paper.pdf",
        "aff": "Tel Aviv University; Google Research",
        "project": "",
        "github": "http://vox-e.github.io/",
        "arxiv": ""
    },
    {
        "title": "WALDO: Future Video Synthesis Using Object Layer Decomposition and Parametric Flow Prediction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Le_Moing_WALDO_Future_Video_Synthesis_Using_Object_Layer_Decomposition_and_Parametric_ICCV_2023_paper.html",
        "author": "Guillaume Le Moing, Jean Ponce, Cordelia Schmid",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Le_Moing_WALDO_Future_Video_Synthesis_Using_Object_Layer_Decomposition_and_Parametric_ICCV_2023_paper.pdf",
        "aff": "Inria, D\u00b4epartement d\u2019informatique de l\u2019ENS (CNRS, ENS-PSL, Inria); Center for Data Science, New York University",
        "project": "https://16lemoing.github.io/waldo",
        "github": "",
        "arxiv": "2211.14308"
    },
    {
        "title": "WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant Analysis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_WDiscOOD_Out-of-Distribution_Detection_via_Whitened_Linear_Discriminant_Analysis_ICCV_2023_paper.html",
        "author": "Yiye Chen, Yunzhi Lin, Ruinian Xu, Patricio A. Vela",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_WDiscOOD_Out-of-Distribution_Detection_via_Whitened_Linear_Discriminant_Analysis_ICCV_2023_paper.pdf",
        "aff": "Georgia Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": "2303.07543"
    },
    {
        "title": "Waffling Around for Performance: Visual Classification with Random Words and Broad Concepts",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Roth_Waffling_Around_for_Performance_Visual_Classification_with_Random_Words_and_ICCV_2023_paper.html",
        "author": "Karsten Roth, Jae Myung Kim, A. Sophia Koepke, Oriol Vinyals, Cordelia Schmid, Zeynep Akata",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Roth_Waffling_Around_for_Performance_Visual_Classification_with_Random_Words_and_ICCV_2023_paper.pdf",
        "aff": "University of T\u00fcbingen, T\u00fcbingen AI Center; Inria, Ecole normale sup\u00e9rieure, CNRS, PSL Research University; Google DeepMind; University of T\u00fcbingen, T\u00fcbingen AI Center, MPI for Intelligent Systems",
        "project": "",
        "github": "https://github.com/ExplainableML/WaffleCLIP",
        "arxiv": "2306.07282"
    },
    {
        "title": "Walking Your LiDOG: A Journey Through Multiple Domains for LiDAR Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Saltori_Walking_Your_LiDOG_A_Journey_Through_Multiple_Domains_for_LiDAR_ICCV_2023_paper.html",
        "author": "Cristiano Saltori, Aljosa Osep, Elisa Ricci, Laura Leal-Taix\u00e9",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Saltori_Walking_Your_LiDOG_A_Journey_Through_Multiple_Domains_for_LiDAR_ICCV_2023_paper.pdf",
        "aff": "TU Munich; Federazione Bruno Kessler; NVIDIA; University of Trento",
        "project": "",
        "github": "",
        "arxiv": "2304.11705"
    },
    {
        "title": "Wasserstein Expansible Variational Autoencoder for Discriminative and Generative Continual Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Wasserstein_Expansible_Variational_Autoencoder_for_Discriminative_and_Generative_Continual_Learning_ICCV_2023_paper.html",
        "author": "Fei Ye, Adrian G. Bors",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Wasserstein_Expansible_Variational_Autoencoder_for_Discriminative_and_Generative_Continual_Learning_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, University of York, York YO10 5GH, UK",
        "project": "",
        "github": "https://github.com/dtuzi123/WEVAE/",
        "arxiv": ""
    },
    {
        "title": "WaterMask: Instance Segmentation for Underwater Imagery",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lian_WaterMask_Instance_Segmentation_for_Underwater_Imagery_ICCV_2023_paper.html",
        "author": "Shijie Lian, Hua Li, Runmin Cong, Suqi Li, Wei Zhang, Sam Kwong",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lian_WaterMask_Instance_Segmentation_for_Underwater_Imagery_ICCV_2023_paper.pdf",
        "aff": "Hainan University; Key Laboratory of Machine Intelligence and System Control, Ministry of Education, Shandong University; City University of Hong Kong, Lingnan University, Hong Kong",
        "project": "",
        "github": "https://github.com/LiamLian0727/WaterMask",
        "arxiv": ""
    },
    {
        "title": "WaveIPT: Joint Attention and Flow Alignment in the Wavelet domain for Pose Transfer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_WaveIPT_Joint_Attention_and_Flow_Alignment_in_the_Wavelet_domain_ICCV_2023_paper.html",
        "author": "Liyuan Ma, Tingwei Gao, Haitian Jiang, Haibin Shen, Kejie Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_WaveIPT_Joint_Attention_and_Flow_Alignment_in_the_Wavelet_domain_ICCV_2023_paper.pdf",
        "aff": "Alibaba Group, Zhejiang University, China; Alibaba Group; Zhejiang University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "WaveNeRF: Wavelet-based Generalizable Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xu_WaveNeRF_Wavelet-based_Generalizable_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Muyu Xu, Fangneng Zhan, Jiahui Zhang, Yingchen Yu, Xiaoqin Zhang, Christian Theobalt, Ling Shao, Shijian Lu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_WaveNeRF_Wavelet-based_Generalizable_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "UCAS-Terminus AI Lab, UCAS; Max Planck Institute for Informatics; Nanyang Technological University; Wenzhou University",
        "project": "",
        "github": "",
        "arxiv": "2308.04826"
    },
    {
        "title": "Weakly Supervised Learning of Semantic Correspondence through Cascaded Online Correspondence Refinement",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Weakly_Supervised_Learning_of_Semantic_Correspondence_through_Cascaded_Online_Correspondence_ICCV_2023_paper.html",
        "author": "Yiwen Huang, Yixuan Sun, Chenghang Lai, Qing Xu, Xiaomei Wang, Xuli Shen, Weifeng Ge",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Weakly_Supervised_Learning_of_Semantic_Correspondence_through_Cascaded_Online_Correspondence_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science, Fudan University, Shanghai, China; UniDT Technology, Shanghai, China; Academy of Engineering & Technology, Fudan University, Shanghai, China",
        "project": "",
        "github": "https://github.com/21210240056/SC-ImageNet",
        "arxiv": ""
    },
    {
        "title": "Weakly Supervised Referring Image Segmentation with Intra-Chunk and Inter-Chunk Consistency",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Weakly_Supervised_Referring_Image_Segmentation_with_Intra-Chunk_and_Inter-Chunk_Consistency_ICCV_2023_paper.html",
        "author": "Jungbeom Lee, Sungjin Lee, Jinseok Nam, Seunghak Yu, Jaeyoung Do, Tara Taghavi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Weakly_Supervised_Referring_Image_Segmentation_with_Intra-Chunk_and_Inter-Chunk_Consistency_ICCV_2023_paper.pdf",
        "aff": "NAVER Search US; Amazon",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Weakly-Supervised Action Localization by Hierarchically-Structured Latent Attention Modeling",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Weakly-Supervised_Action_Localization_by_Hierarchically-Structured_Latent_Attention_Modeling_ICCV_2023_paper.html",
        "author": "Guiqin Wang, Peng Zhao, Cong Zhao, Shusen Yang, Jie Cheng, Luziwei Leng, Jianxing Liao, Qinghai Guo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Weakly-Supervised_Action_Localization_by_Hierarchically-Structured_Latent_Attention_Modeling_ICCV_2023_paper.pdf",
        "aff": "ACS Lab, Huawei Technologies; School of Mathematics and Statistics, Xi\u2019an Jiao Tong University; School of Computer Science and Technology, Xi\u2019an Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2308.09946"
    },
    {
        "title": "Weakly-Supervised Action Segmentation and Unseen Error Detection in Anomalous Instructional Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.html",
        "author": "Reza Ghoddoosian, Isht Dwivedi, Nakul Agarwal, Behzad Dariush",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.pdf",
        "aff": "Honda Research Institute, USA",
        "project": "https://usa.honda-ri.com/ata",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Weakly-Supervised Text-Driven Contrastive Learning for Facial Behavior Understanding",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Weakly-Supervised_Text-Driven_Contrastive_Learning_for_Facial_Behavior_Understanding_ICCV_2023_paper.html",
        "author": "Xiang Zhang, Taoyue Wang, Xiaotian Li, Huiyuan Yang, Lijun Yin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Weakly-Supervised_Text-Driven_Contrastive_Learning_for_Facial_Behavior_Understanding_ICCV_2023_paper.pdf",
        "aff": "Rice University; State University of New York at Binghamton",
        "project": "",
        "github": "",
        "arxiv": "2304.00058"
    },
    {
        "title": "Weakly-supervised 3D Pose Transfer with Keypoints",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Weakly-supervised_3D_Pose_Transfer_with_Keypoints_ICCV_2023_paper.html",
        "author": "Jinnan Chen, Chen Li, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Weakly-supervised_3D_Pose_Transfer_with_Keypoints_ICCV_2023_paper.pdf",
        "aff": "Department of Computer Science, National University of Singapore",
        "project": "",
        "github": "https://github.com/jinnan-chen/3D-Pose-Transfer",
        "arxiv": "2307.13459"
    },
    {
        "title": "What Can Simple Arithmetic Operations Do for Temporal Modeling?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_What_Can_Simple_Arithmetic_Operations_Do_for_Temporal_Modeling_ICCV_2023_paper.html",
        "author": "Wenhao Wu, Yuxin Song, Zhun Sun, Jingdong Wang, Chang Xu, Wanli Ouyang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_What_Can_Simple_Arithmetic_Operations_Do_for_Temporal_Modeling_ICCV_2023_paper.pdf",
        "aff": "Baidu Inc.; Shanghai AI Laboratory; The University of Sydney",
        "project": "",
        "github": "https://github.com/whwu95/ATM",
        "arxiv": "2307.08908"
    },
    {
        "title": "What Can a Cook in Italy Teach a Mechanic in India? Action Recognition Generalisation Over Scenarios and Locations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Plizzari_What_Can_a_Cook_in_Italy_Teach_a_Mechanic_in_ICCV_2023_paper.html",
        "author": "Chiara Plizzari, Toby Perrett, Barbara Caputo, Dima Damen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Plizzari_What_Can_a_Cook_in_Italy_Teach_a_Mechanic_in_ICCV_2023_paper.pdf",
        "aff": "University of Bristol, United Kingdom; Politecnico di Torino, Italy",
        "project": "",
        "github": "https://chiaraplizz.github.io/what-can-a-cook/",
        "arxiv": "2306.08713"
    },
    {
        "title": "What Does a Platypus Look Like? Generating Customized Prompts for Zero-Shot Image Classification",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.html",
        "author": "Sarah Pratt, Ian Covert, Rosanne Liu, Ali Farhadi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.pdf",
        "aff": "Google DeepMind; University of Washington",
        "project": "",
        "github": "https://github.com/sarahpratt/CuPL",
        "arxiv": "2209.03320"
    },
    {
        "title": "What can Discriminator do? Towards Box-free Ownership Verification of Generative Adversarial Networks",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_What_can_Discriminator_do_Towards_Box-free_Ownership_Verification_of_Generative_ICCV_2023_paper.html",
        "author": "Ziheng Huang, Boheng Li, Yan Cai, Run Wang, Shangwei Guo, Liming Fang, Jing Chen, Lina Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_What_can_Discriminator_do_Towards_Box-free_Ownership_Verification_of_Generative_ICCV_2023_paper.pdf",
        "aff": "College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, China; College of Computer Science, Chongqing University, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, China",
        "project": "",
        "github": "https://github.com/AbstractTeen/gan_ownership_verification",
        "arxiv": "2307.15860"
    },
    {
        "title": "What do neural networks learn in image classification? A frequency shortcut perspective",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_What_do_neural_networks_learn_in_image_classification_A_frequency_ICCV_2023_paper.html",
        "author": "Shunxin Wang, Raymond Veldhuis, Christoph Brune, Nicola Strisciuglio",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_What_do_neural_networks_learn_in_image_classification_A_frequency_ICCV_2023_paper.pdf",
        "aff": "University of Twente, The Netherlands",
        "project": "",
        "github": "https://github.com/nis-research/nn-frequency-shortcuts",
        "arxiv": "2307.09829"
    },
    {
        "title": "What does CLIP know about a red circle? Visual prompt engineering for VLMs",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shtedritski_What_does_CLIP_know_about_a_red_circle_Visual_prompt_ICCV_2023_paper.html",
        "author": "Aleksandar Shtedritski, Christian Rupprecht, Andrea Vedaldi",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shtedritski_What_does_CLIP_know_about_a_red_circle_Visual_prompt_ICCV_2023_paper.pdf",
        "aff": "Visual Geometry Group, University of Oxford",
        "project": "",
        "github": "",
        "arxiv": "2304.06712"
    },
    {
        "title": "When Do Curricula Work in Federated Learning?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Vahidian_When_Do_Curricula_Work_in_Federated_Learning_ICCV_2023_paper.html",
        "author": "Saeed Vahidian, Sreevatsank Kadaveru, Woonjoon Baek, Weijia Wang, Vyacheslav Kungurtsev, Chen Chen, Mubarak Shah, Bill Lin",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Vahidian_When_Do_Curricula_Work_in_Federated_Learning_ICCV_2023_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida; Czech Technical University; UC San Diego",
        "project": "",
        "github": "",
        "arxiv": "2212.12712"
    },
    {
        "title": "When Epipolar Constraint Meets Non-Local Operators in Multi-View Stereo",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_When_Epipolar_Constraint_Meets_Non-Local_Operators_in_Multi-View_Stereo_ICCV_2023_paper.html",
        "author": "Tianqi Liu, Xinyi Ye, Weiyue Zhao, Zhiyu Pan, Min Shi, Zhiguo Cao",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_When_Epipolar_Constraint_Meets_Non-Local_Operators_in_Multi-View_Stereo_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Image Processing and Intelligent Control, Ministry of Education; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan 430074, China",
        "project": "",
        "github": "https://github.com/TQTQliu/ET-MVSNet",
        "arxiv": ""
    },
    {
        "title": "When Noisy Labels Meet Long Tail Dilemmas: A Representation Calibration Method",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_When_Noisy_Labels_Meet_Long_Tail_Dilemmas_A_Representation_Calibration_ICCV_2023_paper.html",
        "author": "Manyi Zhang, Xuyang Zhao, Jun Yao, Chun Yuan, Weiran Huang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_When_Noisy_Labels_Meet_Long_Tail_Dilemmas_A_Representation_Calibration_ICCV_2023_paper.pdf",
        "aff": "SIGS, Tsinghua University; Peking University; Huawei Noah\u2019s Ark Lab; Qing Yuan Research Institute, SEIEE, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2211.10955"
    },
    {
        "title": "When Prompt-based Incremental Learning Does Not Meet Strong Pretraining",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Tang_When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining_ICCV_2023_paper.html",
        "author": "Yu-Ming Tang, Yi-Xing Peng, Wei-Shi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining_ICCV_2023_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Peng Cheng Laboratory, Shenzhen, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China",
        "project": "",
        "github": "https://github.com/TOM-tym/APG",
        "arxiv": "2308.10445"
    },
    {
        "title": "When to Learn What: Model-Adaptive Data Augmentation Curriculum",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hou_When_to_Learn_What_Model-Adaptive_Data_Augmentation_Curriculum_ICCV_2023_paper.html",
        "author": "Chengkai Hou, Jieyu Zhang, Tianyi Zhou",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hou_When_to_Learn_What_Model-Adaptive_Data_Augmentation_Curriculum_ICCV_2023_paper.pdf",
        "aff": "University of Maryland; Jilin University; University of Washington",
        "project": "",
        "github": "https://github.com/JackHck/MADAug",
        "arxiv": "2309.04747"
    },
    {
        "title": "Who Are You Referring To? Coreference Resolution In Image Narrations",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.html",
        "author": "Arushi Goel, Basura Fernando, Frank Keller, Hakan Bilen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.pdf",
        "aff": "CFAR, IHPC, A*STAR, Singapore; School of Informatics, University of Edinburgh, UK",
        "project": "",
        "github": "",
        "arxiv": "2211.14563"
    },
    {
        "title": "Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Why_Is_Prompt_Tuning_for_Vision-Language_Models_Robust_to_Noisy_ICCV_2023_paper.html",
        "author": "Cheng-En Wu, Yu Tian, Haichao Yu, Heng Wang, Pedro Morgado, Yu Hen Hu, Linjie Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Why_Is_Prompt_Tuning_for_Vision-Language_Models_Robust_to_Noisy_ICCV_2023_paper.pdf",
        "aff": "University of Wisconsin-Madison; ByteDance Inc.",
        "project": "",
        "github": "https://github.com/CEWu/PTNL",
        "arxiv": "2307.11978"
    },
    {
        "title": "Why do networks have inhibitory/negative connections?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Why_do_networks_have_inhibitorynegative_connections_ICCV_2023_paper.html",
        "author": "Qingyang Wang, Mike A. Powell, Ali Geisa, Eric Bridgeford, Carey E. Priebe, Joshua T. Vogelstein",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Why_do_networks_have_inhibitorynegative_connections_ICCV_2023_paper.pdf",
        "aff": "Johns Hopkins University; United States Military Academy, Department of Mathematical Sciences, West Point NY US",
        "project": "",
        "github": "",
        "arxiv": "2208.03211"
    },
    {
        "title": "Will Large-scale Generative Models Corrupt Future Datasets?",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Hataya_Will_Large-scale_Generative_Models_Corrupt_Future_Datasets_ICCV_2023_paper.html",
        "author": "Ryuichiro Hataya, Han Bao, Hiromi Arai",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hataya_Will_Large-scale_Generative_Models_Corrupt_Future_Datasets_ICCV_2023_paper.pdf",
        "aff": "RIKEN AIP; RIKEN ADSP & RIKEN AIP; Kyoto University",
        "project": "",
        "github": "https://github.com/moskomule/dataset-contamination",
        "arxiv": "2211.08095"
    },
    {
        "title": "Window-Based Early-Exit Cascades for Uncertainty Estimation: When Deep Ensembles are More Efficient than Single Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Window-Based_Early-Exit_Cascades_for_Uncertainty_Estimation_When_Deep_Ensembles_are_ICCV_2023_paper.html",
        "author": "Guoxuan Xia, Christos-Savvas Bouganis",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Window-Based_Early-Exit_Cascades_for_Uncertainty_Estimation_When_Deep_Ensembles_are_ICCV_2023_paper.pdf",
        "aff": "Imperial College London",
        "project": "",
        "github": "https://github.com/Guoxoug/window-early-exit",
        "arxiv": "2303.08010"
    },
    {
        "title": "With a Little Help from Your Own Past: Prototypical Memory Networks for Image Captioning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Barraco_With_a_Little_Help_from_Your_Own_Past_Prototypical_Memory_ICCV_2023_paper.html",
        "author": "Manuele Barraco, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Barraco_With_a_Little_Help_from_Your_Own_Past_Prototypical_Memory_ICCV_2023_paper.pdf",
        "aff": "University of Modena and Reggio Emilia, Modena, Italy; IIT-CNR, Pisa, Italy; University of Modena and Reggio Emilia, Modena, Italy",
        "project": "",
        "github": "https://github.com/aimagelab/PMA-Net",
        "arxiv": "2308.12383"
    },
    {
        "title": "Workie-Talkie: Accelerating Federated Learning by Overlapping Computing and Communications via Contrastive Regularization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Workie-Talkie_Accelerating_Federated_Learning_by_Overlapping_Computing_and_Communications_via_ICCV_2023_paper.html",
        "author": "Rui Chen, Qiyu Wan, Pavana Prakash, Lan Zhang, Xu Yuan, Yanmin Gong, Xin Fu, Miao Pan",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Workie-Talkie_Accelerating_Federated_Learning_by_Overlapping_Computing_and_Communications_via_ICCV_2023_paper.pdf",
        "aff": "University of Houston; Michigan Technological University; University of Delaware; University of Texas at San Antonio",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "X-Mesh: Towards Fast and Accurate Text-driven 3D Stylization via Dynamic Textual Guidance",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ma_X-Mesh_Towards_Fast_and_Accurate_Text-driven_3D_Stylization_via_Dynamic_ICCV_2023_paper.html",
        "author": "Yiwei Ma, Xiaoqing Zhang, Xiaoshuai Sun, Jiayi Ji, Haowei Wang, Guannan Jiang, Weilin Zhuang, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_X-Mesh_Towards_Fast_and_Accurate_Text-driven_3D_Stylization_via_Dynamic_ICCV_2023_paper.pdf",
        "aff": "Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University, 361005, P.R. China.; Contemporary Amperex Technology Co., Limited (CATL), Fujian, China",
        "project": "https://xmu-xiaoma666.github.io/Projects/X-Mesh/",
        "github": "https://github.com/xmu-xiaoma666",
        "arxiv": ""
    },
    {
        "title": "X-VoE: Measuring eXplanatory Violation of Expectation in Physical Events",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dai_X-VoE_Measuring_eXplanatory_Violation_of_Expectation_in_Physical_Events_ICCV_2023_paper.html",
        "author": "Bo Dai, Linge Wang, Baoxiong Jia, Zeyu Zhang, Song-Chun Zhu, Chi Zhang, Yixin Zhu",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_X-VoE_Measuring_eXplanatory_Violation_of_Expectation_in_Physical_Events_ICCV_2023_paper.pdf",
        "aff": "School of Intelligence Science and Technology, Peking University; Beijing Institute for General Artificial Intelligence; Department of Automation, Tsinghua University; Beijing Institute for General Artificial Intelligence; School of Intelligence Science and Technology, Peking University; Beijing Institute for General Artificial Intelligence; Institute for Artificial Intelligence, Peking University; Department of Automation, Tsinghua University",
        "project": "",
        "github": "https://github.com/daibopku/X-VoE",
        "arxiv": ""
    },
    {
        "title": "XMem++: Production-level Video Segmentation From Few Annotated Frames",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Bekuzarov_XMem_Production-level_Video_Segmentation_From_Few_Annotated_Frames_ICCV_2023_paper.html",
        "author": "Maksym Bekuzarov, Ariana Bermudez, Joon-Young Lee, Hao Li",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bekuzarov_XMem_Production-level_Video_Segmentation_From_Few_Annotated_Frames_ICCV_2023_paper.pdf",
        "aff": "MBZUAI; Adobe Research; MBZUAI, Pinscreen",
        "project": "https://max810.github.io/xmem2-project-page/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "XNet: Wavelet-Based Low and High Frequency Fusion Networks for Fully- and Semi-Supervised Semantic Segmentation of Biomedical Images",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_XNet_Wavelet-Based_Low_and_High_Frequency_Fusion_Networks_for_Fully-_ICCV_2023_paper.html",
        "author": "Yanfeng Zhou, Jiaxing Huang, Chenlong Wang, Le Song, Ge Yang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_XNet_Wavelet-Based_Low_and_High_Frequency_Fusion_Networks_for_Fully-_ICCV_2023_paper.pdf",
        "aff": "BioMap Research, California, USA; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "https://github.com/Yanfeng-Zhou/XNet",
        "arxiv": ""
    },
    {
        "title": "XVO: Generalized Visual Odometry via Cross-Modal Self-Training",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Lai_XVO_Generalized_Visual_Odometry_via_Cross-Modal_Self-Training_ICCV_2023_paper.html",
        "author": "Lei Lai, Zhongkai Shangguan, Jimuyang Zhang, Eshed Ohn-Bar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_XVO_Generalized_Visual_Odometry_via_Cross-Modal_Self-Training_ICCV_2023_paper.pdf",
        "aff": "Boston University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "XiNet: Efficient Neural Networks for tinyML",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ancilotto_XiNet_Efficient_Neural_Networks_for_tinyML_ICCV_2023_paper.html",
        "author": "Alberto Ancilotto, Francesco Paissan, Elisabetta Farella",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ancilotto_XiNet_Efficient_Neural_Networks_for_tinyML_ICCV_2023_paper.pdf",
        "aff": "Energy Efficient Embedded Digital Architectures (E3DA), Fondazione Bruno Kessler",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Yes, we CANN: Constrained Approximate Nearest Neighbors for Local Feature-Based Visual Localization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Aiger_Yes_we_CANN_Constrained_Approximate_Nearest_Neighbors_for_Local_Feature-Based_ICCV_2023_paper.html",
        "author": "Dror Aiger, Andre Araujo, Simon Lynen",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Aiger_Yes_we_CANN_Constrained_Approximate_Nearest_Neighbors_for_Local_Feature-Based_ICCV_2023_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "",
        "arxiv": "2306.09012"
    },
    {
        "title": "You Never Get a Second Chance To Make a Good First Impression: Seeding Active Learning for 3D Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Samet_You_Never_Get_a_Second_Chance_To_Make_a_Good_ICCV_2023_paper.html",
        "author": "Nermin Samet, Oriane Sim\u00e9oni, Gilles Puy, Georgy Ponimatkin, Renaud Marlet, Vincent Lepetit",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Samet_You_Never_Get_a_Second_Chance_To_Make_a_Good_ICCV_2023_paper.pdf",
        "aff": "Valeo.ai, Paris, France; LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS, Marne-la-Vall\u00e9e, France",
        "project": "",
        "github": "https://github.com/nerminsamet/seedal",
        "arxiv": ""
    },
    {
        "title": "Your Diffusion Model is Secretly a Zero-Shot Classifier",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Li_Your_Diffusion_Model_is_Secretly_a_Zero-Shot_Classifier_ICCV_2023_paper.html",
        "author": "Alexander C. Li, Mihir Prabhudesai, Shivam Duggal, Ellis Brown, Deepak Pathak",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Your_Diffusion_Model_is_Secretly_a_Zero-Shot_Classifier_ICCV_2023_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "https://diffusion-classifier.github.io/",
        "github": "https://github.com/diffusion-classifier",
        "arxiv": "2303.16203"
    },
    {
        "title": "Zenseact Open Dataset: A Large-Scale and Diverse Multimodal Dataset for Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Alibeigi_Zenseact_Open_Dataset_A_Large-Scale_and_Diverse_Multimodal_Dataset_for_ICCV_2023_paper.html",
        "author": "Mina Alibeigi, William Ljungbergh, Adam Tonderski, Georg Hess, Adam Lilja, Carl Lindstr\u00f6m, Daria Motorniuk, Junsheng Fu, Jenny Widahl, Christoffer Petersson",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Alibeigi_Zenseact_Open_Dataset_A_Large-Scale_and_Diverse_Multimodal_Dataset_for_ICCV_2023_paper.pdf",
        "aff": "Zenseact",
        "project": "atzod.zenseact.com",
        "github": "",
        "arxiv": "2305.02008"
    },
    {
        "title": "Zero-1-to-3: Zero-shot One Image to 3D Object",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.html",
        "author": "Ruoshi Liu, Rundi Wu, Basile Van Hoorick, Pavel Tokmakov, Sergey Zakharov, Carl Vondrick",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.pdf",
        "aff": "Toyota Research Institute; Columbia University",
        "project": "http://zero123.cs.columbia.edu",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Zero-Shot Composed Image Retrieval with Textual Inversion",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Baldrati_Zero-Shot_Composed_Image_Retrieval_with_Textual_Inversion_ICCV_2023_paper.html",
        "author": "Alberto Baldrati, Lorenzo Agnolucci, Marco Bertini, Alberto Del Bimbo",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Zero-Shot_Composed_Image_Retrieval_with_Textual_Inversion_ICCV_2023_paper.pdf",
        "aff": "University of Florence - Media Integration and Communication Center (MICC)",
        "project": "",
        "github": "https://github.com/miccunifi/SEARLE",
        "arxiv": "2303.15247"
    },
    {
        "title": "Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.html",
        "author": "Serin Yang, Hyunmin Hwang, Jong Chul Ye",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.pdf",
        "aff": "Kim Jaechul Graduate School of AI, Korea Advanced Institute of Science and Technology (KAIST)",
        "project": "",
        "github": "https://github.com/YSerin/ZeCon",
        "arxiv": "2303.08622"
    },
    {
        "title": "Zero-Shot Point Cloud Segmentation by Semantic-Visual Aware Synthesis",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Zero-Shot_Point_Cloud_Segmentation_by_Semantic-Visual_Aware_Synthesis_ICCV_2023_paper.html",
        "author": "Yuwei Yang, Munawar Hayat, Zhao Jin, Hongyuan Zhu, Yinjie Lei",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Point_Cloud_Segmentation_by_Semantic-Visual_Aware_Synthesis_ICCV_2023_paper.pdf",
        "aff": "Sichuan University; A*STAR; Monash University",
        "project": "",
        "github": "https://github.com/leolyj/3DPC-GZSL",
        "arxiv": ""
    },
    {
        "title": "Zero-Shot Spatial Layout Conditioning for Text-to-Image Diffusion Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html",
        "author": "Guillaume Couairon, Marl\u00e8ne Careil, Matthieu Cord, St\u00e9phane Lathuili\u00e8re, Jakob Verbeek",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf",
        "aff": "LTCI, T \u00b4el\u00b4ecom Paris, IP Paris; Meta AI; Meta AI, LTCI, T \u00b4el\u00b4ecom Paris, IP Paris; Meta AI, Sorbonne Universit \u00b4e; Sorbonne Universit \u00b4e, Valeo.ai",
        "project": "",
        "github": "",
        "arxiv": "2306.13754"
    },
    {
        "title": "Zero-guidance Segmentation Using Zero Segment Labels",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Rewatbowornwong_Zero-guidance_Segmentation_Using_Zero_Segment_Labels_ICCV_2023_paper.html",
        "author": "Pitchaporn Rewatbowornwong, Nattanat Chatthee, Ekapol Chuangsuwanich, Supasorn Suwajanakorn",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rewatbowornwong_Zero-guidance_Segmentation_Using_Zero_Segment_Labels_ICCV_2023_paper.pdf",
        "aff": "VISTEC, Thailand; Chulalongkorn University, Thailand",
        "project": "https://zero-guide-seg.github.io/",
        "github": "https://github.com/zero-guide-seg",
        "arxiv": "2303.13396"
    },
    {
        "title": "Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Barron_Zip-NeRF_Anti-Aliased_Grid-Based_Neural_Radiance_Fields_ICCV_2023_paper.html",
        "author": "Jonathan T. Barron, Ben Mildenhall, Dor Verbin, Pratul P. Srinivasan, Peter Hedman",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Barron_Zip-NeRF_Anti-Aliased_Grid-Based_Neural_Radiance_Fields_ICCV_2023_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Zolly_Zoom_Focal_Length_Correctly_for_Perspective-Distorted_Human_Mesh_Reconstruction_ICCV_2023_paper.html",
        "author": "Wenjia Wang, Yongtao Ge, Haiyi Mei, Zhongang Cai, Qingping Sun, Yanjun Wang, Chunhua Shen, Lei Yang, Taku Komura",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Zolly_Zoom_Focal_Length_Correctly_for_Perspective-Distorted_Human_Mesh_Reconstruction_ICCV_2023_paper.pdf",
        "aff": "The University of Hong Kong; Shanghai AI Laboratory; The University of Adelaide; Zhejiang University; SenseTime Research",
        "project": "https://wenjiawang0312.github.io/projects/zolly/",
        "github": "https://github.com/wenjiawang0312",
        "arxiv": "2303.13796"
    },
    {
        "title": "eP-ALM: Efficient Perceptual Augmentation of Language Models",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Shukor_eP-ALM_Efficient_Perceptual_Augmentation_of_Language_Models_ICCV_2023_paper.html",
        "author": "Mustafa Shukor, Corentin Dancette, Matthieu Cord",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shukor_eP-ALM_Efficient_Perceptual_Augmentation_of_Language_Models_ICCV_2023_paper.pdf",
        "aff": "Sorbonne University, Valeo.ai; Sorbonne University",
        "project": "",
        "github": "https://github.com/mshukor/eP-ALM",
        "arxiv": ""
    },
    {
        "title": "iDAG: Invariant DAG Searching for Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Huang_iDAG_Invariant_DAG_Searching_for_Domain_Generalization_ICCV_2023_paper.html",
        "author": "Zenan Huang, Haobo Wang, Junbo Zhao, Nenggan Zheng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_iDAG_Invariant_DAG_Searching_for_Domain_Generalization_ICCV_2023_paper.pdf",
        "aff": "Zhejiang University",
        "project": "",
        "github": "https://github.com/lccurious/iDAG",
        "arxiv": ""
    },
    {
        "title": "iVS-Net: Learning Human View Synthesis from Internet Videos",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Dong_iVS-Net_Learning_Human_View_Synthesis_from_Internet_Videos_ICCV_2023_paper.html",
        "author": "Junting Dong, Qi Fang, Tianshuo Yang, Qing Shuai, Chengyu Qiao, Sida Peng",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_iVS-Net_Learning_Human_View_Synthesis_from_Internet_Videos_ICCV_2023_paper.pdf",
        "aff": "NetEase Games AI Lab; Zhejiang University",
        "project": "",
        "github": "https://zju3dv.github.io/ivsnet/",
        "arxiv": ""
    },
    {
        "title": "s-Adaptive Decoupled Prototype for Few-Shot Object Detection",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.html",
        "author": "Jinhao Du, Shan Zhang, Qiang Chen, Haifeng Le, Yanpeng Sun, Yao Ni, Jian Wang, Bin He, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.pdf",
        "aff": "Baidu VIS; Beijing Union University; Nanjing University of Science And Technology; Australian National University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "uSplit: Image Decomposition for Fluorescence Microscopy",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.html",
        "author": "Ashesh Ashesh, Alexander Krull, Moises Di Sante, Francesco Pasqualini, Florian Jug",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.pdf",
        "aff": "University of Birmingham, UK; Human Technopole, Italy; University of Pavia, Italy",
        "project": "",
        "github": "https://github.com/juglab/uSplit",
        "arxiv": ""
    },
    {
        "title": "zPROBE: Zero Peek Robustness Checks for Federated Learning",
        "site": "https://openaccess.thecvf.com/content/ICCV2023/html/Ghodsi_zPROBE_Zero_Peek_Robustness_Checks_for_Federated_Learning_ICCV_2023_paper.html",
        "author": "Zahra Ghodsi, Mojan Javaheripi, Nojan Sheybani, Xinqiao Zhang, Ke Huang, Farinaz Koushanfar",
        "pdf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ghodsi_zPROBE_Zero_Peek_Robustness_Checks_for_Federated_Learning_ICCV_2023_paper.pdf",
        "aff": "Purdue University; San Diego State University; University of California San Diego",
        "project": "",
        "github": "",
        "arxiv": "2206.12100"
    }
]