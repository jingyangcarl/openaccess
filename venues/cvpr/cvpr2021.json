[
    {
        "title": "(AF)2-S3Net: Attentive Feature Fusion With Adaptive Feature Selection for Sparse Semantic Segmentation Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_AF2-S3Net_Attentive_Feature_Fusion_With_Adaptive_Feature_Selection_for_Sparse_CVPR_2021_paper.html",
        "author": "Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, Bingbing Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_AF2-S3Net_Attentive_Feature_Fusion_With_Adaptive_Feature_Selection_for_Sparse_CVPR_2021_paper.pdf",
        "aff": "Huawei Noah's Ark Lab, Canada",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_2D_or_not_2D_Adaptive_3D_Convolution_Selection_for_Efficient_CVPR_2021_paper.html",
        "author": "Hengduo Li, Zuxuan Wu, Abhinav Shrivastava, Larry S. Davis",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_2D_or_not_2D_Adaptive_3D_Convolution_Selection_for_Efficient_CVPR_2021_paper.pdf",
        "aff": "Fudan University; University of Maryland",
        "project": "",
        "github": "",
        "arxiv": "2012.14950"
    },
    {
        "title": "3D AffordanceNet: A Benchmark for Visual Object Affordance Understanding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_3D_AffordanceNet_A_Benchmark_for_Visual_Object_Affordance_Understanding_CVPR_2021_paper.html",
        "author": "Shengheng Deng, Xun Xu, Chaozheng Wu, Ke Chen, Kui Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_3D_AffordanceNet_A_Benchmark_for_Visual_Object_Affordance_Understanding_CVPR_2021_paper.pdf",
        "aff": "South China University of Technology; I2R, A-STAR; South China University of Technology, Pazhou Laboratory, Peng Cheng Laboratory",
        "project": "",
        "github": "",
        "arxiv": "2103.16397"
    },
    {
        "title": "3D CNNs With Adaptive Temporal Feature Resolutions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fayyaz_3D_CNNs_With_Adaptive_Temporal_Feature_Resolutions_CVPR_2021_paper.html",
        "author": "Mohsen Fayyaz, Emad Bahrami, Ali Diba, Mehdi Noroozi, Ehsan Adeli, Luc Van Gool, Jurgen Gall",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fayyaz_3D_CNNs_With_Adaptive_Temporal_Feature_Resolutions_CVPR_2021_paper.pdf",
        "aff": "University of Bonn; KU Leuven and ETH Z\u00fcrich; Stanford University; KU Leuven; Bosch Center for Arti\ufb01cial Intelligence",
        "project": "",
        "github": "",
        "arxiv": "2011.08652"
    },
    {
        "title": "3D Graph Anatomy Geometry-Integrated Network for Pancreatic Mass Segmentation, Diagnosis, and Quantitative Patient Management",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_3D_Graph_Anatomy_Geometry-Integrated_Network_for_Pancreatic_Mass_Segmentation_Diagnosis_CVPR_2021_paper.html",
        "author": "Tianyi Zhao, Kai Cao, Jiawen Yao, Isabella Nogues, Le Lu, Lingyun Huang, Jing Xiao, Zhaozheng Yin, Ling Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_3D_Graph_Anatomy_Geometry-Integrated_Network_for_Pancreatic_Mass_Segmentation_Diagnosis_CVPR_2021_paper.pdf",
        "aff": "Harvard University; PAII Inc.; Stony Brook University; Changhai Hospital; Ping An Technology",
        "project": "",
        "github": "",
        "arxiv": "2012.04701"
    },
    {
        "title": "3D Human Action Representation Learning via Cross-View Consistency Pursuit",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_3D_Human_Action_Representation_Learning_via_Cross-View_Consistency_Pursuit_CVPR_2021_paper.html",
        "author": "Linguo Li, Minsi Wang, Bingbing Ni, Hang Wang, Jiancheng Yang, Wenjun Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_3D_Human_Action_Representation_Learning_via_Cross-View_Consistency_Pursuit_CVPR_2021_paper.pdf",
        "aff": "Shanghai Jiao Tong University, Shanghai 200240, China; MoE Key Lab of Arti\ufb01cial Intelligence, AI Institute, Shanghai Jiao Tong University; Shanghai Jiao Tong University, Shanghai 200240, China",
        "project": "",
        "github": "https://github.com/LinguoLi/CrosSCLR",
        "arxiv": "2104.14466"
    },
    {
        "title": "3D Object Detection With Pointformer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pan_3D_Object_Detection_With_Pointformer_CVPR_2021_paper.html",
        "author": "Xuran Pan, Zhuofan Xia, Shiji Song, Li Erran Li, Gao Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_3D_Object_Detection_With_Pointformer_CVPR_2021_paper.pdf",
        "aff": "Alexa AI, Amazon / Columbia University; Department of Automation, Tsinghua University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": "2012.11409"
    },
    {
        "title": "3D Shape Generation With Grid-Based Implicit Functions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ibing_3D_Shape_Generation_With_Grid-Based_Implicit_Functions_CVPR_2021_paper.html",
        "author": "Moritz Ibing, Isaak Lim, Leif Kobbelt",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ibing_3D_Shape_Generation_With_Grid-Based_Implicit_Functions_CVPR_2021_paper.pdf",
        "aff": "Visual Computing Institute, RWTH Aachen University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "3D Spatial Recognition Without Spatially Labeled 3D",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ren_3D_Spatial_Recognition_Without_Spatially_Labeled_3D_CVPR_2021_paper.html",
        "author": "Zhongzheng Ren, Ishan Misra, Alexander G. Schwing, Rohit Girdhar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ren_3D_Spatial_Recognition_Without_Spatially_Labeled_3D_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; Facebook AI Research and University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign",
        "project": "https://facebookresearch.github.io/WyPR",
        "github": "https://github.com/facebookresearch",
        "arxiv": "2105.06461"
    },
    {
        "title": "3D Video Stabilization With Depth Estimation by CNN-Based Optimization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_3D_Video_Stabilization_With_Depth_Estimation_by_CNN-Based_Optimization_CVPR_2021_paper.html",
        "author": "Yao-Chih Lee, Kuan-Wei Tseng, Yu-Ta Chen, Chien-Cheng Chen, Chu-Song Chen, Yi-Ping Hung",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_3D_Video_Stabilization_With_Depth_Estimation_by_CNN-Based_Optimization_CVPR_2021_paper.pdf",
        "aff": "Academia Sinica, Taiwan; National Taiwan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "3D-MAN: 3D Multi-Frame Attention Network for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_3D-MAN_3D_Multi-Frame_Attention_Network_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Zetong Yang, Yin Zhou, Zhifeng Chen, Jiquan Ngiam",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_3D-MAN_3D_Multi-Frame_Attention_Network_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Google Research, Brain Team; Waymo LLC; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "3D-to-2D Distillation for Indoor Scene Parsing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_3D-to-2D_Distillation_for_Indoor_Scene_Parsing_CVPR_2021_paper.html",
        "author": "Zhengzhe Liu, Xiaojuan Qi, Chi-Wing Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_3D-to-2D_Distillation_for_Indoor_Scene_Parsing_CVPR_2021_paper.pdf",
        "aff": "The University of Hong Kong; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2104.02243"
    },
    {
        "title": "3DCaricShop: A Dataset and a Baseline Method for Single-View 3D Caricature Face Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_3DCaricShop_A_Dataset_and_a_Baseline_Method_for_Single-View_3D_CVPR_2021_paper.html",
        "author": "Yuda Qiu, Xiaojie Xu, Lingteng Qiu, Yan Pan, Yushuang Wu, Weikai Chen, Xiaoguang Han",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qiu_3DCaricShop_A_Dataset_and_a_Baseline_Method_for_Single-View_3D_CVPR_2021_paper.pdf",
        "aff": "Tencent Game AI Research Center; SRIBD, The Chinese University of Hong Kong, Shenzhen",
        "project": "",
        "github": "",
        "arxiv": "2103.08204"
    },
    {
        "title": "3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_3DIoUMatch_Leveraging_IoU_Prediction_for_Semi-Supervised_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "He Wang, Yezhen Cong, Or Litany, Yue Gao, Leonidas J. Guibas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_3DIoUMatch_Leveraging_IoU_Prediction_for_Semi-Supervised_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Stanford University; NVIDIA; Tsinghua University",
        "project": "http://THU17cyz.github.io/3DIoUMatch",
        "github": "",
        "arxiv": "2012.04355"
    },
    {
        "title": "4D Hyperspectral Photoacoustic Data Restoration With Reliability Analysis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liao_4D_Hyperspectral_Photoacoustic_Data_Restoration_With_Reliability_Analysis_CVPR_2021_paper.html",
        "author": "Weihang Liao, Art Subpa-asa, Yinqiang Zheng, Imari Sato",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liao_4D_Hyperspectral_Photoacoustic_Data_Restoration_With_Reliability_Analysis_CVPR_2021_paper.pdf",
        "aff": "The University of Tokyo; Tokyo Institute of Technology; National Institute of Informatics",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "4D Panoptic LiDAR Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Aygun_4D_Panoptic_LiDAR_Segmentation_CVPR_2021_paper.html",
        "author": "Mehmet Aygun, Aljosa Osep, Mark Weber, Maxim Maximov, Cyrill Stachniss, Jens Behley, Laura Leal-Taixe",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Aygun_4D_Panoptic_LiDAR_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Technical University of Munich, Germany; University of Bonn, Germany",
        "project": "",
        "github": "",
        "arxiv": "2102.12472"
    },
    {
        "title": "A 3D GAN for Improved Large-Pose Facial Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Marriott_A_3D_GAN_for_Improved_Large-Pose_Facial_Recognition_CVPR_2021_paper.html",
        "author": "Richard T. Marriott, Sami Romdhani, Liming Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Marriott_A_3D_GAN_for_Improved_Large-Pose_Facial_Recognition_CVPR_2021_paper.pdf",
        "aff": "1Ecole Centrale de Lyon, France; 1Ecole Centrale de Lyon, France2IDEMIA, France; 2IDEMIA, France",
        "project": "",
        "github": "",
        "arxiv": "2012.10545"
    },
    {
        "title": "A Circular-Structured Representation for Visual Emotion Distribution Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_A_Circular-Structured_Representation_for_Visual_Emotion_Distribution_Learning_CVPR_2021_paper.html",
        "author": "Jingyuan Yang, Jie Li, Leida Li, Xiumei Wang, Xinbo Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_A_Circular-Structured_Representation_for_Visual_Emotion_Distribution_Learning_CVPR_2021_paper.pdf",
        "aff": "School of Electronic Engineering, Xidian University, Xi'an, China; The Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Arti\ufb01cial Intelligence, Xidian University, Xi'an, China; School of Electronic Engineering, Xidian University, Xi'an, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Closer Look at Fourier Spectrum Discrepancies for CNN-Generated Images Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chandrasegaran_A_Closer_Look_at_Fourier_Spectrum_Discrepancies_for_CNN-Generated_Images_CVPR_2021_paper.html",
        "author": "Keshigeyan Chandrasegaran, Ngoc-Trung Tran, Ngai-Man Cheung",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chandrasegaran_A_Closer_Look_at_Fourier_Spectrum_Discrepancies_for_CNN-Generated_Images_CVPR_2021_paper.pdf",
        "aff": "Singapore University of Technology and Design (SUTD)",
        "project": "",
        "github": "https://keshik6.github.io/Fourier-Discrepancies-CNN-Detection/",
        "arxiv": "2103.17195"
    },
    {
        "title": "A Decomposition Model for Stereo Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yao_A_Decomposition_Model_for_Stereo_Matching_CVPR_2021_paper.html",
        "author": "Chengtang Yao, Yunde Jia, Huijun Di, Pengxiang Li, Yuwei Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yao_A_Decomposition_Model_for_Stereo_Matching_CVPR_2021_paper.pdf",
        "aff": "Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": "2104.07516"
    },
    {
        "title": "A Deep Emulator for Secondary Motion of 3D Characters",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_A_Deep_Emulator_for_Secondary_Motion_of_3D_Characters_CVPR_2021_paper.html",
        "author": "Mianlun Zheng, Yi Zhou, Duygu Ceylan, Jernej Barbic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_A_Deep_Emulator_for_Secondary_Motion_of_3D_Characters_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; University of Southern California",
        "project": "",
        "github": "",
        "arxiv": "2103.01261"
    },
    {
        "title": "A Dual Iterative Refinement Method for Non-Rigid Shape Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xiang_A_Dual_Iterative_Refinement_Method_for_Non-Rigid_Shape_Matching_CVPR_2021_paper.html",
        "author": "Rui Xiang, Rongjie Lai, Hongkai Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xiang_A_Dual_Iterative_Refinement_Method_for_Non-Rigid_Shape_Matching_CVPR_2021_paper.pdf",
        "aff": "Department of Mathematics, UC, Irvine; Department of Mathematics, Duke University; Department of Mathematics, Rensselaer Polytechnic Institute",
        "project": "",
        "github": "",
        "arxiv": "2007.13049"
    },
    {
        "title": "A Fourier-Based Framework for Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_A_Fourier-Based_Framework_for_Domain_Generalization_CVPR_2021_paper.html",
        "author": "Qinwei Xu, Ruipeng Zhang, Ya Zhang, Yanfeng Wang, Qi Tian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_A_Fourier-Based_Framework_for_Domain_Generalization_CVPR_2021_paper.pdf",
        "aff": "Cooperative Medianet Innovation Center, Shanghai Jiao Tong University/Shanghai AI Laboratory; Cooperative Medianet Innovation Center, Shanghai Jiao Tong University; Huawei Cloud & AI",
        "project": "",
        "github": "",
        "arxiv": "2105.11120"
    },
    {
        "title": "A Functional Approach to Rotation Equivariant Non-Linearities for Tensor Field Networks.",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Poulenard_A_Functional_Approach_to_Rotation_Equivariant_Non-Linearities_for_Tensor_Field_CVPR_2021_paper.html",
        "author": "Adrien Poulenard, Leonidas J. Guibas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Poulenard_A_Functional_Approach_to_Rotation_Equivariant_Non-Linearities_for_Tensor_Field_CVPR_2021_paper.pdf",
        "aff": "Stanford University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Generalized Loss Function for Crowd Counting and Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wan_A_Generalized_Loss_Function_for_Crowd_Counting_and_Localization_CVPR_2021_paper.html",
        "author": "Jia Wan, Ziquan Liu, Antoni B. Chan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wan_A_Generalized_Loss_Function_for_Crowd_Counting_and_Localization_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, City University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Hyperbolic-to-Hyperbolic Graph Convolutional Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_A_Hyperbolic-to-Hyperbolic_Graph_Convolutional_Network_CVPR_2021_paper.html",
        "author": "Jindou Dai, Yuwei Wu, Zhi Gao, Yunde Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_A_Hyperbolic-to-Hyperbolic_Graph_Convolutional_Network_CVPR_2021_paper.pdf",
        "aff": "Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology (BIT), Beijing, 100081, China.",
        "project": "",
        "github": "",
        "arxiv": "2104.06942"
    },
    {
        "title": "A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Feichtenhofer_A_Large-Scale_Study_on_Unsupervised_Spatiotemporal_Representation_Learning_CVPR_2021_paper.html",
        "author": "Christoph Feichtenhofer, Haoqi Fan, Bo Xiong, Ross Girshick, Kaiming He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Feichtenhofer_A_Large-Scale_Study_on_Unsupervised_Spatiotemporal_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research (FAIR)",
        "project": "",
        "github": "https://github.com/facebookresearch/SlowFast",
        "arxiv": "2104.14558"
    },
    {
        "title": "A Multi-Task Network for Joint Specular Highlight Detection and Removal",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fu_A_Multi-Task_Network_for_Joint_Specular_Highlight_Detection_and_Removal_CVPR_2021_paper.html",
        "author": "Gang Fu, Qing Zhang, Lei Zhu, Ping Li, Chunxia Xiao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fu_A_Multi-Task_Network_for_Joint_Specular_Highlight_Detection_and_Removal_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Department of Applied Mathematics and Theoretical Physics, University of Cambridge, UK; School of Computer Science, Wuhan University, China; Department of Computing, The Hong Kong Polytechnic University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Multiplexed Network for End-to-End, Multilingual OCR",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_A_Multiplexed_Network_for_End-to-End_Multilingual_OCR_CVPR_2021_paper.html",
        "author": "Jing Huang, Guan Pang, Rama Kovvuri, Mandy Toh, Kevin J Liang, Praveen Krishnan, Xi Yin, Tal Hassner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_A_Multiplexed_Network_for_End-to-End_Multilingual_OCR_CVPR_2021_paper.pdf",
        "aff": "Facebook AI",
        "project": "",
        "github": "",
        "arxiv": "2103.15992"
    },
    {
        "title": "A Peek Into the Reasoning of Neural Networks: Interpreting With Structural Visual Concepts",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ge_A_Peek_Into_the_Reasoning_of_Neural_Networks_Interpreting_With_CVPR_2021_paper.html",
        "author": "Yunhao Ge, Yao Xiao, Zhi Xu, Meng Zheng, Srikrishna Karanam, Terrence Chen, Laurent Itti, Ziyan Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_A_Peek_Into_the_Reasoning_of_Neural_Networks_Interpreting_With_CVPR_2021_paper.pdf",
        "aff": "United Imaging Intelligence, Cambridge MA; University of Southern California, Los Angeles CA",
        "project": "",
        "github": "",
        "arxiv": "2105.00290"
    },
    {
        "title": "A Quasiconvex Formulation for Radial Cameras",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Olsson_A_Quasiconvex_Formulation_for_Radial_Cameras_CVPR_2021_paper.html",
        "author": "Carl Olsson, Viktor Larsson, Fredrik Kahl",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Olsson_A_Quasiconvex_Formulation_for_Radial_Cameras_CVPR_2021_paper.pdf",
        "aff": "Chalmers University of Technology, Sweden; Department of Computer Science, ETH Z\u00fcrich, Switzerland",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Realistic Evaluation of Semi-Supervised Learning for Fine-Grained Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Su_A_Realistic_Evaluation_of_Semi-Supervised_Learning_for_Fine-Grained_Classification_CVPR_2021_paper.html",
        "author": "Jong-Chyi Su, Zezhou Cheng, Subhransu Maji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Su_A_Realistic_Evaluation_of_Semi-Supervised_Learning_for_Fine-Grained_Classification_CVPR_2021_paper.pdf",
        "aff": "University of Massachusetts Amherst",
        "project": "",
        "github": "",
        "arxiv": "2104.00679"
    },
    {
        "title": "A Second-Order Approach to Learning With Instance-Dependent Label Noise",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_A_Second-Order_Approach_to_Learning_With_Instance-Dependent_Label_Noise_CVPR_2021_paper.html",
        "author": "Zhaowei Zhu, Tongliang Liu, Yang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_A_Second-Order_Approach_to_Learning_With_Instance-Dependent_Label_Noise_CVPR_2021_paper.pdf",
        "aff": "Trustworthy Machine Learning Lab, The University of Sydney; Computer Science and Engineering, University of California, Santa Cruz",
        "project": "",
        "github": "https://github.com/UCSC-REAL/CAL",
        "arxiv": "2012.11854"
    },
    {
        "title": "A Self-Boosting Framework for Automated Radiographic Report Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_A_Self-Boosting_Framework_for_Automated_Radiographic_Report_Generation_CVPR_2021_paper.html",
        "author": "Zhanyu Wang, Luping Zhou, Lei Wang, Xiu Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_A_Self-Boosting_Framework_for_Automated_Radiographic_Report_Generation_CVPR_2021_paper.pdf",
        "aff": "Tsinghua Shenzhen International Graduate School; University of Sydney; University of Wollongong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "A Sliced Wasserstein Loss for Neural Texture Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Heitz_A_Sliced_Wasserstein_Loss_for_Neural_Texture_Synthesis_CVPR_2021_paper.html",
        "author": "Eric Heitz, Kenneth Vanhoey, Thomas Chambon, Laurent Belcour",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Heitz_A_Sliced_Wasserstein_Loss_for_Neural_Texture_Synthesis_CVPR_2021_paper.pdf",
        "aff": "Unity Technologies",
        "project": "",
        "github": "",
        "arxiv": "2006.07229"
    },
    {
        "title": "A2-FPN: Attention Aggregation Based Feature Pyramid Network for Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_A2-FPN_Attention_Aggregation_Based_Feature_Pyramid_Network_for_Instance_Segmentation_CVPR_2021_paper.html",
        "author": "Miao Hu, Yali Li, Lu Fang, Shengjin Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_A2-FPN_Attention_Aggregation_Based_Feature_Pyramid_Network_for_Instance_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Department of Electronic Engineering, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ABMDRNet: Adaptive-Weighted Bi-Directional Modality Difference Reduction Network for RGB-T Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_ABMDRNet_Adaptive-Weighted_Bi-Directional_Modality_Difference_Reduction_Network_for_RGB-T_Semantic_CVPR_2021_paper.html",
        "author": "Qiang Zhang, Shenlu Zhao, Yongjiang Luo, Dingwen Zhang, Nianchang Huang, Jungong Han",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_ABMDRNet_Adaptive-Weighted_Bi-Directional_Modality_Difference_Reduction_Network_for_RGB-T_Semantic_CVPR_2021_paper.pdf",
        "aff": "Computer Science Department, Aberystwyth University, U.K.; School of Electronic Engineering, Xidian University, China; School of Mechano-Electronic Engineering, Xidian University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ACRE: Abstract Causal REasoning Beyond Covariation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_ACRE_Abstract_Causal_REasoning_Beyond_Covariation_CVPR_2021_paper.html",
        "author": "Chi Zhang, Baoxiong Jia, Mark Edmonds, Song-Chun Zhu, Yixin Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_ACRE_Abstract_Causal_REasoning_Beyond_Covariation_CVPR_2021_paper.pdf",
        "aff": "UCLA Center for Vision, Cognition, Learning, and Autonomy",
        "project": "",
        "github": "",
        "arxiv": "2103.14232"
    },
    {
        "title": "ACTION-Net: Multipath Excitation for Action Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_ACTION-Net_Multipath_Excitation_for_Action_Recognition_CVPR_2021_paper.html",
        "author": "Zhengwei Wang, Qi She, Aljosa Smolic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_ACTION-Net_Multipath_Excitation_for_Action_Recognition_CVPR_2021_paper.pdf",
        "aff": "ByteDance AI Lab, China; V-SENSE, Trinity College Dublin, Ireland",
        "project": "",
        "github": "https://github.com/V-Sense/ACTION-Net",
        "arxiv": ""
    },
    {
        "title": "AGORA: Avatars in Geography Optimized for Regression Analysis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Patel_AGORA_Avatars_in_Geography_Optimized_for_Regression_Analysis_CVPR_2021_paper.html",
        "author": "Priyanka Patel, Chun-Hao P. Huang, Joachim Tesch, David T. Hoffmann, Shashank Tripathi, Michael J. Black",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Patel_AGORA_Avatars_in_Geography_Optimized_for_Regression_Analysis_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; University of Freiburg, Bosch Center for Arti\ufb01cial Intelligence",
        "project": "https://agora.is.tue.mpg.de/",
        "github": "",
        "arxiv": "2104.14643"
    },
    {
        "title": "AGQA: A Benchmark for Compositional Spatio-Temporal Reasoning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Grunde-McLaughlin_AGQA_A_Benchmark_for_Compositional_Spatio-Temporal_Reasoning_CVPR_2021_paper.html",
        "author": "Madeleine Grunde-McLaughlin, Ranjay Krishna, Maneesh Agrawala",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Grunde-McLaughlin_AGQA_A_Benchmark_for_Compositional_Spatio-Temporal_Reasoning_CVPR_2021_paper.pdf",
        "aff": "University of Pennsylvania; Stanford University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "AIFit: Automatic 3D Human-Interpretable Feedback Models for Fitness Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fieraru_AIFit_Automatic_3D_Human-Interpretable_Feedback_Models_for_Fitness_Training_CVPR_2021_paper.html",
        "author": "Mihai Fieraru, Mihai Zanfir, Silviu Cristian Pirlea, Vlad Olaru, Cristian Sminchisescu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fieraru_AIFit_Automatic_3D_Human-Interpretable_Feedback_Models_for_Fitness_Training_CVPR_2021_paper.pdf",
        "aff": "AIFit: Automatic 3D Human-Interpretable\nFeedback Models for Fitness Training\nMihai Fieraru1Mihai Zan\ufb01r1Silviu Cristian Pirlea1\nVlad Olaru1Cristian Sminchisescu2,1\n1Institute of Mathematics of the Romanian Academy,2Lund University\n1{firstname.lastname }@imar.ro,2cristian.sminchisescu@math.lth.se\nAbstract\nI went to the gym today, but how well did I do? And\nwhere should I improve? Ah, my back hurts slightly... User\nengagement can be sustained and injuries avoided by being\nable to reconstruct 3d human pose and motion, relate it to\ngood training practices, identify errors, and provide early,\nreal-time feedback. In this paper we introduce the \ufb01rst au-\ntomatic system, AIFit , that performs 3d human sensing for\n\ufb01tness training. The system can be used at home, outdoors,\nor at the gym. AIFit is able to reconstruct 3d human pose,\nshape, and motion, reliably segment exercise repetitions,\nand identify in real-time the deviations between standards\nlearnt from trainers, and the execution of a trainee. As\na result, localized, quantitative feedback for correct exe-\ncution of exercises, reduced risk of injury, and continuous\nimprovement is possible. To support research and evalua-\ntion, we introduce the \ufb01rst large scale dataset, Fit3D , con-\ntaining over 3 million images and corresponding 3d human\nshape and motion capture ground truth con\ufb01gurations, with\nover 37 repeated exercises, covering all the major muscle\ngroups, performed by instructors and trainees. Our statisti-\ncal coach is governed by a global parameter that captures\nhow critical it should be of a trainee\u2019s performance. This\nis an important aspect that helps adapt to a student\u2019s level\nof \ufb01tness (i.e. beginner vs. advanced vs. expert), or to the\nexpected accuracy of a 3d pose reconstruction method. We\nshow that, for different values of the global parameter, our\nfeedback system based on 3d pose estimates achieves good\naccuracy compared to the one based on ground-truth mo-\ntion capture. Our statistical coach offers feedback in nat-\nural language, and with spatio-temporal visual grounding.\n1. Introduction\nIn nowadays busy, high pressure working environments,\n\ufb01tness is essential in order to stay in shape, maintain bal-ance, enhance the immune system, and prevent the emer-\ngence of chronic diseases. It is also critical for the elderly in\norder to maintain mobility, combat anxiety, and slow-down\naging. This has increasingly resonated with the broad pub-\nlic. Besides the growing number of standard gym subscrip-\ntions, there are emergent online services (e.g. Peloton, Mir-\nror or ClassPass, among others) that aim to bring \ufb01tness at\nhome. Some trainers run popular Youtube \ufb01tness channels\nor apps (e.g. Athlean-X, The Fitness Marshall, Blogilates,\netc.), and public interest spurs billions of searches and views\nof such instructional video each year. However, whether at\nthe gym, at home, or outdoors, \ufb01tness enthusiasts face some\nof the same outstanding challenges: making sure they exer-\ncise correctly, avoid injury, gain insights into their progress,\nmaintain motivation to get the job done, and ultimately have\nfun. Even when personal trainers are available, their en-\ngagement is typically limited to the time spent with the\ntrainee at the gym. In practice, personal trainers may need\nto joggle between different clients, making it dif\ufb01cult to\nprovide the continuous observation, feedback, and encour-\nagement their clients sometimes need in order to progress.\nThis naturally raises the question whether personal experi-\nence can be improved by leveraging recent advances in 3d\nhuman sensing and AI. To complement human trainers, in\nthis paper we propose AIFit , the \ufb01rst AI-enhanced training\nsystem for \ufb01tness. The system is able to reconstruct 3d hu-\nman pose over time, count repetitions, and automatically\nprovide localized feedback, visually grounded in images of\nthe trainee, and phrased in natural language displayed on\na screen. In order to support research and evaluation, we\nintroduce Fit3D , a large-scale dataset of over 3 million im-\nages and ground truth 3d motion capture poses, collected\nfrom 13 subjects (including one licensed \ufb01tness instructor\nand one advanced \ufb01tness subject), observed by 4 different\nRGB cameras, together with 3d scans of each subject. The\ndataset features 37 exercises consisting of simple and com-\npound motions, covering all major muscle groups and ar-\nticulation types, including, among many others, warm-ups,\n9919\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ANR: Articulated Neural Rendering for Virtual Avatars",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Raj_ANR_Articulated_Neural_Rendering_for_Virtual_Avatars_CVPR_2021_paper.html",
        "author": "Amit Raj, Julian Tanke, James Hays, Minh Vo, Carsten Stoll, Christoph Lassner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Raj_ANR_Articulated_Neural_Rendering_for_Virtual_Avatars_CVPR_2021_paper.pdf",
        "aff": "Facebook Reality Labs; Georgia Tech; Epic Games; University of Bonn",
        "project": "https://anr-avatars.github.io",
        "github": "https://github.com/anr-avatars",
        "arxiv": "2012.12890"
    },
    {
        "title": "AQD: Towards Accurate Quantized Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_AQD_Towards_Accurate_Quantized_Object_Detection_CVPR_2021_paper.html",
        "author": "Peng Chen, Jing Liu, Bohan Zhuang, Mingkui Tan, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_AQD_Towards_Accurate_Quantized_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "South China University of Technology; The University of Adelaide; Monash University; Monash University, The University of Adelaide",
        "project": "",
        "github": "https://github.com/aim-uofa/model-quantization",
        "arxiv": "2007.06919"
    },
    {
        "title": "ARVo: Learning All-Range Volumetric Correspondence for Video Deblurring",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_ARVo_Learning_All-Range_Volumetric_Correspondence_for_Video_Deblurring_CVPR_2021_paper.html",
        "author": "Dongxu Li, Chenchen Xu, Kaihao Zhang, Xin Yu, Yiran Zhong, Wenqi Ren, Hanna Suominen, Hongdong Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_ARVo_Learning_All-Range_Volumetric_Correspondence_for_Video_Deblurring_CVPR_2021_paper.pdf",
        "aff": "UTS; ANU, University of Turku; IIE-CAS; ANU, DATA61-CSIRO; ANU",
        "project": "",
        "github": "",
        "arxiv": "2103.04260"
    },
    {
        "title": "ATSO: Asynchronous Teacher-Student Optimization for Semi-Supervised Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huo_ATSO_Asynchronous_Teacher-Student_Optimization_for_Semi-Supervised_Image_Segmentation_CVPR_2021_paper.html",
        "author": "Xinyue Huo, Lingxi Xie, Jianzhong He, Zijie Yang, Wengang Zhou, Houqiang Li, Qi Tian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huo_ATSO_Asynchronous_Teacher-Student_Optimization_for_Semi-Supervised_Image_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Chinese Academy of Sciences; Huawei Inc.; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Abstract Spatial-Temporal Reasoning via Probabilistic Abduction and Execution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Abstract_Spatial-Temporal_Reasoning_via_Probabilistic_Abduction_and_Execution_CVPR_2021_paper.html",
        "author": "Chi Zhang, Baoxiong Jia, Song-Chun Zhu, Yixin Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Abstract_Spatial-Temporal_Reasoning_via_Probabilistic_Abduction_and_Execution_CVPR_2021_paper.pdf",
        "aff": "UCLA Center for Vision, Cognition, Learning, and Autonomy",
        "project": "",
        "github": "",
        "arxiv": "2103.14230"
    },
    {
        "title": "Accurate Few-Shot Object Detection With Support-Query Mutual Guidance and Hybrid Loss",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Accurate_Few-Shot_Object_Detection_With_Support-Query_Mutual_Guidance_and_Hybrid_CVPR_2021_paper.html",
        "author": "Lu Zhang, Shuigeng Zhou, Jihong Guan, Ji Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Accurate_Few-Shot_Object_Detection_With_Support-Query_Mutual_Guidance_and_Hybrid_CVPR_2021_paper.pdf",
        "aff": "Zhejiang Laboratory, China; Shanghai Key Lab of Intelligent Information Processing, and School of Computer Science, Fudan University, China; Department of Computer Science & Technology, Tongji University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Achieving Robustness in Classification Using Optimal Transport With Hinge Regularization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Serrurier_Achieving_Robustness_in_Classification_Using_Optimal_Transport_With_Hinge_Regularization_CVPR_2021_paper.html",
        "author": "Mathieu Serrurier, Franck Mamalet, Alberto Gonzalez-Sanz, Thibaut Boissin, Jean-Michel Loubes, Eustasio del Barrio",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Serrurier_Achieving_Robustness_in_Classification_Using_Optimal_Transport_With_Hinge_Regularization_CVPR_2021_paper.pdf",
        "aff": "Universit\u00b4e Paul Sabatier; IRT Saint-Exupery; Universidad de Valladolid",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Action Shuffle Alternating Learning for Unsupervised Action Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Action_Shuffle_Alternating_Learning_for_Unsupervised_Action_Segmentation_CVPR_2021_paper.html",
        "author": "Jun Li, Sinisa Todorovic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Action_Shuffle_Alternating_Learning_for_Unsupervised_Action_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Oregon State University",
        "project": "",
        "github": "",
        "arxiv": "2104.02116"
    },
    {
        "title": "Action Unit Memory Network for Weakly Supervised Temporal Action Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Action_Unit_Memory_Network_for_Weakly_Supervised_Temporal_Action_Localization_CVPR_2021_paper.html",
        "author": "Wang Luo, Tianzhu Zhang, Wenfei Yang, Jingen Liu, Tao Mei, Feng Wu, Yongdong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Action_Unit_Memory_Network_for_Weakly_Supervised_Temporal_Action_Localization_CVPR_2021_paper.pdf",
        "aff": "JD AI Research; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2104.14135"
    },
    {
        "title": "Activate or Not: Learning Customized Activation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Activate_or_Not_Learning_Customized_Activation_CVPR_2021_paper.html",
        "author": "Ningning Ma, Xiangyu Zhang, Ming Liu, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_Activate_or_Not_Learning_Customized_Activation_CVPR_2021_paper.pdf",
        "aff": "MEGVII Technology; The Hong Kong University of Science and Technology",
        "project": "",
        "github": "https://github.com/nmaac/acon",
        "arxiv": "2009.04759"
    },
    {
        "title": "Actor-Context-Actor Relation Network for Spatio-Temporal Action Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pan_Actor-Context-Actor_Relation_Network_for_Spatio-Temporal_Action_Localization_CVPR_2021_paper.html",
        "author": "Junting Pan, Siyu Chen, Mike Zheng Shou, Yu Liu, Jing Shao, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_Actor-Context-Actor_Relation_Network_for_Spatio-Temporal_Action_Localization_CVPR_2021_paper.pdf",
        "aff": "Actor-Context-Actor Relation Network for Spatio-Temporal Action Localization\nJunting Pan1\u2217Siyu Chen4\u2217Mike Zheng Shou2\nYu Liu4Jing Shao4Hongsheng Li1,3\n1CUHK-SenseTime Joint Lab, The Chinese University of Hong Kong2Columbia University\n3School of CST, Xidian University4SenseTime Research\nAbstract\nLocalizing persons and recognizing their actions from\nvideos is a challenging task towards high-level video under-\nstanding. Recent advances have been achieved by modeling\ndirect pairwise relations between entities. In this paper, we\ntake one step further, not only model direct relations between\npairs but also take into account indirect higher-order rela-\ntions established upon multiple elements. We propose to\nexplicitly model the Actor-Context-Actor Relation , which\nis the relation between two actors based on their interac-\ntions with the context. To this end, we design an Actor-\nContext-Actor Relation Network (ACAR-Net) which builds\nupon a novel High-order Relation Reasoning Operator and\nan Actor-Context Feature Bank to enable indirect relation\nreasoning for spatio-temporal action localization. Experi-\nments on AVA and UCF101-24 datasets show the advantages\nof modeling actor-context-actor relations, and visualization\nof attention maps further veri\ufb01es that our model is capable of\n\ufb01nding relevant higher-order relations to support action de-\ntection. Notably, our method ranks \ufb01rst in the AVA-Kinetics\naction localization task of ActivityNet Challenge 2020, out-\nperforming other entries by a signi\ufb01cant margin (+6.71\nmAP). The code is available online.1\n1. Introduction\nSpatio-temporal action localization, which requires lo-\ncalizing persons and recognizing their actions from videos,\nis an important task that has drawn increasing attention in\nrecent years [ 15,12,8,46,35,58,52,54,41,29,55,17,20].\nUnlike object detection which can be accomplished solely\nby observing visual appearances, activity recognition usually\ndemands for reasoning about the actors\u2019 interactions with the\nsurrounding context, including environments, other people\nand objects. Take Fig. 1as an example. To recognize the\naction \u201cride\u201d of the person in the red bounding box, we need\n\u2217Equal contribution\n1https://github.com/Siyu-C/ACAR-Net\nActor of Interest\nSupporting Actor\nActor of InterestActor of Interest\nSupporting Actor\nObject  \nActor of Interest\nContext  \nSupporting Actor\nRideDrive   Actor -Context                   Actor -Actor                \n Actor -Actor  & Actor -Object    Actor -Context -Actor (ours)              Context  Figure 1. We contrast our Actor-Context-Actor relation modeling\nwith existing relation reasoning approaches for action localization.\nReasoning relations between pairs of entities may not always be\nsuf\ufb01cient for correctly predicting the action labels of all individuals.\nOur method not only reasons relations between actors, but also\nmodels connections between different actor-context relations. As\nan illustration, the relation between the blue actor and the steering\nwheel (drive) serves as a crucial clue for recognizing the action\nbeing performed by the red actor (ride).\nto observe that he is inside a car, and there is a driver next\nto him. Therefore, most recent progress in spatio-temporal\naction detection has been driven by the success of relation\nmodeling. These approaches focus on modeling relation-\nships in terms of pairwise interactions between entities.\nHowever, it is not always the case that relations between\nelements can be formulated in terms of pairs; often, higher-\norder relations provide crucial clues for accurate action de-\ntection. In Fig. 1, it is dif\ufb01cult to infer the action of the\nred actor given only its relation with the blue actor, or only\nwith the scene context (steering wheel). Instead, in order to\nidentify that the red actor performs the action \u201cride\u201d, one has\nto reason over the interaction between the blue actor and the\ncontext (drive). In other words, it is necessary to capture the\n464\n",
        "project": "",
        "github": "",
        "arxiv": "2006.07976"
    },
    {
        "title": "AdCo: Adversarial Contrast for Efficient Learning of Unsupervised Representations From Self-Trained Negative Adversaries",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_AdCo_Adversarial_Contrast_for_Efficient_Learning_of_Unsupervised_Representations_From_CVPR_2021_paper.html",
        "author": "Qianjiang Hu, Xiao Wang, Wei Hu, Guo-Jun Qi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_AdCo_Adversarial_Contrast_for_Efficient_Learning_of_Unsupervised_Representations_From_CVPR_2021_paper.pdf",
        "aff": "Peking University; Purdue University; Laboratory for MAchine Perception and LEarning (MAPLE)",
        "project": "",
        "github": "https://github.com/maple-research-lab/AdCo",
        "arxiv": "2011.08435"
    },
    {
        "title": "AdaBins: Depth Estimation Using Adaptive Bins",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bhat_AdaBins_Depth_Estimation_Using_Adaptive_Bins_CVPR_2021_paper.html",
        "author": "Shariq Farooq Bhat, Ibraheem Alhashim, Peter Wonka",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bhat_AdaBins_Depth_Estimation_Using_Adaptive_Bins_CVPR_2021_paper.pdf",
        "aff": "KAUST",
        "project": "",
        "github": "",
        "arxiv": "2011.14141"
    },
    {
        "title": "AdaStereo: A Simple and Efficient Approach for Adaptive Stereo Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_AdaStereo_A_Simple_and_Efficient_Approach_for_Adaptive_Stereo_Matching_CVPR_2021_paper.html",
        "author": "Xiao Song, Guorun Yang, Xinge Zhu, Hui Zhou, Zhe Wang, Jianping Shi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_AdaStereo_A_Simple_and_Efficient_Approach_for_Adaptive_Stereo_Matching_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; The Chinese University of Hong Kong; SenseTime Research, Qing Yuan Research Institute, Shanghai Jiao Tong University; SenseTime Research, Shanghai AI Laboratory; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2004.04627"
    },
    {
        "title": "Adaptive Aggregation Networks for Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Adaptive_Aggregation_Networks_for_Class-Incremental_Learning_CVPR_2021_paper.html",
        "author": "Yaoyao Liu, Bernt Schiele, Qianru Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Adaptive_Aggregation_Networks_for_Class-Incremental_Learning_CVPR_2021_paper.pdf",
        "aff": "School of Computing and Information Systems, Singapore Management University; Max Planck Institute for Informatics, Saarland Informatics Campus",
        "project": "",
        "github": "https://class-il.mpi-inf.mpg.de/",
        "arxiv": "2010.05063"
    },
    {
        "title": "Adaptive Class Suppression Loss for Long-Tail Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Adaptive_Class_Suppression_Loss_for_Long-Tail_Object_Detection_CVPR_2021_paper.html",
        "author": "Tong Wang, Yousong Zhu, Chaoyang Zhao, Wei Zeng, Jinqiao Wang, Ming Tang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Adaptive_Class_Suppression_Loss_for_Long-Tail_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Peking University, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; NEXWISE Co., Ltd., Guangzhou, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; ObjectEye Inc., Beijing, China",
        "project": "",
        "github": "https://github.com/CASIA-IVA-Lab/ACSL",
        "arxiv": "2104.00885"
    },
    {
        "title": "Adaptive Consistency Prior Based Deep Network for Image Denoising",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ren_Adaptive_Consistency_Prior_Based_Deep_Network_for_Image_Denoising_CVPR_2021_paper.html",
        "author": "Chao Ren, Xiaohai He, Chuncheng Wang, Zhibo Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ren_Adaptive_Consistency_Prior_Based_Deep_Network_for_Image_Denoising_CVPR_2021_paper.pdf",
        "aff": "College of Electronics and Information Engineering, Sichuan University, Chengdu 610065, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adaptive Consistency Regularization for Semi-Supervised Transfer Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Abuduweili_Adaptive_Consistency_Regularization_for_Semi-Supervised_Transfer_Learning_CVPR_2021_paper.html",
        "author": "Abulikemu Abuduweili, Xingjian Li, Humphrey Shi, Cheng-Zhong Xu, Dejing Dou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Abuduweili_Adaptive_Consistency_Regularization_for_Semi-Supervised_Transfer_Learning_CVPR_2021_paper.pdf",
        "aff": "SHI Lab, University of Oregon; State Key Lab of IOTSC, Department of Computer Science, University of Macau; Big Data Lab, Baidu Research; Big Data Lab, Baidu Research; State Key Lab of IOTSC, Department of Computer Science, University of Macau; Big Data Lab, Baidu Research; SHI Lab, University of Oregon",
        "project": "",
        "github": "https://github.com/Walleclipse/Semi-Supervised-Transfer-Learning-Paddle",
        "arxiv": "2103.02193"
    },
    {
        "title": "Adaptive Convolutions for Structure-Aware Style Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chandran_Adaptive_Convolutions_for_Structure-Aware_Style_Transfer_CVPR_2021_paper.html",
        "author": "Prashanth Chandran, Gaspard Zoss, Paulo Gotardo, Markus Gross, Derek Bradley",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chandran_Adaptive_Convolutions_for_Structure-Aware_Style_Transfer_CVPR_2021_paper.pdf",
        "aff": "DisneyResearch |Studios, Zurich; Department of Computer Science, ETH Zurich; DisneyResearch |Studios, Zurich",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adaptive Cross-Modal Prototypes for Cross-Domain Visual-Language Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Adaptive_Cross-Modal_Prototypes_for_Cross-Domain_Visual-Language_Retrieval_CVPR_2021_paper.html",
        "author": "Yang Liu, Qingchao Chen, Samuel Albanie",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Adaptive_Cross-Modal_Prototypes_for_Cross-Domain_Visual-Language_Retrieval_CVPR_2021_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University; Visual Geometry Group, University of Oxford; National Institute of Health Data Science, Peking University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adaptive Image Transformer for One-Shot Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Adaptive_Image_Transformer_for_One-Shot_Object_Detection_CVPR_2021_paper.html",
        "author": "Ding-Jie Chen, He-Yen Hsieh, Tyng-Luh Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Adaptive_Image_Transformer_for_One-Shot_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Institute of Information Science, Academia Sinica, Taiwan; Institute of Information Science, Academia Sinica, Taiwan and Taiwan AI Labs",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adaptive Methods for Real-World Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dubey_Adaptive_Methods_for_Real-World_Domain_Generalization_CVPR_2021_paper.html",
        "author": "Abhimanyu Dubey, Vignesh Ramanathan, Alex Pentland, Dhruv Mahajan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dubey_Adaptive_Methods_for_Real-World_Domain_Generalization_CVPR_2021_paper.pdf",
        "aff": "Facebook AI; MIT",
        "project": "",
        "github": "",
        "arxiv": "2103.15796"
    },
    {
        "title": "Adaptive Prototype Learning and Allocation for Few-Shot Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Adaptive_Prototype_Learning_and_Allocation_for_Few-Shot_Segmentation_CVPR_2021_paper.html",
        "author": "Gen Li, Varun Jampani, Laura Sevilla-Lara, Deqing Sun, Jonghyun Kim, Joongkyu Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Adaptive_Prototype_Learning_and_Allocation_for_Few-Shot_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Sungkyunkwan University; University of Edinburgh; Google Research",
        "project": "",
        "github": "https://git.io/ASGNet",
        "arxiv": ""
    },
    {
        "title": "Adaptive Rank Estimate in Robust Principal Component Analysis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Adaptive_Rank_Estimate_in_Robust_Principal_Component_Analysis_CVPR_2021_paper.html",
        "author": "Zhengqin Xu, Rui He, Shoulie Xie, Shiqian Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Adaptive_Rank_Estimate_in_Robust_Principal_Component_Analysis_CVPR_2021_paper.pdf",
        "aff": "School of Machinery and Automation, Wuhan University of Science and Technology; Institute of Robotics and Intelligent Systems, Wuhan University of Science and Technology; School of Information Science and Engineering, Wuhan University of Science and Technology; Signal Processing, RF & Optical Dept. Institute for Infocomm Research A*STAR, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adaptive Weighted Discriminator for Training Generative Adversarial Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zadorozhnyy_Adaptive_Weighted_Discriminator_for_Training_Generative_Adversarial_Networks_CVPR_2021_paper.html",
        "author": "Vasily Zadorozhnyy, Qiang Cheng, Qiang Ye",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zadorozhnyy_Adaptive_Weighted_Discriminator_for_Training_Generative_Adversarial_Networks_CVPR_2021_paper.pdf",
        "aff": "Department of Mathematics, University of Kentucky, Lexington, Kentucky 40506-0027; Institute for Biomedical Informatics, Departments of Computer Science and Internal Medicine, University of Kentucky, Lexington, Kentucky 40506-0027",
        "project": "",
        "github": "",
        "arxiv": "2012.03149"
    },
    {
        "title": "AdderSR: Towards Energy Efficient Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_AdderSR_Towards_Energy_Efficient_Image_Super-Resolution_CVPR_2021_paper.html",
        "author": "Dehua Song, Yunhe Wang, Hanting Chen, Chang Xu, Chunjing Xu, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_AdderSR_Towards_Energy_Efficient_Image_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "The University of Sydney; Noah\u2019s Ark Lab, Huawei Technologies; Noah\u2019s Ark Lab, Huawei Technologies; Peking University",
        "project": "",
        "github": "https://github.com/huawei-noah/AdderNet",
        "arxiv": "2009.08891"
    },
    {
        "title": "AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_AdvSim_Generating_Safety-Critical_Scenarios_for_Self-Driving_Vehicles_CVPR_2021_paper.html",
        "author": "Jingkang Wang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat, Sergio Casas, Mengye Ren, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_AdvSim_Generating_Safety-Critical_Scenarios_for_Self-Driving_Vehicles_CVPR_2021_paper.pdf",
        "aff": "Uber ATG2; University of Waterloo3; University of Toronto1, Uber ATG2",
        "project": "",
        "github": "",
        "arxiv": "2101.06549"
    },
    {
        "title": "Adversarial Generation of Continuous Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Skorokhodov_Adversarial_Generation_of_Continuous_Images_CVPR_2021_paper.html",
        "author": "Ivan Skorokhodov, Savva Ignatyev, Mohamed Elhoseiny",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Skorokhodov_Adversarial_Generation_of_Continuous_Images_CVPR_2021_paper.pdf",
        "aff": "Skolkovo Institute of Science and Technology; King Abdullah University of Science and Technology (KAUST)",
        "project": "https://universome.github.io/inr-gan",
        "github": "",
        "arxiv": "2011.12026"
    },
    {
        "title": "Adversarial Imaging Pipelines",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Phan_Adversarial_Imaging_Pipelines_CVPR_2021_paper.html",
        "author": "Buu Phan, Fahim Mannan, Felix Heide",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Phan_Adversarial_Imaging_Pipelines_CVPR_2021_paper.pdf",
        "aff": "Algolux; Algolux, Princeton University",
        "project": "",
        "github": "",
        "arxiv": "2102.03728"
    },
    {
        "title": "Adversarial Invariant Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Adversarial_Invariant_Learning_CVPR_2021_paper.html",
        "author": "Nanyang Ye, Jingxuan Tang, Huayu Deng, Xiao-Yun Zhou, Qianxiao Li, Zhenguo Li, Guang-Zhong Yang, Zhanxing Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ye_Adversarial_Invariant_Learning_CVPR_2021_paper.pdf",
        "aff": "12446\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Adversarial Laser Beam: Effective Physical-World Attack to DNNs in a Blink",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Duan_Adversarial_Laser_Beam_Effective_Physical-World_Attack_to_DNNs_in_a_CVPR_2021_paper.html",
        "author": "Ranjie Duan, Xiaofeng Mao, A. K. Qin, Yuefeng Chen, Shaokai Ye, Yuan He, Yun Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Duan_Adversarial_Laser_Beam_Effective_Physical-World_Attack_to_DNNs_in_a_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group, China; EPFL, Switzerland; Swinburne University of Technology, Australia",
        "project": "",
        "github": "https://github.com/RjDuan/Advlight",
        "arxiv": "2103.06504"
    },
    {
        "title": "Adversarial Robustness Across Representation Spaces",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Awasthi_Adversarial_Robustness_Across_Representation_Spaces_CVPR_2021_paper.html",
        "author": "Pranjal Awasthi, George Yu, Chun-Sung Ferng, Andrew Tomkins, Da-Cheng Juan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Awasthi_Adversarial_Robustness_Across_Representation_Spaces_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "https://github.com/tensorflow/neural-structured-learning/tree/master/research/multi_representation_adversary",
        "arxiv": "2012.00802"
    },
    {
        "title": "Adversarial Robustness Under Long-Tailed Distribution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Adversarial_Robustness_Under_Long-Tailed_Distribution_CVPR_2021_paper.html",
        "author": "Tong Wu, Ziwei Liu, Qingqiu Huang, Yu Wang, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Adversarial_Robustness_Under_Long-Tailed_Distribution_CVPR_2021_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University; Tsinghua University; Huawei; The Chinese University of Hong Kong, SenseTime-CUHK Joint Lab; The Chinese University of Hong Kong, SenseTime-CUHK Joint Lab, Centre of Perceptual and Interactive Intelligence",
        "project": "",
        "github": "https://github.com/wutong16/Adversarial_Long-Tail",
        "arxiv": "2104.02703"
    },
    {
        "title": "Adversarially Adaptive Normalization for Single Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Adversarially_Adaptive_Normalization_for_Single_Domain_Generalization_CVPR_2021_paper.html",
        "author": "Xinjie Fan, Qifei Wang, Junjie Ke, Feng Yang, Boqing Gong, Mingyuan Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_Adversarially_Adaptive_Normalization_for_Single_Domain_Generalization_CVPR_2021_paper.pdf",
        "aff": "The University of Texas at Austin; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2106.01899"
    },
    {
        "title": "Affect2MM: Affective Analysis of Multimedia Content Using Emotion Causality",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mittal_Affect2MM_Affective_Analysis_of_Multimedia_Content_Using_Emotion_Causality_CVPR_2021_paper.html",
        "author": "Trisha Mittal, Puneet Mathur, Aniket Bera, Dinesh Manocha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mittal_Affect2MM_Affective_Analysis_of_Multimedia_Content_Using_Emotion_Causality_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, University of Maryland, College Park, USA; Department of Computer Science, University of Maryland, College Park, USA",
        "project": "https://gamma.umd.edu/affect2mm",
        "github": "",
        "arxiv": "2103.06541"
    },
    {
        "title": "Affective Processes: Stochastic Modelling of Temporal Context for Emotion and Facial Expression Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sanchez_Affective_Processes_Stochastic_Modelling_of_Temporal_Context_for_Emotion_and_CVPR_2021_paper.html",
        "author": "Enrique Sanchez, Mani Kumar Tellamekala, Michel Valstar, Georgios Tzimiropoulos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sanchez_Affective_Processes_Stochastic_Modelling_of_Temporal_Context_for_Emotion_and_CVPR_2021_paper.pdf",
        "aff": "University of Nottingham, Nottingham, UK; Samsung AI Center, Cambridge, UK; Queen Mary University London, London, UK",
        "project": "",
        "github": "",
        "arxiv": "2103.13372"
    },
    {
        "title": "Affordance Transfer Learning for Human-Object Interaction Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Affordance_Transfer_Learning_for_Human-Object_Interaction_Detection_CVPR_2021_paper.html",
        "author": "Zhi Hou, Baosheng Yu, Yu Qiao, Xiaojiang Peng, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Affordance_Transfer_Learning_for_Human-Object_Interaction_Detection_CVPR_2021_paper.pdf",
        "aff": "Shenzhen Technology University; School of Computer Science, Faculty of Engineering, The University of Sydney, Australia; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/zhihou7/HOI-CL",
        "arxiv": "2104.02867"
    },
    {
        "title": "All Labels Are Not Created Equal: Enhancing Semi-Supervision via Label Grouping and Co-Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nassar_All_Labels_Are_Not_Created_Equal_Enhancing_Semi-Supervision_via_Label_CVPR_2021_paper.html",
        "author": "Islam Nassar, Samitha Herath, Ehsan Abbasnejad, Wray Buntine, Gholamreza Haffari",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nassar_All_Labels_Are_Not_Created_Equal_Enhancing_Semi-Supervision_via_Label_CVPR_2021_paper.pdf",
        "aff": "Dept of Data Science and AI, Faculty of IT, Monash University, Australia; Australian Institute for Machine Learning, University of Adelaide, Australia",
        "project": "",
        "github": "https://github.com/islam-nassar/semco",
        "arxiv": "2104.05248"
    },
    {
        "title": "Alpha-Refine: Boosting Tracking Performance by Precise Bounding Box Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Alpha-Refine_Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation_CVPR_2021_paper.html",
        "author": "Bin Yan, Xinyu Zhang, Dong Wang, Huchuan Lu, Xiaoyun Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Alpha-Refine_Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation_CVPR_2021_paper.pdf",
        "aff": "Remark AI; School of Information and Communication Engineering, Dalian University of Technology, China; School of Information and Communication Engineering, Dalian University of Technology, China; Peng Cheng Laboratory",
        "project": "",
        "github": "https://github.com/MasterBin-IIAU/AlphaRe\ufb01ne",
        "arxiv": ""
    },
    {
        "title": "AlphaMatch: Improving Consistency for Semi-Supervised Learning With Alpha-Divergence",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gong_AlphaMatch_Improving_Consistency_for_Semi-Supervised_Learning_With_Alpha-Divergence_CVPR_2021_paper.html",
        "author": "Chengyue Gong, Dilin Wang, Qiang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gong_AlphaMatch_Improving_Consistency_for_Semi-Supervised_Learning_With_Alpha-Divergence_CVPR_2021_paper.pdf",
        "aff": "University of Texas at Austin",
        "project": "",
        "github": "",
        "arxiv": "2011.11779"
    },
    {
        "title": "Amalgamating Knowledge From Heterogeneous Graph Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jing_Amalgamating_Knowledge_From_Heterogeneous_Graph_Neural_Networks_CVPR_2021_paper.html",
        "author": "Yongcheng Jing, Yiding Yang, Xinchao Wang, Mingli Song, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jing_Amalgamating_Knowledge_From_Heterogeneous_Graph_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "Stevens Institute of Technology; Zhejiang University; National University of Singapore; The University of Sydney",
        "project": "",
        "github": "https://github.com/ycjing/AmalgamateGNN.PyTorch",
        "arxiv": ""
    },
    {
        "title": "An Alternative Probabilistic Interpretation of the Huber Loss",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Meyer_An_Alternative_Probabilistic_Interpretation_of_the_Huber_Loss_CVPR_2021_paper.html",
        "author": "Gregory P. Meyer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Meyer_An_Alternative_Probabilistic_Interpretation_of_the_Huber_Loss_CVPR_2021_paper.pdf",
        "aff": "Uber Advanced Technologies Group",
        "project": "",
        "github": "",
        "arxiv": "1911.02088"
    },
    {
        "title": "Anchor-Constrained Viterbi for Set-Supervised Action Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Anchor-Constrained_Viterbi_for_Set-Supervised_Action_Segmentation_CVPR_2021_paper.html",
        "author": "Jun Li, Sinisa Todorovic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Anchor-Constrained_Viterbi_for_Set-Supervised_Action_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Oregon State University",
        "project": "",
        "github": "",
        "arxiv": "2104.02113"
    },
    {
        "title": "Anchor-Free Person Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Anchor-Free_Person_Search_CVPR_2021_paper.html",
        "author": "Yichao Yan, Jinpeng Li, Jie Qin, Song Bai, Shengcai Liao, Li Liu, Fan Zhu, Ling Shao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Anchor-Free_Person_Search_CVPR_2021_paper.pdf",
        "aff": "University of Oxford, UK; Inception Institute of Arti\ufb01cial Intelligence (IIAI), UAE",
        "project": "",
        "github": "https://github.com/daodaofr/AlignPS",
        "arxiv": "2103.11617"
    },
    {
        "title": "Animating Pictures With Eulerian Motion Fields",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Holynski_Animating_Pictures_With_Eulerian_Motion_Fields_CVPR_2021_paper.html",
        "author": "Aleksander Holynski, Brian L. Curless, Steven M. Seitz, Richard Szeliski",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Holynski_Animating_Pictures_With_Eulerian_Motion_Fields_CVPR_2021_paper.pdf",
        "aff": "University of Washington",
        "project": "http://eulerian.cs.washington.edu",
        "github": "",
        "arxiv": "2011.15128"
    },
    {
        "title": "Anomaly Detection in Video via Self-Supervised and Multi-Task Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Georgescu_Anomaly_Detection_in_Video_via_Self-Supervised_and_Multi-Task_Learning_CVPR_2021_paper.html",
        "author": "Mariana-Iuliana Georgescu, Antonio Barbalau, Radu Tudor Ionescu, Fahad Shahbaz Khan, Marius Popescu, Mubarak Shah",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Georgescu_Anomaly_Detection_in_Video_via_Self-Supervised_and_Multi-Task_Learning_CVPR_2021_paper.pdf",
        "aff": "University of Bucharest, Romania; SecurifAI, Romania; University of Central Florida, Orlando, FL; MBZ University of Arti\ufb01cial Intelligence, Abu Dhabi; University of Bucharest, Romania",
        "project": "",
        "github": "",
        "arxiv": "2011.07491"
    },
    {
        "title": "Anti-Adversarially Manipulated Attributions for Weakly and Semi-Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Anti-Adversarially_Manipulated_Attributions_for_Weakly_and_Semi-Supervised_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Jungbeom Lee, Eunji Kim, Sungroh Yoon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Anti-Adversarially_Manipulated_Attributions_for_Weakly_and_Semi-Supervised_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; ASRI, INMC, ISRC, and Institute of Engineering Research, Seoul National University",
        "project": "",
        "github": "https://github.com/jbeomlee93/AdvCAM",
        "arxiv": "2103.08896"
    },
    {
        "title": "Anti-Aliasing Semantic Reconstruction for Few-Shot Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Anti-Aliasing_Semantic_Reconstruction_for_Few-Shot_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Binghao Liu, Yao Ding, Jianbin Jiao, Xiangyang Ji, Qixiang Ye",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Anti-Aliasing_Semantic_Reconstruction_for_Few-Shot_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "PriSDL, EECE, University of Chinese Academy of Sciences; Department of Automation, Tsinghua University",
        "project": "",
        "github": "github.com/Bibkiller/ASR",
        "arxiv": "2106.00184"
    },
    {
        "title": "Anticipating Human Actions by Correlating Past With the Future With Jaccard Similarity Measures",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fernando_Anticipating_Human_Actions_by_Correlating_Past_With_the_Future_With_CVPR_2021_paper.html",
        "author": "Basura Fernando, Samitha Herath",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fernando_Anticipating_Human_Actions_by_Correlating_Past_With_the_Future_With_CVPR_2021_paper.pdf",
        "aff": "Dept of Data Science & AI, Monash University; IHPC, A*STAR, Singapore",
        "project": "",
        "github": "",
        "arxiv": "2105.12414"
    },
    {
        "title": "Anycost GANs for Interactive Image Synthesis and Editing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Anycost_GANs_for_Interactive_Image_Synthesis_and_Editing_CVPR_2021_paper.html",
        "author": "Ji Lin, Richard Zhang, Frieder Ganz, Song Han, Jun-Yan Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Anycost_GANs_for_Interactive_Image_Synthesis_and_Editing_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; CMU; MIT",
        "project": "https://project-link.com/",
        "github": "https://github.com/",
        "arxiv": "2103.03243"
    },
    {
        "title": "Architectural Adversarial Robustness: The Case for Deep Pursuit",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cazenavette_Architectural_Adversarial_Robustness_The_Case_for_Deep_Pursuit_CVPR_2021_paper.html",
        "author": "George Cazenavette, Calvin Murdock, Simon Lucey",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cazenavette_Architectural_Adversarial_Robustness_The_Case_for_Deep_Pursuit_CVPR_2021_paper.pdf",
        "aff": "Carnegie Mellon University, University of Adelaide; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2011.14427"
    },
    {
        "title": "Are Labels Always Necessary for Classifier Accuracy Evaluation?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Are_Labels_Always_Necessary_for_Classifier_Accuracy_Evaluation_CVPR_2021_paper.html",
        "author": "Weijian Deng, Liang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Are_Labels_Always_Necessary_for_Classifier_Accuracy_Evaluation_CVPR_2021_paper.pdf",
        "aff": "Australian National University",
        "project": "",
        "github": "",
        "arxiv": "2007.02915"
    },
    {
        "title": "ArtCoder: An End-to-End Method for Generating Scanning-Robust Stylized QR Codes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Su_ArtCoder_An_End-to-End_Method_for_Generating_Scanning-Robust_Stylized_QR_Codes_CVPR_2021_paper.html",
        "author": "Hao Su, Jianwei Niu, Xuefeng Liu, Qingfeng Li, Ji Wan, Mingliang Xu, Tao Ren",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Su_ArtCoder_An_End-to-End_Method_for_Generating_Scanning-Robust_Stylized_QR_Codes_CVPR_2021_paper.pdf",
        "aff": "Hangzhou Innovation Institute, Beihang University; Industrial Technology Research Institute, School of Information Engineering, Zhengzhou University; State Key Lab of VR Technology and System, School of Computer Science and Engineering, Beihang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "ArtEmis: Affective Language for Visual Art",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Achlioptas_ArtEmis_Affective_Language_for_Visual_Art_CVPR_2021_paper.html",
        "author": "Panos Achlioptas, Maks Ovsjanikov, Kilichbek Haydarov, Mohamed Elhoseiny, Leonidas J. Guibas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Achlioptas_ArtEmis_Affective_Language_for_Visual_Art_CVPR_2021_paper.pdf",
        "aff": "King Abdullah University of Science and Technology (KAUST), Stanford University; Stanford University; King Abdullah University of Science and Technology (KAUST); LIX, Ecole Polytechnique, IP Paris",
        "project": "https://artemisdataset.org",
        "github": "",
        "arxiv": "2101.07396"
    },
    {
        "title": "ArtFlow: Unbiased Image Style Transfer via Reversible Neural Flows",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/An_ArtFlow_Unbiased_Image_Style_Transfer_via_Reversible_Neural_Flows_CVPR_2021_paper.html",
        "author": "Jie An, Siyu Huang, Yibing Song, Dejing Dou, Wei Liu, Jiebo Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/An_ArtFlow_Unbiased_Image_Style_Transfer_via_Reversible_Neural_Flows_CVPR_2021_paper.pdf",
        "aff": "ArtFlow: Unbiased Image Style Transfer via Reversible Neural Flows\nJie An1\u2217Siyu Huang2\u2217Yibing Song3Dejing Dou2Wei Liu4Jiebo Luo1\n1University of Rochester2Baidu Research3Tencent AI Lab4Tencent Data Platform\n{jan6,jluo }@cs.rochester.edu {huangsiyu,doudejing }@baidu.com\nyibingsong.cv@gmail.com wl2223@columbia.edu\nAbstract\nUniversal style transfer retains styles from reference\nimages in content images. While existing methods have\nachieved state-of-the-art style transfer performance, they\nare not aware of the content leak phenomenon that the im-\nage content may corrupt after several rounds of stylization\nprocess. In this paper, we propose ArtFlow to prevent con-\ntent leak during universal style transfer. ArtFlow consists\nof reversible neural \ufb02ows and an unbiased feature transfer\nmodule. It supports both forward and backward inferences\nand operates in a projection-transfer-reversion scheme. The\nforward inference projects input images into deep features,\nwhile the backward inference remaps deep features back to\ninput images in a lossless and unbiased way. Extensive ex-\nperiments demonstrate that ArtFlow achieves comparable\nperformance to state-of-the-art style transfer methods while\navoiding content leak.\n1. Introduction\nNeural style transfer aims at transferring the artistic\nstyle from a reference image to a content image. Start-\ning from [ 11,13], numerous works based on iterative op-\ntimization [ 12,44,30,34] and feed-forward networks [ 23,\n53,3,63] improve style transfer from either visual qual-\nity or computational ef\ufb01ciency. Despite tremendous efforts,\nthese methods do not generalize well for multiple types\nof style transfer. Universal style transfer (UST) is pro-\nposed to improve this generalization ability. The represen-\ntative UST methods include AdaIN [ 20], WCT [ 32], and\nAvatar-Net [ 45]. These methods are continuously extended\nby [15,22,60,1,45,33,40,31,2,56]. While achieving\nfavorable results as well as generalizations, these methods\nare limited to disentangling and reconstructing image con-\ntent during the stylization process. Fig. 1shows some ex-\namples. Existing methods [ 32,20,45] effectively stylize\n\u2217J. An and S. Huang contribute equally. This work is done when J.\nAn is an intern in Tencent AI Lab. The code is available at https://\ngithub.com/pkuanjie/ArtFlow .\nAdaIN WCT\n(a) Content (c) Round 1 (d) Round 20 (b) Style\nAvatar-Net\nFigure 1. Content leak visualization. Existing style transfer meth-\nods are not effective to preserve image content after several rounds\nof stylization process as shown in (d), although their performance\nis state-of-the-art in the \ufb01rst round as shown in (c).\ncontent images in (c). However, image contents are cor-\nrupted after several rounds of stylization process where we\nsend the reference image and the output result into these\nmethods. We de\ufb01ne this phenomenon as content leak and\nprovide an analysis in the following:\nContent leak appears due to the design of UST methods\nthat usually consist of three parts: the \ufb01rst part is a \ufb01xed en-\ncoder for image embedding, the second part is a learnable\ndecoder to remap deep features back to images, and the third\npart is a style transfer module based on deep features. We\nobserve that the \ufb01rst part is \ufb01xed. The appearance of content\nleak indicates the accumulated image reconstruction errors\nbrought by the decoder, or the biased training process of ei-\nther the decoder or the style transfer module. Speci\ufb01cally,\nthe content leaks of WCT [ 32] and its variants [ 31,40,56]\nis mainly caused by the image reconstruction error of the\ndecoder. The content leak of AdaIN series [ 20,22,60] and\nAvatar-Net [ 45] are additionally caused by the biased de-\ncoder training and a biased style transfer module, respec-\ntively. Sec. 3shows more analyses.\nIn this work, we propose an unbiased style transfer\nframework called ArtFlow to robustify exisiting UST meth-\nods upon overcoming content leak. Different from the\nprevalent encoder-transfer-decoder structure, ArtFlow in-\n862\n",
        "project": "",
        "github": "",
        "arxiv": "2103.16877"
    },
    {
        "title": "Asymmetric Gained Deep Image Compression With Continuous Rate Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cui_Asymmetric_Gained_Deep_Image_Compression_With_Continuous_Rate_Adaptation_CVPR_2021_paper.html",
        "author": "Ze Cui, Jing Wang, Shangyin Gao, Tiansheng Guo, Yihui Feng, Bo Bai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cui_Asymmetric_Gained_Deep_Image_Compression_With_Continuous_Rate_Adaptation_CVPR_2021_paper.pdf",
        "aff": "Huawei Technologies, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Asymmetric Metric Learning for Knowledge Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Budnik_Asymmetric_Metric_Learning_for_Knowledge_Transfer_CVPR_2021_paper.html",
        "author": "Mateusz Budnik, Yannis Avrithis",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Budnik_Asymmetric_Metric_Learning_for_Knowledge_Transfer_CVPR_2021_paper.pdf",
        "aff": "Inria, Univ Rennes, CNRS, IRISA",
        "project": "",
        "github": "https://github.com/budnikm/aml",
        "arxiv": "2006.16331"
    },
    {
        "title": "Attention-Guided Image Compression by Deep Reconstruction of Compressive Sensed Saliency Skeleton",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Attention-Guided_Image_Compression_by_Deep_Reconstruction_of_Compressive_Sensed_Saliency_CVPR_2021_paper.html",
        "author": "Xi Zhang, Xiaolin Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Attention-Guided_Image_Compression_by_Deep_Reconstruction_of_Compressive_Sensed_Saliency_CVPR_2021_paper.pdf",
        "aff": "McMaster Univeristy; Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2103.15368"
    },
    {
        "title": "AttentiveNAS: Improving Neural Architecture Search via Attentive Sampling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_AttentiveNAS_Improving_Neural_Architecture_Search_via_Attentive_Sampling_CVPR_2021_paper.html",
        "author": "Dilin Wang, Meng Li, Chengyue Gong, Vikas Chandra",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_AttentiveNAS_Improving_Neural_Architecture_Search_via_Attentive_Sampling_CVPR_2021_paper.pdf",
        "aff": "Facebook; University of Texas at Austin",
        "project": "",
        "github": "https://github.com/facebookresearch/AttentiveNAS",
        "arxiv": "2011.09011"
    },
    {
        "title": "Audio-Driven Emotional Video Portraits",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ji_Audio-Driven_Emotional_Video_Portraits_CVPR_2021_paper.html",
        "author": "Xinya Ji, Hang Zhou, Kaisiyuan Wang, Wayne Wu, Chen Change Loy, Xun Cao, Feng Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Audio-Driven_Emotional_Video_Portraits_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong; S-Lab, Nanyang Technological University; BNRist and school of software, Tsinghua University; The University of Sydney; Nanjing University; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2104.07452"
    },
    {
        "title": "Audio-Visual Instance Discrimination with Cross-Modal Agreement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Morgado_Audio-Visual_Instance_Discrimination_with_Cross-Modal_Agreement_CVPR_2021_paper.html",
        "author": "Pedro Morgado, Nuno Vasconcelos, Ishan Misra",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Morgado_Audio-Visual_Instance_Discrimination_with_Cross-Modal_Agreement_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; UC San Diego",
        "project": "",
        "github": "",
        "arxiv": "2004.12943"
    },
    {
        "title": "Augmentation Strategies for Learning With Noisy Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nishi_Augmentation_Strategies_for_Learning_With_Noisy_Labels_CVPR_2021_paper.html",
        "author": "Kento Nishi, Yi Ding, Alex Rich, Tobias Hollerer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nishi_Augmentation_Strategies_for_Learning_With_Noisy_Labels_CVPR_2021_paper.pdf",
        "aff": "University of California Santa Barbara, Santa Barbara CA, USA; Lynbrook High School, San Jose CA, USA",
        "project": "",
        "github": "https://github.com/KentoNishi/Augmentation-for-LNL",
        "arxiv": "2103.02130"
    },
    {
        "title": "Auto-Exposure Fusion for Single-Image Shadow Removal",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Auto-Exposure_Fusion_for_Single-Image_Shadow_Removal_CVPR_2021_paper.html",
        "author": "Lan Fu, Changqing Zhou, Qing Guo, Felix Juefei-Xu, Hongkai Yu, Wei Feng, Yang Liu, Song Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fu_Auto-Exposure_Fusion_for_Single-Image_Shadow_Removal_CVPR_2021_paper.pdf",
        "aff": "University of South Carolina, USA; Nanyang Technological University, Singapore; Cleveland State University, USA; Tianjin University, China; Alibaba Group, USA",
        "project": "",
        "github": "https://github.com/tsingqguo/exposure-fusion-shadow-removal",
        "arxiv": "2103.01255"
    },
    {
        "title": "AutoDO: Robust AutoAugment for Biased Data With Label Noise via Scalable Probabilistic Implicit Differentiation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gudovskiy_AutoDO_Robust_AutoAugment_for_Biased_Data_With_Label_Noise_via_CVPR_2021_paper.html",
        "author": "Denis Gudovskiy, Luca Rigazio, Shun Ishizaka, Kazuki Kozuka, Sotaro Tsukizawa",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gudovskiy_AutoDO_Robust_AutoAugment_for_Biased_Data_With_Label_Noise_via_CVPR_2021_paper.pdf",
        "aff": "Panasonic AI Lab, USA; Panasonic Technology Division, Japan; AIoli Labs, USA",
        "project": "",
        "github": "github.com/gudovskiy/autodo",
        "arxiv": "2103.05863"
    },
    {
        "title": "AutoFlow: Learning a Better Training Set for Optical Flow",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_AutoFlow_Learning_a_Better_Training_Set_for_Optical_Flow_CVPR_2021_paper.html",
        "author": "Deqing Sun, Daniel Vlasic, Charles Herrmann, Varun Jampani, Michael Krainin, Huiwen Chang, Ramin Zabih, William T. Freeman, Ce Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_AutoFlow_Learning_a_Better_Training_Set_for_Optical_Flow_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "https://autoflow-google.github.io",
        "arxiv": "2104.14544"
    },
    {
        "title": "AutoInt: Automatic Integration for Fast Neural Volume Rendering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lindell_AutoInt_Automatic_Integration_for_Fast_Neural_Volume_Rendering_CVPR_2021_paper.html",
        "author": "David B. Lindell, Julien N. P. Martel, Gordon Wetzstein",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lindell_AutoInt_Automatic_Integration_for_Fast_Neural_Volume_Rendering_CVPR_2021_paper.pdf",
        "aff": "Stanford University",
        "project": "http://www.computationalimaging.org/publications/automatic-integration/",
        "github": "",
        "arxiv": "2012.01714"
    },
    {
        "title": "Automated Log-Scale Quantization for Low-Cost Deep Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Oh_Automated_Log-Scale_Quantization_for_Low-Cost_Deep_Neural_Networks_CVPR_2021_paper.html",
        "author": "Sangyun Oh, Hyeonuk Sim, Sugil Lee, Jongeun Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Oh_Automated_Log-Scale_Quantization_for_Low-Cost_Deep_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Engineering, UNIST, Ulsan, Korea; Department of Electrical Engineering, UNIST, Ulsan, Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Automatic Correction of Internal Units in Generative Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tousi_Automatic_Correction_of_Internal_Units_in_Generative_Neural_Networks_CVPR_2021_paper.html",
        "author": "Ali Tousi, Haedong Jeong, Jiyeon Han, Hwanil Choi, Jaesik Choi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tousi_Automatic_Correction_of_Internal_Units_in_Generative_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST), South Korea; Ulsan National Institute of Science and Technology (UNIST), South Korea; INEEJI, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2104.06118"
    },
    {
        "title": "Automatic Vertebra Localization and Identification in CT by Spine Rectification and Anatomically-Constrained Optimization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Automatic_Vertebra_Localization_and_Identification_in_CT_by_Spine_Rectification_CVPR_2021_paper.html",
        "author": "Fakai Wang, Kang Zheng, Le Lu, Jing Xiao, Min Wu, Shun Miao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Automatic_Vertebra_Localization_and_Identification_in_CT_by_Spine_Rectification_CVPR_2021_paper.pdf",
        "aff": "Ping An Technology, Shenzhen, China; PAII Inc., Bethesda, Maryland, USA; University of Maryland College Park, USA",
        "project": "",
        "github": "",
        "arxiv": "2012.07947"
    },
    {
        "title": "Autoregressive Stylized Motion Synthesis With Generative Flow",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Autoregressive_Stylized_Motion_Synthesis_With_Generative_Flow_CVPR_2021_paper.html",
        "author": "Yu-Hui Wen, Zhipeng Yang, Hongbo Fu, Lin Gao, Yanan Sun, Yong-Jin Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wen_Autoregressive_Stylized_Motion_Synthesis_With_Generative_Flow_CVPR_2021_paper.pdf",
        "aff": "School of Creative Media, City University of Hong Kong; Beijing Key Laboratory of Mobile Computing and Pervasive Device, ICT, CAS; CS Dept, BNRist, Tsinghua University; University of Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "BABEL: Bodies, Action and Behavior With English Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Punnakkal_BABEL_Bodies_Action_and_Behavior_With_English_Labels_CVPR_2021_paper.html",
        "author": "Abhinanda R. Punnakkal, Arjun Chandrasekaran, Nikos Athanasiou, Alejandra Quiros-Ramirez, Michael J. Black",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Punnakkal_BABEL_Bodies_Action_and_Behavior_With_English_Labels_CVPR_2021_paper.pdf",
        "aff": "Universit\u00e4t Konstanz, Konstanz, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "project": "https://babel.is.tue.mpg.de/",
        "github": "",
        "arxiv": "2106.09696"
    },
    {
        "title": "BASAR:Black-Box Attack on Skeletal Action Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Diao_BASARBlack-Box_Attack_on_Skeletal_Action_Recognition_CVPR_2021_paper.html",
        "author": "Yunfeng Diao, Tianjia Shao, Yong-Liang Yang, Kun Zhou, He Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Diao_BASARBlack-Box_Attack_on_Skeletal_Action_Recognition_CVPR_2021_paper.pdf",
        "aff": "University of Bath, UK; State Key Lab of CAD&CG, Zhejiang University, China; University of Leeds, UK; University of Leeds, UK and Southwest Jiaotong University, China",
        "project": "",
        "github": "",
        "arxiv": "2103.05266"
    },
    {
        "title": "BBAM: Bounding Box Attribution Map for Weakly Supervised Semantic and Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_BBAM_Bounding_Box_Attribution_Map_for_Weakly_Supervised_Semantic_and_CVPR_2021_paper.html",
        "author": "Jungbeom Lee, Jihun Yi, Chaehun Shin, Sungroh Yoon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_BBAM_Bounding_Box_Attribution_Map_for_Weakly_Supervised_Semantic_and_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; ASRI, INMC, ISRC, and Institute of Engineering Research, Seoul National University",
        "project": "",
        "github": "https://github.com/jbeomlee93/BBAM",
        "arxiv": "2103.08907"
    },
    {
        "title": "BCNet: Searching for Network Width With Bilaterally Coupled Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Su_BCNet_Searching_for_Network_Width_With_Bilaterally_Coupled_Network_CVPR_2021_paper.html",
        "author": "Xiu Su, Shan You, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Su_BCNet_Searching_for_Network_Width_With_Bilaterally_Coupled_Network_CVPR_2021_paper.pdf",
        "aff": "Department of Automation, Tsinghua University, Institute for Arti\ufb01cial Intelligence, Tsinghua University (THUAI), Beijing National Research Center for Information Science and Technology (BNRist); School of Computer Science, Faculty of Engineering, The University of Sydney, Australia; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2105.10533"
    },
    {
        "title": "BRepNet: A Topological Message Passing System for Solid Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lambourne_BRepNet_A_Topological_Message_Passing_System_for_Solid_Models_CVPR_2021_paper.html",
        "author": "Joseph G. Lambourne, Karl D.D. Willis, Pradeep Kumar Jayaraman, Aditya Sanghi, Peter Meltzer, Hooman Shayani",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lambourne_BRepNet_A_Topological_Message_Passing_System_for_Solid_Models_CVPR_2021_paper.pdf",
        "aff": "UCL, Computer Science; Autodesk Research",
        "project": "",
        "github": "",
        "arxiv": "2104.00706"
    },
    {
        "title": "Back to Event Basics: Self-Supervised Learning of Image Reconstruction for Event Cameras via Photometric Constancy",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Paredes-Valles_Back_to_Event_Basics_Self-Supervised_Learning_of_Image_Reconstruction_for_CVPR_2021_paper.html",
        "author": "Federico Paredes-Valles, Guido C. H. E. de Croon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Paredes-Valles_Back_to_Event_Basics_Self-Supervised_Learning_of_Image_Reconstruction_for_CVPR_2021_paper.pdf",
        "aff": "Micro Air Vehicle Laboratory, Delft University of Technology, The Netherlands",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Back to the Feature: Learning Robust Camera Localization From Pixels To Pose",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sarlin_Back_to_the_Feature_Learning_Robust_Camera_Localization_From_Pixels_CVPR_2021_paper.html",
        "author": "Paul-Edouard Sarlin, Ajaykumar Unagar, Mans Larsson, Hugo Germain, Carl Toft, Viktor Larsson, Marc Pollefeys, Vincent Lepetit, Lars Hammarstrand, Fredrik Kahl, Torsten Sattler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sarlin_Back_to_the_Feature_Learning_Robust_Camera_Localization_From_Pixels_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; Department of Computer Science, ETH Zurich; Ecole des Ponts; Chalmers University of Technology; Czech Technical University in Prague",
        "project": "",
        "github": "github.com/cvg/pixloc",
        "arxiv": "2103.09213"
    },
    {
        "title": "Back-Tracing Representative Points for Voting-Based 3D Object Detection in Point Clouds",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Back-Tracing_Representative_Points_for_Voting-Based_3D_Object_Detection_in_Point_CVPR_2021_paper.html",
        "author": "Bowen Cheng, Lu Sheng, Shaoshuai Shi, Ming Yang, Dong Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Back-Tracing_Representative_Points_for_Voting-Based_3D_Object_Detection_in_Point_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong; College of Software, Beihang University; The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": "2104.06114"
    },
    {
        "title": "Backdoor Attacks Against Deep Learning Systems in the Physical World",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wenger_Backdoor_Attacks_Against_Deep_Learning_Systems_in_the_Physical_World_CVPR_2021_paper.html",
        "author": "Emily Wenger, Josephine Passananti, Arjun Nitin Bhagoji, Yuanshun Yao, Haitao Zheng, Ben Y. Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wenger_Backdoor_Attacks_Against_Deep_Learning_Systems_in_the_Physical_World_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, University of Chicago",
        "project": "",
        "github": "",
        "arxiv": "2006.14580"
    },
    {
        "title": "Background Splitting: Finding Rare Classes in a Sea of Background",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mullapudi_Background_Splitting_Finding_Rare_Classes_in_a_Sea_of_Background_CVPR_2021_paper.html",
        "author": "Ravi Teja Mullapudi, Fait Poms, William R. Mark, Deva Ramanan, Kayvon Fatahalian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mullapudi_Background_Splitting_Finding_Rare_Classes_in_a_Sea_of_Background_CVPR_2021_paper.pdf",
        "aff": "Stanford University; Carnegie Mellon University; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2008.12873"
    },
    {
        "title": "Background-Aware Pooling and Noise-Aware Loss for Weakly-Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Oh_Background-Aware_Pooling_and_Noise-Aware_Loss_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Youngmin Oh, Beomjun Kim, Bumsub Ham",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Oh_Background-Aware_Pooling_and_Noise-Aware_Loss_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University",
        "project": "",
        "github": "",
        "arxiv": "2104.00905"
    },
    {
        "title": "BasicVSR: The Search for Essential Components in Video Super-Resolution and Beyond",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chan_BasicVSR_The_Search_for_Essential_Components_in_Video_Super-Resolution_and_CVPR_2021_paper.html",
        "author": "Kelvin C.K. Chan, Xintao Wang, Ke Yu, Chao Dong, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chan_BasicVSR_The_Search_for_Essential_Components_in_Video_Super-Resolution_and_CVPR_2021_paper.pdf",
        "aff": "Shenzhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; CUHK \u2013 SenseTime Joint Lab, The Chinese University of Hong Kong; Applied Research Center, Tencent PCG; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "",
        "arxiv": "2012.02181"
    },
    {
        "title": "Bayesian Nested Neural Networks for Uncertainty Calibration and Adaptive Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cui_Bayesian_Nested_Neural_Networks_for_Uncertainty_Calibration_and_Adaptive_Compression_CVPR_2021_paper.html",
        "author": "Yufei Cui, Ziquan Liu, Qiao Li, Antoni B. Chan, Chun Jason Xue",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cui_Bayesian_Nested_Neural_Networks_for_Uncertainty_Calibration_and_Adaptive_Compression_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, City University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2101.11353"
    },
    {
        "title": "Behavior-Driven Synthesis of Human Dynamics",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Blattmann_Behavior-Driven_Synthesis_of_Human_Dynamics_CVPR_2021_paper.html",
        "author": "Andreas Blattmann, Timo Milbich, Michael Dorkenwald, Bjorn Ommer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Blattmann_Behavior-Driven_Synthesis_of_Human_Dynamics_CVPR_2021_paper.pdf",
        "aff": "Heidelberg Collaboratory for Image Processing, IWR, Heidelberg University, Germany",
        "project": "https://cutt.ly/5l7rXEp",
        "github": "",
        "arxiv": "2103.04677"
    },
    {
        "title": "Benchmarking Representation Learning for Natural World Image Collections",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Van_Horn_Benchmarking_Representation_Learning_for_Natural_World_Image_Collections_CVPR_2021_paper.html",
        "author": "Grant Van Horn, Elijah Cole, Sara Beery, Kimberly Wilber, Serge Belongie, Oisin Mac Aodha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Van_Horn_Benchmarking_Representation_Learning_for_Natural_World_Image_Collections_CVPR_2021_paper.pdf",
        "aff": "Cornell University; Caltech; University of Edinburgh; Google",
        "project": "",
        "github": "www.github.com/visipedia/newt",
        "arxiv": "2103.16483"
    },
    {
        "title": "Beyond Bounding-Box: Convex-Hull Feature Adaptation for Oriented and Densely Packed Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Beyond_Bounding-Box_Convex-Hull_Feature_Adaptation_for_Oriented_and_Densely_Packed_CVPR_2021_paper.html",
        "author": "Zonghao Guo, Chang Liu, Xiaosong Zhang, Jianbin Jiao, Xiangyang Ji, Qixiang Ye",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Beyond_Bounding-Box_Convex-Hull_Feature_Adaptation_for_Oriented_and_Densely_Packed_CVPR_2021_paper.pdf",
        "aff": "Tsinghua University, Beijing, China; University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "github.com/SDL-GuoZonghao/BeyondBoundingBox",
        "arxiv": ""
    },
    {
        "title": "Beyond Image to Depth: Improving Depth Prediction Using Echoes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Parida_Beyond_Image_to_Depth_Improving_Depth_Prediction_Using_Echoes_CVPR_2021_paper.html",
        "author": "Kranti Kumar Parida, Siddharth Srivastava, Gaurav Sharma",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Parida_Beyond_Image_to_Depth_Improving_Depth_Prediction_Using_Echoes_CVPR_2021_paper.pdf",
        "aff": "IIT Kanpur; TensorTour Inc.; CDAC Noida",
        "project": "https://krantiparida.github.io/projects/bimgdepth.html",
        "github": "https://github.com/krantiparida",
        "arxiv": "2103.08468"
    },
    {
        "title": "Beyond Max-Margin: Class Margin Equilibrium for Few-Shot Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Beyond_Max-Margin_Class_Margin_Equilibrium_for_Few-Shot_Object_Detection_CVPR_2021_paper.html",
        "author": "Bohao Li, Boyu Yang, Chang Liu, Feng Liu, Rongrong Ji, Qixiang Ye",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Beyond_Max-Margin_Class_Margin_Equilibrium_for_Few-Shot_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "MAC, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China; PriSDL, EECE, University of Chinese Academy of Sciences, 100049, China",
        "project": "",
        "github": "https://github.com/Bohao-Lee/CME",
        "arxiv": ""
    },
    {
        "title": "Beyond Short Clips: End-to-End Video-Level Learning With Collaborative Memories",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Beyond_Short_Clips_End-to-End_Video-Level_Learning_With_Collaborative_Memories_CVPR_2021_paper.html",
        "author": "Xitong Yang, Haoqi Fan, Lorenzo Torresani, Larry S. Davis, Heng Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Beyond_Short_Clips_End-to-End_Video-Level_Learning_With_Collaborative_Memories_CVPR_2021_paper.pdf",
        "aff": "University of Maryland, College Park; Facebook AI, Dartmouth; Facebook AI",
        "project": "",
        "github": "",
        "arxiv": "2104.01198"
    },
    {
        "title": "Beyond Static Features for Temporally Consistent 3D Human Pose and Shape From a Video",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Choi_Beyond_Static_Features_for_Temporally_Consistent_3D_Human_Pose_and_CVPR_2021_paper.html",
        "author": "Hongsuk Choi, Gyeongsik Moon, Ju Yong Chang, Kyoung Mu Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Choi_Beyond_Static_Features_for_Temporally_Consistent_3D_Human_Pose_and_CVPR_2021_paper.pdf",
        "aff": "ECE & ASRI, Seoul National University, Korea; ECE, Kwangwoon University, Korea",
        "project": "",
        "github": "",
        "arxiv": "2011.08627"
    },
    {
        "title": "Bi-GCN: Binary Graph Convolutional Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Bi-GCN_Binary_Graph_Convolutional_Network_CVPR_2021_paper.html",
        "author": "Junfu Wang, Yunhong Wang, Zhen Yang, Liang Yang, Yuanfang Guo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Bi-GCN_Binary_Graph_Convolutional_Network_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Beihang University, China; School of Arti\ufb01cial Intelligence, Hebei University of Technology, China; State Key Laboratory of Software Development Environment, Beihang University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "BiCnet-TKS: Learning Efficient Spatial-Temporal Representation for Video Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hou_BiCnet-TKS_Learning_Efficient_Spatial-Temporal_Representation_for_Video_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Ruibing Hou, Hong Chang, Bingpeng Ma, Rui Huang, Shiguang Shan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_BiCnet-TKS_Learning_Efficient_Spatial-Temporal_Representation_for_Video_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "1. Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, 100190, China 2. University of Chinese Academy of Sciences, Beijing, 100049, China 4. CAS Center for Excellence in Brain Science and Intelligence Technology, Shanghai, 200031, China; 2. University of Chinese Academy of Sciences, Beijing, 100049, China; 3. Shenzhen Institute of Arti\ufb01cial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, 518172, China; 1. Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, 100190, China 2. University of Chinese Academy of Sciences, Beijing, 100049, China",
        "project": "",
        "github": "https://github.com/blue-blue272/BiCnet-TKS",
        "arxiv": ""
    },
    {
        "title": "Bidirectional Projection Network for Cross Dimension Scene Understanding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Bidirectional_Projection_Network_for_Cross_Dimension_Scene_Understanding_CVPR_2021_paper.html",
        "author": "Wenbo Hu, Hengshuang Zhao, Li Jiang, Jiaya Jia, Tien-Tsin Wong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Bidirectional_Projection_Network_for_Cross_Dimension_Scene_Understanding_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong, Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, SIAT, CAS; University of Oxford; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/wbhu/BPNet",
        "arxiv": "2103.14326"
    },
    {
        "title": "Bilateral Grid Learning for Stereo Matching Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Bilateral_Grid_Learning_for_Stereo_Matching_Networks_CVPR_2021_paper.html",
        "author": "Bin Xu, Yuhua Xu, Xiaoli Yang, Wei Jia, Yulan Guo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Bilateral_Grid_Learning_for_Stereo_Matching_Networks_CVPR_2021_paper.pdf",
        "aff": "Orbbec; Sun Yat-sen University; Hefei University of Technology",
        "project": "",
        "github": "https://github.com/YuhuaXu/BGNet",
        "arxiv": "2101.01601"
    },
    {
        "title": "Bilevel Online Adaptation for Out-of-Domain Human Mesh Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guan_Bilevel_Online_Adaptation_for_Out-of-Domain_Human_Mesh_Reconstruction_CVPR_2021_paper.html",
        "author": "Shanyan Guan, Jingwei Xu, Yunbo Wang, Bingbing Ni, Xiaokang Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guan_Bilevel_Online_Adaptation_for_Out-of-Domain_Human_Mesh_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; Shanghai Jiao Tong University, Shanghai 200240, China",
        "project": "https://sites.google.com/view/humanmeshboa",
        "github": "",
        "arxiv": "2103.16449"
    },
    {
        "title": "Bilinear Parameterization for Non-Separable Singular Value Penalties",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ornhag_Bilinear_Parameterization_for_Non-Separable_Singular_Value_Penalties_CVPR_2021_paper.html",
        "author": "Marcus Valtonen Ornhag, Jose Pedro Iglesias, Carl Olsson",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ornhag_Bilinear_Parameterization_for_Non-Separable_Singular_Value_Penalties_CVPR_2021_paper.pdf",
        "aff": "Centre for Mathematical Sciences, Lund University and Department of Electrical Engineering, Chalmers University of Technology; Department of Electrical Engineering, Chalmers University of Technology; Centre for Mathematical Sciences, Lund University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Binary Graph Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bahri_Binary_Graph_Neural_Networks_CVPR_2021_paper.html",
        "author": "Mehdi Bahri, Gaetan Bahl, Stefanos Zafeiriou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bahri_Binary_Graph_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "Imperial College London, UK; Universit \u00b4e C\u02c6ote d\u2019Azur - Inria, IRT Saint-Exup \u00b4ery",
        "project": "",
        "github": "https://github.com/mbahri/binary-gnn",
        "arxiv": "2012.15823"
    },
    {
        "title": "Binary TTC: A Temporal Geofence for Autonomous Navigation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Badki_Binary_TTC_A_Temporal_Geofence_for_Autonomous_Navigation_CVPR_2021_paper.html",
        "author": "Abhishek Badki, Orazio Gallo, Jan Kautz, Pradeep Sen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Badki_Binary_TTC_A_Temporal_Geofence_for_Autonomous_Navigation_CVPR_2021_paper.pdf",
        "aff": "NVIDIA, UC Santa Barbara; NVIDIA; UC Santa Barbara",
        "project": "",
        "github": "https://github.com/NVlabs/BiTTC",
        "arxiv": "2101.04777"
    },
    {
        "title": "Bipartite Graph Network With Adaptive Message Passing for Unbiased Scene Graph Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Bipartite_Graph_Network_With_Adaptive_Message_Passing_for_Unbiased_Scene_CVPR_2021_paper.html",
        "author": "Rongjie Li, Songyang Zhang, Bo Wan, Xuming He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Bipartite_Graph_Network_With_Adaptive_Message_Passing_for_Unbiased_Scene_CVPR_2021_paper.pdf",
        "aff": "School of Information Science and Technology, ShanghaiTech University; Shanghai Engineering Research Center of Intelligent Vision and Imaging; School of Information Science and Technology, ShanghaiTech University; Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; School of Information Science and Technology, ShanghaiTech University; Department of Electrical Engineering(ESAT), KU Leuven",
        "project": "",
        "github": "https://github.com/Scarecrow0/BGNN-SGG",
        "arxiv": "2104.00308"
    },
    {
        "title": "Birds of a Feather: Capturing Avian Shape Models From Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Birds_of_a_Feather_Capturing_Avian_Shape_Models_From_Images_CVPR_2021_paper.html",
        "author": "Yufu Wang, Nikos Kolotouros, Kostas Daniilidis, Marc Badger",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Birds_of_a_Feather_Capturing_Avian_Shape_Models_From_Images_CVPR_2021_paper.pdf",
        "aff": "University of Pennsylvania",
        "project": "",
        "github": "",
        "arxiv": "2105.09396"
    },
    {
        "title": "Black-Box Explanation of Object Detectors via Saliency Maps",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Petsiuk_Black-Box_Explanation_of_Object_Detectors_via_Saliency_Maps_CVPR_2021_paper.html",
        "author": "Vitali Petsiuk, Rajiv Jain, Varun Manjunatha, Vlad I. Morariu, Ashutosh Mehra, Vicente Ordonez, Kate Saenko",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Petsiuk_Black-Box_Explanation_of_Object_Detectors_via_Saliency_Maps_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; University of Virginia; Adobe Document Cloud; Boston University, MIT-IBM Watson AI Lab; Boston University",
        "project": "",
        "github": "",
        "arxiv": "2006.03204"
    },
    {
        "title": "Blind Deblurring for Saturated Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Blind_Deblurring_for_Saturated_Images_CVPR_2021_paper.html",
        "author": "Liang Chen, Jiawei Zhang, Songnan Lin, Faming Fang, Jimmy S. Ren",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Blind_Deblurring_for_Saturated_Images_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research, Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, School of Computer Science and Technology, East China Normal University; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Blocks-World Cameras",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Blocks-World_Cameras_CVPR_2021_paper.html",
        "author": "Jongho Lee, Mohit Gupta",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Blocks-World_Cameras_CVPR_2021_paper.pdf",
        "aff": "University of Wisconsin-Madison",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Blur, Noise, and Compression Robust Generative Adversarial Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kaneko_Blur_Noise_and_Compression_Robust_Generative_Adversarial_Networks_CVPR_2021_paper.html",
        "author": "Takuhiro Kaneko, Tatsuya Harada",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kaneko_Blur_Noise_and_Compression_Robust_Generative_Adversarial_Networks_CVPR_2021_paper.pdf",
        "aff": "The University of Tokyo; The University of Tokyo, RIKEN",
        "project": "https://takuhirok.github.io/BNCR-GAN/",
        "github": "",
        "arxiv": "2003.07849"
    },
    {
        "title": "Body Meshes as Points",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Body_Meshes_as_Points_CVPR_2021_paper.html",
        "author": "Jianfeng Zhang, Dongdong Yu, Jun Hao Liew, Xuecheng Nie, Jiashi Feng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Body_Meshes_as_Points_CVPR_2021_paper.pdf",
        "aff": "ByteDance AI Lab; Yitu Technology; National University of Singapore",
        "project": "",
        "github": "https://github.com/jfzhang95/BMP",
        "arxiv": "2105.02467"
    },
    {
        "title": "Body2Hands: Learning To Infer 3D Hands From Conversational Gesture Body Dynamics",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ng_Body2Hands_Learning_To_Infer_3D_Hands_From_Conversational_Gesture_Body_CVPR_2021_paper.html",
        "author": "Evonne Ng, Shiry Ginosar, Trevor Darrell, Hanbyul Joo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ng_Body2Hands_Learning_To_Infer_3D_Hands_From_Conversational_Gesture_Body_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; Facebook AI Research",
        "project": "http://people.eecs.berkeley.edu/~evonne_ng/projects/body2hands/",
        "github": "",
        "arxiv": "2007.12287"
    },
    {
        "title": "Boosting Ensemble Accuracy by Revisiting Ensemble Diversity Metrics",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Boosting_Ensemble_Accuracy_by_Revisiting_Ensemble_Diversity_Metrics_CVPR_2021_paper.html",
        "author": "Yanzhao Wu, Ling Liu, Zhongwei Xie, Ka-Ho Chow, Wenqi Wei",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Boosting_Ensemble_Accuracy_by_Revisiting_Ensemble_Diversity_Metrics_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, Georgia Institute of Technology, Atlanta, Georgia 30332",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Boosting Monocular Depth Estimation Models to High-Resolution via Content-Adaptive Multi-Resolution Merging",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Miangoleh_Boosting_Monocular_Depth_Estimation_Models_to_High-Resolution_via_Content-Adaptive_Multi-Resolution_CVPR_2021_paper.html",
        "author": "S. Mahdi H. Miangoleh, Sebastian Dille, Long Mai, Sylvain Paris, Yagiz Aksoy",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Miangoleh_Boosting_Monocular_Depth_Estimation_Models_to_High-Resolution_via_Content-Adaptive_Multi-Resolution_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; Adobe Research",
        "project": "",
        "github": "",
        "arxiv": "2105.14021"
    },
    {
        "title": "Boosting Video Representation Learning With Multi-Faceted Integration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_Boosting_Video_Representation_Learning_With_Multi-Faceted_Integration_CVPR_2021_paper.html",
        "author": "Zhaofan Qiu, Ting Yao, Chong-Wah Ngo, Xiao-Ping Zhang, Dong Wu, Tao Mei",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qiu_Boosting_Video_Representation_Learning_With_Multi-Faceted_Integration_CVPR_2021_paper.pdf",
        "aff": "Singapore Management University, Singapore; JD AI Research, Beijing, China; Ryerson University, Toronto, Canada",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Bottleneck Transformers for Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Srinivas_Bottleneck_Transformers_for_Visual_Recognition_CVPR_2021_paper.html",
        "author": "Aravind Srinivas, Tsung-Yi Lin, Niki Parmar, Jonathon Shlens, Pieter Abbeel, Ashish Vaswani",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Srinivas_Bottleneck_Transformers_for_Visual_Recognition_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; Google Research",
        "project": "https://arxiv.org/abs/2101.11605",
        "github": "",
        "arxiv": "2101.11605"
    },
    {
        "title": "Bottom-Up Human Pose Estimation via Disentangled Keypoint Regression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Geng_Bottom-Up_Human_Pose_Estimation_via_Disentangled_Keypoint_Regression_CVPR_2021_paper.html",
        "author": "Zigang Geng, Ke Sun, Bin Xiao, Zhaoxiang Zhang, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Geng_Bottom-Up_Human_Pose_Estimation_via_Disentangled_Keypoint_Regression_CVPR_2021_paper.pdf",
        "aff": "Microsoft; Institute of Automation, CAS, University of Chinese Academy of Sciences, Centre for Arti\ufb01cial Intelligence and Robotics, HKISI CAS; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/HRNet/DEKR",
        "arxiv": "2104.02300"
    },
    {
        "title": "Bottom-Up Shift and Reasoning for Referring Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Bottom-Up_Shift_and_Reasoning_for_Referring_Image_Segmentation_CVPR_2021_paper.html",
        "author": "Sibei Yang, Meng Xia, Guanbin Li, Hong-Yu Zhou, Yizhou Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Bottom-Up_Shift_and_Reasoning_for_Referring_Image_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Sun Yat-sen University; The University of Hong Kong; The University of Hong Kong and Deepwise AI Lab; ShanghaiTech University",
        "project": "",
        "github": "https://github.com/incredibleXM/BUSNet",
        "arxiv": ""
    },
    {
        "title": "Boundary IoU: Improving Object-Centric Image Segmentation Evaluation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Boundary_IoU_Improving_Object-Centric_Image_Segmentation_Evaluation_CVPR_2021_paper.html",
        "author": "Bowen Cheng, Ross Girshick, Piotr Dollar, Alexander C. Berg, Alexander Kirillov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Boundary_IoU_Improving_Object-Centric_Image_Segmentation_Evaluation_CVPR_2021_paper.pdf",
        "aff": "UIUC; Facebook AI Research (FAIR)",
        "project": "https://bowenc0221.github.io/boundary-iou",
        "github": "",
        "arxiv": "2103.16562"
    },
    {
        "title": "BoxInst: High-Performance Instance Segmentation With Box Annotations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html",
        "author": "Zhi Tian, Chunhua Shen, Xinlong Wang, Hao Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.pdf",
        "aff": "The University of Adelaide, Australia",
        "project": "",
        "github": "https://git.io/AdelaiDet",
        "arxiv": "2012.02310"
    },
    {
        "title": "Brain Image Synthesis With Unsupervised Multivariate Canonical CSCl4Net",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Brain_Image_Synthesis_With_Unsupervised_Multivariate_Canonical_CSCl4Net_CVPR_2021_paper.html",
        "author": "Yawen Huang, Feng Zheng, Danyang Wang, Weilin Huang, Matthew R. Scott, Ling Shao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Brain_Image_Synthesis_With_Unsupervised_Multivariate_Canonical_CSCl4Net_CVPR_2021_paper.pdf",
        "aff": "Malong LLC; Inception Institute of Arti\ufb01cial Intelligence; Southern University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Bridge To Answer: Structure-Aware Graph Interaction Network for Video Question Answering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Park_Bridge_To_Answer_Structure-Aware_Graph_Interaction_Network_for_Video_Question_CVPR_2021_paper.html",
        "author": "Jungin Park, Jiyoung Lee, Kwanghoon Sohn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Park_Bridge_To_Answer_Structure-Aware_Graph_Interaction_Network_for_Video_Question_CVPR_2021_paper.pdf",
        "aff": "Yonsei University, Seoul, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2104.14085"
    },
    {
        "title": "Bridging the Visual Gap: Wide-Range Image Blending",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Bridging_the_Visual_Gap_Wide-Range_Image_Blending_CVPR_2021_paper.html",
        "author": "Chia-Ni Lu, Ya-Chu Chang, Wei-Chen Chiu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_Bridging_the_Visual_Gap_Wide-Range_Image_Blending_CVPR_2021_paper.pdf",
        "aff": "MediaTek-NCTU Research Center, Taiwan; National Chiao Tung University (NCTU), Taiwan",
        "project": "",
        "github": "",
        "arxiv": "2103.15149"
    },
    {
        "title": "Building Reliable Explanations of Unreliable Neural Networks: Locally Smoothing Perspective of Model Interpretation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lim_Building_Reliable_Explanations_of_Unreliable_Neural_Networks_Locally_Smoothing_Perspective_CVPR_2021_paper.html",
        "author": "Dohun Lim, Hyeonseok Lee, Sungchan Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lim_Building_Reliable_Explanations_of_Unreliable_Neural_Networks_Locally_Smoothing_Perspective_CVPR_2021_paper.pdf",
        "aff": "Division of Computer Science and Engineering, Jeonbuk National University, Korea",
        "project": "",
        "github": "",
        "arxiv": "2103.14332"
    },
    {
        "title": "CAMERAS: Enhanced Resolution and Sanity Preserving Class Activation Mapping for Image Saliency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jalwana_CAMERAS_Enhanced_Resolution_and_Sanity_Preserving_Class_Activation_Mapping_for_CVPR_2021_paper.html",
        "author": "Mohammad A. A. K. Jalwana, Naveed Akhtar, Mohammed Bennamoun, Ajmal Mian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jalwana_CAMERAS_Enhanced_Resolution_and_Sanity_Preserving_Class_Activation_Mapping_for_CVPR_2021_paper.pdf",
        "aff": "Computer Science and Software Engineering, The University of Western Australia",
        "project": "",
        "github": "https://github.com/VisMIL/CAMERAS",
        "arxiv": "2106.10649"
    },
    {
        "title": "CASTing Your Model: Learning To Localize Improves Self-Supervised Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Selvaraju_CASTing_Your_Model_Learning_To_Localize_Improves_Self-Supervised_Representations_CVPR_2021_paper.html",
        "author": "Ramprasaath R. Selvaraju, Karan Desai, Justin Johnson, Nikhil Naik",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Selvaraju_CASTing_Your_Model_Learning_To_Localize_Improves_Self-Supervised_Representations_CVPR_2021_paper.pdf",
        "aff": "University of Michigan; Salesforce Research",
        "project": "",
        "github": "https://github.com/salesforce/CAST/",
        "arxiv": "2012.04630"
    },
    {
        "title": "CDFI: Compression-Driven Network Design for Frame Interpolation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ding_CDFI_Compression-Driven_Network_Design_for_Frame_Interpolation_CVPR_2021_paper.html",
        "author": "Tianyu Ding, Luming Liang, Zhihui Zhu, Ilya Zharkov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_CDFI_Compression-Driven_Network_Design_for_Frame_Interpolation_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; University of Denver; Microsoft",
        "project": "",
        "github": "https://github.com/tding1/CDFI",
        "arxiv": "2103.10559"
    },
    {
        "title": "CFNet: Cascade and Fused Cost Volume for Robust Stereo Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shen_CFNet_Cascade_and_Fused_Cost_Volume_for_Robust_Stereo_Matching_CVPR_2021_paper.html",
        "author": "Zhelun Shen, Yuchao Dai, Zhibo Rao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_CFNet_Cascade_and_Fused_Cost_Volume_for_Robust_Stereo_Matching_CVPR_2021_paper.pdf",
        "aff": "Northwestern Polytechnical University, Xi'an, China",
        "project": "",
        "github": "https://github.com/gallenszl/CFNet",
        "arxiv": "2104.04314"
    },
    {
        "title": "CGA-Net: Category Guided Aggregation for Point Cloud Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lu_CGA-Net_Category_Guided_Aggregation_for_Point_Cloud_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Tao Lu, Limin Wang, Gangshan Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_CGA-Net_Category_Guided_Aggregation_for_Point_Cloud_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CLCC: Contrastive Learning for Color Constancy",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lo_CLCC_Contrastive_Learning_for_Color_Constancy_CVPR_2021_paper.html",
        "author": "Yi-Chen Lo, Chia-Che Chang, Hsuan-Chao Chiu, Yu-Hao Huang, Chia-Ping Chen, Yu-Lin Chang, Kevin Jou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lo_CLCC_Contrastive_Learning_for_Color_Constancy_CVPR_2021_paper.pdf",
        "aff": "MediaTek Inc., Hsinchu, Taiwan",
        "project": "",
        "github": "https://github.com/howardyclo/clcc-cvpr21",
        "arxiv": "2106.04989"
    },
    {
        "title": "COMPLETER: Incomplete Multi-View Clustering via Contrastive Prediction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_COMPLETER_Incomplete_Multi-View_Clustering_via_Contrastive_Prediction_CVPR_2021_paper.html",
        "author": "Yijie Lin, Yuanbiao Gou, Zitao Liu, Boyun Li, Jiancheng Lv, Xi Peng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_COMPLETER_Incomplete_Multi-View_Clustering_via_Contrastive_Prediction_CVPR_2021_paper.pdf",
        "aff": "TAL Education Group, China.; College of Computer Science, Sichuan University, China.",
        "project": "",
        "github": "https://pengxi.me",
        "arxiv": ""
    },
    {
        "title": "CRFace: Confidence Ranker for Model-Agnostic Face Detection Refinement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Vesdapunt_CRFace_Confidence_Ranker_for_Model-Agnostic_Face_Detection_Refinement_CVPR_2021_paper.html",
        "author": "Noranart Vesdapunt, Baoyuan Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Vesdapunt_CRFace_Confidence_Ranker_for_Model-Agnostic_Face_Detection_Refinement_CVPR_2021_paper.pdf",
        "aff": "Microsoft Cloud&AI; Xiaobing.AI",
        "project": "",
        "github": "",
        "arxiv": "2103.07017"
    },
    {
        "title": "CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wei_CReST_A_Class-Rebalancing_Self-Training_Framework_for_Imbalanced_Semi-Supervised_Learning_CVPR_2021_paper.html",
        "author": "Chen Wei, Kihyuk Sohn, Clayton Mellina, Alan Yuille, Fan Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wei_CReST_A_Class-Rebalancing_Self-Training_Framework_for_Imbalanced_Semi-Supervised_Learning_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Google Cloud AI",
        "project": "",
        "github": "https://github.com/google-research/crest",
        "arxiv": "2102.09559"
    },
    {
        "title": "CT-Net: Complementary Transfering Network for Garment Transfer With Arbitrary Geometric Changes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_CT-Net_Complementary_Transfering_Network_for_Garment_Transfer_With_Arbitrary_Geometric_CVPR_2021_paper.html",
        "author": "Fan Yang, Guosheng Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_CT-Net_Complementary_Transfering_Network_for_Garment_Transfer_With_Arbitrary_Geometric_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Calibrated RGB-D Salient Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ji_Calibrated_RGB-D_Salient_Object_Detection_CVPR_2021_paper.html",
        "author": "Wei Ji, Jingjing Li, Shuang Yu, Miao Zhang, Yongri Piao, Shunyu Yao, Qi Bi, Kai Ma, Yefeng Zheng, Huchuan Lu, Li Cheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Calibrated_RGB-D_Salient_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "University of Alberta, Canada; University of Alberta, Canada / Dalian University of Technology, China; Dalian University of Technology, China; Tencent Jarvis Lab, Shenzhen, China; Tencent Jarvis Lab, Shenzhen, China / Dalian University of Technology, China; Tencent Jarvis Lab, Shenzhen, China / Wuhan University, Hubei, China; University of Alberta, Canada / Tencent Jarvis Lab, Shenzhen, China",
        "project": "",
        "github": "https://github.com/jiwei0921/DCF",
        "arxiv": ""
    },
    {
        "title": "Camera Pose Matters: Improving Depth Prediction by Mitigating Pose Distribution Bias",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Camera_Pose_Matters_Improving_Depth_Prediction_by_Mitigating_Pose_Distribution_CVPR_2021_paper.html",
        "author": "Yunhan Zhao, Shu Kong, Charless Fowlkes",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Camera_Pose_Matters_Improving_Depth_Prediction_by_Mitigating_Pose_Distribution_CVPR_2021_paper.pdf",
        "aff": "UC Irvine; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2007.03887"
    },
    {
        "title": "Camera-Space Hand Mesh Recovery via Semantic Aggregation and Adaptive 2D-1D Registration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Camera-Space_Hand_Mesh_Recovery_via_Semantic_Aggregation_and_Adaptive_2D-1D_CVPR_2021_paper.html",
        "author": "Xingyu Chen, Yufeng Liu, Chongyang Ma, Jianlong Chang, Huayan Wang, Tian Chen, Xiaoyan Guo, Pengfei Wan, Wen Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Camera-Space_Hand_Mesh_Recovery_via_Semantic_Aggregation_and_Adaptive_2D-1D_CVPR_2021_paper.pdf",
        "aff": "Y-tech, Kuaishou Technology; Huawei Cloud & AI",
        "project": "",
        "github": "https://github.com/SeanChenxy/HandMesh",
        "arxiv": "2103.02845"
    },
    {
        "title": "Camouflaged Object Segmentation With Distraction Mining",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mei_Camouflaged_Object_Segmentation_With_Distraction_Mining_CVPR_2021_paper.html",
        "author": "Haiyang Mei, Ge-Peng Ji, Ziqi Wei, Xin Yang, Xiaopeng Wei, Deng-Ping Fan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mei_Camouflaged_Object_Segmentation_With_Distraction_Mining_CVPR_2021_paper.pdf",
        "aff": "IIAI; Dalian University of Technology; Wuhan University; Tsinghua University",
        "project": "https://mhaiyang.github.io/CVPR2021_PFNet/index",
        "github": "",
        "arxiv": "2104.10475"
    },
    {
        "title": "Can Audio-Visual Integration Strengthen Robustness Under Multimodal Attacks?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Can_Audio-Visual_Integration_Strengthen_Robustness_Under_Multimodal_Attacks_CVPR_2021_paper.html",
        "author": "Yapeng Tian, Chenliang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_Can_Audio-Visual_Integration_Strengthen_Robustness_Under_Multimodal_Attacks_CVPR_2021_paper.pdf",
        "aff": "University of Rochester",
        "project": "",
        "github": "https://github.com/YapengTian/AV-Robustness-CVPR21",
        "arxiv": "2104.02000"
    },
    {
        "title": "Can We Characterize Tasks Without Labels or Features?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wallace_Can_We_Characterize_Tasks_Without_Labels_or_Features_CVPR_2021_paper.html",
        "author": "Bram Wallace, Ziyang Wu, Bharath Hariharan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wallace_Can_We_Characterize_Tasks_Without_Labels_or_Features_CVPR_2021_paper.pdf",
        "aff": "Cornell University",
        "project": "",
        "github": "https://github.com/BramSW/task_characterization_cvpr_2021",
        "arxiv": ""
    },
    {
        "title": "CanonPose: Self-Supervised Monocular 3D Human Pose Estimation in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wandt_CanonPose_Self-Supervised_Monocular_3D_Human_Pose_Estimation_in_the_Wild_CVPR_2021_paper.html",
        "author": "Bastian Wandt, Marco Rudolph, Petrissa Zell, Helge Rhodin, Bodo Rosenhahn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wandt_CanonPose_Self-Supervised_Monocular_3D_Human_Pose_Estimation_in_the_Wild_CVPR_2021_paper.pdf",
        "aff": "Leibniz University Hannover, Hannover, Germany; University of British Columbia, Vancouver, Canada",
        "project": "",
        "github": "",
        "arxiv": "2011.14679"
    },
    {
        "title": "Capsule Network Is Not More Robust Than Convolutional Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gu_Capsule_Network_Is_Not_More_Robust_Than_Convolutional_Network_CVPR_2021_paper.html",
        "author": "Jindong Gu, Volker Tresp, Han Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gu_Capsule_Network_Is_Not_More_Robust_Than_Convolutional_Network_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; University of Munich",
        "project": "",
        "github": "",
        "arxiv": "2103.15459"
    },
    {
        "title": "CapsuleRRT: Relationships-Aware Regression Tracking via Capsules",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_CapsuleRRT_Relationships-Aware_Regression_Tracking_via_Capsules_CVPR_2021_paper.html",
        "author": "Ding Ma, Xiangqian Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_CapsuleRRT_Relationships-Aware_Regression_Tracking_via_Capsules_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Technology, Harbin Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Capturing Omni-Range Context for Omnidirectional Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Capturing_Omni-Range_Context_for_Omnidirectional_Segmentation_CVPR_2021_paper.html",
        "author": "Kailun Yang, Jiaming Zhang, Simon Reiss, Xinxin Hu, Rainer Stiefelhagen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Capturing_Omni-Range_Context_for_Omnidirectional_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Huawei Technologies; CV:HCI Lab, Karlsruhe Institute of Technology; CV:HCI Lab, Karlsruhe Institute of Technology; Carl Zeiss AG",
        "project": "",
        "github": "https://github.com/elnino9ykl/WildPASS",
        "arxiv": "2103.05687"
    },
    {
        "title": "Cascaded Prediction Network via Segment Tree for Temporal Video Grounding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Cascaded_Prediction_Network_via_Segment_Tree_for_Temporal_Video_Grounding_CVPR_2021_paper.html",
        "author": "Yang Zhao, Zhou Zhao, Zhu Zhang, Zhijie Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Cascaded_Prediction_Network_via_Segment_Tree_for_Temporal_Video_Grounding_CVPR_2021_paper.pdf",
        "aff": "College of Computer Science, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Categorical Depth Distribution Network for Monocular 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Reading_Categorical_Depth_Distribution_Network_for_Monocular_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "Cody Reading, Ali Harakeh, Julia Chae, Steven L. Waslander",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Reading_Categorical_Depth_Distribution_Network_for_Monocular_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "University of Toronto Robotics Institute",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2103.01100"
    },
    {
        "title": "Causal Attention for Vision-Language Tasks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Causal_Attention_for_Vision-Language_Tasks_CVPR_2021_paper.html",
        "author": "Xu Yang, Hanwang Zhang, Guojun Qi, Jianfei Cai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Causal_Attention_for_Vision-Language_Tasks_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; Futurewei Technologies; Faculty of Information Technology, Monash University, Australia",
        "project": "",
        "github": "https://github.com/yangxuntu/lxmertcatt",
        "arxiv": "2103.03493"
    },
    {
        "title": "Causal Hidden Markov Model for Time Series Disease Forecasting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Causal_Hidden_Markov_Model_for_Time_Series_Disease_Forecasting_CVPR_2021_paper.html",
        "author": "Jing Li, Botong Wu, Xinwei Sun, Yizhou Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Causal_Hidden_Markov_Model_for_Time_Series_Disease_Forecasting_CVPR_2021_paper.pdf",
        "aff": "Dept. of Computer Science, Peking University; Center on Frontiers of Computing Studies, Peking University; Microsoft Research, Asia; Dept. of Computer Science, Peking University; Adv. Inst. of Info. Tech, Peking University; Dept. of Computer Science, Peking University; Deepwise AI Lab",
        "project": "https://sites.google.com/view/causal-hmm",
        "github": "",
        "arxiv": "2103.16391"
    },
    {
        "title": "CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_CausalVAE_Disentangled_Representation_Learning_via_Neural_Structural_Causal_Models_CVPR_2021_paper.html",
        "author": "Mengyue Yang, Furui Liu, Zhitang Chen, Xinwei Shen, Jianye Hao, Jun Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_CausalVAE_Disentangled_Representation_Learning_via_Neural_Structural_Causal_Models_CVPR_2021_paper.pdf",
        "aff": "Noah\u2019s Ark Lab, Huawei, Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong, China; University College London, London, United Kingdom",
        "project": "",
        "github": "",
        "arxiv": "2004.08697"
    },
    {
        "title": "Center-Based 3D Object Detection and Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Center-Based_3D_Object_Detection_and_Tracking_CVPR_2021_paper.html",
        "author": "Tianwei Yin, Xingyi Zhou, Philipp Krahenbuhl",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_Center-Based_3D_Object_Detection_and_Tracking_CVPR_2021_paper.pdf",
        "aff": "UT Austin",
        "project": "",
        "github": "https://github.com/tianweiy/CenterPoint",
        "arxiv": "2006.11275"
    },
    {
        "title": "ChallenCap: Monocular 3D Capture of Challenging Human Performances Using Multi-Modal References",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_ChallenCap_Monocular_3D_Capture_of_Challenging_Human_Performances_Using_Multi-Modal_CVPR_2021_paper.html",
        "author": "Yannan He, Anqi Pang, Xin Chen, Han Liang, Minye Wu, Yuexin Ma, Lan Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_ChallenCap_Monocular_3D_Capture_of_Challenging_Human_Performances_Using_Multi-Modal_CVPR_2021_paper.pdf",
        "aff": "ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; ShanghaiTech University",
        "project": "",
        "github": "",
        "arxiv": "2103.06747"
    },
    {
        "title": "Checkerboard Context Model for Efficient Learned Image Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_Checkerboard_Context_Model_for_Efficient_Learned_Image_Compression_CVPR_2021_paper.html",
        "author": "Dailan He, Yaoyan Zheng, Baocheng Sun, Yan Wang, Hongwei Qin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_Checkerboard_Context_Model_for_Efficient_Learned_Image_Compression_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2103.15306"
    },
    {
        "title": "Class-Aware Robust Adversarial Training for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Class-Aware_Robust_Adversarial_Training_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Pin-Chun Chen, Bo-Han Kung, Jun-Cheng Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Class-Aware_Robust_Adversarial_Training_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Research Center for Information Technology Innovation, Academia Sinica; Columbia University",
        "project": "",
        "github": "",
        "arxiv": "2103.16148"
    },
    {
        "title": "ClassSR: A General Framework to Accelerate Super-Resolution Networks by Data Characteristic",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kong_ClassSR_A_General_Framework_to_Accelerate_Super-Resolution_Networks_by_Data_CVPR_2021_paper.html",
        "author": "Xiangtao Kong, Hengyuan Zhao, Yu Qiao, Chao Dong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kong_ClassSR_A_General_Framework_to_Accelerate_Super-Resolution_Networks_by_Data_CVPR_2021_paper.pdf",
        "aff": "Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences and University of Chinese Academy of Sciences; Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences and Shanghai AI Lab, Shanghai, China; Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences and SIAT Branch, Shenzhen Institute of Arti\ufb01cial Intelligence and Robotics for Society",
        "project": "",
        "github": "",
        "arxiv": "2103.04039"
    },
    {
        "title": "Closed-Form Factorization of Latent Semantics in GANs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Closed-Form_Factorization_of_Latent_Semantics_in_GANs_CVPR_2021_paper.html",
        "author": "Yujun Shen, Bolei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_Closed-Form_Factorization_of_Latent_Semantics_in_GANs_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong",
        "project": "https://genforce.github.io/sefa/",
        "github": "",
        "arxiv": "2007.06600"
    },
    {
        "title": "Closing the Loop: Joint Rain Generation and Removal via Disentangled Image Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Closing_the_Loop_Joint_Rain_Generation_and_Removal_via_Disentangled_CVPR_2021_paper.html",
        "author": "Yuntong Ye, Yi Chang, Hanyu Zhou, Luxin Yan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ye_Closing_the_Loop_Joint_Rain_Generation_and_Removal_via_Disentangled_CVPR_2021_paper.pdf",
        "aff": "AI Center, Peng Cheng Laboratory, Shenzhen, China; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Arti\ufb01cial Intelligence and Automation, Huazhong University of Science and Technology, China",
        "project": "",
        "github": "",
        "arxiv": "2103.13660"
    },
    {
        "title": "Cloud2Curve: Generation and Vectorization of Parametric Sketches",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Das_Cloud2Curve_Generation_and_Vectorization_of_Parametric_Sketches_CVPR_2021_paper.html",
        "author": "Ayan Das, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Das_Cloud2Curve_Generation_and_Vectorization_of_Parametric_Sketches_CVPR_2021_paper.pdf",
        "aff": "SketchX, CVSSP, University of Surrey, United Kingdom; University of Edinburgh, United Kingdom; SketchX, CVSSP, University of Surrey, United Kingdom; iFlyTek-Surrey Joint Research Centre on Artificial Intelligence",
        "project": "",
        "github": "",
        "arxiv": "2103.15536"
    },
    {
        "title": "Clusformer: A Transformer Based Clustering Approach to Unsupervised Large-Scale Face and Visual Landmark Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_Clusformer_A_Transformer_Based_Clustering_Approach_to_Unsupervised_Large-Scale_Face_CVPR_2021_paper.html",
        "author": "Xuan-Bac Nguyen, Duc Toan Bui, Chi Nhan Duong, Tien D. Bui, Khoa Luu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nguyen_Clusformer_A_Transformer_Based_Clustering_Approach_to_Unsupervised_Large-Scale_Face_CVPR_2021_paper.pdf",
        "aff": "Concordia University, Canada; University of Arkansas, USA; VinAI Research, Vietnam",
        "project": "",
        "github": "https://github.com/VinAIResearch/Clusformer",
        "arxiv": ""
    },
    {
        "title": "Cluster, Split, Fuse, and Update: Meta-Learning for Open Compound Domain Adaptive Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gong_Cluster_Split_Fuse_and_Update_Meta-Learning_for_Open_Compound_Domain_CVPR_2021_paper.html",
        "author": "Rui Gong, Yuhua Chen, Danda Pani Paudel, Yawei Li, Ajad Chhatkuli, Wen Li, Dengxin Dai, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gong_Cluster_Split_Fuse_and_Update_Meta-Learning_for_Open_Compound_Domain_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Zurich; UESTC; Computer Vision Lab, ETH Zurich, VISICS, KU Leuven",
        "project": "",
        "github": "",
        "arxiv": "2012.08278"
    },
    {
        "title": "Cluster-Wise Hierarchical Generative Model for Deep Amortized Clustering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Cluster-Wise_Hierarchical_Generative_Model_for_Deep_Amortized_Clustering_CVPR_2021_paper.html",
        "author": "Huafeng Liu, Jiaqi Wang, Liping Jing",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Cluster-Wise_Hierarchical_Generative_Model_for_Deep_Amortized_Clustering_CVPR_2021_paper.pdf",
        "aff": "School of Computer and Information Technology, Beijing Key Lab of Traf\ufb01c Data Analysis and Mining, Beijing Jiaotong University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Co-Attention for Conditioned Image Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wiles_Co-Attention_for_Conditioned_Image_Matching_CVPR_2021_paper.html",
        "author": "Olivia Wiles, Sebastien Ehrhardt, Andrew Zisserman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wiles_Co-Attention_for_Conditioned_Image_Matching_CVPR_2021_paper.pdf",
        "aff": "VGG, Dept. of Eng. Science, University of Oxford",
        "project": "",
        "github": "",
        "arxiv": "2007.08480"
    },
    {
        "title": "Co-Grounding Networks With Semantic Attention for Referring Expression Comprehension in Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_Co-Grounding_Networks_With_Semantic_Attention_for_Referring_Expression_Comprehension_in_CVPR_2021_paper.html",
        "author": "Sijie Song, Xudong Lin, Jiaying Liu, Zongming Guo, Shih-Fu Chang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Co-Grounding_Networks_With_Semantic_Attention_for_Referring_Expression_Comprehension_in_CVPR_2021_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University, Beijing, China; DVMM Lab, Columbia University, New York, NY, USA",
        "project": "https://sijiesong.github.io/co-grounding",
        "github": "",
        "arxiv": "2103.12346"
    },
    {
        "title": "CoCoNets: Continuous Contrastive 3D Scene Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lal_CoCoNets_Continuous_Contrastive_3D_Scene_Representations_CVPR_2021_paper.html",
        "author": "Shamit Lal, Mihir Prabhudesai, Ishita Mediratta, Adam W. Harley, Katerina Fragkiadaki",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lal_CoCoNets_Continuous_Contrastive_3D_Scene_Representations_CVPR_2021_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "https://mihirp1998.github.io/project_pages/coconets/",
        "github": "",
        "arxiv": "2104.03851"
    },
    {
        "title": "CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_CoCosNet_v2_Full-Resolution_Correspondence_Learning_for_Image_Translation_CVPR_2021_paper.html",
        "author": "Xingran Zhou, Bo Zhang, Ting Zhang, Pan Zhang, Jianmin Bao, Dong Chen, Zhongfei Zhang, Fang Wen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_CoCosNet_v2_Full-Resolution_Correspondence_Learning_for_Image_Translation_CVPR_2021_paper.pdf",
        "aff": "USTC; Microsoft Research Asia; Binghamton University; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": "2012.02047"
    },
    {
        "title": "CoLA: Weakly-Supervised Temporal Action Localization With Snippet Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_CoLA_Weakly-Supervised_Temporal_Action_Localization_With_Snippet_Contrastive_Learning_CVPR_2021_paper.html",
        "author": "Can Zhang, Meng Cao, Dongming Yang, Jie Chen, Yuexian Zou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_CoLA_Weakly-Supervised_Temporal_Action_Localization_With_Snippet_Contrastive_Learning_CVPR_2021_paper.pdf",
        "aff": "School of Electronic and Computer Engineering, Peking University; School of Electronic and Computer Engineering, Peking University; Peng Cheng Laboratory",
        "project": "",
        "github": "",
        "arxiv": "2103.16392"
    },
    {
        "title": "CoMoGAN: Continuous Model-Guided Image-to-Image Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pizzati_CoMoGAN_Continuous_Model-Guided_Image-to-Image_Translation_CVPR_2021_paper.html",
        "author": "Fabio Pizzati, Pietro Cerri, Raoul de Charette",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pizzati_CoMoGAN_Continuous_Model-Guided_Image-to-Image_Translation_CVPR_2021_paper.pdf",
        "aff": "Inria, Vislab; Vislab; Inria",
        "project": "",
        "github": "https://github.com/cv-rits/CoMoGAN",
        "arxiv": "2103.06879"
    },
    {
        "title": "CoSMo: Content-Style Modulation for Image Retrieval With Text Feedback",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_CoSMo_Content-Style_Modulation_for_Image_Retrieval_With_Text_Feedback_CVPR_2021_paper.html",
        "author": "Seungmin Lee, Dongwan Kim, Bohyung Han",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_CoSMo_Content-Style_Modulation_for_Image_Retrieval_With_Text_Feedback_CVPR_2021_paper.pdf",
        "aff": "Seoul National University",
        "project": "",
        "github": "https://github.com/postBG/CosMo.pytorch",
        "arxiv": ""
    },
    {
        "title": "Coarse-Fine Networks for Temporal Activity Detection in Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kahatapitiya_Coarse-Fine_Networks_for_Temporal_Activity_Detection_in_Videos_CVPR_2021_paper.html",
        "author": "Kumara Kahatapitiya, Michael S. Ryoo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kahatapitiya_Coarse-Fine_Networks_for_Temporal_Activity_Detection_in_Videos_CVPR_2021_paper.pdf",
        "aff": "Stony Brook University, Stony Brook, NY 11794, USA",
        "project": "",
        "github": "https://github.com/kkahatapitiya/Coarse-Fine-Networks",
        "arxiv": "2103.01302"
    },
    {
        "title": "Coarse-To-Fine Domain Adaptive Semantic Segmentation With Photometric Alignment and Category-Center Regularization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Coarse-To-Fine_Domain_Adaptive_Semantic_Segmentation_With_Photometric_Alignment_and_Category-Center_CVPR_2021_paper.html",
        "author": "Haoyu Ma, Xiangru Lin, Zifeng Wu, Yizhou Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_Coarse-To-Fine_Domain_Adaptive_Semantic_Segmentation_With_Photometric_Alignment_and_Category-Center_CVPR_2021_paper.pdf",
        "aff": "The University of Hong Kong; Deepwise AI Lab",
        "project": "",
        "github": "",
        "arxiv": "2103.13041"
    },
    {
        "title": "Coarse-To-Fine Person Re-Identification With Auxiliary-Domain Classification and Second-Order Information Bottleneck",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Coarse-To-Fine_Person_Re-Identification_With_Auxiliary-Domain_Classification_and_Second-Order_Information_Bottleneck_CVPR_2021_paper.html",
        "author": "Anguo Zhang, Yueming Gao, Yuzhen Niu, Wenxi Liu, Yongcheng Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Coarse-To-Fine_Person_Re-Identification_With_Auxiliary-Domain_Classification_and_Second-Order_Information_Bottleneck_CVPR_2021_paper.pdf",
        "aff": "College of Mathematics and Computer Science, Fuzhou University; College of Physics and Information Engineering, Fuzhou University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CodedStereo: Learned Phase Masks for Large Depth-of-Field Stereo",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tan_CodedStereo_Learned_Phase_Masks_for_Large_Depth-of-Field_Stereo_CVPR_2021_paper.html",
        "author": "Shiyu Tan, Yicheng Wu, Shoou-I Yu, Ashok Veeraraghavan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_CodedStereo_Learned_Phase_Masks_for_Large_Depth-of-Field_Stereo_CVPR_2021_paper.pdf",
        "aff": "Rice University; Facebook Reality Labs",
        "project": "",
        "github": "",
        "arxiv": "2104.04641"
    },
    {
        "title": "Collaborative Spatial-Temporal Modeling for Language-Queried Video Actor Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hui_Collaborative_Spatial-Temporal_Modeling_for_Language-Queried_Video_Actor_Segmentation_CVPR_2021_paper.html",
        "author": "Tianrui Hui, Shaofei Huang, Si Liu, Zihan Ding, Guanbin Li, Wenguan Wang, Jizhong Han, Fei Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hui_Collaborative_Spatial-Temporal_Modeling_for_Language-Queried_Video_Actor_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Zurich; School of Computer Science and Engineering, Sun Yat-sen University; Pazhou Lab, Guangzhou; Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences; SenseTime Research; Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences; SenseTime Research; Institute of Arti\ufb01cial Intelligence, Beihang University",
        "project": "",
        "github": "",
        "arxiv": "2105.06818"
    },
    {
        "title": "ColorRL: Reinforced Coloring for End-to-End Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tuan_ColorRL_Reinforced_Coloring_for_End-to-End_Instance_Segmentation_CVPR_2021_paper.html",
        "author": "Tran Anh Tuan, Nguyen Tuan Khoa, Tran Minh Quan, Won-Ki Jeong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tuan_ColorRL_Reinforced_Coloring_for_End-to-End_Instance_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Engineering, UNIST, Ulsan, Korea; Department of Applied Science, VinBrain and VinUniversity, Vietnam; Department of Computer Science and Engineering, Korea University, Seoul, Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Combinatorial Learning of Graph Edit Distance via Dynamic Embedding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Combinatorial_Learning_of_Graph_Edit_Distance_via_Dynamic_Embedding_CVPR_2021_paper.html",
        "author": "Runzhong Wang, Tianqi Zhang, Tianshu Yu, Junchi Yan, Xiaokang Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Combinatorial_Learning_of_Graph_Edit_Distance_via_Dynamic_Embedding_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Engineering, Shanghai Jiao Tong University; MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University; MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University; Arizona State University",
        "project": "",
        "github": "",
        "arxiv": "2011.15039"
    },
    {
        "title": "Combined Depth Space Based Architecture Search for Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Combined_Depth_Space_Based_Architecture_Search_for_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Hanjun Li, Gaojie Wu, Wei-Shi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Combined_Depth_Space_Based_Architecture_Search_for_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Peng Cheng Laboratory, Shenzhen 518005, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China; School of Computer Science and Engineering, Sun Yat-sen University, China; School of Computer Science and Engineering, Sun Yat-sen University, China; Pazhou Lab, Guangzhou, China",
        "project": "",
        "github": "",
        "arxiv": "2104.04163"
    },
    {
        "title": "Combining Semantic Guidance and Deep Reinforcement Learning for Generating Human Level Paintings",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Singh_Combining_Semantic_Guidance_and_Deep_Reinforcement_Learning_for_Generating_Human_CVPR_2021_paper.html",
        "author": "Jaskirat Singh, Liang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Singh_Combining_Semantic_Guidance_and_Deep_Reinforcement_Learning_for_Generating_Human_CVPR_2021_paper.pdf",
        "aff": "Australian National University",
        "project": "",
        "github": "https://github.com/1jsingh/semantic-guidance",
        "arxiv": "2011.12589"
    },
    {
        "title": "Coming Down to Earth: Satellite-to-Street View Synthesis for Geo-Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Toker_Coming_Down_to_Earth_Satellite-to-Street_View_Synthesis_for_Geo-Localization_CVPR_2021_paper.html",
        "author": "Aysim Toker, Qunjie Zhou, Maxim Maximov, Laura Leal-Taixe",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Toker_Coming_Down_to_Earth_Satellite-to-Street_View_Synthesis_for_Geo-Localization_CVPR_2021_paper.pdf",
        "aff": "Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": "2103.06818"
    },
    {
        "title": "Communication Efficient SGD via Gradient Sampling With Bayes Prior",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_Communication_Efficient_SGD_via_Gradient_Sampling_With_Bayes_Prior_CVPR_2021_paper.html",
        "author": "Liuyihan Song, Kang Zhao, Pan Pan, Yu Liu, Yingya Zhang, Yinghui Xu, Rong Jin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Communication_Efficient_SGD_via_Gradient_Sampling_With_Bayes_Prior_CVPR_2021_paper.pdf",
        "aff": "Machine Intelligence Technology Lab, Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Compatibility-Aware Heterogeneous Visual Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Duggal_Compatibility-Aware_Heterogeneous_Visual_Search_CVPR_2021_paper.html",
        "author": "Rahul Duggal, Hao Zhou, Shuo Yang, Yuanjun Xiong, Wei Xia, Zhuowen Tu, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Duggal_Compatibility-Aware_Heterogeneous_Visual_Search_CVPR_2021_paper.pdf",
        "aff": "AWS/Amazon AI; Currently at the Georgia Institute of Technology; AWS/Amazon AI",
        "project": "",
        "github": "",
        "arxiv": "2105.06047"
    },
    {
        "title": "Complementary Relation Contrastive Distillation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Complementary_Relation_Contrastive_Distillation_CVPR_2021_paper.html",
        "author": "Jinguo Zhu, Shixiang Tang, Dapeng Chen, Shijie Yu, Yakun Liu, Mingzhe Rong, Aijun Yang, Xiaohua Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Complementary_Relation_Contrastive_Distillation_CVPR_2021_paper.pdf",
        "aff": "The University of Sydney; Shenzhen Institutes of Advanced Technology, CAS; Sensetime Group Limited; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": "2103.16367"
    },
    {
        "title": "Complete & Label: A Domain Adaptation Approach to Semantic Segmentation of LiDAR Point Clouds",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yi_Complete__Label_A_Domain_Adaptation_Approach_to_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Li Yi, Boqing Gong, Thomas Funkhouser",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yi_Complete__Label_A_Domain_Adaptation_Approach_to_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "",
        "arxiv": "2007.08488"
    },
    {
        "title": "Composing Photos Like a Photographer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Composing_Photos_Like_a_Photographer_CVPR_2021_paper.html",
        "author": "Chaoyi Hong, Shuaiyuan Du, Ke Xian, Hao Lu, Zhiguo Cao, Weicai Zhong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Composing_Photos_Like_a_Photographer_CVPR_2021_paper.pdf",
        "aff": "Key Laboratory of Image Processing and Intelligent Control, Ministry of Education, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology; Huawei CBG Consumer Cloud Service Search Product & Big Data Platform Department",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "CompositeTasking: Understanding Images by Spatial Composition of Tasks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Popovic_CompositeTasking_Understanding_Images_by_Spatial_Composition_of_Tasks_CVPR_2021_paper.html",
        "author": "Nikola Popovic, Danda Pani Paudel, Thomas Probst, Guolei Sun, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Popovic_CompositeTasking_Understanding_Images_by_Spatial_Composition_of_Tasks_CVPR_2021_paper.pdf",
        "aff": "VISICS, ESAT/PSI, KU Leuven, Belgium; Computer Vision Laboratory, ETH Zurich, Switzerland",
        "project": "",
        "github": "www.github.com/nikola3794/composite-tasking",
        "arxiv": "2012.09030"
    },
    {
        "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Changpinyo_Conceptual_12M_Pushing_Web-Scale_Image-Text_Pre-Training_To_Recognize_Long-Tail_Visual_CVPR_2021_paper.html",
        "author": "Soravit Changpinyo, Piyush Sharma, Nan Ding, Radu Soricut",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Changpinyo_Conceptual_12M_Pushing_Web-Scale_Image-Text_Pre-Training_To_Recognize_Long-Tail_Visual_CVPR_2021_paper.pdf",
        "aff": "3558\n",
        "project": "",
        "github": "",
        "arxiv": "2102.08981"
    },
    {
        "title": "CondenseNet V2: Sparse Feature Reactivation for Deep Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_CondenseNet_V2_Sparse_Feature_Reactivation_for_Deep_Networks_CVPR_2021_paper.html",
        "author": "Le Yang, Haojun Jiang, Ruojin Cai, Yulin Wang, Shiji Song, Gao Huang, Qi Tian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_CondenseNet_V2_Sparse_Feature_Reactivation_for_Deep_Networks_CVPR_2021_paper.pdf",
        "aff": "Cornell University; Huawei Cloud &AI; Department of Automation, Tsinghua University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": "2104.04382"
    },
    {
        "title": "Conditional Bures Metric for Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Conditional_Bures_Metric_for_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "You-Wei Luo, Chuan-Xian Ren",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Conditional_Bures_Metric_for_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "School of Mathematics, Sun Yat-Sen University, China; School of Mathematics, Sun Yat-Sen University, China; Pazhou Lab, Guangzhou, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Confluent Vessel Trees With Accurate Bifurcations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Confluent_Vessel_Trees_With_Accurate_Bifurcations_CVPR_2021_paper.html",
        "author": "Zhongwen Zhang, Dmitrii Marin, Maria Drangova, Yuri Boykov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Confluent_Vessel_Trees_With_Accurate_Bifurcations_CVPR_2021_paper.pdf",
        "aff": "University of Waterloo, Canada / Vector Research Institute, Canada; Robarts Research, Canada; University of Waterloo, Canada",
        "project": "",
        "github": "https://vision.cs.uwaterloo.ca/code",
        "arxiv": "2103.14268"
    },
    {
        "title": "Connecting What To Say With Where To Look by Modeling Human Attention Traces",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Meng_Connecting_What_To_Say_With_Where_To_Look_by_Modeling_CVPR_2021_paper.html",
        "author": "Zihang Meng, Licheng Yu, Ning Zhang, Tamara L. Berg, Babak Damavandi, Vikas Singh, Amy Bearman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Meng_Connecting_What_To_Say_With_Where_To_Look_by_Modeling_CVPR_2021_paper.pdf",
        "aff": "University of Wisconsin Madison; Facebook AI",
        "project": "http://pages.cs.wisc.edu/~zihangm/connect_caption_trace",
        "github": "https://github.com/facebookresearch/connect-caption-and-trace",
        "arxiv": "2105.05964"
    },
    {
        "title": "Consensus Maximisation Using Influences of Monotone Boolean Functions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tennakoon_Consensus_Maximisation_Using_Influences_of_Monotone_Boolean_Functions_CVPR_2021_paper.html",
        "author": "Ruwan Tennakoon, David Suter, Erchuan Zhang, Tat-Jun Chin, Alireza Bab-Hadiashar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tennakoon_Consensus_Maximisation_Using_Influences_of_Monotone_Boolean_Functions_CVPR_2021_paper.pdf",
        "aff": "Edith Cowan University, Perth Australia; RMIT University, Melbourne Australia; University of Adelaide, Adelaide Australia",
        "project": "",
        "github": "",
        "arxiv": "2103.04200"
    },
    {
        "title": "Consistent Instance False Positive Improves Fairness in Face Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Consistent_Instance_False_Positive_Improves_Fairness_in_Face_Recognition_CVPR_2021_paper.html",
        "author": "Xingkun Xu, Yuge Huang, Pengcheng Shen, Shaoxin Li, Jilin Li, Feiyue Huang, Yong Li, Zhen Cui",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Consistent_Instance_False_Positive_Improves_Fairness_in_Face_Recognition_CVPR_2021_paper.pdf",
        "aff": "Nanjing University of Science and Technology; Youtu Lab, Tencent",
        "project": "",
        "github": "https://github.com/xkx0430/FairnessFR",
        "arxiv": "2106.05519"
    },
    {
        "title": "ContactOpt: Optimizing Contact To Improve Grasps",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Grady_ContactOpt_Optimizing_Contact_To_Improve_Grasps_CVPR_2021_paper.html",
        "author": "Patrick Grady, Chengcheng Tang, Christopher D. Twigg, Minh Vo, Samarth Brahmbhatt, Charles C. Kemp",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Grady_ContactOpt_Optimizing_Contact_To_Improve_Grasps_CVPR_2021_paper.pdf",
        "aff": "Intel Labs; Georgia Institute of Technology; Facebook Reality Labs Research",
        "project": "",
        "github": "https://github.com/facebookresearch/contactopt",
        "arxiv": "2104.07267"
    },
    {
        "title": "Content-Aware GAN Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Content-Aware_GAN_Compression_CVPR_2021_paper.html",
        "author": "Yuchen Liu, Zhixin Shu, Yijun Li, Zhe Lin, Federico Perazzi, Sun-Yuan Kung",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Content-Aware_GAN_Compression_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; Princeton University",
        "project": "",
        "github": "",
        "arxiv": "2104.02244"
    },
    {
        "title": "Context Modeling in 3D Human Pose Estimation: A Unified Perspective",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Context_Modeling_in_3D_Human_Pose_Estimation_A_Unified_Perspective_CVPR_2021_paper.html",
        "author": "Xiaoxuan Ma, Jiajun Su, Chunyu Wang, Hai Ci, Yizhou Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_Context_Modeling_in_3D_Human_Pose_Estimation_A_Unified_Perspective_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; Dept. of Computer Science, Center on Frontiers of Computing Studies, Peking University; Center for Data Science, Adv. Inst. of Info. Tech., Peking University",
        "project": "",
        "github": "",
        "arxiv": "2103.15507"
    },
    {
        "title": "Context-Aware Biaffine Localizing Network for Temporal Sentence Grounding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Context-Aware_Biaffine_Localizing_Network_for_Temporal_Sentence_Grounding_CVPR_2021_paper.html",
        "author": "Daizong Liu, Xiaoye Qu, Jianfeng Dong, Pan Zhou, Yu Cheng, Wei Wei, Zichuan Xu, Yulai Xie",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Context-Aware_Biaffine_Localizing_Network_for_Temporal_Sentence_Grounding_CVPR_2021_paper.pdf",
        "aff": "Dalian University of Technology; Zhejiang Gongshang University; Huawei Cloud; Huazhong University of Science and Technology; Microsoft AI",
        "project": "",
        "github": "https://github.com/liudaizong/CBLN",
        "arxiv": "2103.11555"
    },
    {
        "title": "Context-Aware Layout to Image Generation With Enhanced Object Appearance",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_Context-Aware_Layout_to_Image_Generation_With_Enhanced_Object_Appearance_CVPR_2021_paper.html",
        "author": "Sen He, Wentong Liao, Michael Ying Yang, Yongxin Yang, Yi-Zhe Song, Bodo Rosenhahn, Tao Xiang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_Context-Aware_Layout_to_Image_Generation_With_Enhanced_Object_Appearance_CVPR_2021_paper.pdf",
        "aff": "TNT, Leibniz University Hannover; CVSSP, University of Surrey, iFlyTek-Surrey Joint Research Centre on Artificial Intelligence; SUG, University of Twente",
        "project": "",
        "github": "https://github.com/wtliao/layout2img",
        "arxiv": "2103.11897"
    },
    {
        "title": "Continual Adaptation of Visual Representations via Domain Randomization and Meta-Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Volpi_Continual_Adaptation_of_Visual_Representations_via_Domain_Randomization_and_Meta-Learning_CVPR_2021_paper.html",
        "author": "Riccardo Volpi, Diane Larlus, Gregory Rogez",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Volpi_Continual_Adaptation_of_Visual_Representations_via_Domain_Randomization_and_Meta-Learning_CVPR_2021_paper.pdf",
        "aff": "NAVER LABS Europe",
        "project": "www.europe.naverlabs.com",
        "github": "",
        "arxiv": "2012.04324"
    },
    {
        "title": "Continual Learning via Bit-Level Information Preserving",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Continual_Learning_via_Bit-Level_Information_Preserving_CVPR_2021_paper.html",
        "author": "Yujun Shi, Li Yuan, Yunpeng Chen, Jiashi Feng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_Continual_Learning_via_Bit-Level_Information_Preserving_CVPR_2021_paper.pdf",
        "aff": "YITU Technology; National University of Singapore",
        "project": "",
        "github": "https://github.com/Yujun-Shi/BLIP",
        "arxiv": "2105.04444"
    },
    {
        "title": "Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Michieli_Continual_Semantic_Segmentation_via_Repulsion-Attraction_of_Sparse_and_Disentangled_Latent_CVPR_2021_paper.html",
        "author": "Umberto Michieli, Pietro Zanuttigh",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Michieli_Continual_Semantic_Segmentation_via_Repulsion-Attraction_of_Sparse_and_Disentangled_Latent_CVPR_2021_paper.pdf",
        "aff": "Department of Information Engineering, University of Padova",
        "project": "",
        "github": "",
        "arxiv": "2103.06342"
    },
    {
        "title": "Continuous Face Aging via Self-Estimated Residual Age Embedding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Continuous_Face_Aging_via_Self-Estimated_Residual_Age_Embedding_CVPR_2021_paper.html",
        "author": "Zeqi Li, Ruowei Jiang, Parham Aarabi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Continuous_Face_Aging_via_Self-Estimated_Residual_Age_Embedding_CVPR_2021_paper.pdf",
        "aff": "ModiFace",
        "project": "",
        "github": "",
        "arxiv": "2105.00020"
    },
    {
        "title": "Contrastive Embedding for Generalized Zero-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Han_Contrastive_Embedding_for_Generalized_Zero-Shot_Learning_CVPR_2021_paper.html",
        "author": "Zongyan Han, Zhenyong Fu, Shuo Chen, Jian Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Han_Contrastive_Embedding_for_Generalized_Zero-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "PCALab, Nanjing University of Science and Technology, China; RIKEN Center for Advanced Intelligence Project, Japan",
        "project": "",
        "github": "https://github.com/Hanzy1996/CE-GZSL",
        "arxiv": "2103.16173"
    },
    {
        "title": "Contrastive Learning Based Hybrid Networks for Long-Tailed Image Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Contrastive_Learning_Based_Hybrid_Networks_for_Long-Tailed_Image_Classification_CVPR_2021_paper.html",
        "author": "Peng Wang, Kai Han, Xiu-Shen Wei, Lei Zhang, Lei Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Contrastive_Learning_Based_Hybrid_Networks_for_Long-Tailed_Image_Classification_CVPR_2021_paper.pdf",
        "aff": "Northwestern Polytechnical University; University of Bristol; Nanjing University of Science and Technology; University of Wollongong",
        "project": "",
        "github": "",
        "arxiv": "2103.14267"
    },
    {
        "title": "Contrastive Learning for Compact Single Image Dehazing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Contrastive_Learning_for_Compact_Single_Image_Dehazing_CVPR_2021_paper.html",
        "author": "Haiyan Wu, Yanyun Qu, Shaohui Lin, Jian Zhou, Ruizhi Qiao, Zhizhong Zhang, Yuan Xie, Lizhuang Ma",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Contrastive_Learning_for_Compact_Single_Image_Dehazing_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Information Science and Engineering, Xiamen University, Fujian, China; Tencent Youtu Lab, Shanghai, China",
        "project": "",
        "github": "https://github.com/GlassyWu/AECR-Net",
        "arxiv": "2104.09367"
    },
    {
        "title": "Contrastive Neural Architecture Search With Neural Architecture Comparators",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Contrastive_Neural_Architecture_Search_With_Neural_Architecture_Comparators_CVPR_2021_paper.html",
        "author": "Yaofo Chen, Yong Guo, Qi Chen, Minli Li, Wei Zeng, Yaowei Wang, Mingkui Tan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Contrastive_Neural_Architecture_Search_With_Neural_Architecture_Comparators_CVPR_2021_paper.pdf",
        "aff": "South China University of Technology, Key Laboratory of Big Data and Intelligent Robot, Ministry of Education; South China University of Technology; Peng Cheng Laboratory; Peking University; South China University of Technology, Peng Cheng Laboratory",
        "project": "",
        "github": "",
        "arxiv": "2103.05471"
    },
    {
        "title": "Controllable Image Restoration for Under-Display Camera in Smartphones",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kwon_Controllable_Image_Restoration_for_Under-Display_Camera_in_Smartphones_CVPR_2021_paper.html",
        "author": "Kinam Kwon, Eunhee Kang, Sangwon Lee, Su-Jin Lee, Hyong-Euk Lee, ByungIn Yoo, Jae-Joon Han",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kwon_Controllable_Image_Restoration_for_Under-Display_Camera_in_Smartphones_CVPR_2021_paper.pdf",
        "aff": "Samsung Advanced Institute of Technology (SAIT), South Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Controlling the Rain: From Removal to Rendering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ni_Controlling_the_Rain_From_Removal_to_Rendering_CVPR_2021_paper.html",
        "author": "Siqi Ni, Xueyun Cao, Tao Yue, Xuemei Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ni_Controlling_the_Rain_From_Removal_to_Rendering_CVPR_2021_paper.pdf",
        "aff": "School of Electronic Science and Engineering, Nanjing University, Nanjing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Convolutional Dynamic Alignment Networks for Interpretable Classifications",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bohle_Convolutional_Dynamic_Alignment_Networks_for_Interpretable_Classifications_CVPR_2021_paper.html",
        "author": "Moritz Bohle, Mario Fritz, Bernt Schiele",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bohle_Convolutional_Dynamic_Alignment_Networks_for_Interpretable_Classifications_CVPR_2021_paper.pdf",
        "aff": "CISPA Helmholtz Center for Information Security; MPI for Informatics, Saarland Informatics Campus",
        "project": "",
        "github": "github.com/moboehle/CoDA-Nets",
        "arxiv": "2104.00032"
    },
    {
        "title": "Convolutional Hough Matching Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Min_Convolutional_Hough_Matching_Networks_CVPR_2021_paper.html",
        "author": "Juhong Min, Minsu Cho",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Min_Convolutional_Hough_Matching_Networks_CVPR_2021_paper.pdf",
        "aff": "POSTECH CSE & GSAI",
        "project": "http://cvlab.postech.ac.kr/research/CHM/",
        "github": "",
        "arxiv": "2103.16831"
    },
    {
        "title": "Convolutional Neural Network Pruning With Structural Redundancy Reduction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Convolutional_Neural_Network_Pruning_With_Structural_Redundancy_Reduction_CVPR_2021_paper.html",
        "author": "Zi Wang, Chengcheng Li, Xiangyang Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Convolutional_Neural_Network_Pruning_With_Structural_Redundancy_Reduction_CVPR_2021_paper.pdf",
        "aff": "Sun Yat-sen University, Guangzhou, China; The University of Tennessee, Knoxville, TN, USA",
        "project": "",
        "github": "",
        "arxiv": "2104.03438"
    },
    {
        "title": "Coordinate Attention for Efficient Mobile Network Design",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.html",
        "author": "Qibin Hou, Daquan Zhou, Jiashi Feng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.pdf",
        "aff": "National University of Singapore and SEA AI Lab; National University of Singapore",
        "project": "",
        "github": "https://github.com/Andrew-Qibin/CoordAttention",
        "arxiv": "2103.02907"
    },
    {
        "title": "CorrNet3D: Unsupervised End-to-End Learning of Dense Correspondence for 3D Point Clouds",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zeng_CorrNet3D_Unsupervised_End-to-End_Learning_of_Dense_Correspondence_for_3D_Point_CVPR_2021_paper.html",
        "author": "Yiming Zeng, Yue Qian, Zhiyu Zhu, Junhui Hou, Hui Yuan, Ying He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zeng_CorrNet3D_Unsupervised_End-to-End_Learning_of_Dense_Correspondence_for_3D_Point_CVPR_2021_paper.pdf",
        "aff": "Shandong University; City University of Hong Kong; Nanyang Technological University",
        "project": "",
        "github": "https://github.com/ZENGYIMING-EAMON/CorrNet3D.git",
        "arxiv": "2012.15638"
    },
    {
        "title": "Correlated Input-Dependent Label Noise in Large-Scale Image Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Collier_Correlated_Input-Dependent_Label_Noise_in_Large-Scale_Image_Classification_CVPR_2021_paper.html",
        "author": "Mark Collier, Basil Mustafa, Efi Kokiopoulou, Rodolphe Jenatton, Jesse Berent",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Collier_Correlated_Input-Dependent_Label_Noise_in_Large-Scale_Image_Classification_CVPR_2021_paper.pdf",
        "aff": "Google AI",
        "project": "",
        "github": "",
        "arxiv": "2105.10305"
    },
    {
        "title": "Counterfactual VQA: A Cause-Effect Look at Language Bias",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Niu_Counterfactual_VQA_A_Cause-Effect_Look_at_Language_Bias_CVPR_2021_paper.html",
        "author": "Yulei Niu, Kaihua Tang, Hanwang Zhang, Zhiwu Lu, Xian-Sheng Hua, Ji-Rong Wen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Niu_Counterfactual_VQA_A_Cause-Effect_Look_at_Language_Bias_CVPR_2021_paper.pdf",
        "aff": "Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China, Beijing, China; Beijing Key Laboratory of Big Data Management and Analysis Methods; Nanyang Technological University, Singapore",
        "project": "",
        "github": "https://github.com/yuleiniu/cfvqa",
        "arxiv": "2006.04315"
    },
    {
        "title": "Counterfactual Zero-Shot and Open-Set Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yue_Counterfactual_Zero-Shot_and_Open-Set_Visual_Recognition_CVPR_2021_paper.html",
        "author": "Zhongqi Yue, Tan Wang, Qianru Sun, Xian-Sheng Hua, Hanwang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yue_Counterfactual_Zero-Shot_and_Open-Set_Visual_Recognition_CVPR_2021_paper.pdf",
        "aff": "15404\n",
        "project": "",
        "github": "",
        "arxiv": "2103.00887"
    },
    {
        "title": "Cross Modal Focal Loss for RGBD Face Anti-Spoofing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/George_Cross_Modal_Focal_Loss_for_RGBD_Face_Anti-Spoofing_CVPR_2021_paper.html",
        "author": "Anjith George, Sebastien Marcel",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/George_Cross_Modal_Focal_Loss_for_RGBD_Face_Anti-Spoofing_CVPR_2021_paper.pdf",
        "aff": "Idiap Research Institute, Rue Marconi 19, CH - 1920, Martigny, Switzerland",
        "project": "",
        "github": "",
        "arxiv": "2103.00948"
    },
    {
        "title": "Cross-Domain Adaptive Clustering for Semi-Supervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Cross-Domain_Adaptive_Clustering_for_Semi-Supervised_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Jichang Li, Guanbin Li, Yemin Shi, Yizhou Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Cross-Domain_Adaptive_Clustering_for_Semi-Supervised_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "Sun Yat-sen University; The University of Hong Kong; Deepwise AI Lab",
        "project": "",
        "github": "",
        "arxiv": "2104.09415"
    },
    {
        "title": "Cross-Domain Gradient Discrepancy Minimization for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Du_Cross-Domain_Gradient_Discrepancy_Minimization_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Zhekai Du, Jingjing Li, Hongzu Su, Lei Zhu, Ke Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Du_Cross-Domain_Gradient_Discrepancy_Minimization_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; Shandong Normal University",
        "project": "",
        "github": "",
        "arxiv": "2106.04151"
    },
    {
        "title": "Cross-Domain Similarity Learning for Face Recognition in Unseen Domains",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Faraki_Cross-Domain_Similarity_Learning_for_Face_Recognition_in_Unseen_Domains_CVPR_2021_paper.html",
        "author": "Masoud Faraki, Xiang Yu, Yi-Hsuan Tsai, Yumin Suh, Manmohan Chandraker",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Faraki_Cross-Domain_Similarity_Learning_for_Face_Recognition_in_Unseen_Domains_CVPR_2021_paper.pdf",
        "aff": "NEC Labs America, University of California, San Diego; NEC Labs America",
        "project": "",
        "github": "",
        "arxiv": "2103.07503"
    },
    {
        "title": "Cross-Iteration Batch Normalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yao_Cross-Iteration_Batch_Normalization_CVPR_2021_paper.html",
        "author": "Zhuliang Yao, Yue Cao, Shuxin Zheng, Gao Huang, Stephen Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yao_Cross-Iteration_Batch_Normalization_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; Tsinghua University",
        "project": "",
        "github": "https://aka.ms/cbn",
        "arxiv": "2002.05712"
    },
    {
        "title": "Cross-MPI: Cross-Scale Stereo for Image Super-Resolution Using Multiplane Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Cross-MPI_Cross-Scale_Stereo_for_Image_Super-Resolution_Using_Multiplane_Images_CVPR_2021_paper.html",
        "author": "Yuemei Zhou, Gaochang Wu, Ying Fu, Kun Li, Yebin Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Cross-MPI_Cross-Scale_Stereo_for_Image_Super-Resolution_Using_Multiplane_Images_CVPR_2021_paper.pdf",
        "aff": "Tianjin University; Northeastern University; Beijing Institute of Technology; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Cross-Modal Center Loss for 3D Cross-Modal Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jing_Cross-Modal_Center_Loss_for_3D_Cross-Modal_Retrieval_CVPR_2021_paper.html",
        "author": "Longlong Jing, Elahe Vahdani, Jiaxing Tan, Yingli Tian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jing_Cross-Modal_Center_Loss_for_3D_Cross-Modal_Retrieval_CVPR_2021_paper.pdf",
        "aff": "The City University of New York",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Cross-Modal Collaborative Representation Learning and a Large-Scale RGBT Benchmark for Crowd Counting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Cross-Modal_Collaborative_Representation_Learning_and_a_Large-Scale_RGBT_Benchmark_for_CVPR_2021_paper.html",
        "author": "Lingbo Liu, Jiaqi Chen, Hefeng Wu, Guanbin Li, Chenglong Li, Liang Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Cross-Modal_Collaborative_Representation_Learning_and_a_Large-Scale_RGBT_Benchmark_for_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Anhui University, China; School of Computer Science and Engineering, Sun Yat-sen University, China; DarkMatter AI Research, China; School of Computer Science and Engineering, Sun Yat-sen University, China; Pazhou Lab, Guangzhou, China",
        "project": "",
        "github": "http://lingboliu.com/RGBT_Crowd_Counting.html",
        "arxiv": "2012.04529"
    },
    {
        "title": "Cross-Modal Contrastive Learning for Text-to-Image Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Cross-Modal_Contrastive_Learning_for_Text-to-Image_Generation_CVPR_2021_paper.html",
        "author": "Han Zhang, Jing Yu Koh, Jason Baldridge, Honglak Lee, Yinfei Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Cross-Modal_Contrastive_Learning_for_Text-to-Image_Generation_CVPR_2021_paper.pdf",
        "aff": "University of Michigan; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2101.04702"
    },
    {
        "title": "Cross-View Cross-Scene Multi-View Crowd Counting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Cross-View_Cross-Scene_Multi-View_Crowd_Counting_CVPR_2021_paper.html",
        "author": "Qi Zhang, Wei Lin, Antoni B. Chan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Cross-View_Cross-Scene_Multi-View_Crowd_Counting_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, City University of Hong Kong, Hong Kong SAR, China; School of Computer Science and School of Arti\ufb01cial Intelligence, Northwestern Polytechnical University, Xi\u2019an, Shaanxi, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Cross-View Gait Recognition With Deep Universal Linear Embeddings",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Cross-View_Gait_Recognition_With_Deep_Universal_Linear_Embeddings_CVPR_2021_paper.html",
        "author": "Shaoxiong Zhang, Yunhong Wang, Annan Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Cross-View_Gait_Recognition_With_Deep_Universal_Linear_Embeddings_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Cross-View Regularization for Domain Adaptive Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Cross-View_Regularization_for_Domain_Adaptive_Panoptic_Segmentation_CVPR_2021_paper.html",
        "author": "Jiaxing Huang, Dayan Guan, Aoran Xiao, Shijian Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Cross-View_Regularization_for_Domain_Adaptive_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science Engineering, Nanyang Technological University",
        "project": "",
        "github": "",
        "arxiv": "2103.02584"
    },
    {
        "title": "Crossing Cuts Polygonal Puzzles: Models and Solvers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Harel_Crossing_Cuts_Polygonal_Puzzles_Models_and_Solvers_CVPR_2021_paper.html",
        "author": "Peleg Harel, Ohad Ben-Shahar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Harel_Crossing_Cuts_Polygonal_Puzzles_Models_and_Solvers_CVPR_2021_paper.pdf",
        "aff": "Ben-Gurion University of the Negev",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Cuboids Revisited: Learning Robust 3D Shape Fitting to Single RGB Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kluger_Cuboids_Revisited_Learning_Robust_3D_Shape_Fitting_to_Single_RGB_CVPR_2021_paper.html",
        "author": "Florian Kluger, Hanno Ackermann, Eric Brachmann, Michael Ying Yang, Bodo Rosenhahn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kluger_Cuboids_Revisited_Learning_Robust_3D_Shape_Fitting_to_Single_RGB_CVPR_2021_paper.pdf",
        "aff": "Niantic; University of Twente; Leibniz University Hannover",
        "project": "",
        "github": "",
        "arxiv": "2105.02047"
    },
    {
        "title": "Curriculum Graph Co-Teaching for Multi-Target Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Roy_Curriculum_Graph_Co-Teaching_for_Multi-Target_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Subhankar Roy, Evgeny Krivosheev, Zhun Zhong, Nicu Sebe, Elisa Ricci",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Roy_Curriculum_Graph_Co-Teaching_for_Multi-Target_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "University of Trento, Italy; Fondazione Bruno Kessler, Italy; University of Trento, Italy",
        "project": "https://roysubhankar.github.io/graph-coteaching-adaptation",
        "github": "",
        "arxiv": "2104.00808"
    },
    {
        "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_CutPaste_Self-Supervised_Learning_for_Anomaly_Detection_and_Localization_CVPR_2021_paper.html",
        "author": "Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, Tomas Pfister",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_CutPaste_Self-Supervised_Learning_for_Anomaly_Detection_and_Localization_CVPR_2021_paper.pdf",
        "aff": "Google Cloud AI Research",
        "project": "",
        "github": "",
        "arxiv": "2104.04015"
    },
    {
        "title": "Cycle4Completion: Unpaired Point Cloud Completion Using Cycle Transformation With Missing Region Coding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Cycle4Completion_Unpaired_Point_Cloud_Completion_Using_Cycle_Transformation_With_Missing_CVPR_2021_paper.html",
        "author": "Xin Wen, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, Yu-Shen Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wen_Cycle4Completion_Unpaired_Point_Cloud_Completion_Using_Cycle_Transformation_With_Missing_CVPR_2021_paper.pdf",
        "aff": "Y-tech, Kuaishou Technology, Beijing, China; Department of Computer Science, Wayne State University, USA; School of Software, BNRist, Tsinghua University, Beijing, China",
        "project": "",
        "github": "https://github.com/diviswen/Cycle4Completion",
        "arxiv": "2103.07838"
    },
    {
        "title": "Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Cyclic_Co-Learning_of_Sounding_Object_Visual_Grounding_and_Sound_Separation_CVPR_2021_paper.html",
        "author": "Yapeng Tian, Di Hu, Chenliang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_Cyclic_Co-Learning_of_Sounding_Object_Visual_Grounding_and_Sound_Separation_CVPR_2021_paper.pdf",
        "aff": "Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China; Beijing Key Laboratory of Big Data Management and Analysis Methods; University of Rochester",
        "project": "",
        "github": "https://github.com/YapengTian/CCOL-CVPR21",
        "arxiv": "2104.02026"
    },
    {
        "title": "Cylindrical and Asymmetrical 3D Convolution Networks for LiDAR Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Cylindrical_and_Asymmetrical_3D_Convolution_Networks_for_LiDAR_Segmentation_CVPR_2021_paper.html",
        "author": "Xinge Zhu, Hui Zhou, Tai Wang, Fangzhou Hong, Yuexin Ma, Wei Li, Hongsheng Li, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Cylindrical_and_Asymmetrical_3D_Convolution_Networks_for_LiDAR_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Centre of Perceptual and Interactive Intelligence; Nanyang Technological University; Inceptio; CUHK-SenseTime Joint Lab, CUHK; ShanghaiTech University; School of CST, Xidian University",
        "project": "",
        "github": "https://github.com/xinge008/Cylinder3D",
        "arxiv": "2011.10033"
    },
    {
        "title": "D-NeRF: Neural Radiance Fields for Dynamic Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pumarola_D-NeRF_Neural_Radiance_Fields_for_Dynamic_Scenes_CVPR_2021_paper.html",
        "author": "Albert Pumarola, Enric Corona, Gerard Pons-Moll, Francesc Moreno-Noguer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pumarola_D-NeRF_Neural_Radiance_Fields_for_Dynamic_Scenes_CVPR_2021_paper.pdf",
        "aff": "Institut de Rob `otica i Inform `atica Industrial, CSIC-UPC; University of T \u00a8ubingen",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "D2IM-Net: Learning Detail Disentangled Implicit Fields From Single Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_D2IM-Net_Learning_Detail_Disentangled_Implicit_Fields_From_Single_Images_CVPR_2021_paper.html",
        "author": "Manyi Li, Hao Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_D2IM-Net_Learning_Detail_Disentangled_Implicit_Fields_From_Single_Images_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DANNet: A One-Stage Domain Adaptation Network for Unsupervised Nighttime Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_DANNet_A_One-Stage_Domain_Adaptation_Network_for_Unsupervised_Nighttime_Semantic_CVPR_2021_paper.html",
        "author": "Xinyi Wu, Zhenyao Wu, Hao Guo, Lili Ju, Song Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_DANNet_A_One-Stage_Domain_Adaptation_Network_for_Unsupervised_Nighttime_Semantic_CVPR_2021_paper.pdf",
        "aff": "University of South Carolina, USA; University of South Carolina, USA; Farsee2 Technology Ltd, China",
        "project": "",
        "github": "https://github.com/W-zx-Y/DANNet",
        "arxiv": "2104.10834"
    },
    {
        "title": "DAP: Detection-Aware Pre-Training With Weak Supervision",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_DAP_Detection-Aware_Pre-Training_With_Weak_Supervision_CVPR_2021_paper.html",
        "author": "Yuanyi Zhong, Jianfeng Wang, Lijuan Wang, Jian Peng, Yu-Xiong Wang, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_DAP_Detection-Aware_Pre-Training_With_Weak_Supervision_CVPR_2021_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign; Microsoft",
        "project": "",
        "github": "",
        "arxiv": "2103.16651"
    },
    {
        "title": "DARCNN: Domain Adaptive Region-Based Convolutional Neural Network for Unsupervised Instance Segmentation in Biomedical Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hsu_DARCNN_Domain_Adaptive_Region-Based_Convolutional_Neural_Network_for_Unsupervised_Instance_CVPR_2021_paper.html",
        "author": "Joy Hsu, Wah Chiu, Serena Yeung",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hsu_DARCNN_Domain_Adaptive_Region-Based_Convolutional_Neural_Network_for_Unsupervised_Instance_CVPR_2021_paper.pdf",
        "aff": "Stanford University",
        "project": "",
        "github": "",
        "arxiv": "2104.01325"
    },
    {
        "title": "DAT: Training Deep Networks Robust To Label-Noise by Matching the Feature Distributions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qu_DAT_Training_Deep_Networks_Robust_To_Label-Noise_by_Matching_the_CVPR_2021_paper.html",
        "author": "Yuntao Qu, Shasha Mo, Jianwei Niu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qu_DAT_Training_Deep_Networks_Robust_To_Label-Noise_by_Matching_the_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University; Zhengzhou University Research Institute of Industrial Technology, Zhengzhou University; Hangzhou Innovation Institute of Beihang University; School of Cyber Science and Technology, Beihang University",
        "project": "",
        "github": "https://github.com/Tyqnn0323/DAT",
        "arxiv": ""
    },
    {
        "title": "DCNAS: Densely Connected Neural Architecture Search for Semantic Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DCNAS_Densely_Connected_Neural_Architecture_Search_for_Semantic_Image_Segmentation_CVPR_2021_paper.html",
        "author": "Xiong Zhang, Hongmin Xu, Hong Mo, Jianchao Tan, Cheng Yang, Lei Wang, Wenqi Ren",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_DCNAS_Densely_Connected_Neural_Architecture_Search_for_Semantic_Image_Segmentation_CVPR_2021_paper.pdf",
        "aff": "State Key Lab of VR, Beihang University; SKLOIS, IIE, CAS; Joyy Inc.; AI Platform, Kwai Inc.",
        "project": "",
        "github": "",
        "arxiv": "2003.11883"
    },
    {
        "title": "DCT-Mask: Discrete Cosine Transform Mask Representation for Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shen_DCT-Mask_Discrete_Cosine_Transform_Mask_Representation_for_Instance_Segmentation_CVPR_2021_paper.html",
        "author": "Xing Shen, Jirui Yang, Chunbo Wei, Bing Deng, Jianqiang Huang, Xian-Sheng Hua, Xiaoliang Cheng, Kewei Liang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_DCT-Mask_Discrete_Cosine_Transform_Mask_Representation_for_Instance_Segmentation_CVPR_2021_paper.pdf",
        "aff": "School of Mathematical Sciences, Zhejiang University; DAMO Academy, Alibaba Group; DAMO Academy, Alibaba Group; School of Mathematical Sciences, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DECOR-GAN: 3D Shape Detailization by Conditional Refinement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_DECOR-GAN_3D_Shape_Detailization_by_Conditional_Refinement_CVPR_2021_paper.html",
        "author": "Zhiqin Chen, Vladimir G. Kim, Matthew Fisher, Noam Aigerman, Hao Zhang, Siddhartha Chaudhuri",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_DECOR-GAN_3D_Shape_Detailization_by_Conditional_Refinement_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; Adobe Research; Adobe Research, IIT Bombay",
        "project": "",
        "github": "https://github.com/czq142857/DECOR-GAN",
        "arxiv": ""
    },
    {
        "title": "DER: Dynamically Expandable Representation for Class Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_DER_Dynamically_Expandable_Representation_for_Class_Incremental_Learning_CVPR_2021_paper.html",
        "author": "Shipeng Yan, Jiangwei Xie, Xuming He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_DER_Dynamically_Expandable_Representation_for_Class_Incremental_Learning_CVPR_2021_paper.pdf",
        "aff": "School of Information Science and Technology, ShanghaiTech University; Shanghai Engineering Research Center of Intelligent Vision and Imaging; School of Information Science and Technology, ShanghaiTech University; School of Information Science and Technology, ShanghaiTech University; Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/Rhyssiyan/DER-ClassIL.pytorch",
        "arxiv": "2103.16788"
    },
    {
        "title": "DG-Font: Deformable Generative Networks for Unsupervised Font Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xie_DG-Font_Deformable_Generative_Networks_for_Unsupervised_Font_Generation_CVPR_2021_paper.html",
        "author": "Yangchen Xie, Xinyuan Chen, Li Sun, Yue Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xie_DG-Font_Deformable_Generative_Networks_for_Unsupervised_Font_Generation_CVPR_2021_paper.pdf",
        "aff": "Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, 200241 Shanghai, China",
        "project": "",
        "github": "https://github.com/ecnuycxie/DG-Font",
        "arxiv": ""
    },
    {
        "title": "DI-Fusion: Online Implicit 3D Reconstruction With Deep Priors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_DI-Fusion_Online_Implicit_3D_Reconstruction_With_Deep_Priors_CVPR_2021_paper.html",
        "author": "Jiahui Huang, Shi-Sheng Huang, Haoxuan Song, Shi-Min Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_DI-Fusion_Online_Implicit_3D_Reconstruction_With_Deep_Priors_CVPR_2021_paper.pdf",
        "aff": "BNRist, Department of Computer Science and Technology, Tsinghua University, Beijing",
        "project": "",
        "github": "https://www.github.com/huangjh-pub/di-fusion",
        "arxiv": ""
    },
    {
        "title": "DISCO: Dynamic and Invariant Sensitive Channel Obfuscation for Deep Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Singh_DISCO_Dynamic_and_Invariant_Sensitive_Channel_Obfuscation_for_Deep_Neural_CVPR_2021_paper.html",
        "author": "Abhishek Singh, Ayush Chopra, Ethan Garza, Emily Zhang, Praneeth Vepakomma, Vivek Sharma, Ramesh Raskar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Singh_DISCO_Dynamic_and_Invariant_Sensitive_Channel_Obfuscation_for_Deep_Neural_CVPR_2021_paper.pdf",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology, Harvard Medical School",
        "project": "",
        "github": "https://github.com/splitlearning/InferenceBenchmark",
        "arxiv": "2012.11025"
    },
    {
        "title": "DOTS: Decoupling Operation and Topology in Differentiable Architecture Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gu_DOTS_Decoupling_Operation_and_Topology_in_Differentiable_Architecture_Search_CVPR_2021_paper.html",
        "author": "Yu-Chao Gu, Li-Juan Wang, Yun Liu, Yi Yang, Yu-Huan Wu, Shao-Ping Lu, Ming-Ming Cheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gu_DOTS_Decoupling_Operation_and_Topology_in_Differentiable_Architecture_Search_CVPR_2021_paper.pdf",
        "aff": "TKLNDST, CS, Nankai University; Zhejiang University",
        "project": "",
        "github": "https://github.com/guyuchao/DOTS",
        "arxiv": "2010.00969"
    },
    {
        "title": "DRANet: Disentangling Representation and Adaptation Networks for Unsupervised Cross-Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_DRANet_Disentangling_Representation_and_Adaptation_Networks_for_Unsupervised_Cross-Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Seunghun Lee, Sunghyun Cho, Sunghoon Im",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_DRANet_Disentangling_Representation_and_Adaptation_Networks_for_Unsupervised_Cross-Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "POSTECH CSE & GSAI; DGIST",
        "project": "",
        "github": "",
        "arxiv": "2103.13447"
    },
    {
        "title": "DSC-PoseNet: Learning 6DoF Object Pose Estimation via Dual-Scale Consistency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_DSC-PoseNet_Learning_6DoF_Object_Pose_Estimation_via_Dual-Scale_Consistency_CVPR_2021_paper.html",
        "author": "Zongxin Yang, Xin Yu, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_DSC-PoseNet_Learning_6DoF_Object_Pose_Estimation_via_Dual-Scale_Consistency_CVPR_2021_paper.pdf",
        "aff": "ReLER, University of Technology Sydney; Baidu Research, ReLER, University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DSRNA: Differentiable Search of Robust Neural Architectures",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hosseini_DSRNA_Differentiable_Search_of_Robust_Neural_Architectures_CVPR_2021_paper.html",
        "author": "Ramtin Hosseini, Xingyi Yang, Pengtao Xie",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hosseini_DSRNA_Differentiable_Search_of_Robust_Neural_Architectures_CVPR_2021_paper.pdf",
        "aff": "UC San Diego",
        "project": "",
        "github": "",
        "arxiv": "2012.06122"
    },
    {
        "title": "Data-Free Knowledge Distillation for Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Data-Free_Knowledge_Distillation_for_Image_Super-Resolution_CVPR_2021_paper.html",
        "author": "Yiman Zhang, Hanting Chen, Xinghao Chen, Yiping Deng, Chunjing Xu, Yunhe Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Data-Free_Knowledge_Distillation_for_Image_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "Noah\u2019s Ark Lab, Huawei Technologies; Noah\u2019s Ark Lab, Huawei Technologies; Key Lab of Machine Perception (MOE), Dept. of Machine Intelligence, Peking University; Central Software Institution, Huawei Technologies",
        "project": "",
        "github": "https://github.com/huawei-noah/Data-Ef\ufb01cient-Model-Compression",
        "arxiv": ""
    },
    {
        "title": "Data-Free Model Extraction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Truong_Data-Free_Model_Extraction_CVPR_2021_paper.html",
        "author": "Jean-Baptiste Truong, Pratyush Maini, Robert J. Walls, Nicolas Papernot",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Truong_Data-Free_Model_Extraction_CVPR_2021_paper.pdf",
        "aff": "Worcester Polytechnic Institute; University of Toronto and Vector Institute; Indian Institute of Technology Delhi",
        "project": "",
        "github": "",
        "arxiv": "2011.14779"
    },
    {
        "title": "Data-Uncertainty Guided Multi-Phase Learning for Semi-Supervised Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Data-Uncertainty_Guided_Multi-Phase_Learning_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.html",
        "author": "Zhenyu Wang, Yali Li, Ye Guo, Lu Fang, Shengjin Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Data-Uncertainty_Guided_Multi-Phase_Learning_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Department of Electronic Engineering, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2103.16368"
    },
    {
        "title": "DatasetGAN: Efficient Labeled Data Factory With Minimal Human Effort",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DatasetGAN_Efficient_Labeled_Data_Factory_With_Minimal_Human_Effort_CVPR_2021_paper.html",
        "author": "Yuxuan Zhang, Huan Ling, Jun Gao, Kangxue Yin, Jean-Francois Lafleche, Adela Barriuso, Antonio Torralba, Sanja Fidler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_DatasetGAN_Efficient_Labeled_Data_Factory_With_Minimal_Human_Effort_CVPR_2021_paper.pdf",
        "aff": "University of Waterloo; NVIDIA; MIT",
        "project": "",
        "github": "",
        "arxiv": "2104.06490"
    },
    {
        "title": "De-Rendering the World's Revolutionary Artefacts",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_De-Rendering_the_Worlds_Revolutionary_Artefacts_CVPR_2021_paper.html",
        "author": "Shangzhe Wu, Ameesh Makadia, Jiajun Wu, Noah Snavely, Richard Tucker, Angjoo Kanazawa",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_De-Rendering_the_Worlds_Revolutionary_Artefacts_CVPR_2021_paper.pdf",
        "aff": "Stanford University; University of Oxford; University of California, Berkeley; Google Research",
        "project": "",
        "github": "https://sorderender.github.io/",
        "arxiv": ""
    },
    {
        "title": "DeFLOCNet: Deep Image Editing via Flexible Low-Level Controls",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_DeFLOCNet_Deep_Image_Editing_via_Flexible_Low-Level_Controls_CVPR_2021_paper.html",
        "author": "Hongyu Liu, Ziyu Wan, Wei Huang, Yibing Song, Xintong Han, Jing Liao, Bin Jiang, Wei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_DeFLOCNet_Deep_Image_Editing_via_Flexible_Low-Level_Controls_CVPR_2021_paper.pdf",
        "aff": "City University of Hong Kong; Hunan University; Tencent AI Lab; Tencent Data Platform; Huya Inc",
        "project": "",
        "github": "https://github.com/KumapowerLIU/DeFLOCNet",
        "arxiv": "2103.12723"
    },
    {
        "title": "DeFMO: Deblurring and Shape Recovery of Fast Moving Objects",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Rozumnyi_DeFMO_Deblurring_and_Shape_Recovery_of_Fast_Moving_Objects_CVPR_2021_paper.html",
        "author": "Denys Rozumnyi, Martin R. Oswald, Vittorio Ferrari, Jiri Matas, Marc Pollefeys",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Rozumnyi_DeFMO_Deblurring_and_Shape_Recovery_of_Fast_Moving_Objects_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich; Microsoft Mixed Reality and AI Zurich Lab; Google Research; Visual Recognition Group, Czech Technical University in Prague; Department of Computer Science, ETH Zurich; Visual Recognition Group, Czech Technical University in Prague",
        "project": "",
        "github": "",
        "arxiv": "2012.00595"
    },
    {
        "title": "DeFlow: Learning Complex Image Degradations From Unpaired Data With Conditional Flows",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wolf_DeFlow_Learning_Complex_Image_Degradations_From_Unpaired_Data_With_Conditional_CVPR_2021_paper.html",
        "author": "Valentin Wolf, Andreas Lugmayr, Martin Danelljan, Luc Van Gool, Radu Timofte",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wolf_DeFlow_Learning_Complex_Image_Degradations_From_Unpaired_Data_With_Conditional_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Zurich, Switzerland",
        "project": "",
        "github": "https://github.com/volflow/DeFlow",
        "arxiv": "2101.05796"
    },
    {
        "title": "DeRF: Decomposed Radiance Fields",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Rebain_DeRF_Decomposed_Radiance_Fields_CVPR_2021_paper.html",
        "author": "Daniel Rebain, Wei Jiang, Soroosh Yazdani, Ke Li, Kwang Moo Yi, Andrea Tagliasacchi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Rebain_DeRF_Decomposed_Radiance_Fields_CVPR_2021_paper.pdf",
        "aff": "University of Toronto, Google Research; University of British Columbia; Simon Fraser University, Google Research; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2011.12490"
    },
    {
        "title": "Debiased Subjective Assessment of Real-World Image Enhancement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cao_Debiased_Subjective_Assessment_of_Real-World_Image_Enhancement_CVPR_2021_paper.html",
        "author": "Peibei Cao, Zhangyang Wang, Kede Ma",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cao_Debiased_Subjective_Assessment_of_Real-World_Image_Enhancement_CVPR_2021_paper.pdf",
        "aff": "City University of Hong Kong; University of Texas at Austin",
        "project": "",
        "github": "",
        "arxiv": "2106.10080"
    },
    {
        "title": "Decoupled Dynamic Filter Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Decoupled_Dynamic_Filter_Networks_CVPR_2021_paper.html",
        "author": "Jingkai Zhou, Varun Jampani, Zhixiong Pi, Qiong Liu, Ming-Hsuan Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Decoupled_Dynamic_Filter_Networks_CVPR_2021_paper.pdf",
        "aff": "University of California at Merced; South China University of Technology; Huazhong University of Science and Technology; Google Research",
        "project": "https://thefoxofsky.github.io/project_pages/ddf",
        "github": "",
        "arxiv": "2104.14107"
    },
    {
        "title": "Deep Active Surface Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wickramasinghe_Deep_Active_Surface_Models_CVPR_2021_paper.html",
        "author": "Udaranga Wickramasinghe, Pascal Fua, Graham Knott",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wickramasinghe_Deep_Active_Surface_Models_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Laboratory, EPFL; BioEM Laboratory, EPFL",
        "project": "",
        "github": "",
        "arxiv": "2011.08826"
    },
    {
        "title": "Deep Analysis of CNN-Based Spatio-Temporal Representations for Action Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Deep_Analysis_of_CNN-Based_Spatio-Temporal_Representations_for_Action_Recognition_CVPR_2021_paper.html",
        "author": "Chun-Fu Richard Chen, Rameswar Panda, Kandan Ramakrishnan, Rogerio Feris, John Cohn, Aude Oliva, Quanfu Fan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Deep_Analysis_of_CNN-Based_Spatio-Temporal_Representations_for_Action_Recognition_CVPR_2021_paper.pdf",
        "aff": "Massachusetts Institute of Technology; MIT-IBM Watson AI Lab",
        "project": "",
        "github": "https://github.com/IBM/action-recognition-pytorch",
        "arxiv": "2010.11757"
    },
    {
        "title": "Deep Animation Video Interpolation in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Siyao_Deep_Animation_Video_Interpolation_in_the_Wild_CVPR_2021_paper.html",
        "author": "Li Siyao, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, Dimitris Metaxas, Chen Change Loy, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Siyao_Deep_Animation_Video_Interpolation_in_the_Wild_CVPR_2021_paper.pdf",
        "aff": "Sun Yat-sen University; Rutgers University; SenseTime Research and Shanghai AI Laboratory; SenseTime Research and Tetras.AI; Rutgers University and SenseTime Research; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/lisiyao21/AnimeInterp/",
        "arxiv": "2104.02495"
    },
    {
        "title": "Deep Burst Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bhat_Deep_Burst_Super-Resolution_CVPR_2021_paper.html",
        "author": "Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bhat_Deep_Burst_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Zurich, Switzerland",
        "project": "",
        "github": "",
        "arxiv": "2101.10997"
    },
    {
        "title": "Deep Compositional Metric Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Deep_Compositional_Metric_Learning_CVPR_2021_paper.html",
        "author": "Wenzhao Zheng, Chengkun Wang, Jiwen Lu, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Deep_Compositional_Metric_Learning_CVPR_2021_paper.pdf",
        "aff": "Department of Automation, Tsinghua University, China",
        "project": "",
        "github": "https://github.com/wzzheng/DCML",
        "arxiv": ""
    },
    {
        "title": "Deep Convolutional Dictionary Learning for Image Denoising",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Deep_Convolutional_Dictionary_Learning_for_Image_Denoising_CVPR_2021_paper.html",
        "author": "Hongyi Zheng, Hongwei Yong, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Deep_Convolutional_Dictionary_Learning_for_Image_Denoising_CVPR_2021_paper.pdf",
        "aff": "The Hong Kong Polytechnic University; DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/natezhenghy/DCDicL_denoising",
        "arxiv": ""
    },
    {
        "title": "Deep Denoising of Flash and No-Flash Pairs for Photography in Low-Light Environments",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xia_Deep_Denoising_of_Flash_and_No-Flash_Pairs_for_Photography_in_CVPR_2021_paper.html",
        "author": "Zhihao Xia, Michael Gharbi, Federico Perazzi, Kalyan Sunkavalli, Ayan Chakrabarti",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xia_Deep_Denoising_of_Flash_and_No-Flash_Pairs_for_Photography_in_CVPR_2021_paper.pdf",
        "aff": "Washington University in St. Louis; Adobe Research; Facebook",
        "project": "",
        "github": "",
        "arxiv": "2012.05116"
    },
    {
        "title": "Deep Dual Consecutive Network for Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Deep_Dual_Consecutive_Network_for_Human_Pose_Estimation_CVPR_2021_paper.html",
        "author": "Zhenguang Liu, Haoming Chen, Runyang Feng, Shuang Wu, Shouling Ji, Bailin Yang, Xun Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Deep_Dual_Consecutive_Network_for_Human_Pose_Estimation_CVPR_2021_paper.pdf",
        "aff": "Zhejiang Gongshang University; Nanyang Technological University; Zhejiang University",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2103.07254"
    },
    {
        "title": "Deep Gaussian Scale Mixture Prior for Spectral Compressive Imaging",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Deep_Gaussian_Scale_Mixture_Prior_for_Spectral_Compressive_Imaging_CVPR_2021_paper.html",
        "author": "Tao Huang, Weisheng Dong, Xin Yuan, Jinjian Wu, Guangming Shi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Deep_Gaussian_Scale_Mixture_Prior_for_Spectral_Compressive_Imaging_CVPR_2021_paper.pdf",
        "aff": "Bell Labs; School of Arti\ufb01cial Intelligence, Xidian University",
        "project": "https://see.xidian.edu.cn/faculty/wsdong/Projects/DGSM-SCI.htm",
        "github": "",
        "arxiv": "2103.07152"
    },
    {
        "title": "Deep Gradient Projection Networks for Pan-sharpening",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Deep_Gradient_Projection_Networks_for_Pan-sharpening_CVPR_2021_paper.html",
        "author": "Shuang Xu, Jiangshe Zhang, Zixiang Zhao, Kai Sun, Junmin Liu, Chunxia Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Deep_Gradient_Projection_Networks_for_Pan-sharpening_CVPR_2021_paper.pdf",
        "aff": "School of Mathematics and Statistics, Xi\u2019an Jiaotong University, Xi\u2019an 710049, China",
        "project": "",
        "github": "https://github.com/xsxjtu/GPPNN",
        "arxiv": "2103.04584"
    },
    {
        "title": "Deep Graph Matching Under Quadratic Constraint",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Deep_Graph_Matching_Under_Quadratic_Constraint_CVPR_2021_paper.html",
        "author": "Quankai Gao, Fudong Wang, Nan Xue, Jin-Gang Yu, Gui-Song Xia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Deep_Graph_Matching_Under_Quadratic_Constraint_CVPR_2021_paper.pdf",
        "aff": "Wuhan University, Wuhan, China.; South China University of Technology, Guangzhou, China.",
        "project": "",
        "github": "https://github.com/Zerg-Overmind/QC-DGM",
        "arxiv": "2103.06643"
    },
    {
        "title": "Deep Homography for Efficient Stereo Image Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Deep_Homography_for_Efficient_Stereo_Image_Compression_CVPR_2021_paper.html",
        "author": "Xin Deng, Wenzhe Yang, Ren Yang, Mai Xu, Enpeng Liu, Qianhan Feng, Radu Timofte",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Deep_Homography_for_Efficient_Stereo_Image_Compression_CVPR_2021_paper.pdf",
        "aff": "School of Electronic and Information Engineering, Beihang University, Beijing, China; Computer Vision Lab, D-ITET, ETH Zurich, Zurich, Switzerland; School of Cyber Science and Technology, Beihang University, Beijing, China",
        "project": "",
        "github": "https://github.com/ywz978020607/HESIC",
        "arxiv": ""
    },
    {
        "title": "Deep Implicit Moving Least-Squares Functions for 3D Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Deep_Implicit_Moving_Least-Squares_Functions_for_3D_Reconstruction_CVPR_2021_paper.html",
        "author": "Shi-Lin Liu, Hao-Xiang Guo, Hao Pan, Peng-Shuai Wang, Xin Tong, Yang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Deep_Implicit_Moving_Least-Squares_Functions_for_3D_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; Tsinghua University; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2103.12266"
    },
    {
        "title": "Deep Implicit Templates for 3D Shape Representation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Deep_Implicit_Templates_for_3D_Shape_Representation_CVPR_2021_paper.html",
        "author": "Zerong Zheng, Tao Yu, Qionghai Dai, Yebin Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Deep_Implicit_Templates_for_3D_Shape_Representation_CVPR_2021_paper.pdf",
        "aff": "Department of Automation, Tsinghua University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": "2011.14565"
    },
    {
        "title": "Deep Learning in Latent Space for Video Prediction and Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Deep_Learning_in_Latent_Space_for_Video_Prediction_and_Compression_CVPR_2021_paper.html",
        "author": "Bowen Liu, Yu Chen, Shiyu Liu, Hun-Seok Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Deep_Learning_in_Latent_Space_for_Video_Prediction_and_Compression_CVPR_2021_paper.pdf",
        "aff": "University of Michigan, Ann Arbor",
        "project": "",
        "github": "https://github.com/BowenL0218/Video-compression",
        "arxiv": ""
    },
    {
        "title": "Deep Lesion Tracker: Monitoring Lesions in 4D Longitudinal Imaging Studies",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Deep_Lesion_Tracker_Monitoring_Lesions_in_4D_Longitudinal_Imaging_Studies_CVPR_2021_paper.html",
        "author": "Jinzheng Cai, Youbao Tang, Ke Yan, Adam P. Harrison, Jing Xiao, Gigin Lin, Le Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cai_Deep_Lesion_Tracker_Monitoring_Lesions_in_4D_Longitudinal_Imaging_Studies_CVPR_2021_paper.pdf",
        "aff": "PAII Inc.; Ping An Technology; Chang Gung Memorial Hospital",
        "project": "",
        "github": "",
        "arxiv": "2012.04872"
    },
    {
        "title": "Deep Lucas-Kanade Homography for Multimodal Image Alignment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Deep_Lucas-Kanade_Homography_for_Multimodal_Image_Alignment_CVPR_2021_paper.html",
        "author": "Yiming Zhao, Xinming Huang, Ziming Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Deep_Lucas-Kanade_Homography_for_Multimodal_Image_Alignment_CVPR_2021_paper.pdf",
        "aff": "Worcester Polytechnic Institute",
        "project": "",
        "github": "https://github.com/placeforyiming/CVPR21-Deep-Lucas-Kanade-Homography",
        "arxiv": "2104.11693"
    },
    {
        "title": "Deep Multi-Task Learning for Joint Localization, Perception, and Prediction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Phillips_Deep_Multi-Task_Learning_for_Joint_Localization_Perception_and_Prediction_CVPR_2021_paper.html",
        "author": "John Phillips, Julieta Martinez, Ioan Andrei Barsan, Sergio Casas, Abbas Sadat, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Phillips_Deep_Multi-Task_Learning_for_Joint_Localization_Perception_and_Prediction_CVPR_2021_paper.pdf",
        "aff": "Uber Advanced Technologies Group, University of Toronto; Uber Advanced Technologies Group, University of Waterloo; Uber Advanced Technologies Group",
        "project": "",
        "github": "",
        "arxiv": "2101.06720"
    },
    {
        "title": "Deep Occlusion-Aware Instance Segmentation With Overlapping BiLayers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ke_Deep_Occlusion-Aware_Instance_Segmentation_With_Overlapping_BiLayers_CVPR_2021_paper.html",
        "author": "Lei Ke, Yu-Wing Tai, Chi-Keung Tang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ke_Deep_Occlusion-Aware_Instance_Segmentation_With_Overlapping_BiLayers_CVPR_2021_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology; Kuaishou Technology",
        "project": "",
        "github": "https://github.com/lkeab/BCNet",
        "arxiv": "2103.12340"
    },
    {
        "title": "Deep Optimized Priors for 3D Shape Modeling and Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Deep_Optimized_Priors_for_3D_Shape_Modeling_and_Reconstruction_CVPR_2021_paper.html",
        "author": "Mingyue Yang, Yuxin Wen, Weikai Chen, Yongwei Chen, Kui Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Deep_Optimized_Priors_for_3D_Shape_Modeling_and_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "South China University of Technology; South China University of Technology, Pazhou Laboratory, Peng Cheng Laboratory; Tencent Game AI Research Center",
        "project": "",
        "github": "",
        "arxiv": "2012.07241"
    },
    {
        "title": "Deep Perceptual Preprocessing for Video Coding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chadha_Deep_Perceptual_Preprocessing_for_Video_Coding_CVPR_2021_paper.html",
        "author": "Aaron Chadha, Yiannis Andreopoulos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chadha_Deep_Perceptual_Preprocessing_for_Video_Coding_CVPR_2021_paper.pdf",
        "aff": "iSIZE, isize.co",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Deep Polarization Imaging for 3D Shape and SVBRDF Acquisition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deschaintre_Deep_Polarization_Imaging_for_3D_Shape_and_SVBRDF_Acquisition_CVPR_2021_paper.html",
        "author": "Valentin Deschaintre, Yiming Lin, Abhijeet Ghosh",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deschaintre_Deep_Polarization_Imaging_for_3D_Shape_and_SVBRDF_Acquisition_CVPR_2021_paper.pdf",
        "aff": "Imperial College London",
        "project": "",
        "github": "",
        "arxiv": "2105.02875"
    },
    {
        "title": "Deep RGB-D Saliency Detection With Depth-Sensitive Attention and Automatic Multi-Modal Fusion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Deep_RGB-D_Saliency_Detection_With_Depth-Sensitive_Attention_and_Automatic_Multi-Modal_CVPR_2021_paper.html",
        "author": "Peng Sun, Wenhu Zhang, Huanyu Wang, Songyuan Li, Xi Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Deep_RGB-D_Saliency_Detection_With_Depth-Sensitive_Attention_and_Automatic_Multi-Modal_CVPR_2021_paper.pdf",
        "aff": "College of Computer Science & Technology, Shanghai Institute for Advanced Study, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Deep Stable Learning for Out-of-Distribution Generalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Deep_Stable_Learning_for_Out-of-Distribution_Generalization_CVPR_2021_paper.html",
        "author": "Xingxuan Zhang, Peng Cui, Renzhe Xu, Linjun Zhou, Yue He, Zheyan Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Deep_Stable_Learning_for_Out-of-Distribution_Generalization_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, Tsinghua University, Beijing, China; Department of Computer Science, Tsinghua University, Beijing, China; Beijing Key Lab of Networked Multimedia",
        "project": "",
        "github": "",
        "arxiv": "2104.07876"
    },
    {
        "title": "Deep Texture Recognition via Exploiting Cross-Layer Statistical Self-Similarity",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Deep_Texture_Recognition_via_Exploiting_Cross-Layer_Statistical_Self-Similarity_CVPR_2021_paper.html",
        "author": "Zhile Chen, Feng Li, Yuhui Quan, Yong Xu, Hui Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Deep_Texture_Recognition_via_Exploiting_Cross-Layer_Statistical_Self-Similarity_CVPR_2021_paper.pdf",
        "aff": "Department of Mathematics, National University of Singapore, 119076, Singapore; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Deep Two-View Structure-From-Motion Revisited",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Deep_Two-View_Structure-From-Motion_Revisited_CVPR_2021_paper.html",
        "author": "Jianyuan Wang, Yiran Zhong, Yuchao Dai, Stan Birchfield, Kaihao Zhang, Nikolai Smolyanskiy, Hongdong Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Deep_Two-View_Structure-From-Motion_Revisited_CVPR_2021_paper.pdf",
        "aff": "Northwestern Polytechnical University; NVIDIA; Australian National University",
        "project": "",
        "github": "",
        "arxiv": "2104.00556"
    },
    {
        "title": "Deep Video Matting via Spatio-Temporal Alignment and Aggregation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Deep_Video_Matting_via_Spatio-Temporal_Alignment_and_Aggregation_CVPR_2021_paper.html",
        "author": "Yanan Sun, Guanzhi Wang, Qiao Gu, Chi-Keung Tang, Yu-Wing Tai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Deep_Video_Matting_via_Spatio-Temporal_Alignment_and_Aggregation_CVPR_2021_paper.pdf",
        "aff": "HKUST; Stanford University; Kuaishou Technology; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/nowsyn/DVM",
        "arxiv": "2104.11208"
    },
    {
        "title": "DeepACG: Co-Saliency Detection via Semantic-Aware Contrast Gromov-Wasserstein Distance",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DeepACG_Co-Saliency_Detection_via_Semantic-Aware_Contrast_Gromov-Wasserstein_Distance_CVPR_2021_paper.html",
        "author": "Kaihua Zhang, Mingliang Dong, Bo Liu, Xiao-Tong Yuan, Qingshan Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_DeepACG_Co-Saliency_Detection_via_Semantic-Aware_Contrast_Gromov-Wasserstein_Distance_CVPR_2021_paper.pdf",
        "aff": "JD Digits, Mountain View, CA, USA; School of Automation, Nanjing University of Information Science and Technology, Nanjing, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DeepI2P: Image-to-Point Cloud Registration via Deep Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_DeepI2P_Image-to-Point_Cloud_Registration_via_Deep_Classification_CVPR_2021_paper.html",
        "author": "Jiaxin Li, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_DeepI2P_Image-to-Point_Cloud_Registration_via_Deep_Classification_CVPR_2021_paper.pdf",
        "aff": "National University of Singapore; Bytedance",
        "project": "",
        "github": "https://github.com/lijx10/DeepI2P",
        "arxiv": "2104.03501"
    },
    {
        "title": "DeepLM: Large-Scale Nonlinear Least Squares on Deep Learning Frameworks Using Stochastic Domain Decomposition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_DeepLM_Large-Scale_Nonlinear_Least_Squares_on_Deep_Learning_Frameworks_Using_CVPR_2021_paper.html",
        "author": "Jingwei Huang, Shan Huang, Mingwei Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_DeepLM_Large-Scale_Nonlinear_Least_Squares_on_Deep_Learning_Frameworks_Using_CVPR_2021_paper.pdf",
        "aff": "Rieman Lab, Huawei Technologies; Wuhan University; Rieman Lab, Huawei Technologies",
        "project": "https://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/3d/DeepLM",
        "github": "https://github.com/hjwdzh/DeepLM",
        "arxiv": ""
    },
    {
        "title": "DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes With Biharmonic Coordinates",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_DeepMetaHandles_Learning_Deformation_Meta-Handles_of_3D_Meshes_With_Biharmonic_Coordinates_CVPR_2021_paper.html",
        "author": "Minghua Liu, Minhyuk Sung, Radomir Mech, Hao Su",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_DeepMetaHandles_Learning_Deformation_Meta-Handles_of_3D_Meshes_With_Biharmonic_Coordinates_CVPR_2021_paper.pdf",
        "aff": "KAIST; University of California San Diego; Adobe Research",
        "project": "",
        "github": "https://github.com/Colin97/DeepMetaHandles",
        "arxiv": "2102.09105"
    },
    {
        "title": "DeepSurfels: Learning Online Appearance Fusion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mihajlovic_DeepSurfels_Learning_Online_Appearance_Fusion_CVPR_2021_paper.html",
        "author": "Marko Mihajlovic, Silvan Weder, Marc Pollefeys, Martin R. Oswald",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mihajlovic_DeepSurfels_Learning_Online_Appearance_Fusion_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich2Microsoft Mixed Reality and AI Zurich Lab",
        "project": "OnlineReconstruction.github.io/DeepSurfels",
        "github": "",
        "arxiv": "2012.14240"
    },
    {
        "title": "DeepTag: An Unsupervised Deep Learning Method for Motion Tracking on Cardiac Tagging Magnetic Resonance Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ye_DeepTag_An_Unsupervised_Deep_Learning_Method_for_Motion_Tracking_on_CVPR_2021_paper.html",
        "author": "Meng Ye, Mikael Kanski, Dong Yang, Qi Chang, Zhennan Yan, Qiaoying Huang, Leon Axel, Dimitris Metaxas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ye_DeepTag_An_Unsupervised_Deep_Learning_Method_for_Motion_Tracking_on_CVPR_2021_paper.pdf",
        "aff": "SenseBrain and Shanghai AI Laboratory and Centre for Perceptual and Interactive Intellgience; Rutgers University; NVIDIA; New York University School of Medicine",
        "project": "",
        "github": "https://github.com/DeepTag/cardiac_tagging_motion_estimation",
        "arxiv": "2103.02772"
    },
    {
        "title": "DeepVideoMVS: Multi-View Stereo on Video With Recurrent Spatio-Temporal Fusion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Duzceker_DeepVideoMVS_Multi-View_Stereo_on_Video_With_Recurrent_Spatio-Temporal_Fusion_CVPR_2021_paper.html",
        "author": "Arda Duzceker, Silvano Galliani, Christoph Vogel, Pablo Speciale, Mihai Dusmanu, Marc Pollefeys",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Duzceker_DeepVideoMVS_Multi-View_Stereo_on_Video_With_Recurrent_Spatio-Temporal_Fusion_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich; Microsoft Mixed Reality & AI Zurich Lab",
        "project": "",
        "github": "https://github.com/ardaduz/deep-video-mvs",
        "arxiv": "2012.02177"
    },
    {
        "title": "Deeply Shape-Guided Cascade for Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ding_Deeply_Shape-Guided_Cascade_for_Instance_Segmentation_CVPR_2021_paper.html",
        "author": "Hao Ding, Siyuan Qiao, Alan Yuille, Wei Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_Deeply_Shape-Guided_Cascade_for_Instance_Segmentation_CVPR_2021_paper.pdf",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Department of Computer Science, Johns Hopkins University",
        "project": "",
        "github": "https://github.com/hding2455/DSC",
        "arxiv": "1911.11263"
    },
    {
        "title": "Defending Multimodal Fusion Models Against Single-Source Adversaries",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Defending_Multimodal_Fusion_Models_Against_Single-Source_Adversaries_CVPR_2021_paper.html",
        "author": "Karren Yang, Wan-Yi Lin, Manash Barman, Filipe Condessa, Zico Kolter",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Defending_Multimodal_Fusion_Models_Against_Single-Source_Adversaries_CVPR_2021_paper.pdf",
        "aff": "Massachusetts Institute of Technology; Bosch Center for AI; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Deformed Implicit Field: Modeling 3D Shapes With Learned Dense Correspondence",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Deformed_Implicit_Field_Modeling_3D_Shapes_With_Learned_Dense_Correspondence_CVPR_2021_paper.html",
        "author": "Yu Deng, Jiaolong Yang, Xin Tong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Deformed_Implicit_Field_Modeling_3D_Shapes_With_Learned_Dense_Correspondence_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; Tsinghua University",
        "project": "",
        "github": "https://github.com/microsoft/DIF-Net",
        "arxiv": "2011.13650"
    },
    {
        "title": "Delving Deep Into Many-to-Many Attention for Few-Shot Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Delving_Deep_Into_Many-to-Many_Attention_for_Few-Shot_Video_Object_Segmentation_CVPR_2021_paper.html",
        "author": "Haoxin Chen, Hanjie Wu, Nanxuan Zhao, Sucheng Ren, Shengfeng He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Delving_Deep_Into_Many-to-Many_Attention_for_Few-Shot_Video_Object_Segmentation_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, South China University of Technology; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/scutpaul/DANet",
        "arxiv": ""
    },
    {
        "title": "Delving Into Localization Errors for Monocular 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Delving_Into_Localization_Errors_for_Monocular_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "Xinzhu Ma, Yinmin Zhang, Dan Xu, Dongzhan Zhou, Shuai Yi, Haojie Li, Wanli Ouyang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_Delving_Into_Localization_Errors_for_Monocular_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Dalian University of Technology; The Hong Kong University of Science and Technology; SenseTime Research; The University of Sydney",
        "project": "",
        "github": "https://github.com/xinzhuma/monodle",
        "arxiv": "2103.16237"
    },
    {
        "title": "Delving into Data: Effectively Substitute Training for Black-box Attack",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Delving_into_Data_Effectively_Substitute_Training_for_Black-box_Attack_CVPR_2021_paper.html",
        "author": "Wenxuan Wang, Bangjie Yin, Taiping Yao, Li Zhang, Yanwei Fu, Shouhong Ding, Jilin Li, Feiyue Huang, Xiangyang Xue",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Delving_into_Data_Effectively_Substitute_Training_for_Black-box_Attack_CVPR_2021_paper.pdf",
        "aff": "Fudan University; Youtu Lab, Tencent",
        "project": "",
        "github": "",
        "arxiv": "2104.12378"
    },
    {
        "title": "Denoise and Contrast for Category Agnostic Shape Completion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Alliegro_Denoise_and_Contrast_for_Category_Agnostic_Shape_Completion_CVPR_2021_paper.html",
        "author": "Antonio Alliegro, Diego Valsesia, Giulia Fracastoro, Enrico Magli, Tatiana Tommasi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Alliegro_Denoise_and_Contrast_for_Category_Agnostic_Shape_Completion_CVPR_2021_paper.pdf",
        "aff": "Politecnico di Torino, Italy and Italian Institute of Technology; Politecnico di Torino, Italy",
        "project": "",
        "github": "",
        "arxiv": "2103.16671"
    },
    {
        "title": "Dense Contrastive Learning for Self-Supervised Visual Pre-Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Dense_Contrastive_Learning_for_Self-Supervised_Visual_Pre-Training_CVPR_2021_paper.html",
        "author": "Xinlong Wang, Rufeng Zhang, Chunhua Shen, Tao Kong, Lei Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Dense_Contrastive_Learning_for_Self-Supervised_Visual_Pre-Training_CVPR_2021_paper.pdf",
        "aff": "Tongji University, China; ByteDance AI Lab; The University of Adelaide, Australia",
        "project": "",
        "github": "https://git.io/DenseCL",
        "arxiv": "2011.09157"
    },
    {
        "title": "Dense Label Encoding for Boundary Discontinuity Free Rotation Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Dense_Label_Encoding_for_Boundary_Discontinuity_Free_Rotation_Detection_CVPR_2021_paper.html",
        "author": "Xue Yang, Liping Hou, Yue Zhou, Wentao Wang, Junchi Yan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Dense_Label_Encoding_for_Boundary_Discontinuity_Free_Rotation_Detection_CVPR_2021_paper.pdf",
        "aff": "Department of CSE, SJTU; Department of EE, SJTU; Department of CSE, SJTU; MoE Key Lab of Artificial Intelligence, AI Institute, SJTU; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/RotationDetection",
        "arxiv": "2011.09670"
    },
    {
        "title": "Dense Relation Distillation With Context-Aware Aggregation for Few-Shot Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Dense_Relation_Distillation_With_Context-Aware_Aggregation_for_Few-Shot_Object_Detection_CVPR_2021_paper.html",
        "author": "Hanzhe Hu, Shuai Bai, Aoxue Li, Jinshi Cui, Liwei Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Dense_Relation_Distillation_With_Context-Aware_Aggregation_for_Few-Shot_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Key Laboratory of Machine Perception (MOE), School of EECS, Peking University; Beijing University of Posts and Telecommunications",
        "project": "",
        "github": "https://github.com/hzhupku/DCNet",
        "arxiv": "2103.17115"
    },
    {
        "title": "Densely Connected Multi-Dilated Convolutional Networks for Dense Prediction Tasks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Takahashi_Densely_Connected_Multi-Dilated_Convolutional_Networks_for_Dense_Prediction_Tasks_CVPR_2021_paper.html",
        "author": "Naoya Takahashi, Yuki Mitsufuji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Takahashi_Densely_Connected_Multi-Dilated_Convolutional_Networks_for_Dense_Prediction_Tasks_CVPR_2021_paper.pdf",
        "aff": "Sony Corporation, Japan",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Depth Completion Using Plane-Residual Representation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Depth_Completion_Using_Plane-Residual_Representation_CVPR_2021_paper.html",
        "author": "Byeong-Uk Lee, Kyunghyun Lee, In So Kweon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Depth_Completion_Using_Plane-Residual_Representation_CVPR_2021_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2104.07350"
    },
    {
        "title": "Depth Completion With Twin Surface Extrapolation at Occlusion Boundaries",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Imran_Depth_Completion_With_Twin_Surface_Extrapolation_at_Occlusion_Boundaries_CVPR_2021_paper.html",
        "author": "Saif Imran, Xiaoming Liu, Daniel Morris",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Imran_Depth_Completion_With_Twin_Surface_Extrapolation_at_Occlusion_Boundaries_CVPR_2021_paper.pdf",
        "aff": "2583\n",
        "project": "",
        "github": "",
        "arxiv": "2104.02253"
    },
    {
        "title": "Depth From Camera Motion and Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Griffin_Depth_From_Camera_Motion_and_Object_Detection_CVPR_2021_paper.html",
        "author": "Brent A. Griffin, Jason J. Corso",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Griffin_Depth_From_Camera_Motion_and_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Stevens Institute for Arti\ufb01cial Intelligence; University of Michigan",
        "project": "",
        "github": "",
        "arxiv": "2103.01468"
    },
    {
        "title": "Depth-Aware Mirror Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mei_Depth-Aware_Mirror_Segmentation_CVPR_2021_paper.html",
        "author": "Haiyang Mei, Bo Dong, Wen Dong, Pieter Peers, Xin Yang, Qiang Zhang, Xiaopeng Wei",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mei_Depth-Aware_Mirror_Segmentation_CVPR_2021_paper.pdf",
        "aff": "College of William & Mary; Dalian University of Technology; SRI International",
        "project": "https://mhaiyang.github.io/CVPR2021_PDNet/index",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Depth-Conditioned Dynamic Message Propagation for Monocular 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Depth-Conditioned_Dynamic_Message_Propagation_for_Monocular_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "Li Wang, Liang Du, Xiaoqing Ye, Yanwei Fu, Guodong Guo, Xiangyang Xue, Jianfeng Feng, Li Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Depth-Conditioned_Dynamic_Message_Propagation_for_Monocular_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "454\n",
        "project": "",
        "github": "",
        "arxiv": "2103.16470"
    },
    {
        "title": "Detecting Human-Object Interaction via Fabricated Compositional Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Detecting_Human-Object_Interaction_via_Fabricated_Compositional_Learning_CVPR_2021_paper.html",
        "author": "Zhi Hou, Baosheng Yu, Yu Qiao, Xiaojiang Peng, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Detecting_Human-Object_Interaction_via_Fabricated_Compositional_Learning_CVPR_2021_paper.pdf",
        "aff": "Shenzhen Technology University; School of Computer Science, Faculty of Engineering, The University of Sydney, Australia; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/zhihou7/HOI-CL",
        "arxiv": "2103.08214"
    },
    {
        "title": "Detection, Tracking, and Counting Meets Drones in Crowds: A Benchmark",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Detection_Tracking_and_Counting_Meets_Drones_in_Crowds_A_Benchmark_CVPR_2021_paper.html",
        "author": "Longyin Wen, Dawei Du, Pengfei Zhu, Qinghua Hu, Qilong Wang, Liefeng Bo, Siwei Lyu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wen_Detection_Tracking_and_Counting_Meets_Drones_in_Crowds_A_Benchmark_CVPR_2021_paper.pdf",
        "aff": "Tianjin University, Tianjin, China; JD Finance America Corporation, Mountain View, CA, USA; University at Albany, State University of New York, Albany, NY, USA",
        "project": "",
        "github": "https://github.com/VisDrone/DroneCrowd",
        "arxiv": "2105.02440"
    },
    {
        "title": "DetectoRS: Detecting Objects With Recursive Feature Pyramid and Switchable Atrous Convolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qiao_DetectoRS_Detecting_Objects_With_Recursive_Feature_Pyramid_and_Switchable_Atrous_CVPR_2021_paper.html",
        "author": "Siyuan Qiao, Liang-Chieh Chen, Alan Yuille",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qiao_DetectoRS_Detecting_Objects_With_Recursive_Feature_Pyramid_and_Switchable_Atrous_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Google Research",
        "project": "",
        "github": "https://github.com/joe-siyuan-qiao/DetectoRS",
        "arxiv": "2006.02334"
    },
    {
        "title": "DexYCB: A Benchmark for Capturing Hand Grasping of Objects",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chao_DexYCB_A_Benchmark_for_Capturing_Hand_Grasping_of_Objects_CVPR_2021_paper.html",
        "author": "Yu-Wei Chao, Wei Yang, Yu Xiang, Pavlo Molchanov, Ankur Handa, Jonathan Tremblay, Yashraj S. Narang, Karl Van Wyk, Umar Iqbal, Stan Birchfield, Jan Kautz, Dieter Fox",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chao_DexYCB_A_Benchmark_for_Capturing_Hand_Grasping_of_Objects_CVPR_2021_paper.pdf",
        "aff": "NVIDIA; NVIDIA, University of Washington",
        "project": "https://dex-ycb.github.io",
        "github": "https://github.com/dex-ycb",
        "arxiv": "2104.04631"
    },
    {
        "title": "DiNTS: Differentiable Neural Network Topology Search for 3D Medical Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_DiNTS_Differentiable_Neural_Network_Topology_Search_for_3D_Medical_Image_CVPR_2021_paper.html",
        "author": "Yufan He, Dong Yang, Holger Roth, Can Zhao, Daguang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_DiNTS_Differentiable_Neural_Network_Topology_Search_for_3D_Medical_Image_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; NVIDIA",
        "project": "",
        "github": "",
        "arxiv": "2103.15954"
    },
    {
        "title": "Dictionary-Guided Scene Text Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_Dictionary-Guided_Scene_Text_Recognition_CVPR_2021_paper.html",
        "author": "Nguyen Nguyen, Thu Nguyen, Vinh Tran, Minh-Triet Tran, Thanh Duc Ngo, Thien Huu Nguyen, Minh Hoai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nguyen_Dictionary-Guided_Scene_Text_Recognition_CVPR_2021_paper.pdf",
        "aff": "Vietnam National University, Ho Chi Minh City, Vietnam; University of Science, VNU-HCM, Vietnam; University of Information Technology, VNU-HCM, Vietnam; University of Oregon, Eugene, OR, USA; VinAI Research, Hanoi, Vietnam; Stony Brook University, Stony Brook, NY, USA",
        "project": "",
        "github": "https://github.com/VinAIResearch/dict-guided",
        "arxiv": ""
    },
    {
        "title": "Differentiable Diffusion for Dense Depth Estimation From Multi-View Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Khan_Differentiable_Diffusion_for_Dense_Depth_Estimation_From_Multi-View_Images_CVPR_2021_paper.html",
        "author": "Numair Khan, Min H. Kim, James Tompkin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Khan_Differentiable_Diffusion_for_Dense_Depth_Estimation_From_Multi-View_Images_CVPR_2021_paper.pdf",
        "aff": "Brown University; KAIST",
        "project": "http://visual.cs.brown.edu/diffdiffdepth",
        "github": "",
        "arxiv": "2106.08917"
    },
    {
        "title": "Differentiable Multi-Granularity Human Representation Learning for Instance-Aware Human Semantic Parsing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Differentiable_Multi-Granularity_Human_Representation_Learning_for_Instance-Aware_Human_Semantic_Parsing_CVPR_2021_paper.html",
        "author": "Tianfei Zhou, Wenguan Wang, Si Liu, Yi Yang, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Differentiable_Multi-Granularity_Human_Representation_Learning_for_Instance-Aware_Human_Semantic_Parsing_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Zurich; University of Technology Sydney; Institute of Arti\ufb01cial Intelligence, Beihang University",
        "project": "",
        "github": "https://github.com/tfzhou/MG-HumanParsing",
        "arxiv": "2103.04570"
    },
    {
        "title": "Differentiable Patch Selection for Image Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cordonnier_Differentiable_Patch_Selection_for_Image_Recognition_CVPR_2021_paper.html",
        "author": "Jean-Baptiste Cordonnier, Aravindh Mahendran, Alexey Dosovitskiy, Dirk Weissenborn, Jakob Uszkoreit, Thomas Unterthiner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cordonnier_Differentiable_Patch_Selection_for_Image_Recognition_CVPR_2021_paper.pdf",
        "aff": "EPFL, Switzerland; Google Research, Brain Team",
        "project": "",
        "github": "",
        "arxiv": "2104.03059"
    },
    {
        "title": "Differentiable SLAM-Net: Learning Particle SLAM for Visual Navigation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Karkus_Differentiable_SLAM-Net_Learning_Particle_SLAM_for_Visual_Navigation_CVPR_2021_paper.html",
        "author": "Peter Karkus, Shaojun Cai, David Hsu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Karkus_Differentiable_SLAM-Net_Learning_Particle_SLAM_for_Visual_Navigation_CVPR_2021_paper.pdf",
        "aff": "National University of Singapore",
        "project": "http://sites.google.com/view/slamnet",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Diffusion Probabilistic Models for 3D Point Cloud Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Diffusion_Probabilistic_Models_for_3D_Point_Cloud_Generation_CVPR_2021_paper.html",
        "author": "Shitong Luo, Wei Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Diffusion_Probabilistic_Models_for_3D_Point_Cloud_Generation_CVPR_2021_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University",
        "project": "",
        "github": "https://github.com/luost26/diffusion-point-cloud",
        "arxiv": "2103.01458"
    },
    {
        "title": "Digital Gimbal: End-to-End Deep Image Stabilization With Learnable Exposure Times",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dahary_Digital_Gimbal_End-to-End_Deep_Image_Stabilization_With_Learnable_Exposure_Times_CVPR_2021_paper.html",
        "author": "Omer Dahary, Matan Jacoby, Alex M. Bronstein",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dahary_Digital_Gimbal_End-to-End_Deep_Image_Stabilization_With_Learnable_Exposure_Times_CVPR_2021_paper.pdf",
        "aff": "Technion - Israel Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": "2012.04515"
    },
    {
        "title": "Discover Cross-Modality Nuances for Visible-Infrared Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Discover_Cross-Modality_Nuances_for_Visible-Infrared_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Qiong Wu, Pingyang Dai, Jie Chen, Chia-Wen Lin, Yongjian Wu, Feiyue Huang, Bineng Zhong, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Discover_Cross-Modality_Nuances_for_Visible-Infrared_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "School of Electronic and Computer Engineering, Peking University, China.; Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China.; Tencent Youtu Lab.; Guangxi Normal University, China.; National Tsing Hua University.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Discovering Hidden Physics Behind Transport Dynamics",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Discovering_Hidden_Physics_Behind_Transport_Dynamics_CVPR_2021_paper.html",
        "author": "Peirong Liu, Lin Tian, Yubo Zhang, Stephen Aylward, Yueh Lee, Marc Niethammer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Discovering_Hidden_Physics_Behind_Transport_Dynamics_CVPR_2021_paper.pdf",
        "aff": "Kitware Inc., New York, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, USA; Department of Radiology, University of North Carolina at Chapel Hill, Chapel Hill, USA",
        "project": "",
        "github": "",
        "arxiv": "2011.12222"
    },
    {
        "title": "Discovering Interpretable Latent Space Directions of GANs Beyond Binary Attributes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Discovering_Interpretable_Latent_Space_Directions_of_GANs_Beyond_Binary_Attributes_CVPR_2021_paper.html",
        "author": "Huiting Yang, Liangyu Chai, Qiang Wen, Shuang Zhao, Zixun Sun, Shengfeng He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Discovering_Interpretable_Latent_Space_Directions_of_GANs_Beyond_Binary_Attributes_CVPR_2021_paper.pdf",
        "aff": "Interactive Entertainment Group, Tencent Inc.; School of Computer Science and Engineering, South China University of Technology",
        "project": "",
        "github": "https://github.com/BERYLSHEEP/AdvStyle",
        "arxiv": ""
    },
    {
        "title": "Discovering Relationships Between Object Categories via Universal Canonical Maps",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Neverova_Discovering_Relationships_Between_Object_Categories_via_Universal_Canonical_Maps_CVPR_2021_paper.html",
        "author": "Natalia Neverova, Artsiom Sanakoyeu, Patrick Labatut, David Novotny, Andrea Vedaldi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Neverova_Discovering_Relationships_Between_Object_Categories_via_Universal_Canonical_Maps_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research",
        "project": "",
        "github": "",
        "arxiv": "2106.09758"
    },
    {
        "title": "Discrete-Continuous Action Space Policy Gradient-Based Attention for Image-Text Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Discrete-Continuous_Action_Space_Policy_Gradient-Based_Attention_for_Image-Text_Matching_CVPR_2021_paper.html",
        "author": "Shiyang Yan, Li Yu, Yuan Xie",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Discrete-Continuous_Action_Space_Policy_Gradient-Based_Attention_for_Image-Text_Matching_CVPR_2021_paper.pdf",
        "aff": "Nanjing University of Information Science and Technology, Nanjing, China; East China Normal University, Shanghai, China",
        "project": "",
        "github": "",
        "arxiv": "2104.10406"
    },
    {
        "title": "Discrimination-Aware Mechanism for Fine-Grained Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Discrimination-Aware_Mechanism_for_Fine-Grained_Representation_Learning_CVPR_2021_paper.html",
        "author": "Furong Xu, Meng Wang, Wei Zhang, Yuan Cheng, Wei Chu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Discrimination-Aware_Mechanism_for_Fine-Grained_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Ant Financial Services Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Discriminative Appearance Modeling With Multi-Track Pooling for Real-Time Multi-Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Discriminative_Appearance_Modeling_With_Multi-Track_Pooling_for_Real-Time_Multi-Object_Tracking_CVPR_2021_paper.html",
        "author": "Chanho Kim, Li Fuxin, Mazen Alotaibi, James M. Rehg",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Discriminative_Appearance_Modeling_With_Multi-Track_Pooling_for_Real-Time_Multi-Object_Tracking_CVPR_2021_paper.pdf",
        "aff": "Oregon State University; Georgia Institute of Technology",
        "project": "",
        "github": "https://github.com/chkim403/blstm-mtp",
        "arxiv": "2101.12159"
    },
    {
        "title": "Disentangled Cycle Consistency for Highly-Realistic Virtual Try-On",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ge_Disentangled_Cycle_Consistency_for_Highly-Realistic_Virtual_Try-On_CVPR_2021_paper.html",
        "author": "Chongjian Ge, Yibing Song, Yuying Ge, Han Yang, Wei Liu, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_Disentangled_Cycle_Consistency_for_Highly-Realistic_Virtual_Try-On_CVPR_2021_paper.pdf",
        "aff": "Disentangled Cycle Consistency for Highly-realistic Virtual Try-On\nChongjian Ge1Yibing Song2\u2217Yuying Ge1Han Yang3Wei Liu4Ping Luo1\n1The University of Hong Kong2Tencent AI Lab\n3ETH Z \u00a8urich4Tencent Data Platform\n{rhettgee, yuyingge }@connect.hku.hk yibingsong.cv@gmail.com hanyang@ethz.ch\nwl2223@columbia.edu pluo@cs.hku.hk\nAbstract\nImage virtual try-on replaces the clothes on a person\nimage with a desired in-shop clothes image. It is chal-\nlenging because the person and the in-shop clothes are un-\npaired. Existing methods formulate virtual try-on as either\nin-painting or cycle consistency. Both of these two formula-\ntions encourage the generation networks to reconstruct the\ninput image in a self-supervised manner. However, exist-\ning methods do not differentiate clothing and non-clothing\nregions. A straightforward generation impedes the virtual\ntry-on quality because of the heavily coupled image con-\ntents. In this paper, we propose a Disentangled Cycle-\nconsistency Try-On Network (DCTON). The DCTON is able\nto produce highly-realistic try-on images by disentangling\nimportant components of virtual try-on including clothes\nwarping, skin synthesis, and image composition. Moreover,\nDCTON can be naturally trained in a self-supervised man-\nner following cycle consistency learning. Extensive exper-\niments on challenging benchmarks show that DCTON out-\nperforms state-of-the-art approaches favorably.\n1. Introduction\nVirtual try-on of fashion images aims at changing the\nclothes of a person with other in-shop clothes. There are\nwide applications including costume matching, fashion im-\nage editing, and clothes retrieval for e-commerce. Exist-\ning methods mainly focus on a direct try-on based on 2D\nimages because of the available person images and in-shop\nclothes images online. However, these images are unpaired\nsince the collection of images with multiple models, of\nwhich each model wears different and pixel-wise aligned\nclothes is infeasible.\nTo handle unpaired images, existing methods such\nas VITON [ 15], CP-VTON [ 35], CP-VTON+ [ 24], and\n*Y . Song is the corresponding author. This work is done when C. Ge is\nan intern in Tencent AI Lab. The code is available at https://github.\ncom/ChongjianGE/DCTON .\nCNNInput 1 Masked 1\nClothes 1Reconstruct 1\nSupervisionSelf-supervised learning\n(One-way)\nCNN 1\nCNN 2Input 1 Clothes 2 Try-on 1 Clothes 1\nCycle consistency\n(Vanilla)\nWarping\nGenerationCNN 1\nCycle consistency\n(Ours)\nCNN 2Input 1 Try-on 1 Clothes 2 Clothes 1\n Surface Surface\nWarpingGenerationGenerationGenerationGenerationFigure 1. Comparison of virtual try-on pipelines. The inpainting\nmethods (e.g., CP-VTON [ 35] and ACGPN [ 40]) shown in the top\nrow use one in-shop clothes to replace the same input clothes. The\nvanilla CycleGAN [ 18] shown in the middle row introduces two\nin-shop clothes for cycle consistency at the expense of generating\ncoupled image contents (i.e., clothes, skin, and human poses). In\nthe last row, we propose DCTON to disentangle virtual try-on as\nclothes warping and non-clothes generation, which is built upon\nvanilla cycle consistency for self-supervised learning.\nACGPN [ 40] formulate virtual try-on as an inpainting prob-\nlem. They \ufb01rst mask the clothes region of a person im-\nage, and then recover the clothes region by using the same\nin-shop clothes for self-supervised network training. The\npipeline is shown in the top row of Fig. 1. It is regarded\nas a one-way reconstruction from the corrupted input im-\nage to its original image. Since these methods only use one\nclothes during training (i.e., clothes 1 is matched to input 1),\nthey are not effective when the person image and the target\n16928\n",
        "project": "",
        "github": "",
        "arxiv": "2103.09479"
    },
    {
        "title": "Disentangling Label Distribution for Long-Tailed Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Disentangling_Label_Distribution_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.html",
        "author": "Youngkyu Hong, Seungju Han, Kwanghee Choi, Seokjun Seo, Beomsu Kim, Buru Chang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Disentangling_Label_Distribution_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.pdf",
        "aff": "Hyperconnect",
        "project": "",
        "github": "",
        "arxiv": "2012.00321"
    },
    {
        "title": "Distilling Audio-Visual Knowledge by Compositional Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Distilling_Audio-Visual_Knowledge_by_Compositional_Contrastive_Learning_CVPR_2021_paper.html",
        "author": "Yanbei Chen, Yongqin Xian, A. Sophia Koepke, Ying Shan, Zeynep Akata",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Distilling_Audio-Visual_Knowledge_by_Compositional_Contrastive_Learning_CVPR_2021_paper.pdf",
        "aff": "MPI for Informatics; Tencent PCG; University of T\u00fcbingen, MPI for Intelligent Systems; University of T\u00fcbingen",
        "project": "",
        "github": "https://github.com/yanbeic/CCL",
        "arxiv": "2104.10955"
    },
    {
        "title": "Distilling Causal Effect of Data in Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Distilling_Causal_Effect_of_Data_in_Class-Incremental_Learning_CVPR_2021_paper.html",
        "author": "Xinting Hu, Kaihua Tang, Chunyan Miao, Xian-Sheng Hua, Hanwang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Distilling_Causal_Effect_of_Data_in_Class-Incremental_Learning_CVPR_2021_paper.pdf",
        "aff": "Damo Academy, Alibaba Group; Nanyang Technological University",
        "project": "",
        "github": "https://github.com/JoyHuYY1412/DDE_CIL",
        "arxiv": "2103.01737"
    },
    {
        "title": "Distilling Knowledge via Knowledge Review",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Distilling_Knowledge_via_Knowledge_Review_CVPR_2021_paper.html",
        "author": "Pengguang Chen, Shu Liu, Hengshuang Zhao, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Distilling_Knowledge_via_Knowledge_Review_CVPR_2021_paper.pdf",
        "aff": "SmartMore; The Chinese University of Hong Kong, SmartMore; University of Oxford; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2104.09044"
    },
    {
        "title": "Distilling Object Detectors via Decoupled Features",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Distilling_Object_Detectors_via_Decoupled_Features_CVPR_2021_paper.html",
        "author": "Jianyuan Guo, Kai Han, Yunhe Wang, Han Wu, Xinghao Chen, Chunjing Xu, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Distilling_Object_Detectors_via_Decoupled_Features_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, Faculty of Engineering, University of Sydney.; Noah\u2019s Ark Lab, Huawei Technologies.",
        "project": "https://www.mindspore.cn/resources/hub",
        "github": "https://github.com/huawei-noah/noah-research/tree/master/DeFeat",
        "arxiv": "2103.14475"
    },
    {
        "title": "Distractor-Aware Fast Tracking via Dynamic Convolutions and MOT Philosophy",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Distractor-Aware_Fast_Tracking_via_Dynamic_Convolutions_and_MOT_Philosophy_CVPR_2021_paper.html",
        "author": "Zikai Zhang, Bineng Zhong, Shengping Zhang, Zhenjun Tang, Xin Liu, Zhaoxiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Distractor-Aware_Fast_Tracking_via_Dynamic_Convolutions_and_MOT_Philosophy_CVPR_2021_paper.pdf",
        "aff": "Institute of Automation, CAS & University of Chinese Academy of Sciences & Centre for Arti\ufb01cial Intelligence and Robotics, HKISI CAS; Beijing Seetatech Technology; Guangxi Key Lab of Multi-Source Information Mining & Security, Guangxi Normal University; Harbin Institute of Technology / Peng Cheng Laboratory; Guangxi Key Lab of Multi-Source Information Mining & Security, Guangxi Normal University / Department of Computer Science and Technology, Huaqiao University",
        "project": "",
        "github": "https://github.com/hqucv/dmtrack",
        "arxiv": "2104.12041"
    },
    {
        "title": "Distribution Alignment: A Unified Framework for Long-Tail Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Distribution_Alignment_A_Unified_Framework_for_Long-Tail_Visual_Recognition_CVPR_2021_paper.html",
        "author": "Songyang Zhang, Zeming Li, Shipeng Yan, Xuming He, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Distribution_Alignment_A_Unified_Framework_for_Long-Tail_Visual_Recognition_CVPR_2021_paper.pdf",
        "aff": "Megvii Technology; ShanghaiTech University",
        "project": "",
        "github": "https://github.com/Megvii-BaseDetection/DisAlign",
        "arxiv": "2103.16370"
    },
    {
        "title": "Distribution-Aware Adaptive Multi-Bit Quantization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Distribution-Aware_Adaptive_Multi-Bit_Quantization_CVPR_2021_paper.html",
        "author": "Sijie Zhao, Tao Yue, Xuemei Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Distribution-Aware_Adaptive_Multi-Bit_Quantization_CVPR_2021_paper.pdf",
        "aff": "School of Electronic Science and Engineering, Nanjing University, Nanjing, China; Shenzhen Institute of Future Media Technology, Shenzhen 518071, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DivCo: Diverse Conditional Image Synthesis via Contrastive Generative Adversarial Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_DivCo_Diverse_Conditional_Image_Synthesis_via_Contrastive_Generative_Adversarial_Network_CVPR_2021_paper.html",
        "author": "Rui Liu, Yixiao Ge, Ching Lam Choi, Xiaogang Wang, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_DivCo_Diverse_Conditional_Image_Synthesis_via_Contrastive_Generative_Adversarial_Network_CVPR_2021_paper.pdf",
        "aff": "NVIDIA AI Technology Center, NVIDIA, Hong Kong; School of CST, Xidian University; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/ruiliu-ai/DivCo",
        "arxiv": "2103.07893"
    },
    {
        "title": "Dive Into Ambiguity: Latent Distribution Mining and Pairwise Uncertainty Estimation for Facial Expression Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/She_Dive_Into_Ambiguity_Latent_Distribution_Mining_and_Pairwise_Uncertainty_Estimation_CVPR_2021_paper.html",
        "author": "Jiahui She, Yibo Hu, Hailin Shi, Jun Wang, Qiu Shen, Tao Mei",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/She_Dive_Into_Ambiguity_Latent_Distribution_Mining_and_Pairwise_Uncertainty_Estimation_CVPR_2021_paper.pdf",
        "aff": "Nanjing University; JD AI Research",
        "project": "",
        "github": "",
        "arxiv": "2104.00232"
    },
    {
        "title": "Divergence Optimization for Noisy Universal Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Divergence_Optimization_for_Noisy_Universal_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Qing Yu, Atsushi Hashimoto, Yoshitaka Ushiku",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_Divergence_Optimization_for_Noisy_Universal_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "OMRON SINIC X Corporation; The University of Tokyo, OMRON SINIC X Corporation",
        "project": "",
        "github": "",
        "arxiv": "2104.00246"
    },
    {
        "title": "Diverse Branch Block: Building a Convolution as an Inception-Like Unit",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ding_Diverse_Branch_Block_Building_a_Convolution_as_an_Inception-Like_Unit_CVPR_2021_paper.html",
        "author": "Xiaohan Ding, Xiangyu Zhang, Jungong Han, Guiguang Ding",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_Diverse_Branch_Block_Building_a_Convolution_as_an_Inception-Like_Unit_CVPR_2021_paper.pdf",
        "aff": "MEGVII Technology; Beijing National Research Center for Information Science and Technology (BNRist); School of Software, Tsinghua University, Beijing, China; Computer Science Department, Aberystwyth University, SY23 3FL, UK",
        "project": "",
        "github": "https://github.com/DingXiaoH/DiverseBranchBlock",
        "arxiv": "2103.13425"
    },
    {
        "title": "Diverse Part Discovery: Occluded Person Re-Identification With Part-Aware Transformer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Diverse_Part_Discovery_Occluded_Person_Re-Identification_With_Part-Aware_Transformer_CVPR_2021_paper.html",
        "author": "Yulin Li, Jianfeng He, Tianzhu Zhang, Xiang Liu, Yongdong Zhang, Feng Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Diverse_Part_Discovery_Occluded_Person_Re-Identification_With_Part-Aware_Transformer_CVPR_2021_paper.pdf",
        "aff": "2898\n",
        "project": "",
        "github": "",
        "arxiv": "2106.04095"
    },
    {
        "title": "Diverse Semantic Image Synthesis via Probability Distribution Modeling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tan_Diverse_Semantic_Image_Synthesis_via_Probability_Distribution_Modeling_CVPR_2021_paper.html",
        "author": "Zhentao Tan, Menglei Chai, Dongdong Chen, Jing Liao, Qi Chu, Bin Liu, Gang Hua, Nenghai Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_Diverse_Semantic_Image_Synthesis_via_Probability_Distribution_Modeling_CVPR_2021_paper.pdf",
        "aff": "City University of Hong Kong; Wormpex AI Research LLC; Snap Inc.; University of Science and Technology of China; Microsoft Cloud AI",
        "project": "",
        "github": "https://github.com/tzt101/INADE.git",
        "arxiv": "2103.06878"
    },
    {
        "title": "Diversifying Sample Generation for Accurate Data-Free Quantization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Diversifying_Sample_Generation_for_Accurate_Data-Free_Quantization_CVPR_2021_paper.html",
        "author": "Xiangguo Zhang, Haotong Qin, Yifu Ding, Ruihao Gong, Qinghua Yan, Renshuai Tao, Yuhang Li, Fengwei Yu, Xianglong Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Diversifying_Sample_Generation_for_Accurate_Data-Free_Quantization_CVPR_2021_paper.pdf",
        "aff": "Shanghai AI Laboratory; Beihang University; SenseTime Research; Yale University",
        "project": "",
        "github": "",
        "arxiv": "2103.01049"
    },
    {
        "title": "Divide-and-Conquer for Lane-Aware Diverse Trajectory Prediction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Narayanan_Divide-and-Conquer_for_Lane-Aware_Diverse_Trajectory_Prediction_CVPR_2021_paper.html",
        "author": "Sriram Narayanan, Ramin Moslemi, Francesco Pittaluga, Buyu Liu, Manmohan Chandraker",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Narayanan_Divide-and-Conquer_for_Lane-Aware_Diverse_Trajectory_Prediction_CVPR_2021_paper.pdf",
        "aff": "NEC Labs America; NEC Labs America, UC San Diego",
        "project": "",
        "github": "",
        "arxiv": "2104.08277"
    },
    {
        "title": "DoDNet: Learning To Segment Multi-Organ and Tumors From Multiple Partially Labeled Datasets",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DoDNet_Learning_To_Segment_Multi-Organ_and_Tumors_From_Multiple_Partially_CVPR_2021_paper.html",
        "author": "Jianpeng Zhang, Yutong Xie, Yong Xia, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_DoDNet_Learning_To_Segment_Multi-Organ_and_Tumors_From_Multiple_Partially_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Northwestern Polytechnical University, China; School of Computer Science and Engineering, Northwestern Polytechnical University, China and The University of Adelaide, Australia; The University of Adelaide, Australia",
        "project": "",
        "github": "https://git.io/DoDNet",
        "arxiv": "2011.10217"
    },
    {
        "title": "Dogfight: Detecting Drones From Drones Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ashraf_Dogfight_Detecting_Drones_From_Drones_Videos_CVPR_2021_paper.html",
        "author": "Muhammad Waseem Ashraf, Waqas Sultani, Mubarak Shah",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ashraf_Dogfight_Detecting_Drones_From_Drones_Videos_CVPR_2021_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida, USA; Intelligent Machines Lab, Information Technology University, Pakistan",
        "project": "",
        "github": "",
        "arxiv": "2103.17242"
    },
    {
        "title": "Domain Adaptation With Auxiliary Target Domain-Oriented Classifier",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liang_Domain_Adaptation_With_Auxiliary_Target_Domain-Oriented_Classifier_CVPR_2021_paper.html",
        "author": "Jian Liang, Dapeng Hu, Jiashi Feng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liang_Domain_Adaptation_With_Auxiliary_Target_Domain-Oriented_Classifier_CVPR_2021_paper.pdf",
        "aff": "Sea AI Lab (SAIL); National University of Singapore (NUS)",
        "project": "",
        "github": "",
        "arxiv": "2007.04171"
    },
    {
        "title": "Domain Consensus Clustering for Universal Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Domain_Consensus_Clustering_for_Universal_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Guangrui Li, Guoliang Kang, Yi Zhu, Yunchao Wei, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Domain_Consensus_Clustering_for_Universal_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "Amazon Web Services; ReLER Lab, AAII, University of Technology Sydney; Carnegie Mellon University",
        "project": "",
        "github": "https://git.io/JY86C",
        "arxiv": ""
    },
    {
        "title": "Domain-Independent Dominance of Adaptive Methods",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Savarese_Domain-Independent_Dominance_of_Adaptive_Methods_CVPR_2021_paper.html",
        "author": "Pedro Savarese, David McAllester, Sudarshan Babu, Michael Maire",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Savarese_Domain-Independent_Dominance_of_Adaptive_Methods_CVPR_2021_paper.pdf",
        "aff": "University of Chicago; TTI-Chicago",
        "project": "",
        "github": "github.com/lolemacs/avagrads",
        "arxiv": "1912.01823"
    },
    {
        "title": "Domain-Robust VQA With Diverse Datasets and Methods but No Target Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Domain-Robust_VQA_With_Diverse_Datasets_and_Methods_but_No_Target_CVPR_2021_paper.html",
        "author": "Mingda Zhang, Tristan Maidment, Ahmad Diab, Adriana Kovashka, Rebecca Hwa",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Domain-Robust_VQA_With_Diverse_Datasets_and_Methods_but_No_Target_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, University of Pittsburgh",
        "project": "https://people.cs.pitt.edu/~mzhang/domain-robust-vqa/",
        "github": "",
        "arxiv": "2103.15974"
    },
    {
        "title": "Domain-Specific Suppression for Adaptive Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Domain-Specific_Suppression_for_Adaptive_Object_Detection_CVPR_2021_paper.html",
        "author": "Yu Wang, Rui Zhang, Shuo Zhang, Miao Li, Yangyang Xia, Xishan Zhang, Shaoli Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Domain-Specific_Suppression_for_Adaptive_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "SKL of Computer Architecture, Institute of Computing Technology, CAS, Beijing, China; Cambricon Technologies, China; SKL of Computer Architecture, Institute of Computing Technology, CAS, Beijing, China; Cambricon Technologies, China; University of Chinese Academy of Sciences, China; SKL of Computer Architecture, Institute of Computing Technology, CAS, Beijing, China; Cambricon Technologies, China",
        "project": "",
        "github": "",
        "arxiv": "2105.03570"
    },
    {
        "title": "Double Low-Rank Representation With Projection Distance Penalty for Clustering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Double_Low-Rank_Representation_With_Projection_Distance_Penalty_for_Clustering_CVPR_2021_paper.html",
        "author": "Zhiqiang Fu, Yao Zhao, Dongxia Chang, Xingxing Zhang, Yiming Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fu_Double_Low-Rank_Representation_With_Projection_Distance_Penalty_for_Clustering_CVPR_2021_paper.pdf",
        "aff": "Institute of Information Science, Beijing Jiaotong University; Department of Computer Science and Technology, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Drafting and Revision: Laplacian Pyramid Network for Fast High-Quality Artistic Style Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Drafting_and_Revision_Laplacian_Pyramid_Network_for_Fast_High-Quality_Artistic_CVPR_2021_paper.html",
        "author": "Tianwei Lin, Zhuoqi Ma, Fu Li, Dongliang He, Xin Li, Errui Ding, Nannan Wang, Jie Li, Xinbo Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Drafting_and_Revision_Laplacian_Pyramid_Network_for_Fast_High-Quality_Artistic_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Vision Technology (VIS), Baidu Inc.; Xidian University; Chongqing University of Posts and Telecommunications; Department of Computer Vision Technology (VIS), Baidu Inc., Xidian University",
        "project": "",
        "github": "",
        "arxiv": "2104.05376"
    },
    {
        "title": "DriveGAN: Towards a Controllable High-Quality Neural Simulation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_DriveGAN_Towards_a_Controllable_High-Quality_Neural_Simulation_CVPR_2021_paper.html",
        "author": "Seung Wook Kim, Jonah Philion, Antonio Torralba, Sanja Fidler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_DriveGAN_Towards_a_Controllable_High-Quality_Neural_Simulation_CVPR_2021_paper.pdf",
        "aff": "NVIDIA, University of Toronto, Vector Institute; MIT",
        "project": "",
        "github": "",
        "arxiv": "2104.15060"
    },
    {
        "title": "Dual Attention Guided Gaze Target Detection in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fang_Dual_Attention_Guided_Gaze_Target_Detection_in_the_Wild_CVPR_2021_paper.html",
        "author": "Yi Fang, Jiapeng Tang, Wang Shen, Wei Shen, Xiao Gu, Li Song, Guangtao Zhai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fang_Dual_Attention_Guided_Gaze_Target_Detection_in_the_Wild_CVPR_2021_paper.pdf",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Dual Attention Suppression Attack: Generate Adversarial Camouflage in Physical World",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Dual_Attention_Suppression_Attack_Generate_Adversarial_Camouflage_in_Physical_World_CVPR_2021_paper.html",
        "author": "Jiakai Wang, Aishan Liu, Zixin Yin, Shunchang Liu, Shiyu Tang, Xianglong Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Dual_Attention_Suppression_Attack_Generate_Adversarial_Camouflage_in_Physical_World_CVPR_2021_paper.pdf",
        "aff": "State Key Lab of Software Development Environment, Beihang University, Beijing, China",
        "project": "",
        "github": "https://github.com/nlsde-safety-team/DualAttentionAttack",
        "arxiv": "2103.01050"
    },
    {
        "title": "Dual Contradistinctive Generative Autoencoder",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Parmar_Dual_Contradistinctive_Generative_Autoencoder_CVPR_2021_paper.html",
        "author": "Gaurav Parmar, Dacheng Li, Kwonjoon Lee, Zhuowen Tu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Parmar_Dual_Contradistinctive_Generative_Autoencoder_CVPR_2021_paper.pdf",
        "aff": "UC San Diego; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/mlpc-ucsd/DC-VAE",
        "arxiv": "2011.10063"
    },
    {
        "title": "Dual Pixel Exploration: Simultaneous Depth Estimation and Image Restoration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pan_Dual_Pixel_Exploration_Simultaneous_Depth_Estimation_and_Image_Restoration_CVPR_2021_paper.html",
        "author": "Liyuan Pan, Shah Chowdhury, Richard Hartley, Miaomiao Liu, Hongguang Zhang, Hongdong Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_Dual_Pixel_Exploration_Simultaneous_Depth_Estimation_and_Image_Restoration_CVPR_2021_paper.pdf",
        "aff": "Australian National University, Data61, CSIRO; Australian National University, A&F, CSIRO; Australian National University; Australian National University, SE Institute, AMS",
        "project": "",
        "github": "",
        "arxiv": "2012.00301"
    },
    {
        "title": "Dual-GAN: Joint BVP and Noise Modeling for Remote Physiological Measurement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Dual-GAN_Joint_BVP_and_Noise_Modeling_for_Remote_Physiological_Measurement_CVPR_2021_paper.html",
        "author": "Hao Lu, Hu Han, S. Kevin Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_Dual-GAN_Joint_BVP_and_Noise_Modeling_for_Remote_Physiological_Measurement_CVPR_2021_paper.pdf",
        "aff": "Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China; University of Chinese Academy of Sciences, Beijing 100049, China; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China; Peng Cheng Laboratory, Shenzhen, China; Medical Imaging, Robotics, and Analytic Computing Laboratory and Engineering (MIRACLE), School of Biomedical Engineering & Suzhou Institute for Advance Research, University of Science and Technology of China, Suzhou 215123, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Dual-Stream Multiple Instance Learning Network for Whole Slide Image Classification With Self-Supervised Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dual-Stream_Multiple_Instance_Learning_Network_for_Whole_Slide_Image_Classification_CVPR_2021_paper.html",
        "author": "Bin Li, Yin Li, Kevin W. Eliceiri",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Dual-Stream_Multiple_Instance_Learning_Network_for_Whole_Slide_Image_Classification_CVPR_2021_paper.pdf",
        "aff": "Department of Biomedical Engineering, University of Wisconsin-Madison; Morgridge Institute for Research, Madison, WI USA; Department of Medical Physics, University of Wisconsin-Madison; Department of Biomedical Engineering, University of Wisconsin-Madison; Morgridge Institute for Research, Madison, WI USA; Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison; Department of Computer Sciences, University of Wisconsin-Madison",
        "project": "",
        "github": "",
        "arxiv": "2011.08939"
    },
    {
        "title": "DualAST: Dual Style-Learning Networks for Artistic Style Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_DualAST_Dual_Style-Learning_Networks_for_Artistic_Style_Transfer_CVPR_2021_paper.html",
        "author": "Haibo Chen, Lei Zhao, Zhizhong Wang, Huiming Zhang, Zhiwen Zuo, Ailin Li, Wei Xing, Dongming Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_DualAST_Dual_Style-Learning_Networks_for_Artistic_Style_Transfer_CVPR_2021_paper.pdf",
        "aff": "College of Computer Science and Technology, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DualGraph: A Graph-Based Method for Reasoning About Label Noise",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DualGraph_A_Graph-Based_Method_for_Reasoning_About_Label_Noise_CVPR_2021_paper.html",
        "author": "HaiYang Zhang, XiMing Xing, Liang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_DualGraph_A_Graph-Based_Method_for_Reasoning_About_Label_Noise_CVPR_2021_paper.pdf",
        "aff": "Beijing University of Posts and Telecommunications, School of Computer Science",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "DyCo3D: Robust Instance Segmentation of 3D Point Clouds Through Dynamic Convolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_DyCo3D_Robust_Instance_Segmentation_of_3D_Point_Clouds_Through_Dynamic_CVPR_2021_paper.html",
        "author": "Tong He, Chunhua Shen, Anton van den Hengel",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_DyCo3D_Robust_Instance_Segmentation_of_3D_Point_Clouds_Through_Dynamic_CVPR_2021_paper.pdf",
        "aff": "The University of Adelaide, Australia",
        "project": "",
        "github": "https://git.io/DyCo3D",
        "arxiv": "2011.13328"
    },
    {
        "title": "DyGLIP: A Dynamic Graph Model With Link Prediction for Accurate Multi-Camera Multiple Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Quach_DyGLIP_A_Dynamic_Graph_Model_With_Link_Prediction_for_Accurate_CVPR_2021_paper.html",
        "author": "Kha Gia Quach, Pha Nguyen, Huu Le, Thanh-Dat Truong, Chi Nhan Duong, Minh-Triet Tran, Khoa Luu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Quach_DyGLIP_A_Dynamic_Graph_Model_With_Link_Prediction_for_Accurate_CVPR_2021_paper.pdf",
        "aff": "VinAI Research, VIETNAM; Chalmers University of Technology, SWEDEN; University of Arkansas, USA; University of Science, VNU-HCM, VIETNAM; Concordia University, CANADA",
        "project": "",
        "github": "https://github.com/uark-cviu/DyGLIP",
        "arxiv": "2106.06856"
    },
    {
        "title": "DyStaB: Unsupervised Object Segmentation via Dynamic-Static Bootstrapping",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_DyStaB_Unsupervised_Object_Segmentation_via_Dynamic-Static_Bootstrapping_CVPR_2021_paper.html",
        "author": "Yanchao Yang, Brian Lai, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_DyStaB_Unsupervised_Object_Segmentation_via_Dynamic-Static_Bootstrapping_CVPR_2021_paper.pdf",
        "aff": "Stanford University; UCLA Vision Lab",
        "project": "",
        "github": "https://github.com/blai88/unsupervised_segmentation",
        "arxiv": "2008.07012"
    },
    {
        "title": "Dynamic Class Queue for Large Scale Face Recognition in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dynamic_Class_Queue_for_Large_Scale_Face_Recognition_in_the_CVPR_2021_paper.html",
        "author": "Bi Li, Teng Xi, Gang Zhang, Haocheng Feng, Junyu Han, Jingtuo Liu, Errui Ding, Wenyu Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Dynamic_Class_Queue_for_Large_Scale_Face_Recognition_in_the_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Vision Technology (VIS), Baidu Inc.; School of Electronic Information and Communications, Huazhong University of Science and Technology; Department of Computer Science and Technology, Tsinghua University",
        "project": "",
        "github": "https://github.com/bilylee/DCQ",
        "arxiv": "2105.11113"
    },
    {
        "title": "Dynamic Domain Adaptation for Efficient Inference",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dynamic_Domain_Adaptation_for_Efficient_Inference_CVPR_2021_paper.html",
        "author": "Shuang Li, JinMing Zhang, Wenxuan Ma, Chi Harold Liu, Wei Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Dynamic_Domain_Adaptation_for_Efficient_Inference_CVPR_2021_paper.pdf",
        "aff": "Beijing Institute of Technology; Inceptio Tech",
        "project": "",
        "github": "",
        "arxiv": "2103.16403"
    },
    {
        "title": "Dynamic Head: Unifying Object Detection Heads With Attentions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Dynamic_Head_Unifying_Object_Detection_Heads_With_Attentions_CVPR_2021_paper.html",
        "author": "Xiyang Dai, Yinpeng Chen, Bin Xiao, Dongdong Chen, Mengchen Liu, Lu Yuan, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Dynamic_Head_Unifying_Object_Detection_Heads_With_Attentions_CVPR_2021_paper.pdf",
        "aff": "Microsoft, Redmond, USA",
        "project": "",
        "github": "https://github.com/microsoft/DynamicHead",
        "arxiv": "2106.08322"
    },
    {
        "title": "Dynamic Metric Learning: Towards a Scalable Metric Space To Accommodate Multiple Semantic Scales",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Dynamic_Metric_Learning_Towards_a_Scalable_Metric_Space_To_Accommodate_CVPR_2021_paper.html",
        "author": "Yifan Sun, Yuke Zhu, Yuhan Zhang, Pengkun Zheng, Xi Qiu, Chi Zhang, Yichen Wei",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Dynamic_Metric_Learning_Towards_a_Scalable_Metric_Space_To_Accommodate_CVPR_2021_paper.pdf",
        "aff": "Megvii Technology, Beihang University, Baidu Research; Beihang University; Megvii Technology",
        "project": "",
        "github": "https://github.com/SupetZYK/DynamicMetricLearning",
        "arxiv": "2103.11781"
    },
    {
        "title": "Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gafni_Dynamic_Neural_Radiance_Fields_for_Monocular_4D_Facial_Avatar_Reconstruction_CVPR_2021_paper.html",
        "author": "Guy Gafni, Justus Thies, Michael Zollhofer, Matthias Niessner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gafni_Dynamic_Neural_Radiance_Fields_for_Monocular_4D_Facial_Avatar_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "Technical University of Munich; Facebook Reality Labs Research",
        "project": "",
        "github": "https://gafniguy.github.io/4D-Facial-Avatars",
        "arxiv": "2012.03065"
    },
    {
        "title": "Dynamic Probabilistic Graph Convolution for Facial Action Unit Intensity Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_Dynamic_Probabilistic_Graph_Convolution_for_Facial_Action_Unit_Intensity_Estimation_CVPR_2021_paper.html",
        "author": "Tengfei Song, Zijun Cui, Yuru Wang, Wenming Zheng, Qiang Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Dynamic_Probabilistic_Graph_Convolution_for_Facial_Action_Unit_Intensity_Estimation_CVPR_2021_paper.pdf",
        "aff": "Rensselaer Polytechnic Institute; Southeast University; Northeast Normal University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Dynamic Region-Aware Convolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Dynamic_Region-Aware_Convolution_CVPR_2021_paper.html",
        "author": "Jin Chen, Xijun Wang, Zichao Guo, Xiangyu Zhang, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Dynamic_Region-Aware_Convolution_CVPR_2021_paper.pdf",
        "aff": "MEGVII Technology",
        "project": "",
        "github": "",
        "arxiv": "2003.12243"
    },
    {
        "title": "Dynamic Slimmable Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dynamic_Slimmable_Network_CVPR_2021_paper.html",
        "author": "Changlin Li, Guangrun Wang, Bing Wang, Xiaodan Liang, Zhihui Li, Xiaojun Chang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Dynamic_Slimmable_Network_CVPR_2021_paper.pdf",
        "aff": "Sun Yat-Sen University; Shandong Artificial Intelligence, Qilu University of Technology; University of Oxford; GORSE Lab, Dept. of DSAI, Monash University; Alibaba Group",
        "project": "",
        "github": "https://github.com/changlin31/DS-Net",
        "arxiv": "2103.13258"
    },
    {
        "title": "Dynamic Transfer for Multi-Source Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dynamic_Transfer_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Yunsheng Li, Lu Yuan, Yinpeng Chen, Pei Wang, Nuno Vasconcelos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Dynamic_Transfer_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "UC San Diego; Microsoft",
        "project": "",
        "github": "https://github.com/liyunsheng13/DRT",
        "arxiv": "2103.10583"
    },
    {
        "title": "Dynamic Weighted Learning for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_Dynamic_Weighted_Learning_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Ni Xiao, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xiao_Dynamic_Weighted_Learning_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "School of Microelectronics and Communication Engineering, Chongqing University, China",
        "project": "",
        "github": "https://github.com/NiXiao-cqu/TransferLearning-dwl-cvpr2021",
        "arxiv": "2103.13814"
    },
    {
        "title": "ECKPN: Explicit Class Knowledge Propagation Network for Transductive Few-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_ECKPN_Explicit_Class_Knowledge_Propagation_Network_for_Transductive_Few-Shot_Learning_CVPR_2021_paper.html",
        "author": "Chaofan Chen, Xiaoshan Yang, Changsheng Xu, Xuhui Huang, Zhe Ma",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_ECKPN_Explicit_Class_Knowledge_Propagation_Network_for_Transductive_Few-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "X Lab, The Second Academy of CASIC, Beijing China; School of Information Science and Technology, University of Science and Technology of China (USTC); National Lab of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA)",
        "project": "",
        "github": "",
        "arxiv": "2106.08523"
    },
    {
        "title": "EDNet: Efficient Disparity Estimation With Cost Volume Combination and Attention-Based Spatial Residual",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_EDNet_Efficient_Disparity_Estimation_With_Cost_Volume_Combination_and_Attention-Based_CVPR_2021_paper.html",
        "author": "Songyan Zhang, Zhicheng Wang, Qiang Wang, Jinshuo Zhang, Gang Wei, Xiaowen Chu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_EDNet_Efficient_Disparity_Estimation_With_Cost_Volume_Combination_and_Attention-Based_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, Hong Kong Baptist University; CAD Research Center, Tongji University",
        "project": "",
        "github": "",
        "arxiv": "2010.13338"
    },
    {
        "title": "Effective Snapshot Compressive-Spectral Imaging via Deep Denoising and Total Variation Priors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_Effective_Snapshot_Compressive-Spectral_Imaging_via_Deep_Denoising_and_Total_Variation_CVPR_2021_paper.html",
        "author": "Haiquan Qiu, Yao Wang, Deyu Meng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qiu_Effective_Snapshot_Compressive-Spectral_Imaging_via_Deep_Denoising_and_Total_Variation_CVPR_2021_paper.pdf",
        "aff": "Shanghai Em-Data Technology Co., Ltd., China; The Macau University of Science and Technology, Macau, China; Xi\u2019an Jiaotong University, Xi\u2019an, China",
        "project": "",
        "github": "https://github.com/ucker/SCI-TV-FFDNet",
        "arxiv": ""
    },
    {
        "title": "Effective Sparsification of Neural Networks With Global Sparsity Constraint",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Effective_Sparsification_of_Neural_Networks_With_Global_Sparsity_Constraint_CVPR_2021_paper.html",
        "author": "Xiao Zhou, Weizhong Zhang, Hang Xu, Tong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Effective_Sparsification_of_Neural_Networks_With_Global_Sparsity_Constraint_CVPR_2021_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; The Hong Kong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2105.01571"
    },
    {
        "title": "EffiScene: Efficient Per-Pixel Rigidity Inference for Unsupervised Joint Learning of Optical Flow, Depth, Camera Pose and Motion Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jiao_EffiScene_Efficient_Per-Pixel_Rigidity_Inference_for_Unsupervised_Joint_Learning_of_CVPR_2021_paper.html",
        "author": "Yang Jiao, Trac D. Tran, Guangming Shi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jiao_EffiScene_Efficient_Per-Pixel_Rigidity_Inference_for_Unsupervised_Joint_Learning_of_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Xidian University, Johns Hopkins University, Xidian Guangzhou Institute of Technology; Xidian University, Xidian Guangzhou Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": "2011.08332"
    },
    {
        "title": "Efficient Conditional GAN Transfer With Knowledge Propagation Across Classes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shahbazi_Efficient_Conditional_GAN_Transfer_With_Knowledge_Propagation_Across_Classes_CVPR_2021_paper.html",
        "author": "Mohamad Shahbazi, Zhiwu Huang, Danda Pani Paudel, Ajad Chhatkuli, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shahbazi_Efficient_Conditional_GAN_Transfer_With_Knowledge_Propagation_Across_Classes_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Z\u00fcrich, Switzerland; Computer Vision Lab, ETH Z\u00fcrich, Switzerland; PSI, KU Leuven, Belgium",
        "project": "",
        "github": "https://github.com/mshahbazi72/cGANTransfer",
        "arxiv": "2102.06696"
    },
    {
        "title": "Efficient Deformable Shape Correspondence via Multiscale Spectral Manifold Wavelets Preservation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Efficient_Deformable_Shape_Correspondence_via_Multiscale_Spectral_Manifold_Wavelets_Preservation_CVPR_2021_paper.html",
        "author": "Ling Hu, Qinsong Li, Shengjun Liu, Xinru Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Efficient_Deformable_Shape_Correspondence_via_Multiscale_Spectral_Manifold_Wavelets_Preservation_CVPR_2021_paper.pdf",
        "aff": "Institute of Engineering Modeling and Scienti\ufb01c Computing, Central South University; State Key Laboratory of High Performance Manufacturing Complex, Central South University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Efficient Feature Transformations for Discriminative and Generative Continual Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Verma_Efficient_Feature_Transformations_for_Discriminative_and_Generative_Continual_Learning_CVPR_2021_paper.html",
        "author": "Vinay Kumar Verma, Kevin J Liang, Nikhil Mehta, Piyush Rai, Lawrence Carin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Verma_Efficient_Feature_Transformations_for_Discriminative_and_Generative_Continual_Learning_CVPR_2021_paper.pdf",
        "aff": "IIT Kanpur; Duke University, Facebook AI; Duke University",
        "project": "",
        "github": "",
        "arxiv": "2103.13558"
    },
    {
        "title": "Efficient Initial Pose-Graph Generation for Global SfM",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Barath_Efficient_Initial_Pose-Graph_Generation_for_Global_SfM_CVPR_2021_paper.html",
        "author": "Daniel Barath, Dmytro Mishkin, Ivan Eichhardt, Ilia Shipachev, Jiri Matas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Barath_Efficient_Initial_Pose-Graph_Generation_for_Global_SfM_CVPR_2021_paper.pdf",
        "aff": "1. Visual Recognition Group, Faculty of Electrical Engineering, Czech Technical University in Prague; 2. MPLab, SZTAKI, Budapest; 3. Department of Computer Science, ETH Zurich; MPLab, SZTAKI, Budapest; Visual Recognition Group, Faculty of Electrical Engineering, Czech Technical University in Prague",
        "project": "",
        "github": "https://github.com/danini/pose-graph-initialization",
        "arxiv": "2011.11986"
    },
    {
        "title": "Efficient Multi-Stage Video Denoising With Recurrent Spatio-Temporal Fusion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Maggioni_Efficient_Multi-Stage_Video_Denoising_With_Recurrent_Spatio-Temporal_Fusion_CVPR_2021_paper.html",
        "author": "Matteo Maggioni, Yibin Huang, Cheng Li, Shuai Xiao, Zhongqian Fu, Fenglong Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Maggioni_Efficient_Multi-Stage_Video_Denoising_With_Recurrent_Spatio-Temporal_Fusion_CVPR_2021_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab",
        "project": "",
        "github": "",
        "arxiv": "2103.05407"
    },
    {
        "title": "Efficient Object Embedding for Spliced Image Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Efficient_Object_Embedding_for_Spliced_Image_Retrieval_CVPR_2021_paper.html",
        "author": "Bor-Chun Chen, Zuxuan Wu, Larry S. Davis, Ser-Nam Lim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Efficient_Object_Embedding_for_Spliced_Image_Retrieval_CVPR_2021_paper.pdf",
        "aff": "University of Maryland, College Park; Facebook AI; Fudan University",
        "project": "",
        "github": "",
        "arxiv": "1905.11903"
    },
    {
        "title": "Efficient Regional Memory Network for Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Efficient_Regional_Memory_Network_for_Video_Object_Segmentation_CVPR_2021_paper.html",
        "author": "Haozhe Xie, Hongxun Yao, Shangchen Zhou, Shengping Zhang, Wenxiu Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xie_Efficient_Regional_Memory_Network_for_Video_Object_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Harbin Institute of Technology, SenseTime Research and Tetras.AI; SenseTime Research and Tetras.AI, Shanghai AI Laboratory; Harbin Institute of Technology, Peng Cheng Laboratory; Harbin Institute of Technology; S-Lab, Nanyang Technological University",
        "project": "https://haozhexie.com/project/rmnet",
        "github": "",
        "arxiv": "2103.12934"
    },
    {
        "title": "Ego-Exo: Transferring Visual Representations From Third-Person to First-Person Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Ego-Exo_Transferring_Visual_Representations_From_Third-Person_to_First-Person_Videos_CVPR_2021_paper.html",
        "author": "Yanghao Li, Tushar Nagarajan, Bo Xiong, Kristen Grauman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Ego-Exo_Transferring_Visual_Representations_From_Third-Person_to_First-Person_Videos_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; Facebook AI Research, UT Austin",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Embedded Discriminative Attention Mechanism for Weakly Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Embedded_Discriminative_Attention_Mechanism_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Tong Wu, Junshi Huang, Guangyu Gao, Xiaoming Wei, Xiaolin Wei, Xuan Luo, Chi Harold Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Embedded_Discriminative_Attention_Mechanism_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Meituan; Beijing Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Embedding Transfer With Label Relaxation for Improved Metric Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Embedding_Transfer_With_Label_Relaxation_for_Improved_Metric_Learning_CVPR_2021_paper.html",
        "author": "Sungyeon Kim, Dongwon Kim, Minsu Cho, Suha Kwak",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Embedding_Transfer_With_Label_Relaxation_for_Improved_Metric_Learning_CVPR_2021_paper.pdf",
        "aff": "Dept. of CSE, POSTECH; Graduate School of AI, POSTECH; Dept. of CSE, POSTECH; Graduate School of AI, POSTECH",
        "project": "",
        "github": "",
        "arxiv": "2103.14908"
    },
    {
        "title": "Embracing Uncertainty: Decoupling and De-Bias for Robust Temporal Grounding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Embracing_Uncertainty_Decoupling_and_De-Bias_for_Robust_Temporal_Grounding_CVPR_2021_paper.html",
        "author": "Hao Zhou, Chongyang Zhang, Yan Luo, Yanjun Chen, Chuanping Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Embracing_Uncertainty_Decoupling_and_De-Bias_for_Robust_Temporal_Grounding_CVPR_2021_paper.pdf",
        "aff": "Zhengzhou University, Zhengzhou, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2103.16848"
    },
    {
        "title": "EnD: Entangling and Disentangling Deep Representations for Bias Correction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tartaglione_EnD_Entangling_and_Disentangling_Deep_Representations_for_Bias_Correction_CVPR_2021_paper.html",
        "author": "Enzo Tartaglione, Carlo Alberto Barbano, Marco Grangetto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tartaglione_EnD_Entangling_and_Disentangling_Deep_Representations_for_Bias_Correction_CVPR_2021_paper.pdf",
        "aff": "University of Turin, Computer Science Department",
        "project": "",
        "github": "",
        "arxiv": "2103.02023"
    },
    {
        "title": "Encoder Fusion Network With Co-Attention Embedding for Referring Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Encoder_Fusion_Network_With_Co-Attention_Embedding_for_Referring_Image_Segmentation_CVPR_2021_paper.html",
        "author": "Guang Feng, Zhiwei Hu, Lihe Zhang, Huchuan Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Encoder_Fusion_Network_With_Co-Attention_Embedding_for_Referring_Image_Segmentation_CVPR_2021_paper.pdf",
        "aff": "School of Information and Communication Engineering, Dalian University of Technology; Ningbo Institute, Dalian University of Technology",
        "project": "",
        "github": "",
        "arxiv": "2105.01839"
    },
    {
        "title": "Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Richardson_Encoding_in_Style_A_StyleGAN_Encoder_for_Image-to-Image_Translation_CVPR_2021_paper.html",
        "author": "Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, Daniel Cohen-Or",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Richardson_Encoding_in_Style_A_StyleGAN_Encoder_for_Image-to-Image_Translation_CVPR_2021_paper.pdf",
        "aff": "Penta-AI; Penta-AI, Tel-Aviv University; Tel-Aviv University",
        "project": "",
        "github": "https://github.com/eladrich/pixel2style2pixel",
        "arxiv": "2008.00951"
    },
    {
        "title": "End-to-End High Dynamic Range Camera Pipeline Optimization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Robidoux_End-to-End_High_Dynamic_Range_Camera_Pipeline_Optimization_CVPR_2021_paper.html",
        "author": "Nicolas Robidoux, Luis E. Garcia Capel, Dong-eun Seo, Avinash Sharma, Federico Ariza, Felix Heide",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Robidoux_End-to-End_High_Dynamic_Range_Camera_Pipeline_Optimization_CVPR_2021_paper.pdf",
        "aff": "Algolux; Algolux, Princeton University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "End-to-End Human Object Interaction Detection With HOI Transformer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zou_End-to-End_Human_Object_Interaction_Detection_With_HOI_Transformer_CVPR_2021_paper.html",
        "author": "Cheng Zou, Bohan Wang, Yue Hu, Junqi Liu, Qian Wu, Yu Zhao, Boxun Li, Chenguang Zhang, Chi Zhang, Yichen Wei, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zou_End-to-End_Human_Object_Interaction_Detection_With_HOI_Transformer_CVPR_2021_paper.pdf",
        "aff": "MEGVII Technology",
        "project": "",
        "github": "https://github.com/bbepoch/HoiTransformer",
        "arxiv": "2103.04503"
    },
    {
        "title": "End-to-End Human Pose and Mesh Reconstruction with Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_End-to-End_Human_Pose_and_Mesh_Reconstruction_with_Transformers_CVPR_2021_paper.html",
        "author": "Kevin Lin, Lijuan Wang, Zicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_End-to-End_Human_Pose_and_Mesh_Reconstruction_with_Transformers_CVPR_2021_paper.pdf",
        "aff": "Microsoft",
        "project": "",
        "github": "",
        "arxiv": "2012.09760"
    },
    {
        "title": "End-to-End Learning for Joint Image Demosaicing, Denoising and Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xing_End-to-End_Learning_for_Joint_Image_Demosaicing_Denoising_and_Super-Resolution_CVPR_2021_paper.html",
        "author": "Wenzhu Xing, Karen Egiazarian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xing_End-to-End_Learning_for_Joint_Image_Demosaicing_Denoising_and_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "Computational Image Group, Tampere University, Finland",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "End-to-End Object Detection With Fully Convolutional Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_End-to-End_Object_Detection_With_Fully_Convolutional_Network_CVPR_2021_paper.html",
        "author": "Jianfeng Wang, Lin Song, Zeming Li, Hongbin Sun, Jian Sun, Nanning Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_End-to-End_Object_Detection_With_Fully_Convolutional_Network_CVPR_2021_paper.pdf",
        "aff": "College of Artificial Intelligence, Xi'an Jiaotong University; Megvii Technology",
        "project": "",
        "github": "https://github.com/Megvii-BaseDetection/DeFCN",
        "arxiv": "2012.03544"
    },
    {
        "title": "End-to-End Rotation Averaging With Multi-Source Propagation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_End-to-End_Rotation_Averaging_With_Multi-Source_Propagation_CVPR_2021_paper.html",
        "author": "Luwei Yang, Heng Li, Jamal Ahmed Rahim, Zhaopeng Cui, Ping Tan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_End-to-End_Rotation_Averaging_With_Multi-Source_Propagation_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; State Key Lab of CAD & CG, Zhejiang University",
        "project": "",
        "github": "github.com/sfu-gruvi-3dv/msp-rotavg",
        "arxiv": ""
    },
    {
        "title": "End-to-End Video Instance Segmentation With Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_End-to-End_Video_Instance_Segmentation_With_Transformers_CVPR_2021_paper.html",
        "author": "Yuqing Wang, Zhaoliang Xu, Xinlong Wang, Chunhua Shen, Baoshan Cheng, Hao Shen, Huaxia Xia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_End-to-End_Video_Instance_Segmentation_With_Transformers_CVPR_2021_paper.pdf",
        "aff": "Meituan; The University of Adelaide, Australia",
        "project": "",
        "github": "https://git.io/VisTR",
        "arxiv": "2011.14503"
    },
    {
        "title": "Energy-Based Learning for Scene Graph Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Suhail_Energy-Based_Learning_for_Scene_Graph_Generation_CVPR_2021_paper.html",
        "author": "Mohammed Suhail, Abhay Mittal, Behjat Siddiquie, Chris Broaddus, Jayan Eledath, Gerard Medioni, Leonid Sigal",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Suhail_Energy-Based_Learning_for_Scene_Graph_Generation_CVPR_2021_paper.pdf",
        "aff": "University of British Columbia, Vector Institute for AI, Canada CIFAR AI Chair; Amazon",
        "project": "",
        "github": "https://github.com/mods333/energy-based-scene-graph",
        "arxiv": "2103.02221"
    },
    {
        "title": "Enhance Curvature Information by Structured Stochastic Quasi-Newton Methods",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Enhance_Curvature_Information_by_Structured_Stochastic_Quasi-Newton_Methods_CVPR_2021_paper.html",
        "author": "Minghan Yang, Dong Xu, Hongyu Chen, Zaiwen Wen, Mengyun Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Enhance_Curvature_Information_by_Structured_Stochastic_Quasi-Newton_Methods_CVPR_2021_paper.pdf",
        "aff": "School of Mathematical Sciences, Peking University, China; Beijing International Center for Mathematical Research, Peking University, China; Huawei Technologies Co. Ltd, China",
        "project": "",
        "github": "",
        "arxiv": "2006.09606"
    },
    {
        "title": "Enhancing the Transferability of Adversarial Attacks Through Variance Tuning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Enhancing_the_Transferability_of_Adversarial_Attacks_Through_Variance_Tuning_CVPR_2021_paper.html",
        "author": "Xiaosen Wang, Kun He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Enhancing_the_Transferability_of_Adversarial_Attacks_Through_Variance_Tuning_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Technology, Huazhong University of Science and Technology",
        "project": "",
        "github": "https://github.com/JHL-HUST/VT",
        "arxiv": "2103.15571"
    },
    {
        "title": "Enriching ImageNet With Human Similarity Judgments and Psychological Embeddings",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Roads_Enriching_ImageNet_With_Human_Similarity_Judgments_and_Psychological_Embeddings_CVPR_2021_paper.html",
        "author": "Brett D. Roads, Bradley C. Love",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Roads_Enriching_ImageNet_With_Human_Similarity_Judgments_and_Psychological_Embeddings_CVPR_2021_paper.pdf",
        "aff": "Department of Experimental Psychology, University College London, London, United Kingdom",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2011.11015"
    },
    {
        "title": "Ensembling With Deep Generative Views",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chai_Ensembling_With_Deep_Generative_Views_CVPR_2021_paper.html",
        "author": "Lucy Chai, Jun-Yan Zhu, Eli Shechtman, Phillip Isola, Richard Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chai_Ensembling_With_Deep_Generative_Views_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; MIT",
        "project": "",
        "github": "",
        "arxiv": "2104.14551"
    },
    {
        "title": "Equalization Loss v2: A New Gradient Balance Approach for Long-Tailed Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tan_Equalization_Loss_v2_A_New_Gradient_Balance_Approach_for_Long-Tailed_CVPR_2021_paper.html",
        "author": "Jingru Tan, Xin Lu, Gang Zhang, Changqing Yin, Quanquan Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_Equalization_Loss_v2_A_New_Gradient_Balance_Approach_for_Long-Tailed_CVPR_2021_paper.pdf",
        "aff": "Tsinghua University; Tongji University; SenseTime Research",
        "project": "",
        "github": "https://github.com/tztztztztz/eqlv2",
        "arxiv": "2012.08548"
    },
    {
        "title": "Equivariant Point Network for 3D Point Cloud Analysis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Equivariant_Point_Network_for_3D_Point_Cloud_Analysis_CVPR_2021_paper.html",
        "author": "Haiwei Chen, Shichen Liu, Weikai Chen, Hao Li, Randall Hill",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Equivariant_Point_Network_for_3D_Point_Cloud_Analysis_CVPR_2021_paper.pdf",
        "aff": "University of Southern California, USC Institute for Creative Technologies; Tencent Game AI Research Center; Pinscreen",
        "project": "",
        "github": "https://github.com/nintendops/EPNPointCloud",
        "arxiv": "2103.14147"
    },
    {
        "title": "Euro-PVI: Pedestrian Vehicle Interactions in Dense Urban Centers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bhattacharyya_Euro-PVI_Pedestrian_Vehicle_Interactions_in_Dense_Urban_Centers_CVPR_2021_paper.html",
        "author": "Apratim Bhattacharyya, Daniel Olmeda Reino, Mario Fritz, Bernt Schiele",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bhattacharyya_Euro-PVI_Pedestrian_Vehicle_Interactions_in_Dense_Urban_Centers_CVPR_2021_paper.pdf",
        "aff": "CISPA Helmholtz Center for Information Security; Toyota Motor Europe; Max Planck Institute for Informatics, Saarland Informatics Campus",
        "project": "www.europvi.mpi-inf.mpg.de",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "EvDistill: Asynchronous Events To End-Task Learning via Bidirectional Reconstruction-Guided Cross-Modal Knowledge Distillation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_EvDistill_Asynchronous_Events_To_End-Task_Learning_via_Bidirectional_Reconstruction-Guided_Cross-Modal_CVPR_2021_paper.html",
        "author": "Lin Wang, Yujeong Chae, Sung-Hoon Yoon, Tae-Kyun Kim, Kuk-Jin Yoon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_EvDistill_Asynchronous_Events_To_End-Task_Learning_via_Bidirectional_Reconstruction-Guided_Cross-Modal_CVPR_2021_paper.pdf",
        "aff": "Visual Intelligence Lab., KAIST, Korea; ICVL Lab., KAIST, Korea and Imperial College London, UK",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Event-Based Bispectral Photometry Using Temporally Modulated Illumination",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Takatani_Event-Based_Bispectral_Photometry_Using_Temporally_Modulated_Illumination_CVPR_2021_paper.html",
        "author": "Tsuyoshi Takatani, Yuzuha Ito, Ayaka Ebisu, Yinqiang Zheng, Takahito Aoto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Takatani_Event-Based_Bispectral_Photometry_Using_Temporally_Modulated_Illumination_CVPR_2021_paper.pdf",
        "aff": "The University of Tokyo, Japan; University of Tsukuba, Japan",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Event-Based Synthetic Aperture Imaging With a Hybrid Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Event-Based_Synthetic_Aperture_Imaging_With_a_Hybrid_Network_CVPR_2021_paper.html",
        "author": "Xiang Zhang, Wei Liao, Lei Yu, Wen Yang, Gui-Song Xia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Event-Based_Synthetic_Aperture_Imaging_With_a_Hybrid_Network_CVPR_2021_paper.pdf",
        "aff": "Wuhan University, Wuhan, China.",
        "project": "",
        "github": "",
        "arxiv": "2103.02376"
    },
    {
        "title": "EventZoom: Learning To Denoise and Super Resolve Neuromorphic Events",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Duan_EventZoom_Learning_To_Denoise_and_Super_Resolve_Neuromorphic_Events_CVPR_2021_paper.html",
        "author": "Peiqi Duan, Zihao W. Wang, Xinyu Zhou, Yi Ma, Boxin Shi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Duan_EventZoom_Learning_To_Denoise_and_Super_Resolve_Neuromorphic_Events_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Engineering, Northwestern University; NELVT, Department of Computer Science and Technology, Peking University; NELVT, Department of Computer Science and Technology, Peking University and Institute for Arti\ufb01cial Intelligence, Peking University",
        "project": "https://sites.google.com/view/EventZoom",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Every Annotation Counts: Multi-Label Deep Supervision for Medical Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Reiss_Every_Annotation_Counts_Multi-Label_Deep_Supervision_for_Medical_Image_Segmentation_CVPR_2021_paper.html",
        "author": "Simon Reiss, Constantin Seibold, Alexander Freytag, Erik Rodner, Rainer Stiefelhagen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Reiss_Every_Annotation_Counts_Multi-Label_Deep_Supervision_for_Medical_Image_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Karlsruhe Institute of Technology; Carl Zeiss AG; University of Applied Sciences Berlin",
        "project": "",
        "github": "",
        "arxiv": "2104.13243"
    },
    {
        "title": "Exemplar-Based Open-Set Panoptic Segmentation Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hwang_Exemplar-Based_Open-Set_Panoptic_Segmentation_Network_CVPR_2021_paper.html",
        "author": "Jaedong Hwang, Seoung Wug Oh, Joon-Young Lee, Bohyung Han",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hwang_Exemplar-Based_Open-Set_Panoptic_Segmentation_Network_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; ECE and ASRI, Seoul National University",
        "project": "https://cv.snu.ac.kr/research/EOPSN",
        "github": "",
        "arxiv": "2105.08336"
    },
    {
        "title": "Explaining Classifiers Using Adversarial Perturbations on the Perceptual Ball",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Elliott_Explaining_Classifiers_Using_Adversarial_Perturbations_on_the_Perceptual_Ball_CVPR_2021_paper.html",
        "author": "Andrew Elliott, Stephen Law, Chris Russell",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Elliott_Explaining_Classifiers_Using_Adversarial_Perturbations_on_the_Perceptual_Ball_CVPR_2021_paper.pdf",
        "aff": "Uni. of Glasgow/Turing Institute; Amazon T\u00fcbingen; UCL/Turing Institute",
        "project": "",
        "github": "",
        "arxiv": "1912.09405"
    },
    {
        "title": "Explicit Knowledge Incorporation for Visual Reasoning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Explicit_Knowledge_Incorporation_for_Visual_Reasoning_CVPR_2021_paper.html",
        "author": "Yifeng Zhang, Ming Jiang, Qi Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Explicit_Knowledge_Incorporation_for_Visual_Reasoning_CVPR_2021_paper.pdf",
        "aff": "University of Minnesota",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Exploit Visual Dependency Relations for Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Exploit_Visual_Dependency_Relations_for_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Mingyuan Liu, Dan Schonfeld, Wei Tang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Exploit_Visual_Dependency_Relations_for_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "University of Illinois at Chicago",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Exploiting & Refining Depth Distributions With Triangulation Light Curtains",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Raaj_Exploiting__Refining_Depth_Distributions_With_Triangulation_Light_Curtains_CVPR_2021_paper.html",
        "author": "Yaadhav Raaj, Siddharth Ancha, Robert Tamburo, David Held, Srinivasa G. Narasimhan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Raaj_Exploiting__Refining_Depth_Distributions_With_Triangulation_Light_Curtains_CVPR_2021_paper.pdf",
        "aff": "The Robotics Institute, Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Exploiting Aliasing for Manga Restoration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Exploiting_Aliasing_for_Manga_Restoration_CVPR_2021_paper.html",
        "author": "Minshan Xie, Menghan Xia, Tien-Tsin Wong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xie_Exploiting_Aliasing_for_Manga_Restoration_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, SIAT, CAS; Department of Computer Science and Engineering, The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2105.06830"
    },
    {
        "title": "Exploiting Edge-Oriented Reasoning for 3D Point-Based Scene Graph Analysis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Exploiting_Edge-Oriented_Reasoning_for_3D_Point-Based_Scene_Graph_Analysis_CVPR_2021_paper.html",
        "author": "Chaoyi Zhang, Jianhui Yu, Yang Song, Weidong Cai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Exploiting_Edge-Oriented_Reasoning_for_3D_Point-Based_Scene_Graph_Analysis_CVPR_2021_paper.pdf",
        "aff": "University of New South Wales; University of Sydney",
        "project": "",
        "github": "https://SGGpoint.github.io",
        "arxiv": "2103.05558"
    },
    {
        "title": "Exploiting Semantic Embedding and Visual Feature for Facial Action Unit Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Exploiting_Semantic_Embedding_and_Visual_Feature_for_Facial_Action_Unit_CVPR_2021_paper.html",
        "author": "Huiyuan Yang, Lijun Yin, Yi Zhou, Jiuxiang Gu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Exploiting_Semantic_Embedding_and_Visual_Feature_for_Facial_Action_Unit_CVPR_2021_paper.pdf",
        "aff": "Adobe Research, USA; Department of Computer Science, Binghamton University, Binghamton, NY, USA; IBM, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Exploiting Spatial Dimensions of Latent in GAN for Real-Time Image Editing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Exploiting_Spatial_Dimensions_of_Latent_in_GAN_for_Real-Time_Image_CVPR_2021_paper.html",
        "author": "Hyunsu Kim, Yunjey Choi, Junho Kim, Sungjoo Yoo, Youngjung Uh",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Exploiting_Spatial_Dimensions_of_Latent_in_GAN_for_Real-Time_Image_CVPR_2021_paper.pdf",
        "aff": "Yonsei University; Seoul National University; NAVER AI Lab",
        "project": "",
        "github": "https://github.com/naver-ai/StyleMapGAN",
        "arxiv": "2104.14754"
    },
    {
        "title": "Explore Image Deblurring via Encoded Blur Kernel Space",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tran_Explore_Image_Deblurring_via_Encoded_Blur_Kernel_Space_CVPR_2021_paper.html",
        "author": "Phong Tran, Anh Tuan Tran, Quynh Phung, Minh Hoai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tran_Explore_Image_Deblurring_via_Encoded_Blur_Kernel_Space_CVPR_2021_paper.pdf",
        "aff": "Stony Brook University, Stony Brook, NY 11790, USA; VinAI Research, Hanoi, Vietnam; VinUniversity, Hanoi, Vietnam",
        "project": "",
        "github": "https://github.com/VinAIResearch/blur-kernel-space-exploring",
        "arxiv": ""
    },
    {
        "title": "Exploring Adversarial Fake Images on Face Manifold",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Exploring_Adversarial_Fake_Images_on_Face_Manifold_CVPR_2021_paper.html",
        "author": "Dongze Li, Wei Wang, Hongxing Fan, Jing Dong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Exploring_Adversarial_Fake_Images_on_Face_Manifold_CVPR_2021_paper.pdf",
        "aff": "School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; Center for Research on Intelligent Perception and Computing, CASIA",
        "project": "",
        "github": "",
        "arxiv": "2101.03272"
    },
    {
        "title": "Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Rizve_Exploring_Complementary_Strengths_of_Invariant_and_Equivariant_Representations_for_Few-Shot_CVPR_2021_paper.html",
        "author": "Mamshad Nayeem Rizve, Salman Khan, Fahad Shahbaz Khan, Mubarak Shah",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Rizve_Exploring_Complementary_Strengths_of_Invariant_and_Equivariant_Representations_for_Few-Shot_CVPR_2021_paper.pdf",
        "aff": "Center for Research in Computer Vision, UCF, USA; Mohamed bin Zayed University of AI, UAE",
        "project": "",
        "github": "",
        "arxiv": "2103.01315"
    },
    {
        "title": "Exploring Data-Efficient 3D Scene Understanding With Contrastive Scene Contexts",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Exploring_Data-Efficient_3D_Scene_Understanding_With_Contrastive_Scene_Contexts_CVPR_2021_paper.html",
        "author": "Ji Hou, Benjamin Graham, Matthias Niessner, Saining Xie",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Exploring_Data-Efficient_3D_Scene_Understanding_With_Contrastive_Scene_Contexts_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": "2012.09165"
    },
    {
        "title": "Exploring Heterogeneous Clues for Weakly-Supervised Audio-Visual Video Parsing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Exploring_Heterogeneous_Clues_for_Weakly-Supervised_Audio-Visual_Video_Parsing_CVPR_2021_paper.html",
        "author": "Yu Wu, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Exploring_Heterogeneous_Clues_for_Weakly-Supervised_Audio-Visual_Video_Parsing_CVPR_2021_paper.pdf",
        "aff": "ReLER, University of Technology Sydney; Baidu Research, ReLER, University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Exploring Simple Siamese Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.html",
        "author": "Xinlei Chen, Kaiming He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research (FAIR)",
        "project": "",
        "github": "https://github.com/facebookresearch/simsiam",
        "arxiv": "2011.10566"
    },
    {
        "title": "Exploring Sparsity in Image Super-Resolution for Efficient Inference",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Exploring_Sparsity_in_Image_Super-Resolution_for_Efficient_Inference_CVPR_2021_paper.html",
        "author": "Longguang Wang, Xiaoyu Dong, Yingqian Wang, Xinyi Ying, Zaiping Lin, Wei An, Yulan Guo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Exploring_Sparsity_in_Image_Super-Resolution_for_Efficient_Inference_CVPR_2021_paper.pdf",
        "aff": "The University of Tokyo; National University of Defense Technology",
        "project": "",
        "github": "https://github.com/LongguangWang/SMSR",
        "arxiv": "2006.09603"
    },
    {
        "title": "Exploring and Distilling Posterior and Prior Knowledge for Radiology Report Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Exploring_and_Distilling_Posterior_and_Prior_Knowledge_for_Radiology_Report_CVPR_2021_paper.html",
        "author": "Fenglin Liu, Xian Wu, Shen Ge, Wei Fan, Yuexian Zou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Exploring_and_Distilling_Posterior_and_Prior_Knowledge_for_Radiology_Report_CVPR_2021_paper.pdf",
        "aff": "Peng Cheng Laboratory, Shenzhen, China; ADSPLAB, School of ECE, Peking University; Tencent Medical AI Lab, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": "2106.06963"
    },
    {
        "title": "Exploring intermediate representation for monocular vehicle pose estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Exploring_intermediate_representation_for_monocular_vehicle_pose_estimation_CVPR_2021_paper.html",
        "author": "Shichao Li, Zengqiang Yan, Hongyang Li, Kwang-Ting Cheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Exploring_intermediate_representation_for_monocular_vehicle_pose_estimation_CVPR_2021_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology; SenseTime Research",
        "project": "",
        "github": "https://github.com/Nicholasli1995/EgoNet",
        "arxiv": "2011.08464"
    },
    {
        "title": "Exponential Moving Average Normalization for Self-Supervised and Semi-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Exponential_Moving_Average_Normalization_for_Self-Supervised_and_Semi-Supervised_Learning_CVPR_2021_paper.html",
        "author": "Zhaowei Cai, Avinash Ravichandran, Subhransu Maji, Charless Fowlkes, Zhuowen Tu, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cai_Exponential_Moving_Average_Normalization_for_Self-Supervised_and_Semi-Supervised_Learning_CVPR_2021_paper.pdf",
        "aff": "Amazon Web Services",
        "project": "",
        "github": "",
        "arxiv": "2101.08482"
    },
    {
        "title": "Extreme Low-Light Environment-Driven Image Denoising Over Permanently Shadowed Lunar Regions With a Physical Noise Model",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Moseley_Extreme_Low-Light_Environment-Driven_Image_Denoising_Over_Permanently_Shadowed_Lunar_Regions_CVPR_2021_paper.html",
        "author": "Ben Moseley, Valentin Bickel, Ignacio G. Lopez-Francos, Loveneesh Rana",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Moseley_Extreme_Low-Light_Environment-Driven_Image_Denoising_Over_Permanently_Shadowed_Lunar_Regions_CVPR_2021_paper.pdf",
        "aff": "NASA Ames Research Center, Moffett Field, CA, USA; ETH Zurich/ MPS Goettingen, Zurich/ Goettingen, CH/ GER; University of Luxembourg, Luxembourg, LUX; University of Oxford, Oxford, UK",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Extreme Rotation Estimation Using Dense Correlation Volumes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Extreme_Rotation_Estimation_Using_Dense_Correlation_Volumes_CVPR_2021_paper.html",
        "author": "Ruojin Cai, Bharath Hariharan, Noah Snavely, Hadar Averbuch-Elor",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cai_Extreme_Rotation_Estimation_Using_Dense_Correlation_Volumes_CVPR_2021_paper.pdf",
        "aff": "Cornell University, Cornell Tech; Cornell University",
        "project": "",
        "github": "https://ruojincai.github.io/ExtremeRotation/",
        "arxiv": "2104.13530"
    },
    {
        "title": "FAIEr: Fidelity and Adequacy Ensured Image Caption Evaluation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_FAIEr_Fidelity_and_Adequacy_Ensured_Image_Caption_Evaluation_CVPR_2021_paper.html",
        "author": "Sijin Wang, Ziwei Yao, Ruiping Wang, Zhongqin Wu, Xilin Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_FAIEr_Fidelity_and_Adequacy_Ensured_Image_Caption_Evaluation_CVPR_2021_paper.pdf",
        "aff": "Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, 100190, China; University of Chinese Academy of Sciences, Beijing, 100049, China; Tomorrow Advancing Life Education Group, Beijing, 100080, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FAPIS: A Few-Shot Anchor-Free Part-Based Instance Segmenter",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_FAPIS_A_Few-Shot_Anchor-Free_Part-Based_Instance_Segmenter_CVPR_2021_paper.html",
        "author": "Khoi Nguyen, Sinisa Todorovic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nguyen_FAPIS_A_Few-Shot_Anchor-Free_Part-Based_Instance_Segmenter_CVPR_2021_paper.pdf",
        "aff": "Oregon State University",
        "project": "",
        "github": "",
        "arxiv": "2104.00073"
    },
    {
        "title": "FBI-Denoiser: Fast Blind Image Denoiser for Poisson-Gaussian Noise",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Byun_FBI-Denoiser_Fast_Blind_Image_Denoiser_for_Poisson-Gaussian_Noise_CVPR_2021_paper.html",
        "author": "Jaeseok Byun, Sungmin Cha, Taesup Moon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Byun_FBI-Denoiser_Fast_Blind_Image_Denoiser_for_Poisson-Gaussian_Noise_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FBNetV3: Joint Architecture-Recipe Search Using Predictor Pretraining",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_FBNetV3_Joint_Architecture-Recipe_Search_Using_Predictor_Pretraining_CVPR_2021_paper.html",
        "author": "Xiaoliang Dai, Alvin Wan, Peizhao Zhang, Bichen Wu, Zijian He, Zhen Wei, Kan Chen, Yuandong Tian, Matthew Yu, Peter Vajda, Joseph E. Gonzalez",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_FBNetV3_Joint_Architecture-Recipe_Search_Using_Predictor_Pretraining_CVPR_2021_paper.pdf",
        "aff": "Facebook Inc.; UC Berkeley; UNC Chapel Hill",
        "project": "",
        "github": "",
        "arxiv": "2006.02049"
    },
    {
        "title": "FCPose: Fully Convolutional Multi-Person Pose Estimation With Dynamic Instance-Aware Convolutions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mao_FCPose_Fully_Convolutional_Multi-Person_Pose_Estimation_With_Dynamic_Instance-Aware_Convolutions_CVPR_2021_paper.html",
        "author": "Weian Mao, Zhi Tian, Xinlong Wang, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mao_FCPose_Fully_Convolutional_Multi-Person_Pose_Estimation_With_Dynamic_Instance-Aware_Convolutions_CVPR_2021_paper.pdf",
        "aff": "The University of Adelaide, Australia and Monash University, Australia; The University of Adelaide, Australia",
        "project": "",
        "github": "https://git.io/AdelaiDet",
        "arxiv": "2105.14185"
    },
    {
        "title": "FESTA: Flow Estimation via Spatial-Temporal Attention for Scene Point Clouds",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_FESTA_Flow_Estimation_via_Spatial-Temporal_Attention_for_Scene_Point_Clouds_CVPR_2021_paper.html",
        "author": "Haiyan Wang, Jiahao Pang, Muhammad A. Lodhi, Yingli Tian, Dong Tian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_FESTA_Flow_Estimation_via_Spatial-Temporal_Attention_for_Scene_Point_Clouds_CVPR_2021_paper.pdf",
        "aff": "The City College of New York; InterDigital; InterDigital, The City College of New York",
        "project": "",
        "github": "",
        "arxiv": "2104.00798"
    },
    {
        "title": "FFB6D: A Full Flow Bidirectional Fusion Network for 6D Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_FFB6D_A_Full_Flow_Bidirectional_Fusion_Network_for_6D_Pose_CVPR_2021_paper.html",
        "author": "Yisheng He, Haibin Huang, Haoqiang Fan, Qifeng Chen, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_FFB6D_A_Full_Flow_Bidirectional_Fusion_Network_for_6D_Pose_CVPR_2021_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; Kuaishou Technology; Megvii Technology",
        "project": "",
        "github": "https://github.com/ethnhe/FFB6D.git",
        "arxiv": "2103.02242"
    },
    {
        "title": "FP-NAS: Fast Probabilistic Neural Architecture Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_FP-NAS_Fast_Probabilistic_Neural_Architecture_Search_CVPR_2021_paper.html",
        "author": "Zhicheng Yan, Xiaoliang Dai, Peizhao Zhang, Yuandong Tian, Bichen Wu, Matt Feiszli",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_FP-NAS_Fast_Probabilistic_Neural_Architecture_Search_CVPR_2021_paper.pdf",
        "aff": "Facebook AI",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FS-Net: Fast Shape-Based Network for Category-Level 6D Object Pose Estimation With Decoupled Rotation Mechanism",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_FS-Net_Fast_Shape-Based_Network_for_Category-Level_6D_Object_Pose_Estimation_CVPR_2021_paper.html",
        "author": "Wei Chen, Xi Jia, Hyung Jin Chang, Jinming Duan, Linlin Shen, Ales Leonardis",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_FS-Net_Fast_Shape-Based_Network_for_Category-Level_6D_Object_Pose_Estimation_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, University of Birmingham; Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University",
        "project": "",
        "github": "https://github.com/DC1991/FS-Net",
        "arxiv": ""
    },
    {
        "title": "FSCE: Few-Shot Object Detection via Contrastive Proposal Encoding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_FSCE_Few-Shot_Object_Detection_via_Contrastive_Proposal_Encoding_CVPR_2021_paper.html",
        "author": "Bo Sun, Banghuai Li, Shengcai Cai, Ye Yuan, Chi Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_FSCE_Few-Shot_Object_Detection_via_Contrastive_Proposal_Encoding_CVPR_2021_paper.pdf",
        "aff": "MEGVII Technology; University of Southern California",
        "project": "",
        "github": "https://github.com/MegviiDetection/FSCE",
        "arxiv": "2103.05950"
    },
    {
        "title": "FSDR: Frequency Space Domain Randomization for Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_FSDR_Frequency_Space_Domain_Randomization_for_Domain_Generalization_CVPR_2021_paper.html",
        "author": "Jiaxing Huang, Dayan Guan, Aoran Xiao, Shijian Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_FSDR_Frequency_Space_Domain_Randomization_for_Domain_Generalization_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science Engineering, Nanyang Technological University",
        "project": "",
        "github": "",
        "arxiv": "2103.02370"
    },
    {
        "title": "FVC: A New Framework Towards Deep Video Compression in Feature Space",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_FVC_A_New_Framework_Towards_Deep_Video_Compression_in_Feature_CVPR_2021_paper.html",
        "author": "Zhihao Hu, Guo Lu, Dong Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_FVC_A_New_Framework_Towards_Deep_Video_Compression_in_Feature_CVPR_2021_paper.pdf",
        "aff": "University of Sydney; Beijing Institute of Technology; Beihang University",
        "project": "",
        "github": "",
        "arxiv": "2105.09600"
    },
    {
        "title": "Face Forensics in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Face_Forensics_in_the_Wild_CVPR_2021_paper.html",
        "author": "Tianfei Zhou, Wenguan Wang, Zhiyuan Liang, Jianbing Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Face_Forensics_in_the_Wild_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; Inception Institute of Arti\ufb01cial Intelligence; Beijing Institute of Technology",
        "project": "",
        "github": "https://github.com/tfzhou/FFIW",
        "arxiv": "2103.16076"
    },
    {
        "title": "Face Forgery Detection by 3D Decomposition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Face_Forgery_Detection_by_3D_Decomposition_CVPR_2021_paper.html",
        "author": "Xiangyu Zhu, Hao Wang, Hongyan Fei, Zhen Lei, Stan Z. Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Face_Forgery_Detection_by_3D_Decomposition_CVPR_2021_paper.pdf",
        "aff": "School of Engineering, Westlake University; School of Automation and Electrical Engineering, University of Science and Technology Beijing; CBSR & NLPR, Institute of Automation, Chinese Academy of Sciences; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; CBSR & NLPR, Institute of Automation, Chinese Academy of Sciences; CBSR & NLPR, Institute of Automation, Chinese Academy of Sciences; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; Centre for Arti\ufb01cial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": "2011.09737"
    },
    {
        "title": "FaceInpainter: High Fidelity Face Adaptation to Heterogeneous Domains",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_FaceInpainter_High_Fidelity_Face_Adaptation_to_Heterogeneous_Domains_CVPR_2021_paper.html",
        "author": "Jia Li, Zhaoyang Li, Jie Cao, Xingguang Song, Ran He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_FaceInpainter_High_Fidelity_Face_Adaptation_to_Heterogeneous_Domains_CVPR_2021_paper.pdf",
        "aff": "National Laboratory of Pattern Recognition, CASIA; Center for Excellence in Brain Science and Intelligence Technology, CAS; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, CASIA; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FaceSec: A Fine-Grained Robustness Evaluation Framework for Face Recognition Systems",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tong_FaceSec_A_Fine-Grained_Robustness_Evaluation_Framework_for_Face_Recognition_Systems_CVPR_2021_paper.html",
        "author": "Liang Tong, Zhengzhang Chen, Jingchao Ni, Wei Cheng, Dongjin Song, Haifeng Chen, Yevgeniy Vorobeychik",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tong_FaceSec_A_Fine-Grained_Robustness_Evaluation_Framework_for_Face_Recognition_Systems_CVPR_2021_paper.pdf",
        "aff": "Washington University in St. Louis; University of Connecticut; NEC Laboratories America",
        "project": "",
        "github": "",
        "arxiv": "2104.04107"
    },
    {
        "title": "Facial Action Unit Detection With Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jacob_Facial_Action_Unit_Detection_With_Transformers_CVPR_2021_paper.html",
        "author": "Geethu Miriam Jacob, Bjorn Stenger",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jacob_Facial_Action_Unit_Detection_With_Transformers_CVPR_2021_paper.pdf",
        "aff": "Rakuten Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Fair Attribute Classification Through Latent Space De-Biasing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ramaswamy_Fair_Attribute_Classification_Through_Latent_Space_De-Biasing_CVPR_2021_paper.html",
        "author": "Vikram V. Ramaswamy, Sunnie S. Y. Kim, Olga Russakovsky",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ramaswamy_Fair_Attribute_Classification_Through_Latent_Space_De-Biasing_CVPR_2021_paper.pdf",
        "aff": "Princeton University",
        "project": "",
        "github": "https://github.com/princetonvisualai/gan-debiasing",
        "arxiv": "2012.01469"
    },
    {
        "title": "Fair Feature Distillation for Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jung_Fair_Feature_Distillation_for_Visual_Recognition_CVPR_2021_paper.html",
        "author": "Sangwon Jung, Donggyu Lee, Taeeon Park, Taesup Moon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jung_Fair_Feature_Distillation_for_Visual_Recognition_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea",
        "project": "",
        "github": "",
        "arxiv": "2106.04411"
    },
    {
        "title": "Farewell to Mutual Information: Variational Distillation for Cross-Modal Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Farewell_to_Mutual_Information_Variational_Distillation_for_Cross-Modal_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Xudong Tian, Zhizhong Zhang, Shaohui Lin, Yanyun Qu, Yuan Xie, Lizhuang Ma",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_Farewell_to_Mutual_Information_Variational_Distillation_for_Cross-Modal_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "East China Normal University, Shanghai Jiao Tong University; Xiamen University; East China Normal University",
        "project": "",
        "github": "",
        "arxiv": "2104.02862"
    },
    {
        "title": "Fashion IQ: A New Dataset Towards Retrieving Images by Natural Language Feedback",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Fashion_IQ_A_New_Dataset_Towards_Retrieving_Images_by_Natural_CVPR_2021_paper.html",
        "author": "Hui Wu, Yupeng Gao, Xiaoxiao Guo, Ziad Al-Halah, Steven Rennie, Kristen Grauman, Rogerio Feris",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Fashion_IQ_A_New_Dataset_Towards_Retrieving_Images_by_Natural_CVPR_2021_paper.pdf",
        "aff": "IBM Research; MIT-IBM Watson AI Lab, IBM Research; Pryon; UT Austin",
        "project": "",
        "github": "https://github.com/XiaoxiaoGuo/fashion-iq",
        "arxiv": "1905.12794"
    },
    {
        "title": "Fast Bayesian Uncertainty Estimation and Reduction of Batch Normalized Single Image Super-Resolution Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kar_Fast_Bayesian_Uncertainty_Estimation_and_Reduction_of_Batch_Normalized_Single_CVPR_2021_paper.html",
        "author": "Aupendu Kar, Prabir Kumar Biswas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kar_Fast_Bayesian_Uncertainty_Estimation_and_Reduction_of_Batch_Normalized_Single_CVPR_2021_paper.pdf",
        "aff": "Indian Institute of Technology Kharagpur, WB, India",
        "project": "aupendu.github.io/sr-uncertainty",
        "github": "",
        "arxiv": "1903.09410"
    },
    {
        "title": "Fast End-to-End Learning on Protein Surfaces",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sverrisson_Fast_End-to-End_Learning_on_Protein_Surfaces_CVPR_2021_paper.html",
        "author": "Freyr Sverrisson, Jean Feydy, Bruno E. Correia, Michael M. Bronstein",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sverrisson_Fast_End-to-End_Learning_on_Protein_Surfaces_CVPR_2021_paper.pdf",
        "aff": "\u00b4Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne and Swiss Institute of Bioinformatics; Imperial College London / Twitter; Imperial College London",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Fast Sinkhorn Filters: Using Matrix Scaling for Non-Rigid Shape Correspondence With Functional Maps",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pai_Fast_Sinkhorn_Filters_Using_Matrix_Scaling_for_Non-Rigid_Shape_Correspondence_CVPR_2021_paper.html",
        "author": "Gautam Pai, Jing Ren, Simone Melzi, Peter Wonka, Maks Ovsjanikov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pai_Fast_Sinkhorn_Filters_Using_Matrix_Scaling_for_Non-Rigid_Shape_Correspondence_CVPR_2021_paper.pdf",
        "aff": "Sapienza University of Rome; LIX, Ecole Polytechnique, IP Paris; KAUST",
        "project": "",
        "github": "https://github.com/paigautam/CVPR21_FastSinkhornFilters",
        "arxiv": ""
    },
    {
        "title": "Fast and Accurate Model Scaling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dollar_Fast_and_Accurate_Model_Scaling_CVPR_2021_paper.html",
        "author": "Piotr Dollar, Mannat Singh, Ross Girshick",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dollar_Fast_and_Accurate_Model_Scaling_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research (FAIR)",
        "project": "",
        "github": "",
        "arxiv": "2103.06877"
    },
    {
        "title": "Faster Meta Update Strategy for Noise-Robust Deep Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Faster_Meta_Update_Strategy_for_Noise-Robust_Deep_Learning_CVPR_2021_paper.html",
        "author": "Youjiang Xu, Linchao Zhu, Lu Jiang, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Faster_Meta_Update_Strategy_for_Noise-Robust_Deep_Learning_CVPR_2021_paper.pdf",
        "aff": "Baidu Research; Google Research; ReLER, University of Technology Sydney",
        "project": "",
        "github": "https://github.com/youjiangxu/FaMUS",
        "arxiv": "2104.15092"
    },
    {
        "title": "Feature Decomposition and Reconstruction Learning for Effective Facial Expression Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ruan_Feature_Decomposition_and_Reconstruction_Learning_for_Effective_Facial_Expression_Recognition_CVPR_2021_paper.html",
        "author": "Delian Ruan, Yan Yan, Shenqi Lai, Zhenhua Chai, Chunhua Shen, Hanzi Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ruan_Feature_Decomposition_and_Reconstruction_Learning_for_Effective_Facial_Expression_Recognition_CVPR_2021_paper.pdf",
        "aff": "University of Adelaide; Xiamen University, China; Vision Intelligence Center, Meituan",
        "project": "",
        "github": "",
        "arxiv": "2104.05160"
    },
    {
        "title": "Feature-Level Collaboration: Joint Unsupervised Learning of Optical Flow, Stereo Depth and Camera Motion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chi_Feature-Level_Collaboration_Joint_Unsupervised_Learning_of_Optical_Flow_Stereo_Depth_CVPR_2021_paper.html",
        "author": "Cheng Chi, Qingjie Wang, Tianyu Hao, Peng Guo, Xin Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chi_Feature-Level_Collaboration_Joint_Unsupervised_Learning_of_Optical_Flow_Stereo_Depth_CVPR_2021_paper.pdf",
        "aff": "Huazhong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "FedDG: Federated Domain Generalization on Medical Image Segmentation via Episodic Learning in Continuous Frequency Space",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_FedDG_Federated_Domain_Generalization_on_Medical_Image_Segmentation_via_Episodic_CVPR_2021_paper.html",
        "author": "Quande Liu, Cheng Chen, Jing Qin, Qi Dou, Pheng-Ann Heng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_FedDG_Federated_Domain_Generalization_on_Medical_Image_Segmentation_via_Episodic_CVPR_2021_paper.pdf",
        "aff": "FedDG: Federated Domain Generalization on Medical Image Segmentation\nvia Episodic Learning in Continuous Frequency Space\nQuande Liu1, Cheng Chen1, Jing Qin2, Qi Dou1,*, Pheng-Ann Heng1\n1Department of Computer Science and Engineering, The Chinese University of Hong Kong\n2School of Nursing, The Hong Kong Polytechnic University\n{qdliu, cchen, qdou, pheng }@cse.cuhk.edu.hk, harry.qin@polyu.edu.hk\nAbstract\nFederated learning allows distributed medical institu-\ntions to collaboratively learn a shared prediction model\nwith privacy protection. While at clinical deployment, the\nmodels trained in federated learning can still suffer from\nperformance drop when applied to completely unseen hos-\npitals outside the federation. In this paper, we point out and\nsolve a novel problem setting of federated domain gener-\nalization (FedDG), which aims to learn a federated model\nfrom multiple distributed source domains such that it can\ndirectly generalize to unseen target domains. We present\na novel approach, named as Episodic Learning in Contin-\nuous Frequency Space (ELCFS), for this problem by en-\nabling each client to exploit multi-source data distributions\nunder the challenging constraint of data decentralization.\nOur approach transmits the distribution information across\nclients in a privacy-protecting way through an effective con-\ntinuous frequency space interpolation mechanism. With the\ntransferred multi-source distributions, we further carefully\ndesign a boundary-oriented episodic learning paradigm to\nexpose the local learning to domain distribution shifts and\nparticularly meet the challenges of model generalization in\nmedical image segmentation scenario. The effectiveness\nof our method is demonstrated with superior performance\nover state-of-the-arts and in-depth ablation experiments on\ntwo medical image segmentation tasks. The code is avail-\nable at https://github.com/liuquande/FedDG-ELCFS .\n1. Introduction\nData collaboration across multiple medical institutions is\nincreasingly desired to build accurate and robust data-driven\ndeep networks for medical image segmentation [ 7,18,50].\nFederated learning (FL) [ 20] has recently opened the door\nfor a promising privacy-preserving solution, which allows\ntraining a model on distributed datasets while keeping data\n*Corresponding author(a) (b) \n...: Source domain\n: Unseen domain\n: Data parivacy\n: Central server\n: Model\n... \nAmplitude spectrum \n(frequency space)\nLocal client k??\nLocal episodic learning\nLocal data \nTransformed data with\nmulti-source distributions\nFigure 1. (a) The novel problem setting of federated domain gen-\neralization (FedDG), which aims to learn a federated model from\nmultiple decentralized source domains such that it can directly\ngeneralize to completely unseen target domains. (b) Our main\nidea to tackle FedDG by transferring distribution information in\nfrequency space and episodic learning at each local client.\nlocally. The paradigm works in a way that each local client\n(e.g., hospital) learns from their own data, and only aggre-\ngates the model parameters at a certain frequency at the cen-\ntral server to generate a global model. All the data samples\nare kept within each local client during federated training.\nAlthough FL has witnessed some pilot progress on med-\nical image segmentation tasks [ 4,44,49], all existing works\nonly focus on improving model performance on the internal\nclients, while neglecting model generalizability onto unseen\ndomains outside the federation. This is a crucial problem\nimpeding wide applicability of FL models in real practice.\nThe testing medical images encountered in unseen hospi-\ntals can differ signi\ufb01cantly from the source clients in terms\nof data distributions, due to the variations in imaging scan-\nners and protocols. How to generalize the federated model\nunder such distribution shifts is technically challenging yet\nunexplored so far. In this work, we identify the novel prob-\nlem setting of Federated Domain Generalization (FedDG),\nwhich aims to learn a federated model from multiple decen-\ntralized source domains such that it can directly generalize\nto completely unseen domains, as illustrated in Fig. 1(a).\nUnseen domain generalization (DG) is an active research\ntopic with different methods being proposed [ 3,8,11,24,\n25,26,29,37,43], but the federated paradigm with dis-\n1013\n",
        "project": "",
        "github": "",
        "arxiv": "2103.06030"
    },
    {
        "title": "Few-Shot 3D Point Cloud Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Few-Shot_3D_Point_Cloud_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Na Zhao, Tat-Seng Chua, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Few-Shot_3D_Point_Cloud_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, National University of Singapore",
        "project": "",
        "github": "https://github.com/Na-Z/attMPTI",
        "arxiv": "2006.12052"
    },
    {
        "title": "Few-Shot Classification With Feature Map Reconstruction Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wertheimer_Few-Shot_Classification_With_Feature_Map_Reconstruction_Networks_CVPR_2021_paper.html",
        "author": "Davis Wertheimer, Luming Tang, Bharath Hariharan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wertheimer_Few-Shot_Classification_With_Feature_Map_Reconstruction_Networks_CVPR_2021_paper.pdf",
        "aff": "Cornell University",
        "project": "",
        "github": "https://github.com/Tsingularity/FRN",
        "arxiv": "2012.01506"
    },
    {
        "title": "Few-Shot Human Motion Transfer by Personalized Geometry and Texture Modeling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Few-Shot_Human_Motion_Transfer_by_Personalized_Geometry_and_Texture_Modeling_CVPR_2021_paper.html",
        "author": "Zhichao Huang, Xintong Han, Jia Xu, Tong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Few-Shot_Human_Motion_Transfer_by_Personalized_Geometry_and_Texture_Modeling_CVPR_2021_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology; Huya Inc",
        "project": "",
        "github": "https://github.com/HuangZhiChao95/FewShotMotionTransfer",
        "arxiv": "2103.14338"
    },
    {
        "title": "Few-Shot Image Generation via Cross-Domain Correspondence",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ojha_Few-Shot_Image_Generation_via_Cross-Domain_Correspondence_CVPR_2021_paper.html",
        "author": "Utkarsh Ojha, Yijun Li, Jingwan Lu, Alexei A. Efros, Yong Jae Lee, Eli Shechtman, Richard Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ojha_Few-Shot_Image_Generation_via_Cross-Domain_Correspondence_CVPR_2021_paper.pdf",
        "aff": "UC Davis; Adobe Research; Adobe Research; UC Berkeley; Adobe Research; UC Davis",
        "project": "",
        "github": "",
        "arxiv": "2104.06820"
    },
    {
        "title": "Few-Shot Incremental Learning With Continually Evolved Classifiers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Few-Shot_Incremental_Learning_With_Continually_Evolved_Classifiers_CVPR_2021_paper.html",
        "author": "Chi Zhang, Nan Song, Guosheng Lin, Yun Zheng, Pan Pan, Yinghui Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Few-Shot_Incremental_Learning_With_Continually_Evolved_Classifiers_CVPR_2021_paper.pdf",
        "aff": "Alibaba DAMO Academy; Nanyang Technological University, Singapore",
        "project": "",
        "github": "",
        "arxiv": "2104.03047"
    },
    {
        "title": "Few-Shot Object Detection via Classification Refinement and Distractor Retreatment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Few-Shot_Object_Detection_via_Classification_Refinement_and_Distractor_Retreatment_CVPR_2021_paper.html",
        "author": "Yiting Li, Haiyue Zhu, Yu Cheng, Wenxin Wang, Chek Sing Teo, Cheng Xiang, Prahlad Vadakkepat, Tong Heng Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Few-Shot_Object_Detection_via_Classification_Refinement_and_Distractor_Retreatment_CVPR_2021_paper.pdf",
        "aff": "SIMTech, Agency for Science, Technology and Research; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Few-Shot Open-Set Recognition by Transformation Consistency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jeong_Few-Shot_Open-Set_Recognition_by_Transformation_Consistency_CVPR_2021_paper.html",
        "author": "Minki Jeong, Seokeon Choi, Changick Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jeong_Few-Shot_Open-Set_Recognition_by_Transformation_Consistency_CVPR_2021_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "project": "",
        "github": "",
        "arxiv": "2103.01537"
    },
    {
        "title": "Few-Shot Segmentation Without Meta-Learning: A Good Transductive Inference Is All You Need?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Boudiaf_Few-Shot_Segmentation_Without_Meta-Learning_A_Good_Transductive_Inference_Is_All_CVPR_2021_paper.html",
        "author": "Malik Boudiaf, Hoel Kervadec, Ziko Imtiaz Masud, Pablo Piantanida, Ismail Ben Ayed, Jose Dolz",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Boudiaf_Few-Shot_Segmentation_Without_Meta-Learning_A_Good_Transductive_Inference_Is_All_CVPR_2021_paper.pdf",
        "aff": "CentraleSup \u00b4elec-CNRS, Universit \u00b4e Paris-Saclay; \u00b4ETS Montreal",
        "project": "",
        "github": "https://github.com/mboudiaf/RePRI-for-Few-Shot-Segmentation",
        "arxiv": ""
    },
    {
        "title": "Few-Shot Transformation of Common Actions Into Time and Space",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Few-Shot_Transformation_of_Common_Actions_Into_Time_and_Space_CVPR_2021_paper.html",
        "author": "Pengwan Yang, Pascal Mettes, Cees G. M. Snoek",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Few-Shot_Transformation_of_Common_Actions_Into_Time_and_Space_CVPR_2021_paper.pdf",
        "aff": "University of Amsterdam",
        "project": "",
        "github": "",
        "arxiv": "2104.02439"
    },
    {
        "title": "Fine-Grained Angular Contrastive Learning With Coarse Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bukchin_Fine-Grained_Angular_Contrastive_Learning_With_Coarse_Labels_CVPR_2021_paper.html",
        "author": "Guy Bukchin, Eli Schwartz, Kate Saenko, Ori Shahar, Rogerio Feris, Raja Giryes, Leonid Karlinsky",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bukchin_Fine-Grained_Angular_Contrastive_Learning_With_Coarse_Labels_CVPR_2021_paper.pdf",
        "aff": "IBM Research AI1, Tel-Aviv University2; Penta-AI3; Tel-Aviv University2; Boston University4, IBM Research AI1; IBM Research AI1; Penta-AI3, Tel-Aviv University2",
        "project": "",
        "github": "",
        "arxiv": "2012.03515"
    },
    {
        "title": "Fine-Grained Shape-Appearance Mutual Learning for Cloth-Changing Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Fine-Grained_Shape-Appearance_Mutual_Learning_for_Cloth-Changing_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Peixian Hong, Tao Wu, Ancong Wu, Xintong Han, Wei-Shi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Fine-Grained_Shape-Appearance_Mutual_Learning_for_Cloth-Changing_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; School of Computer Science and Engineering, Sun Yat-sen University, China; Peng Cheng Laboratory, Shenzhen, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China; Huya Inc, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Fingerspelling Detection in American Sign Language",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Fingerspelling_Detection_in_American_Sign_Language_CVPR_2021_paper.html",
        "author": "Bowen Shi, Diane Brentari, Greg Shakhnarovich, Karen Livescu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_Fingerspelling_Detection_in_American_Sign_Language_CVPR_2021_paper.pdf",
        "aff": "Toyota Technological Institute at Chicago, USA; University of Chicago, USA",
        "project": "",
        "github": "",
        "arxiv": "2104.01291"
    },
    {
        "title": "FixBi: Bridging Domain Spaces for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Na_FixBi_Bridging_Domain_Spaces_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Jaemin Na, Heechul Jung, Hyung Jin Chang, Wonjun Hwang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Na_FixBi_Bridging_Domain_Spaces_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "University of Birmingham, UK; Ajou University, Korea; Kyungpook National University, Korea",
        "project": "",
        "github": "https://github.com/NaJaeMin92/FixBi",
        "arxiv": "2011.09230"
    },
    {
        "title": "Flow Guided Transformable Bottleneck Networks for Motion Retargeting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ren_Flow_Guided_Transformable_Bottleneck_Networks_for_Motion_Retargeting_CVPR_2021_paper.html",
        "author": "Jian Ren, Menglei Chai, Oliver J. Woodford, Kyle Olszewski, Sergey Tulyakov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ren_Flow_Guided_Transformable_Bottleneck_Networks_for_Motion_Retargeting_CVPR_2021_paper.pdf",
        "aff": "Snap Inc.",
        "project": "",
        "github": "",
        "arxiv": "2106.07771"
    },
    {
        "title": "Flow-Based Kernel Prior With Application to Blind Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liang_Flow-Based_Kernel_Prior_With_Application_to_Blind_Super-Resolution_CVPR_2021_paper.html",
        "author": "Jingyun Liang, Kai Zhang, Shuhang Gu, Luc Van Gool, Radu Timofte",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liang_Flow-Based_Kernel_Prior_With_Application_to_Blind_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "The University of Sydney, Australia; KU Leuven, Belgium; Computer Vision Lab, ETH Zurich, Switzerland",
        "project": "",
        "github": "https://github.com/JingyunLiang/FKP",
        "arxiv": "2103.15977"
    },
    {
        "title": "Flow-Guided One-Shot Talking Face Generation With a High-Resolution Audio-Visual Dataset",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Flow-Guided_One-Shot_Talking_Face_Generation_With_a_High-Resolution_Audio-Visual_Dataset_CVPR_2021_paper.html",
        "author": "Zhimeng Zhang, Lincheng Li, Yu Ding, Changjie Fan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Flow-Guided_One-Shot_Talking_Face_Generation_With_a_High-Resolution_Audio-Visual_Dataset_CVPR_2021_paper.pdf",
        "aff": "Virtual Human Group, Netease Fuxi AI Lab",
        "project": "",
        "github": "https://github.com/MRzzm/HDTF",
        "arxiv": ""
    },
    {
        "title": "FlowStep3D: Model Unrolling for Self-Supervised Scene Flow Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kittenplon_FlowStep3D_Model_Unrolling_for_Self-Supervised_Scene_Flow_Estimation_CVPR_2021_paper.html",
        "author": "Yair Kittenplon, Yonina C. Eldar, Dan Raviv",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kittenplon_FlowStep3D_Model_Unrolling_for_Self-Supervised_Scene_Flow_Estimation_CVPR_2021_paper.pdf",
        "aff": "Tel Aviv University; Weizmann Institute of Science",
        "project": "",
        "github": "https://github.com/yairkit/flowstep3d",
        "arxiv": "2011.10147"
    },
    {
        "title": "Focus on Local: Detecting Lane Marker From Bottom Up via Key Point",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qu_Focus_on_Local_Detecting_Lane_Marker_From_Bottom_Up_via_CVPR_2021_paper.html",
        "author": "Zhan Qu, Huan Jin, Yang Zhou, Zhen Yang, Wei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qu_Focus_on_Local_Detecting_Lane_Marker_From_Bottom_Up_via_CVPR_2021_paper.pdf",
        "aff": "Noah\u2019s Ark Lab, Huawei Technologies",
        "project": "",
        "github": "",
        "arxiv": "2105.13680"
    },
    {
        "title": "Forecasting Irreversible Disease via Progression Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Forecasting_Irreversible_Disease_via_Progression_Learning_CVPR_2021_paper.html",
        "author": "Botong Wu, Sijie Ren, Jing Li, Xinwei Sun, Shi-Ming Li, Yizhou Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Forecasting_Irreversible_Disease_via_Progression_Learning_CVPR_2021_paper.pdf",
        "aff": "Beijing Tongren Hospital, Capital Medical University; Beijing Stars Universal Technology Co., Ltd; Dept. of Computer Science, Peking University; Center on Frontiers of Computing Studies, Peking University; Dept. of Computer Science, Peking University; Deepwise AI Lab; Microsoft Research, Asia; Dept. of Computer Science, Peking University; Adv. Inst. of Info. Tech, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2012.11107"
    },
    {
        "title": "ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_ForgeryNet_A_Versatile_Benchmark_for_Comprehensive_Forgery_Analysis_CVPR_2021_paper.html",
        "author": "Yinan He, Bei Gan, Siyu Chen, Yichun Zhou, Guojun Yin, Luchuan Song, Lu Sheng, Jing Shao, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_ForgeryNet_A_Versatile_Benchmark_for_Comprehensive_Forgery_Analysis_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research, Beijing University of Posts and Telecommunications; S-Lab, Nanyang Technological University; University of Science and Technology of China; SenseTime Research, Shanghai AI Laboratory; College of Software, Beihang University; SenseTime Research, College of Software, Beihang University",
        "project": "https://yinanhe.github.io/projects/forgerynet.html",
        "github": "",
        "arxiv": "2103.05630"
    },
    {
        "title": "Fostering Generalization in Single-View 3D Reconstruction by Learning a Hierarchy of Local and Global Shape Priors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bechtold_Fostering_Generalization_in_Single-View_3D_Reconstruction_by_Learning_a_Hierarchy_CVPR_2021_paper.html",
        "author": "Jan Bechtold, Maxim Tatarchenko, Volker Fischer, Thomas Brox",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bechtold_Fostering_Generalization_in_Single-View_3D_Reconstruction_by_Learning_a_Hierarchy_CVPR_2021_paper.pdf",
        "aff": "University of Freiburg; Bosch Center for Arti\ufb01cial Intelligence",
        "project": "",
        "github": "",
        "arxiv": "2104.00476"
    },
    {
        "title": "Found a Reason for me? Weakly-supervised Grounded Visual Question Answering using Capsules",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Urooj_Found_a_Reason_for_me_Weakly-supervised_Grounded_Visual_Question_Answering_CVPR_2021_paper.html",
        "author": "Aisha Urooj, Hilde Kuehne, Kevin Duarte, Chuang Gan, Niels Lobo, Mubarak Shah",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Urooj_Found_a_Reason_for_me_Weakly-supervised_Grounded_Visual_Question_Answering_CVPR_2021_paper.pdf",
        "aff": "MIT-IBM Watson AI Lab; CRCV, University of Central Florida",
        "project": "",
        "github": "https://github.com/aurooj/WeakGroundedVQA_Capsules.git",
        "arxiv": "2105.04836"
    },
    {
        "title": "Fourier Contour Embedding for Arbitrary-Shaped Text Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Fourier_Contour_Embedding_for_Arbitrary-Shaped_Text_Detection_CVPR_2021_paper.html",
        "author": "Yiqin Zhu, Jianyong Chen, Lingyu Liang, Zhanghui Kuang, Lianwen Jin, Wayne Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Fourier_Contour_Embedding_for_Arbitrary-Shaped_Text_Detection_CVPR_2021_paper.pdf",
        "aff": "South China University of Technology; SenseTime Research, Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai AI Laboratory; SenseTime Research; South China University of Technology, Pazhou Lab",
        "project": "",
        "github": "",
        "arxiv": "2104.10442"
    },
    {
        "title": "FrameExit: Conditional Early Exiting for Efficient Video Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ghodrati_FrameExit_Conditional_Early_Exiting_for_Efficient_Video_Recognition_CVPR_2021_paper.html",
        "author": "Amir Ghodrati, Babak Ehteshami Bejnordi, Amirhossein Habibian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ghodrati_FrameExit_Conditional_Early_Exiting_for_Efficient_Video_Recognition_CVPR_2021_paper.pdf",
        "aff": "Qualcomm AI Research\u2020",
        "project": "",
        "github": "",
        "arxiv": "2104.13400"
    },
    {
        "title": "Frequency-Aware Discriminative Feature Learning Supervised by Single-Center Loss for Face Forgery Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Frequency-Aware_Discriminative_Feature_Learning_Supervised_by_Single-Center_Loss_for_Face_CVPR_2021_paper.html",
        "author": "Jiaming Li, Hongtao Xie, Jiahong Li, Zhongyuan Wang, Yongdong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Frequency-Aware_Discriminative_Feature_Learning_Supervised_by_Single-Center_Loss_for_Face_CVPR_2021_paper.pdf",
        "aff": "Kuaishou Technology; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2103.09096"
    },
    {
        "title": "From Points to Multi-Object 3D Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Engelmann_From_Points_to_Multi-Object_3D_Reconstruction_CVPR_2021_paper.html",
        "author": "Francis Engelmann, Konstantinos Rematas, Bastian Leibe, Vittorio Ferrari",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Engelmann_From_Points_to_Multi-Object_3D_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "Google Research; RWTH Aachen University",
        "project": "",
        "github": "",
        "arxiv": "2012.11575"
    },
    {
        "title": "From Rain Generation to Rain Removal",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_From_Rain_Generation_to_Rain_Removal_CVPR_2021_paper.html",
        "author": "Hong Wang, Zongsheng Yue, Qi Xie, Qian Zhao, Yefeng Zheng, Deyu Meng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_From_Rain_Generation_to_Rain_Removal_CVPR_2021_paper.pdf",
        "aff": "Tencent Jarvis Lab, Shenzhen, China; Macau University of Science and Technology, Macau, China; Xi\u2019an Jiaotong University, Xi\u2019an, China",
        "project": "",
        "github": "https://github.com/hongwang01/VRGNet",
        "arxiv": "2008.03580"
    },
    {
        "title": "From Semantic Categories to Fixations: A Novel Weakly-Supervised Visual-Auditory Saliency Detection Approach",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_From_Semantic_Categories_to_Fixations_A_Novel_Weakly-Supervised_Visual-Auditory_Saliency_CVPR_2021_paper.html",
        "author": "Guotao Wang, Chenglizhao Chen, Deng-Ping Fan, Aimin Hao, Hong Qin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_From_Semantic_Categories_to_Fixations_A_Novel_Weakly-Supervised_Visual-Auditory_Saliency_CVPR_2021_paper.pdf",
        "aff": "College of Computer Science and Technology, Qingdao University; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; Research Unit of Virtual Human and Virtual Surgery, Chinese Academy of Medical Sciences; Pengcheng Laboratory; Inception Institute of Arti\ufb01cial Intelligence; Stony Brook University; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University",
        "project": "",
        "github": "https://github.com/guotaowang/STANet",
        "arxiv": ""
    },
    {
        "title": "From Shadow Generation To Shadow Removal",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_From_Shadow_Generation_To_Shadow_Removal_CVPR_2021_paper.html",
        "author": "Zhihao Liu, Hui Yin, Xinyi Wu, Zhenyao Wu, Yang Mi, Song Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_From_Shadow_Generation_To_Shadow_Removal_CVPR_2021_paper.pdf",
        "aff": "China Agriculture University, China; University of South Carolina, USA; Beijing Jiaotong University, China",
        "project": "",
        "github": "https://github.com/hhqweasd/G2R-ShadowNet",
        "arxiv": "2103.12997"
    },
    {
        "title": "From Synthetic to Real: Unsupervised Domain Adaptation for Animal Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_From_Synthetic_to_Real_Unsupervised_Domain_Adaptation_for_Animal_Pose_CVPR_2021_paper.html",
        "author": "Chen Li, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_From_Synthetic_to_Real_Unsupervised_Domain_Adaptation_for_Animal_Pose_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, National University of Singapore",
        "project": "",
        "github": "https://github.com/chaneyddtt/UDA-Animal-Pose",
        "arxiv": "2103.14843"
    },
    {
        "title": "Fully Convolutional Networks for Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Fully_Convolutional_Networks_for_Panoptic_Segmentation_CVPR_2021_paper.html",
        "author": "Yanwei Li, Hengshuang Zhao, Xiaojuan Qi, Liwei Wang, Zeming Li, Jian Sun, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Fully_Convolutional_Networks_for_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "MEGVII Technology; The University of Hong Kong; The Chinese University of Hong Kong; SmartMore; University of Oxford",
        "project": "",
        "github": "https://github.com/Jia-Research-Lab/PanopticFCN",
        "arxiv": "2012.00720"
    },
    {
        "title": "Fully Convolutional Scene Graph Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Fully_Convolutional_Scene_Graph_Generation_CVPR_2021_paper.html",
        "author": "Hengyue Liu, Ning Yan, Masood Mortazavi, Bir Bhanu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Fully_Convolutional_Scene_Graph_Generation_CVPR_2021_paper.pdf",
        "aff": "University of California, Riverside; Futurewei Technologies Inc.",
        "project": "",
        "github": "",
        "arxiv": "2103.16083"
    },
    {
        "title": "Fully Understanding Generic Objects: Modeling, Segmentation, and Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Fully_Understanding_Generic_Objects_Modeling_Segmentation_and_Reconstruction_CVPR_2021_paper.html",
        "author": "Feng Liu, Luan Tran, Xiaoming Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Fully_Understanding_Generic_Objects_Modeling_Segmentation_and_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "Michigan State University, East Lansing MI 48824",
        "project": "http://cvlab.cse.msu.edu/project-fully3dobject.html",
        "github": "",
        "arxiv": "2104.00858"
    },
    {
        "title": "Function4D: Real-Time Human Volumetric Capture From Very Sparse Consumer RGBD Sensors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Function4D_Real-Time_Human_Volumetric_Capture_From_Very_Sparse_Consumer_RGBD_CVPR_2021_paper.html",
        "author": "Tao Yu, Zerong Zheng, Kaiwen Guo, Pengpeng Liu, Qionghai Dai, Yebin Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_Function4D_Real-Time_Human_Volumetric_Capture_From_Very_Sparse_Consumer_RGBD_CVPR_2021_paper.pdf",
        "aff": "Google, Switzerland; Department of Automation, Tsinghua University, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": "2105.01859"
    },
    {
        "title": "Fusing the Old with the New: Learning Relative Camera Pose with Geometry-Guided Uncertainty",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhuang_Fusing_the_Old_with_the_New_Learning_Relative_Camera_Pose_CVPR_2021_paper.html",
        "author": "Bingbing Zhuang, Manmohan Chandraker",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhuang_Fusing_the_Old_with_the_New_Learning_Relative_Camera_Pose_CVPR_2021_paper.pdf",
        "aff": "University of California, San Diego; NEC Labs America",
        "project": "",
        "github": "",
        "arxiv": "2104.08278"
    },
    {
        "title": "GAIA: A Transfer Learning System of Object Detection That Fits Your Needs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bu_GAIA_A_Transfer_Learning_System_of_Object_Detection_That_Fits_CVPR_2021_paper.html",
        "author": "Xingyuan Bu, Junran Peng, Junjie Yan, Tieniu Tan, Zhaoxiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bu_GAIA_A_Transfer_Learning_System_of_Object_Detection_That_Fits_CVPR_2021_paper.pdf",
        "aff": "SenseTime Group Limited; Beijing Institute of Technology; University of Chinese Academy of Sciences",
        "project": "",
        "github": "https://github.com/GAIA-vision",
        "arxiv": "2106.11346"
    },
    {
        "title": "GAN Prior Embedded Network for Blind Face Restoration in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_GAN_Prior_Embedded_Network_for_Blind_Face_Restoration_in_the_CVPR_2021_paper.html",
        "author": "Tao Yang, Peiran Ren, Xuansong Xie, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_GAN_Prior_Embedded_Network_for_Blind_Face_Restoration_in_the_CVPR_2021_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group and Department of Computing, The Hong Kong Polytechnic University; DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/yangxy/GPEN",
        "arxiv": "2105.06070"
    },
    {
        "title": "GANmut: Learning Interpretable Conditional Space for Gamut of Emotions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/dApolito_GANmut_Learning_Interpretable_Conditional_Space_for_Gamut_of_Emotions_CVPR_2021_paper.html",
        "author": "Stefano d'Apolito, Danda Pani Paudel, Zhiwu Huang, Andres Romero, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/dApolito_GANmut_Learning_Interpretable_Conditional_Space_for_Gamut_of_Emotions_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Z\u00fcrich, Switzerland; Computer Vision Lab, ETH Z\u00fcrich, Switzerland; PSI, KU Leuven, Belgium",
        "project": "",
        "github": "https://github.com/stefanodapolito/GANmut",
        "arxiv": ""
    },
    {
        "title": "GATSBI: Generative Agent-Centric Spatio-Temporal Object Interaction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Min_GATSBI_Generative_Agent-Centric_Spatio-Temporal_Object_Interaction_CVPR_2021_paper.html",
        "author": "Cheol-Hui Min, Jinseok Bae, Junho Lee, Young Min Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Min_GATSBI_Generative_Agent-Centric_Spatio-Temporal_Object_Interaction_CVPR_2021_paper.pdf",
        "aff": "Dept. of Electrical and Computer Engineering, Seoul National University, Korea",
        "project": "",
        "github": "",
        "arxiv": "2104.04275"
    },
    {
        "title": "GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_GDR-Net_Geometry-Guided_Direct_Regression_Network_for_Monocular_6D_Object_Pose_CVPR_2021_paper.html",
        "author": "Gu Wang, Fabian Manhardt, Federico Tombari, Xiangyang Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_GDR-Net_Geometry-Guided_Direct_Regression_Network_for_Monocular_6D_Object_Pose_CVPR_2021_paper.pdf",
        "aff": "Tsinghua University; Technical University of Munich; Tsinghua University, BNRist; Technical University of Munich, Google",
        "project": "",
        "github": "https://git.io/GDR-Net",
        "arxiv": ""
    },
    {
        "title": "GIRAFFE: Representing Scenes As Compositional Generative Neural Feature Fields",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Niemeyer_GIRAFFE_Representing_Scenes_As_Compositional_Generative_Neural_Feature_Fields_CVPR_2021_paper.html",
        "author": "Michael Niemeyer, Andreas Geiger",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Niemeyer_GIRAFFE_Representing_Scenes_As_Compositional_Generative_Neural_Feature_Fields_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen; University of T\u00fcbingen",
        "project": "",
        "github": "",
        "arxiv": "2011.12100"
    },
    {
        "title": "GLAVNet: Global-Local Audio-Visual Cues for Fine-Grained Material Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_GLAVNet_Global-Local_Audio-Visual_Cues_for_Fine-Grained_Material_Recognition_CVPR_2021_paper.html",
        "author": "Fengmin Shi, Jie Guo, Haonan Zhang, Shan Yang, Xiying Wang, Yanwen Guo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_GLAVNet_Global-Local_Audio-Visual_Cues_for_Fine-Grained_Material_Recognition_CVPR_2021_paper.pdf",
        "aff": "IQIYI Intelligence; State Key Lab for Novel Software Technology, Nanjing University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chan_GLEAN_Generative_Latent_Bank_for_Large-Factor_Image_Super-Resolution_CVPR_2021_paper.html",
        "author": "Kelvin C.K. Chan, Xintao Wang, Xiangyu Xu, Jinwei Gu, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chan_GLEAN_Generative_Latent_Bank_for_Large-Factor_Image_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "Applied Research Center, Tencent PCG; S-Lab, Nanyang Technological University; Tetras.AI, Shanghai AI Laboratory",
        "project": "",
        "github": "",
        "arxiv": "2012.00739"
    },
    {
        "title": "GMOT-40: A Benchmark for Generic Multiple Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bai_GMOT-40_A_Benchmark_for_Generic_Multiple_Object_Tracking_CVPR_2021_paper.html",
        "author": "Hexin Bai, Wensheng Cheng, Peng Chu, Juehuan Liu, Kai Zhang, Haibin Ling",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bai_GMOT-40_A_Benchmark_for_Generic_Multiple_Object_Tracking_CVPR_2021_paper.pdf",
        "aff": "Microsoft, Redmond, USA; Temple University, Philadelphia, USA; Stony Brook University, Stony Brook, USA",
        "project": "",
        "github": "https://github.com/Spritea/GMOT40",
        "arxiv": ""
    },
    {
        "title": "Gated Spatio-Temporal Attention-Guided Video Deblurring",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Suin_Gated_Spatio-Temporal_Attention-Guided_Video_Deblurring_CVPR_2021_paper.html",
        "author": "Maitreya Suin, A. N. Rajagopalan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Suin_Gated_Spatio-Temporal_Attention-Guided_Video_Deblurring_CVPR_2021_paper.pdf",
        "aff": "Indian Institute of Technology Madras, India",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Gaussian Context Transformer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ruan_Gaussian_Context_Transformer_CVPR_2021_paper.html",
        "author": "Dongsheng Ruan, Daiyin Wang, Yuan Zheng, Nenggan Zheng, Min Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ruan_Gaussian_Context_Transformer_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory for Diagnosis and Treatment of Infectious Diseases, The First Affiliated Hospital, College of Medicine, Zhejiang University; Qiushi Academy for Advanced Studies, Zhejiang University; College of Computer Science and Technology, Zhejiang University; College of Optical Science and Engineering, Zhejiang University; School of Aeronautics and Astronautics, Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "General Instance Distillation for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_General_Instance_Distillation_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Xing Dai, Zeren Jiang, Zhao Wu, Yiping Bao, Zhicheng Wang, Si Liu, Erjin Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_General_Instance_Distillation_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "General Instance Distillation for Object Detection\nXing Dai\u22171Zeren Jiang\u2217\u20201,2Zhao Wu1\nYiping Bao1Zhicheng Wang1Si Liu2Erjin Zhou1\n1MEGVII Technology2BeiHang University\ndaixinghome@gmail.com zeren.jiang99@gmail.com wuzhao@megvii.com\nbaoyiping@megvii.com wangzhicheng@megvii.com liusi@buaa.edu.cn zej@megvii.com\nAbstract\nIn recent years, knowledge distillation has been proved\nto be an effective solution for model compression. This\napproach can make lightweight student models acquire\nthe knowledge extracted from cumbersome teacher mod-\nels. However, previous distillation methods of detection\nhave weak generalization for different detection frameworks\nand rely heavily on ground truth (GT), ignoring the valu-\nable relation information between instances. Thus, we pro-\npose a novel distillation method for detection tasks based\non discriminative instances without considering the posi-\ntive or negative distinguished by GT, which is called gen-\neral instance distillation (GID). Our approach contains a\ngeneral instance selection module (GISM) to make full use\nof feature-based, relation-based and response-based knowl-\nedge for distillation. Extensive results demonstrate that\nthe student model achieves signi\ufb01cant AP improvement and\neven outperforms the teacher in various detection frame-\nworks. Speci\ufb01cally, RetinaNet with ResNet-50 achieves\n39.1% in mAP with GID on COCO dataset, which sur-\npasses the baseline 36.2% by 2.9%, and even better than\nthe ResNet-101 based teacher model with 38.1% AP .\n1. Introduction\nIn recent years, the accuracy of object detection has\nmade a great progress due to the blossom of deep con-\nvolutional neural network (CNN). The deep learning net-\nwork structure, including a variety of one-stage detection\nmodels [ 19,23,24,25,17] and two-stage detection mod-\nels [26,16,8,2], has replaced the traditional object detec-\ntion and has become the mainstream method in this \ufb01eld.\nFurthermore, the anchor-free frameworks [ 13,5,32] have\nalso achieved better performance with more simpli\ufb01ed ap-\n\u2217The \ufb01rst two authors contribute equally and the order is alphabetical.\n\u2020This work was done when Zeren was an intern at MEGVII Tech.Student Backbone Teacher Backbone\nDetHead\ncls regDetHead\ncls regGIs Response \nLossGIs Feature\nLoss\nGIs Relation\nLossDistillation Loss\nGISM\nFigure 1. Overall pipeline of general instance distillation (GID).\nGeneral instances (GIs) are adaptively selected by the output both\nfrom teacher and student model. Then the feature-based, relation-\nbased and response-based knowledge are extracted for distillation\nbased on the selected GIs.\nproaches. However, these high-precision deep learning\nbased models are usually cumbersome, while a lightweight\nwith high performance model is demanded in practical ap-\nplications. Therefore, how to \ufb01nd a better trade-off between\nthe accuracy and ef\ufb01ciency has become a crucial problem.\nKnowledge Distillation (KD), proposed by Hinton et al.\n[10], is a promising solution for the above problem. Knowl-\nedge distillation is to transfer the knowledge of large model\nto small model, thereby improving the performance of the\nsmall model and achieving the purpose of model compres-\nsion. At present, the typical forms of knowledge can be di-\nvided into three categories [ 7], response-based knowledge\n[10,22], feature-based knowledge [ 27,35,9] and relation-\nbased knowledge [ 22,20,31,33,15]. However, most of\nthe distillation methods are mainly designed for multi-class\nclassi\ufb01cation problems. Directly migrating the classi\ufb01ca-\ntion speci\ufb01c distillation method to the detection model is\n1\n7842\n",
        "project": "",
        "github": "",
        "arxiv": "2103.02340"
    },
    {
        "title": "General Multi-Label Image Classification With Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lanchantin_General_Multi-Label_Image_Classification_With_Transformers_CVPR_2021_paper.html",
        "author": "Jack Lanchantin, Tianlu Wang, Vicente Ordonez, Yanjun Qi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lanchantin_General_Multi-Label_Image_Classification_With_Transformers_CVPR_2021_paper.pdf",
        "aff": "University of Virginia",
        "project": "",
        "github": "",
        "arxiv": "2011.14027"
    },
    {
        "title": "Generalizable Pedestrian Detection: The Elephant in the Room",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hasan_Generalizable_Pedestrian_Detection_The_Elephant_in_the_Room_CVPR_2021_paper.html",
        "author": "Irtiza Hasan, Shengcai Liao, Jinpeng Li, Saad Ullah Akram, Ling Shao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hasan_Generalizable_Pedestrian_Detection_The_Elephant_in_the_Room_CVPR_2021_paper.pdf",
        "aff": "Inception Institute of Arti\ufb01cial Intelligence (IIAI); Aalto University, Finland",
        "project": "",
        "github": "https://github.com/hasanirtiza/Pedestron",
        "arxiv": "2003.08799"
    },
    {
        "title": "Generalizable Person Re-Identification With Relevance-Aware Mixture of Experts",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Generalizable_Person_Re-Identification_With_Relevance-Aware_Mixture_of_Experts_CVPR_2021_paper.html",
        "author": "Yongxing Dai, Xiaotong Li, Jun Liu, Zekun Tong, Ling-Yu Duan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Generalizable_Person_Re-Identification_With_Relevance-Aware_Mixture_of_Experts_CVPR_2021_paper.pdf",
        "aff": "National University of Singapore, Singapore; Singapore University of Technology and Design, Singapore; National Engineering Lab for Video Technology, Peking University, Beijing, China; National Engineering Lab for Video Technology, Peking University, Beijing, China; Peng Cheng Laboratory, Shenzhen, China",
        "project": "",
        "github": "",
        "arxiv": "2105.09156"
    },
    {
        "title": "Generalization on Unseen Domains via Inference-Time Label-Preserving Target Projections",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pandey_Generalization_on_Unseen_Domains_via_Inference-Time_Label-Preserving_Target_Projections_CVPR_2021_paper.html",
        "author": "Prashant Pandey, Mrigank Raman, Sumanth Varambally, Prathosh AP",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pandey_Generalization_on_Unseen_Domains_via_Inference-Time_Label-Preserving_Target_Projections_CVPR_2021_paper.pdf",
        "aff": "IIT Delhi",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Generalized Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mitsuzumi_Generalized_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Yu Mitsuzumi, Go Irie, Daiki Ikami, Takashi Shibata",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mitsuzumi_Generalized_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "NTT Communication Science Laboratories, NTT Corporation, Japan",
        "project": "",
        "github": "",
        "arxiv": "2106.01656"
    },
    {
        "title": "Generalized Few-Shot Object Detection Without Forgetting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Generalized_Few-Shot_Object_Detection_Without_Forgetting_CVPR_2021_paper.html",
        "author": "Zhibo Fan, Yuchen Ma, Zeming Li, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_Generalized_Few-Shot_Object_Detection_Without_Forgetting_CVPR_2021_paper.pdf",
        "aff": "Megvii Technology",
        "project": "",
        "github": "",
        "arxiv": "2105.09491"
    },
    {
        "title": "Generalized Focal Loss V2: Learning Reliable Localization Quality Estimation for Dense Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Generalized_Focal_Loss_V2_Learning_Reliable_Localization_Quality_Estimation_for_CVPR_2021_paper.html",
        "author": "Xiang Li, Wenhai Wang, Xiaolin Hu, Jun Li, Jinhui Tang, Jian Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Generalized_Focal_Loss_V2_Learning_Reliable_Localization_Quality_Estimation_for_CVPR_2021_paper.pdf",
        "aff": "Nanjing University of Science and Technology, Momenta; Nanjing University of Science and Technology; Nanjing University; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2011.12885"
    },
    {
        "title": "Generalizing Face Forgery Detection With High-Frequency Features",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Generalizing_Face_Forgery_Detection_With_High-Frequency_Features_CVPR_2021_paper.html",
        "author": "Yuchen Luo, Yong Zhang, Junchi Yan, Wei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Generalizing_Face_Forgery_Detection_With_High-Frequency_Features_CVPR_2021_paper.pdf",
        "aff": "1Department of Computer Science and Engineering, Shanghai Jiao Tong University; 2MoE Key Lab of Arti\ufb01cial Intelligence, AI Institute, Shanghai Jiao Tong University; Tencent AI Lab; Tencent Data Platform",
        "project": "",
        "github": "",
        "arxiv": "2103.12376"
    },
    {
        "title": "Generalizing to the Open World: Deep Visual Odometry With Online Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Generalizing_to_the_Open_World_Deep_Visual_Odometry_With_Online_CVPR_2021_paper.html",
        "author": "Shunkai Li, Xin Wu, Yingdian Cao, Hongbin Zha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Generalizing_to_the_Open_World_Deep_Visual_Odometry_With_Online_CVPR_2021_paper.pdf",
        "aff": "PKU-SenseTime Machine Vision Joint Lab; Key Laboratory of Machine Perception (MOE), School of EECS, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2103.15279"
    },
    {
        "title": "Generating Diverse Structure for Image Inpainting With Hierarchical VQ-VAE",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Peng_Generating_Diverse_Structure_for_Image_Inpainting_With_Hierarchical_VQ-VAE_CVPR_2021_paper.html",
        "author": "Jialun Peng, Dong Liu, Songcen Xu, Houqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Peng_Generating_Diverse_Structure_for_Image_Inpainting_With_Hierarchical_VQ-VAE_CVPR_2021_paper.pdf",
        "aff": "Noah\u2019s Ark Lab, Huawei Technologies Co., Ltd.; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/USTC-JialunPeng/Diverse-Structure-Inpainting",
        "arxiv": "2103.10022"
    },
    {
        "title": "Generating Manga From Illustrations via Mimicking Manga Creation Workflow",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Generating_Manga_From_Illustrations_via_Mimicking_Manga_Creation_Workflow_CVPR_2021_paper.html",
        "author": "Lvmin Zhang, Xinrui Wang, Qingnan Fan, Yi Ji, Chunping Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Generating_Manga_From_Illustrations_via_Mimicking_Manga_Creation_Workflow_CVPR_2021_paper.pdf",
        "aff": "Soochow University / Style2Paints Research, China; The University of Tokyo / Tencent, China; Soochow University, China; Stanford University, United States",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Generative Classifiers as a Basis for Trustworthy Image Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mackowiak_Generative_Classifiers_as_a_Basis_for_Trustworthy_Image_Classification_CVPR_2021_paper.html",
        "author": "Radek Mackowiak, Lynton Ardizzone, Ullrich Kothe, Carsten Rother",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mackowiak_Generative_Classifiers_as_a_Basis_for_Trustworthy_Image_Classification_CVPR_2021_paper.pdf",
        "aff": "Visual Learning Lab, Heidelberg University",
        "project": "",
        "github": "github.com/VLL-HD/trustworthy-GCs",
        "arxiv": "2007.15036"
    },
    {
        "title": "Generative Hierarchical Features From Synthesizing Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Generative_Hierarchical_Features_From_Synthesizing_Images_CVPR_2021_paper.html",
        "author": "Yinghao Xu, Yujun Shen, Jiapeng Zhu, Ceyuan Yang, Bolei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Generative_Hierarchical_Features_From_Synthesizing_Images_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong",
        "project": "https://genforce.github.io/ghfeat/",
        "github": "",
        "arxiv": "2007.10379"
    },
    {
        "title": "Generative Interventions for Causal Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mao_Generative_Interventions_for_Causal_Learning_CVPR_2021_paper.html",
        "author": "Chengzhi Mao, Augustine Cha, Amogh Gupta, Hao Wang, Junfeng Yang, Carl Vondrick",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mao_Generative_Interventions_for_Causal_Learning_CVPR_2021_paper.pdf",
        "aff": "Rutgers University; Columbia University",
        "project": "",
        "github": "",
        "arxiv": "2012.12265"
    },
    {
        "title": "Generative PointNet: Deep Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Generative_PointNet_Deep_Energy-Based_Learning_on_Unordered_Point_Sets_for_CVPR_2021_paper.html",
        "author": "Jianwen Xie, Yifei Xu, Zilong Zheng, Song-Chun Zhu, Ying Nian Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xie_Generative_PointNet_Deep_Energy-Based_Learning_on_Unordered_Point_Sets_for_CVPR_2021_paper.pdf",
        "aff": "University of California, Los Angeles (UCLA), CA, USA; Cognitive Computing Lab, Baidu Research, Bellevue, WA, USA",
        "project": "",
        "github": "",
        "arxiv": "2004.01301"
    },
    {
        "title": "Generic Perceptual Loss for Modeling Structured Output Dependencies",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Generic_Perceptual_Loss_for_Modeling_Structured_Output_Dependencies_CVPR_2021_paper.html",
        "author": "Yifan Liu, Hao Chen, Yu Chen, Wei Yin, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Generic_Perceptual_Loss_for_Modeling_Structured_Output_Dependencies_CVPR_2021_paper.pdf",
        "aff": "Monash University, Australia; The University of Adelaide; Automind",
        "project": "",
        "github": "",
        "arxiv": "2103.10571"
    },
    {
        "title": "Geo-FARM: Geodesic Factor Regression Model for Misaligned Pre-Shape Responses in Statistical Shape Analysis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Geo-FARM_Geodesic_Factor_Regression_Model_for_Misaligned_Pre-Shape_Responses_in_CVPR_2021_paper.html",
        "author": "Chao Huang, Anuj Srivastava, Rongjie Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Geo-FARM_Geodesic_Factor_Regression_Model_for_Misaligned_Pre-Shape_Responses_in_CVPR_2021_paper.pdf",
        "aff": "Department of Statistics, Florida State University, Tallahassee, FL 32306, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_GeoSim_Realistic_Video_Simulation_via_Geometry-Aware_Composition_for_Self-Driving_CVPR_2021_paper.html",
        "author": "Yun Chen, Frieda Rong, Shivam Duggal, Shenlong Wang, Xinchen Yan, Sivabalan Manivasagam, Shangjie Xue, Ersin Yumer, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_GeoSim_Realistic_Video_Simulation_via_Geometry-Aware_Composition_for_Self-Driving_CVPR_2021_paper.pdf",
        "aff": "University of Toronto; Massachusetts Institute of Techonology; Stanford University; Uber Advanced Technologies Group",
        "project": "https://tmux.top/publication/geosim/",
        "github": "",
        "arxiv": "2101.06543"
    },
    {
        "title": "Glance and Gaze: Inferring Action-Aware Points for One-Stage Human-Object Interaction Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Glance_and_Gaze_Inferring_Action-Aware_Points_for_One-Stage_Human-Object_Interaction_CVPR_2021_paper.html",
        "author": "Xubin Zhong, Xian Qu, Changxing Ding, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_Glance_and_Gaze_Inferring_Action-Aware_Points_for_One-Stage_Human-Object_Interaction_CVPR_2021_paper.pdf",
        "aff": "The University of Sydney; South China University of Technology; South China University of Technology, Pazhou Lab, Guangzhou",
        "project": "",
        "github": "https://github.com/SherlockHolmes221/GGNet",
        "arxiv": "2104.05269"
    },
    {
        "title": "Glancing at the Patch: Anomaly Localization With Global and Local Feature Comparison",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Glancing_at_the_Patch_Anomaly_Localization_With_Global_and_Local_CVPR_2021_paper.html",
        "author": "Shenzhi Wang, Liwei Wu, Lei Cui, Yujun Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Glancing_at_the_Patch_Anomaly_Localization_With_Global_and_Local_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Global Transport for Fluid Reconstruction With Learned Self-Supervision",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Franz_Global_Transport_for_Fluid_Reconstruction_With_Learned_Self-Supervision_CVPR_2021_paper.html",
        "author": "Erik Franz, Barbara Solenthaler, Nils Thuerey",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Franz_Global_Transport_for_Fluid_Reconstruction_With_Learned_Self-Supervision_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": "2104.06031"
    },
    {
        "title": "Global2Local: Efficient Structure Search for Video Action Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Global2Local_Efficient_Structure_Search_for_Video_Action_Segmentation_CVPR_2021_paper.html",
        "author": "Shang-Hua Gao, Qi Han, Zhong-Yu Li, Pai Peng, Liang Wang, Ming-Ming Cheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Global2Local_Efficient_Structure_Search_for_Video_Action_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Tencent; TKLNDST, CS, Nankai University; NLPR",
        "project": "http://mmcheng.net/g2lsearch",
        "github": "",
        "arxiv": "2101.00910"
    },
    {
        "title": "Globally Optimal Relative Pose Estimation With Gravity Prior",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ding_Globally_Optimal_Relative_Pose_Estimation_With_Gravity_Prior_CVPR_2021_paper.html",
        "author": "Yaqing Ding, Daniel Barath, Jian Yang, Hui Kong, Zuzana Kukelova",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_Globally_Optimal_Relative_Pose_Estimation_With_Gravity_Prior_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology; Visual Recognition Group, Faculty of Electrical Engineering, Czech Technical University in Prague",
        "project": "",
        "github": "https://github.com/yaqding/opt_pose_gravity",
        "arxiv": "2012.00458"
    },
    {
        "title": "Goal-Oriented Gaze Estimation for Zero-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Goal-Oriented_Gaze_Estimation_for_Zero-Shot_Learning_CVPR_2021_paper.html",
        "author": "Yang Liu, Lei Zhou, Xiao Bai, Yifei Huang, Lin Gu, Jun Zhou, Tatsuya Harada",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Goal-Oriented_Gaze_Estimation_for_Zero-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, State Key Laboratory of Software Development Environment, Jiangxi Research Institute, Beihang University, Beijing, China; The University of Tokyo, RIKEN AIP, Tokyo, Japan; RIKEN AIP, Tokyo, Japan; Grif\ufb01th University, Australia; The University of Tokyo",
        "project": "",
        "github": "https://github.com/osierboy/GEM-ZSL",
        "arxiv": "2103.03433"
    },
    {
        "title": "Gradient Forward-Propagation for Large-Scale Temporal Video Modelling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Malinowski_Gradient_Forward-Propagation_for_Large-Scale_Temporal_Video_Modelling_CVPR_2021_paper.html",
        "author": "Mateusz Malinowski, Dimitrios Vytiniotis, Grzegorz Swirszcz, Viorica Patraucean, Joao Carreira",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Malinowski_Gradient_Forward-Propagation_for_Large-Scale_Temporal_Video_Modelling_CVPR_2021_paper.pdf",
        "aff": "Gradient Forward-Propagation for Large-Scale Temporal Video Modelling\nMateusz Malinowski\u2217\nDeepMindDimitrios Vytiniotis\nDeepMindGrzegorz \u00b4Swirszcz\nDeepMindViorica P \u02d8atr\u02d8aucean\nDeepMind\nJo\u00e3o Carreira\nDeepMind\nAbstract\nHow can neural networks be trained on large-volume\ntemporal data ef\ufb01ciently? To compute the gradients required\nto update parameters, backpropagation blocks computations\nuntil the forward and backward passes are completed. For\ntemporal signals, this introduces high latency and hinders\nreal-time learning. It also creates a coupling between consec-\nutive layers, which limits model parallelism and increases\nmemory consumption. In this paper, we build upon Side-\nways, which avoids blocking by propagating approximate\ngradients forward in time, and we propose mechanisms for\ntemporal integration of information based on different vari-\nants of skip connections. We also show how to decouple\ncomputation and delegate individual neural modules to dif-\nferent devices, allowing distributed and parallel training.\nThe proposed Skip-Sideways achieves low latency training,\nmodel parallelism, and, importantly, is capable of extracting\ntemporal features, leading to more stable training and im-\nproved performance on real-world action recognition video\ndatasets such as HMDB51, UCF101, and the large-scale\nKinetics-600. Finally, we also show that models trained with\nSkip-Sideways generate better future frames than Sideways\nmodels, and hence they can better utilize motion cues.\n1. Introduction\nPopular deep video models generally rely on spatio-\ntemporal convolutional networks (3D CNNs) [ 12,18,52,\n55,63] or recurrent networks [ 16,24,34] that are trained\nwith backpropagation (BP) using stochastic gradient descent\n(SGD) [ 7,19,29,33,46,57,58,60,64]. This is a powerful\ntraining paradigm but also an expensive one as it needs to\nstore all the activations in memory to compute Jacobian ten-\nsors for the gradient calculations. First, all the activations\nare computed in the forward mode, from the beginning to\nthe end of the sequence. Next, gradients are computed in\nthe reverse direction, from the end to the beginning. All that\n\u2217The corresponding author: mateuszm@google.comseverely limits the scale at which we can train temporal mod-\nels on large-volume sequences such as videos. Therefore,\ntypically these video models are trained on short video clips\n(about 2.5s at usual frame rate), in of\ufb02ine batch mode.\nSideways [38] is a recent training technique for video\nmodels that decouples the computation along the depth of\nthe network and introduces computation steps . As a new\nframe is fed into the processing pipeline, each layer indepen-\ndently updates the internal state of the network by computing\nnew activations and gradients. Next, these are passed to the\nlayers above and below in the next computation step (see\nFigure 1left). Moreover, the information cannot be back-\npropagated to the same units that produced the activations\nas this happened in the past computation steps. One may\nsay that \u201ceverything \ufb02ows forward in time\u201d, including the\nbackward pass. Due to these properties, Sideways is more\nbiologically plausible than the regular backprop, as it does\nnot block the computation and respects the arrow of time.\nAlthough Sideways , as originally proposed, operates in\na temporal forward fashion, it is not a temporal model per\nse, as it has access only to the present frame at each time\nstep. This results in improved memory ef\ufb01ciency similar to\nsingle-frame models, making it suitable for real-time appli-\ncations. However, this comes with the cost of not integrating\ninformation temporally, which limits the expressive power\nof the resulting models.\nIn this work, we show that it is possible for models to\nprocess one frame at a time similar to Sideways , while still\nbeing able to extract temporal features. We do this by in-\ntroducing shortcut (skip) connections in addition to direct\nconnections between the layers of the model. We study the\ntraining dynamics of the resulting training procedure, which\nwe call Skip-Sideways , and show that shortcut connections\nlead to more stable training and higher accuracy.\nRegular skip connections [ 21] alter the information \ufb02ow\nalong the data path of the network by allowing activations\nto \u2018skip\u2019 layers, creating data shortcuts. In the proposed\nSkip-Sideways , activations and gradients along the shortcut\nconnections are also sent forward in time, effectively cre-\nating data paths across time, making it possible to extract\n9249\n",
        "project": "",
        "github": "",
        "arxiv": "2106.08318"
    },
    {
        "title": "Gradient-Based Algorithms for Machine Teaching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Gradient-Based_Algorithms_for_Machine_Teaching_CVPR_2021_paper.html",
        "author": "Pei Wang, Kabir Nagrecha, Nuno Vasconcelos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Gradient-Based_Algorithms_for_Machine_Teaching_CVPR_2021_paper.pdf",
        "aff": "UC, San Diego",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Graph Attention Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Graph_Attention_Tracking_CVPR_2021_paper.html",
        "author": "Dongyan Guo, Yanyan Shao, Ying Cui, Zhenhua Wang, Liyan Zhang, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Graph_Attention_Tracking_CVPR_2021_paper.pdf",
        "aff": "Nanjing University of Aeronautics & Astronautics, China; Monash University, Australia; Zhejiang University of Technology, China",
        "project": "",
        "github": "https://git.io/SiamGAT",
        "arxiv": "2011.11204"
    },
    {
        "title": "Graph Stacked Hourglass Networks for 3D Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Graph_Stacked_Hourglass_Networks_for_3D_Human_Pose_Estimation_CVPR_2021_paper.html",
        "author": "Tianhan Xu, Wataru Takano",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Graph_Stacked_Hourglass_Networks_for_3D_Human_Pose_Estimation_CVPR_2021_paper.pdf",
        "aff": "Osaka University",
        "project": "",
        "github": "",
        "arxiv": "2103.16385"
    },
    {
        "title": "Graph-Based High-Order Relation Discovery for Fine-Grained Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Graph-Based_High-Order_Relation_Discovery_for_Fine-Grained_Recognition_CVPR_2021_paper.html",
        "author": "Yifan Zhao, Ke Yan, Feiyue Huang, Jia Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Graph-Based_High-Order_Relation_Discovery_for_Fine-Grained_Recognition_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory of Virtual Reality Technology and Systems, SCSE, Beihang University; Peng Cheng Laboratory, Shenzhen, China; State Key Laboratory of Virtual Reality Technology and Systems, SCSE, Beihang University; Tencent Youtu Lab, Shanghai, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Graph-Based High-Order Relation Modeling for Long-Term Action Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Graph-Based_High-Order_Relation_Modeling_for_Long-Term_Action_Recognition_CVPR_2021_paper.html",
        "author": "Jiaming Zhou, Kun-Yu Lin, Haoxin Li, Wei-Shi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Graph-Based_High-Order_Relation_Modeling_for_Long-Term_Action_Recognition_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Peng Cheng Laboratory, Shenzhen 518005, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China; School of Computer Science and Engineering, Sun Yat-sen University, China; School of Electronics and Information Technology, Sun Yat-sen University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Greedy Hierarchical Variational Autoencoders for Large-Scale Video Prediction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Greedy_Hierarchical_Variational_Autoencoders_for_Large-Scale_Video_Prediction_CVPR_2021_paper.html",
        "author": "Bohan Wu, Suraj Nair, Roberto Martin-Martin, Li Fei-Fei, Chelsea Finn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Greedy_Hierarchical_Variational_Autoencoders_for_Large-Scale_Video_Prediction_CVPR_2021_paper.pdf",
        "aff": "Stanford University, Stanford, CA 94305",
        "project": "https://sites.google.com/view/ghvae",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "GrooMeD-NMS: Grouped Mathematically Differentiable NMS for Monocular 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kumar_GrooMeD-NMS_Grouped_Mathematically_Differentiable_NMS_for_Monocular_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "Abhinav Kumar, Garrick Brazil, Xiaoming Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kumar_GrooMeD-NMS_Grouped_Mathematically_Differentiable_NMS_for_Monocular_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Michigan State University, East Lansing, MI, USA",
        "project": "",
        "github": "https://github.com/abhi1kumar/groomed_nms",
        "arxiv": ""
    },
    {
        "title": "Group Collaborative Learning for Co-Salient Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Group_Collaborative_Learning_for_Co-Salient_Object_Detection_CVPR_2021_paper.html",
        "author": "Qi Fan, Deng-Ping Fan, Huazhu Fu, Chi-Keung Tang, Ling Shao, Yu-Wing Tai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_Group_Collaborative_Learning_for_Co-Salient_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Inception Institute of Arti\ufb01cial Intelligence; HKUST, Kuaishou Technology; HKUST",
        "project": "",
        "github": "https://github.com/fanq15/GCoNet",
        "arxiv": "2104.01108"
    },
    {
        "title": "Group Whitening: Balancing Learning Efficiency and Representational Capacity",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Group_Whitening_Balancing_Learning_Efficiency_and_Representational_Capacity_CVPR_2021_paper.html",
        "author": "Lei Huang, Yi Zhou, Li Liu, Fan Zhu, Ling Shao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Group_Whitening_Balancing_Learning_Efficiency_and_Representational_Capacity_CVPR_2021_paper.pdf",
        "aff": "Inception Institute of Arti\ufb01cial Intelligence (IIAI), Abu Dhabi, UAE; SKLSDE, Institute of Arti\ufb01cial Intelligence, Beihang University, Beijing, China; MOE Key Laboratory of Computer Network and Information Integration, Southeast University, China",
        "project": "",
        "github": "",
        "arxiv": "2009.13333"
    },
    {
        "title": "Group-aware Label Transfer for Domain Adaptive Person Re-identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Group-aware_Label_Transfer_for_Domain_Adaptive_Person_Re-identification_CVPR_2021_paper.html",
        "author": "Kecheng Zheng, Wu Liu, Lingxiao He, Tao Mei, Jiebo Luo, Zheng-Jun Zha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Group-aware_Label_Transfer_for_Domain_Adaptive_Person_Re-identification_CVPR_2021_paper.pdf",
        "aff": "AI Research of JD; University of Rochester; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/JDAI-CV/fast-reid",
        "arxiv": "2103.12366"
    },
    {
        "title": "Guided Integrated Gradients: An Adaptive Path Method for Removing Noise",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kapishnikov_Guided_Integrated_Gradients_An_Adaptive_Path_Method_for_Removing_Noise_CVPR_2021_paper.html",
        "author": "Andrei Kapishnikov, Subhashini Venugopalan, Besim Avci, Ben Wedin, Michael Terry, Tolga Bolukbasi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kapishnikov_Guided_Integrated_Gradients_An_Adaptive_Path_Method_for_Removing_Noise_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "",
        "arxiv": "2106.09788"
    },
    {
        "title": "Guided Interactive Video Object Segmentation Using Reliability-Based Attention Maps",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Heo_Guided_Interactive_Video_Object_Segmentation_Using_Reliability-Based_Attention_Maps_CVPR_2021_paper.html",
        "author": "Yuk Heo, Yeong Jun Koh, Chang-Su Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Heo_Guided_Interactive_Video_Object_Segmentation_Using_Reliability-Based_Attention_Maps_CVPR_2021_paper.pdf",
        "aff": "Korea University; Chungnam National University",
        "project": "",
        "github": "https://github.com/yuk6heo/GIS-RAmap",
        "arxiv": "2104.10386"
    },
    {
        "title": "HCRF-Flow: Scene Flow From Point Clouds With Continuous High-Order CRFs and Position-Aware Flow Embedding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_HCRF-Flow_Scene_Flow_From_Point_Clouds_With_Continuous_High-Order_CRFs_CVPR_2021_paper.html",
        "author": "Ruibo Li, Guosheng Lin, Tong He, Fayao Liu, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_HCRF-Flow_Scene_Flow_From_Point_Clouds_With_Continuous_High-Order_CRFs_CVPR_2021_paper.pdf",
        "aff": "HCRF-Flow: Scene Flow from Point Clouds with Continuous High-order CRFs\nand Position-aware Flow Embedding\nRuibo Li1,2, Guosheng Lin1,2\u2217, Tong He3, Fayao Liu4, Chunhua Shen3\n1S-Lab, Nanyang Technological University, Singapore\n2School of Computer Science and Engineering, Nanyang Technological University, Singapore\n3University of Adelaide, Australia4Institute for Infocomm Research, A*STAR, Singapore\nE-mail:ruibo001 @e.ntu.edu.sg,gslin@ntu.edu.sg\nAbstract\nScene \ufb02ow in 3D point clouds plays an important role\nin understanding dynamic environments. Although signi\ufb01-\ncant advances have been made by deep neural networks, the\nperformance is far from satisfactory as only per-point trans-\nlational motion is considered, neglecting the constraints of\nthe rigid motion in local regions. To address the issue, we\npropose to introduce the motion consistency to force the\nsmoothness among neighboring points. In addition, con-\nstraints on the rigidity of the local transformation are also\nadded by sharing unique rigid motion parameters for all\npoints within each local region. To this end, a high-order\nCRFs based relation module (Con-HCRFs) is deployed to\nexplore both point-wise smoothness and region-wise rigid-\nity. To empower the CRFs to have a discriminative unary\nterm, we also introduce a position-aware \ufb02ow estimation\nmodule to be incorporated into the Con-HCRFs. Compre-\nhensive experiments on FlyingThings3D and KITTI show\nthat our proposed framework (HCRF-Flow) achieves state-\nof-the-art performance and signi\ufb01cantly outperforms previ-\nous approaches substantially.\n1. Introduction\nScene \ufb02ow estimation [ 37] aims to provide dense or\nsemi-dense 3D vectors, representing the per-point 3D mo-\ntion in two consecutive frames. The information provided\nhas proven invaluable in analyzing dynamic scenes. Al-\nthough signi\ufb01cant advances have been made in the 2D opti-\ncal \ufb02ow, the counterpart in 3D point cloud is far more chal-\nlenging. This is partly due to the irregularity and sparsity of\nthe data, but also due to the diversity of the scene.\nAs pointed out in [ 17], most of the structures in the vi-\nsual world are rigid or at least nearly so. Many previous top-\nperforming approaches [ 13,5,45,26] simplify this task as a\n\u2217Corresponding author: G. Lin. (e-mail: gslin@ntu.edu.sg)\n(a) (b)\n(c) (d)\nFigure 1. The warped point cloud at the next frame based on differ-\nent scene \ufb02ow. Green points represent the point cloud at frame t.\nRed points are the warped results at frame t+ 1by adding scene\n\ufb02ow back to corresponding green points. (a) scene \ufb02ow pro-\nduced by FlowNet3D [ 13]; (b) scene \ufb02ow produced by FlowNet3D\nand re\ufb01ned by a conventional CRF; (c) scene \ufb02ow produced by\nFlowNet3D and re\ufb01ned by our continuous high order CRFs; (d)\nground truth scene \ufb02ow. The local structure of the warped point\ncloud is distorted in Flownet3d and the conventional CRF but pre-\nserved in our method.\nregression problem by estimating a point-wise translational\nmotion. Although promising results have been achieved,\nthe performance is far from satisfactory as the potential\nrigid motion constraints existing in the local region are ig-\nnored. As shown in Fig. 1(a), the results generated by the\nFlowNet3D [ 13] are deformed and fail to maintain the lo-\ncal geometric smoothness. A straightforward remedy is to\nutilize pair-wise regularization to smooth the \ufb02ow predic-\ntion. However, ignoring the potential rigid transformations\n364\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HDMapGen: A Hierarchical Graph Generative Model of High Definition Maps",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mi_HDMapGen_A_Hierarchical_Graph_Generative_Model_of_High_Definition_Maps_CVPR_2021_paper.html",
        "author": "Lu Mi, Hang Zhao, Charlie Nash, Xiaohan Jin, Jiyang Gao, Chen Sun, Cordelia Schmid, Nir Shavit, Yuning Chai, Dragomir Anguelov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mi_HDMapGen_A_Hierarchical_Graph_Generative_Model_of_High_Definition_Maps_CVPR_2021_paper.pdf",
        "aff": "Google; Waymo; DeepMind; Waymo/MIT; MIT",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HDR Environment Map Estimation for Real-Time Augmented Reality",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Somanath_HDR_Environment_Map_Estimation_for_Real-Time_Augmented_Reality_CVPR_2021_paper.html",
        "author": "Gowri Somanath, Daniel Kurz",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Somanath_HDR_Environment_Map_Estimation_for_Real-Time_Augmented_Reality_CVPR_2021_paper.pdf",
        "aff": "Apple",
        "project": "",
        "github": "",
        "arxiv": "2011.10687"
    },
    {
        "title": "HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tankovich_HITNet_Hierarchical_Iterative_Tile_Refinement_Network_for_Real-time_Stereo_Matching_CVPR_2021_paper.html",
        "author": "Vladimir Tankovich, Christian Hane, Yinda Zhang, Adarsh Kowdle, Sean Fanello, Sofien Bouaziz",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tankovich_HITNet_Hierarchical_Iterative_Tile_Refinement_Network_for_Real-time_Stereo_Matching_CVPR_2021_paper.pdf",
        "aff": "Google",
        "project": "",
        "github": "",
        "arxiv": "2007.12140"
    },
    {
        "title": "HLA-Face: Joint High-Low Adaptation for Low Light Face Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_HLA-Face_Joint_High-Low_Adaptation_for_Low_Light_Face_Detection_CVPR_2021_paper.html",
        "author": "Wenjing Wang, Wenhan Yang, Jiaying Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_HLA-Face_Joint_High-Low_Adaptation_for_Low_Light_Face_Detection_CVPR_2021_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University, Beijing, China",
        "project": "https://daooshee.github.io/HLA-Face-Website/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HOTR: End-to-End Human-Object Interaction Detection With Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_HOTR_End-to-End_Human-Object_Interaction_Detection_With_Transformers_CVPR_2021_paper.html",
        "author": "Bumsoo Kim, Junhyun Lee, Jaewoo Kang, Eun-Sol Kim, Hyunwoo J. Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_HOTR_End-to-End_Human-Object_Interaction_Detection_With_Transformers_CVPR_2021_paper.pdf",
        "aff": "Korea University; Kakao Brain",
        "project": "",
        "github": "",
        "arxiv": "2104.13682"
    },
    {
        "title": "HR-NAS: Searching Efficient High-Resolution Neural Architectures With Lightweight Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ding_HR-NAS_Searching_Efficient_High-Resolution_Neural_Architectures_With_Lightweight_Transformers_CVPR_2021_paper.html",
        "author": "Mingyu Ding, Xiaochen Lian, Linjie Yang, Peng Wang, Xiaojie Jin, Zhiwu Lu, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_HR-NAS_Searching_Efficient_High-Resolution_Neural_Architectures_With_Lightweight_Transformers_CVPR_2021_paper.pdf",
        "aff": "The University of Hong Kong; Bytedance Inc.; Gaoling School of Artificial Intelligence, Renmin University of China",
        "project": "",
        "github": "https://github.com/dingmyu/HR-NAS",
        "arxiv": ""
    },
    {
        "title": "HVPR: Hybrid Voxel-Point Representation for Single-Stage 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Noh_HVPR_Hybrid_Voxel-Point_Representation_for_Single-Stage_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "Jongyoun Noh, Sanghoon Lee, Bumsub Ham",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Noh_HVPR_Hybrid_Voxel-Point_Representation_for_Single-Stage_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University",
        "project": "",
        "github": "",
        "arxiv": "2104.00902"
    },
    {
        "title": "Hallucination Improves Few-Shot Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Hallucination_Improves_Few-Shot_Object_Detection_CVPR_2021_paper.html",
        "author": "Weilin Zhang, Yu-Xiong Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Hallucination_Improves_Few-Shot_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign",
        "project": "",
        "github": "",
        "arxiv": "2105.01294"
    },
    {
        "title": "Hardness Sampling for Self-Training Based Transductive Zero-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bo_Hardness_Sampling_for_Self-Training_Based_Transductive_Zero-Shot_Learning_CVPR_2021_paper.html",
        "author": "Liu Bo, Qiulei Dong, Zhanyi Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bo_Hardness_Sampling_for_Self-Training_Based_Transductive_Zero-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "School of Arti\ufb01cial Intelligence, UCAS; Center for Excellence in Brain Science and Intelligence Technology, CAS; National Laboratory of Pattern Recognition, CASIA; School of Future Technology, UCAS",
        "project": "",
        "github": "",
        "arxiv": "2106.00264"
    },
    {
        "title": "Harmonious Semantic Line Detection via Maximal Weight Clique Selection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jin_Harmonious_Semantic_Line_Detection_via_Maximal_Weight_Clique_Selection_CVPR_2021_paper.html",
        "author": "Dongkwon Jin, Wonhui Park, Seong-Gyun Jeong, Chang-Su Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jin_Harmonious_Semantic_Line_Detection_via_Maximal_Weight_Clique_Selection_CVPR_2021_paper.pdf",
        "aff": "Korea University; 42dot.ai",
        "project": "",
        "github": "https://github.com/dongkwonjin/Semantic-Line-MWCS",
        "arxiv": "2104.06903"
    },
    {
        "title": "Heterogeneous Grid Convolution for Adaptive, Efficient, and Controllable Computation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hamaguchi_Heterogeneous_Grid_Convolution_for_Adaptive_Efficient_and_Controllable_Computation_CVPR_2021_paper.html",
        "author": "Ryuhei Hamaguchi, Yasutaka Furukawa, Masaki Onishi, Ken Sakurada",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hamaguchi_Heterogeneous_Grid_Convolution_for_Adaptive_Efficient_and_Controllable_Computation_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; National Institute of Advanced Industrial Science and Technology (AIST)",
        "project": "",
        "github": "",
        "arxiv": "2104.11176"
    },
    {
        "title": "Hierarchical Layout-Aware Graph Convolutional Network for Unified Aesthetics Assessment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/She_Hierarchical_Layout-Aware_Graph_Convolutional_Network_for_Unified_Aesthetics_Assessment_CVPR_2021_paper.html",
        "author": "Dongyu She, Yu-Kun Lai, Gaoxiong Yi, Kun Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/She_Hierarchical_Layout-Aware_Graph_Convolutional_Network_for_Unified_Aesthetics_Assessment_CVPR_2021_paper.pdf",
        "aff": "Tencent; Cardiff University; Tsinghua University",
        "project": "",
        "github": "http://github.com/days1011/HLAGCN",
        "arxiv": ""
    },
    {
        "title": "Hierarchical Lovasz Embeddings for Proposal-Free Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kerola_Hierarchical_Lovasz_Embeddings_for_Proposal-Free_Panoptic_Segmentation_CVPR_2021_paper.html",
        "author": "Tommi Kerola, Jie Li, Atsushi Kanehira, Yasunori Kudo, Alexis Vallet, Adrien Gaidon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kerola_Hierarchical_Lovasz_Embeddings_for_Proposal-Free_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Preferred Networks, Inc.; Toyota Research Institute (TRI)",
        "project": "",
        "github": "",
        "arxiv": "2106.04555"
    },
    {
        "title": "Hierarchical Motion Understanding via Motion Programs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kulal_Hierarchical_Motion_Understanding_via_Motion_Programs_CVPR_2021_paper.html",
        "author": "Sumith Kulal, Jiayuan Mao, Alex Aiken, Jiajun Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kulal_Hierarchical_Motion_Understanding_via_Motion_Programs_CVPR_2021_paper.pdf",
        "aff": "Stanford University; MIT",
        "project": "",
        "github": "https://sumith1896.github.io/motion2prog",
        "arxiv": "2104.11216"
    },
    {
        "title": "Hierarchical Video Prediction Using Relational Layouts for Human-Object Interactions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bodla_Hierarchical_Video_Prediction_Using_Relational_Layouts_for_Human-Object_Interactions_CVPR_2021_paper.html",
        "author": "Navaneeth Bodla, Gaurav Shrivastava, Rama Chellappa, Abhinav Shrivastava",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bodla_Hierarchical_Video_Prediction_Using_Relational_Layouts_for_Human-Object_Interactions_CVPR_2021_paper.pdf",
        "aff": "University of Maryland, College Park; Johns Hopkins University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Hierarchical and Partially Observable Goal-Driven Policy Learning With Goals Relational Graph",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Hierarchical_and_Partially_Observable_Goal-Driven_Policy_Learning_With_Goals_Relational_CVPR_2021_paper.html",
        "author": "Xin Ye, Yezhou Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ye_Hierarchical_and_Partially_Observable_Goal-Driven_Policy_Learning_With_Goals_Relational_CVPR_2021_paper.pdf",
        "aff": "Active Perception Group, School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, USA",
        "project": "",
        "github": "https://github.com/Xin-Ye-1/HRL-GRG",
        "arxiv": "2103.01350"
    },
    {
        "title": "High-Fidelity Face Tracking for AR/VR via Deep Lighting Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_High-Fidelity_Face_Tracking_for_ARVR_via_Deep_Lighting_Adaptation_CVPR_2021_paper.html",
        "author": "Lele Chen, Chen Cao, Fernando De la Torre, Jason Saragih, Chenliang Xu, Yaser Sheikh",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_High-Fidelity_Face_Tracking_for_ARVR_via_Deep_Lighting_Adaptation_CVPR_2021_paper.pdf",
        "aff": "Facebook Reality Labs; University of Rochester; Facebook Reality Labs, University of Rochester",
        "project": "this website",
        "github": "",
        "arxiv": "2103.15876"
    },
    {
        "title": "High-Fidelity Neural Human Motion Transfer From Monocular Video",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kappel_High-Fidelity_Neural_Human_Motion_Transfer_From_Monocular_Video_CVPR_2021_paper.html",
        "author": "Moritz Kappel, Vladislav Golyanik, Mohamed Elgharib, Jann-Ole Henningson, Hans-Peter Seidel, Susana Castillo, Christian Theobalt, Marcus Magnor",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kappel_High-Fidelity_Neural_Human_Motion_Transfer_From_Monocular_Video_CVPR_2021_paper.pdf",
        "aff": "Computer Graphics Lab, TU Braunschweig, Germany; Max Planck Institute for Informatics, Saarland Informatics Campus, Germany",
        "project": "",
        "github": "https://graphics.tu-bs.de/publications/kappel2020high-fidelity",
        "arxiv": "2012.10974"
    },
    {
        "title": "High-Fidelity and Arbitrary Face Editing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_High-Fidelity_and_Arbitrary_Face_Editing_CVPR_2021_paper.html",
        "author": "Yue Gao, Fangyun Wei, Jianmin Bao, Shuyang Gu, Dong Chen, Fang Wen, Zhouhui Lian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_High-Fidelity_and_Arbitrary_Face_Editing_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; Wangxuan Institute of Computer Technology, Peking University, China; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2103.15814"
    },
    {
        "title": "High-Quality Stereo Image Restoration From Double Refraction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_High-Quality_Stereo_Image_Restoration_From_Double_Refraction_CVPR_2021_paper.html",
        "author": "Hakyeong Kim, Andreas Meuleman, Daniel S. Jeon, Min H. Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_High-Quality_Stereo_Image_Restoration_From_Double_Refraction_CVPR_2021_paper.pdf",
        "aff": "KAIST",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "High-Resolution Photorealistic Image Translation in Real-Time: A Laplacian Pyramid Translation Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liang_High-Resolution_Photorealistic_Image_Translation_in_Real-Time_A_Laplacian_Pyramid_Translation_CVPR_2021_paper.html",
        "author": "Jie Liang, Hui Zeng, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liang_High-Resolution_Photorealistic_Image_Translation_in_Real-Time_A_Laplacian_Pyramid_Translation_CVPR_2021_paper.pdf",
        "aff": "The HongKong Polytechnic University, DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/csjliang/LPTN",
        "arxiv": ""
    },
    {
        "title": "High-Speed Image Reconstruction Through Short-Term Plasticity for Spiking Cameras",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_High-Speed_Image_Reconstruction_Through_Short-Term_Plasticity_for_Spiking_Cameras_CVPR_2021_paper.html",
        "author": "Yajing Zheng, Lingxiao Zheng, Zhaofei Yu, Boxin Shi, Yonghong Tian, Tiejun Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_High-Speed_Image_Reconstruction_Through_Short-Term_Plasticity_for_Spiking_Cameras_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Technology, Peking University; Department of Computer Science and Technology, Peking University; Institute for Arti\ufb01cial Intelligence, Peking University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Hijack-GAN: Unintended-Use of Pretrained, Black-Box GANs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Hijack-GAN_Unintended-Use_of_Pretrained_Black-Box_GANs_CVPR_2021_paper.html",
        "author": "Hui-Po Wang, Ning Yu, Mario Fritz",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Hijack-GAN_Unintended-Use_of_Pretrained_Black-Box_GANs_CVPR_2021_paper.pdf",
        "aff": "CISPA Helmholtz Center for Information Security, Germany; Max Planck Institute for Informatics, Saarland Informatics Campus, Germany",
        "project": "",
        "github": "https://github.com/a514514772/hijackgan",
        "arxiv": ""
    },
    {
        "title": "Hilbert Sinkhorn Divergence for Optimal Transport",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Hilbert_Sinkhorn_Divergence_for_Optimal_Transport_CVPR_2021_paper.html",
        "author": "Qian Li, Zhichao Wang, Gang Li, Jun Pang, Guandong Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Hilbert_Sinkhorn_Divergence_for_Optimal_Transport_CVPR_2021_paper.pdf",
        "aff": "Faculty of Engineering and Information Technology, University of Technology Sydney, Australia; School of Electrical Engineering and Telecommunications, University of New South Wales, Australia; Faculty of Science, Technology and Medicine, University of Luxembourg; Centre for Cyber Security Research and Innovation, Deakin University, Geelong, VIC 3216, Australia",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HistoGAN: Controlling Colors of GAN-Generated and Real Images via Color Histograms",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Afifi_HistoGAN_Controlling_Colors_of_GAN-Generated_and_Real_Images_via_Color_CVPR_2021_paper.html",
        "author": "Mahmoud Afifi, Marcus A. Brubaker, Michael S. Brown",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Afifi_HistoGAN_Controlling_Colors_of_GAN-Generated_and_Real_Images_via_Color_CVPR_2021_paper.pdf",
        "aff": "York University",
        "project": "",
        "github": "",
        "arxiv": "2011.11731"
    },
    {
        "title": "HoHoNet: 360 Indoor Holistic Understanding With Latent Horizontal Features",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_HoHoNet_360_Indoor_Holistic_Understanding_With_Latent_Horizontal_Features_CVPR_2021_paper.html",
        "author": "Cheng Sun, Min Sun, Hwann-Tzong Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_HoHoNet_360_Indoor_Holistic_Understanding_With_Latent_Horizontal_Features_CVPR_2021_paper.pdf",
        "aff": "1. National Tsing Hua University, 4. Aeolus Robotics; 1. National Tsing Hua University, 3. Joint Research Center for AI Technology and All Vista Healthcare; 1. National Tsing Hua University, 2. ASUS AICS Department",
        "project": "",
        "github": "https://github.com/sunset1995/HoHoNet",
        "arxiv": "2011.11498"
    },
    {
        "title": "Holistic 3D Human and Scene Mesh Estimation From Single View Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Weng_Holistic_3D_Human_and_Scene_Mesh_Estimation_From_Single_View_CVPR_2021_paper.html",
        "author": "Zhenzhen Weng, Serena Yeung",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Weng_Holistic_3D_Human_and_Scene_Mesh_Estimation_From_Single_View_CVPR_2021_paper.pdf",
        "aff": "Stanford University",
        "project": "",
        "github": "",
        "arxiv": "2012.01591"
    },
    {
        "title": "Holistic 3D Scene Understanding From a Single Image With Implicit Representation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Holistic_3D_Scene_Understanding_From_a_Single_Image_With_Implicit_CVPR_2021_paper.html",
        "author": "Cheng Zhang, Zhaopeng Cui, Yinda Zhang, Bing Zeng, Marc Pollefeys, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Holistic_3D_Scene_Understanding_From_a_Single_Image_With_Implicit_CVPR_2021_paper.pdf",
        "aff": "Google; University of Electronic Science and Technology of China; State Key Lab of CAD & CG, Zhejiang University; ETH Z\u00fcrich",
        "project": "https://chengzhag.github.io/publication/im3d/",
        "github": "",
        "arxiv": "2103.06422"
    },
    {
        "title": "Home Action Genome: Cooperative Compositional Action Understanding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Rai_Home_Action_Genome_Cooperative_Compositional_Action_Understanding_CVPR_2021_paper.html",
        "author": "Nishant Rai, Haofeng Chen, Jingwei Ji, Rishi Desai, Kazuki Kozuka, Shun Ishizaka, Ehsan Adeli, Juan Carlos Niebles",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Rai_Home_Action_Genome_Cooperative_Compositional_Action_Understanding_CVPR_2021_paper.pdf",
        "aff": "Stanford University; Panasonic Corporation",
        "project": "http://www.homeactiongenome.org",
        "github": "",
        "arxiv": "2105.05226"
    },
    {
        "title": "HourNAS: Extremely Fast Neural Architecture Search Through an Hourglass Lens",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_HourNAS_Extremely_Fast_Neural_Architecture_Search_Through_an_Hourglass_Lens_CVPR_2021_paper.html",
        "author": "Zhaohui Yang, Yunhe Wang, Xinghao Chen, Jianyuan Guo, Wei Zhang, Chao Xu, Chunjing Xu, Dacheng Tao, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_HourNAS_Extremely_Fast_Neural_Architecture_Search_Through_an_Hourglass_Lens_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, Faculty of Engineering, University of Sydney; Noah\u2019s Ark Lab, Huawei Technologies; Key Lab of Machine Perception (MOE), Dept. of Machine Intelligence, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2005.14446"
    },
    {
        "title": "House-GAN++: Generative Adversarial Layout Refinement Network towards Intelligent Computational Agent for Professional Architects",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nauata_House-GAN_Generative_Adversarial_Layout_Refinement_Network_towards_Intelligent_Computational_Agent_CVPR_2021_paper.html",
        "author": "Nelson Nauata, Sepidehsadat Hosseini, Kai-Hung Chang, Hang Chu, Chin-Yi Cheng, Yasutaka Furukawa",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nauata_House-GAN_Generative_Adversarial_Layout_Refinement_Network_towards_Intelligent_Computational_Agent_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; Autodesk Research",
        "project": "https://ennauata.github.io/houseganpp/page.html",
        "github": "https://github.com/ennauata/houseganpp",
        "arxiv": ""
    },
    {
        "title": "How Does Topology Influence Gradient Propagation and Model Performance of Deep Networks With DenseNet-Type Skip Connections?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bhardwaj_How_Does_Topology_Influence_Gradient_Propagation_and_Model_Performance_of_CVPR_2021_paper.html",
        "author": "Kartikeya Bhardwaj, Guihong Li, Radu Marculescu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bhardwaj_How_Does_Topology_Influence_Gradient_Propagation_and_Model_Performance_of_CVPR_2021_paper.pdf",
        "aff": "The University of Texas at Austin, Austin, TX, USA 78712; Arm Inc., San Jose, CA, USA 95134",
        "project": "",
        "github": "https://github.com/SLDGroup/NN_Mass",
        "arxiv": "1910.00780"
    },
    {
        "title": "How Privacy-Preserving Are Line Clouds? Recovering Scene Details From 3D Lines",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chelani_How_Privacy-Preserving_Are_Line_Clouds_Recovering_Scene_Details_From_3D_CVPR_2021_paper.html",
        "author": "Kunal Chelani, Fredrik Kahl, Torsten Sattler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chelani_How_Privacy-Preserving_Are_Line_Clouds_Recovering_Scene_Details_From_3D_CVPR_2021_paper.pdf",
        "aff": "Chalmers University of Technology; Chalmers University of Technology, Czech Technical University in Prague",
        "project": "",
        "github": "https://github.com/kunalchelani/Line2Point",
        "arxiv": "2103.05086"
    },
    {
        "title": "How Robust Are Randomized Smoothing Based Defenses to Data Poisoning?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mehra_How_Robust_Are_Randomized_Smoothing_Based_Defenses_to_Data_Poisoning_CVPR_2021_paper.html",
        "author": "Akshay Mehra, Bhavya Kailkhura, Pin-Yu Chen, Jihun Hamm",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mehra_How_Robust_Are_Randomized_Smoothing_Based_Defenses_to_Data_Poisoning_CVPR_2021_paper.pdf",
        "aff": "IBM Research; Tulane University; Lawrence Livermore National Laboratory",
        "project": "",
        "github": "",
        "arxiv": "2012.01274"
    },
    {
        "title": "How To Exploit the Transferability of Learned Image Compression to Conventional Codecs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Klopp_How_To_Exploit_the_Transferability_of_Learned_Image_Compression_to_CVPR_2021_paper.html",
        "author": "Jan P. Klopp, Keng-Chi Liu, Liang-Gee Chen, Shao-Yi Chien",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Klopp_How_To_Exploit_the_Transferability_of_Learned_Image_Compression_to_CVPR_2021_paper.pdf",
        "aff": "National Taiwan University; Taiwan AI Labs",
        "project": "",
        "github": "",
        "arxiv": "2012.01874"
    },
    {
        "title": "How Transferable Are Reasoning Patterns in VQA?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kervadec_How_Transferable_Are_Reasoning_Patterns_in_VQA_CVPR_2021_paper.html",
        "author": "Corentin Kervadec, Theo Jaunet, Grigory Antipov, Moez Baccouche, Romain Vuillemot, Christian Wolf",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kervadec_How_Transferable_Are_Reasoning_Patterns_in_VQA_CVPR_2021_paper.pdf",
        "aff": "Orange, Cesson-S\u00e9vign\u00e9, France; LIRIS, INSA - \u00c9cole Centrale, Lyon, UMR CNRS 5205, France",
        "project": "https://reasoningpatterns.github.io",
        "github": "https://github.com/corentinkervadec",
        "arxiv": "2104.03656"
    },
    {
        "title": "How Well Do Self-Supervised Models Transfer?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ericsson_How_Well_Do_Self-Supervised_Models_Transfer_CVPR_2021_paper.html",
        "author": "Linus Ericsson, Henry Gouk, Timothy M. Hospedales",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ericsson_How_Well_Do_Self-Supervised_Models_Transfer_CVPR_2021_paper.pdf",
        "aff": "University of Edinburgh, Samsung AI Research, Cambridge; University of Edinburgh",
        "project": "",
        "github": "",
        "arxiv": "2011.13377"
    },
    {
        "title": "How2Sign: A Large-Scale Multimodal Dataset for Continuous American Sign Language",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Duarte_How2Sign_A_Large-Scale_Multimodal_Dataset_for_Continuous_American_Sign_Language_CVPR_2021_paper.html",
        "author": "Amanda Duarte, Shruti Palaskar, Lucas Ventura, Deepti Ghadiyaram, Kenneth DeHaan, Florian Metze, Jordi Torres, Xavier Giro-i-Nieto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Duarte_How2Sign_A_Large-Scale_Multimodal_Dataset_for_Continuous_American_Sign_Language_CVPR_2021_paper.pdf",
        "aff": "Universitat Polit\u00e8cnica de Catalunya, Barcelona Supercomputing Center, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC; Carnegie Mellon University; Carnegie Mellon University, Facebook AI; Facebook AI; Universitat Polit\u00e8cnica de Catalunya, Barcelona Supercomputing Center; Gallaudet University",
        "project": "",
        "github": "http://how2sign.github.io/",
        "arxiv": "2008.08143"
    },
    {
        "title": "Human De-Occlusion: Invisible Perception and Recovery for Humans",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Human_De-Occlusion_Invisible_Perception_and_Recovery_for_Humans_CVPR_2021_paper.html",
        "author": "Qiang Zhou, Shiyin Wang, Yitong Wang, Zilong Huang, Xinggang Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Human_De-Occlusion_Invisible_Perception_and_Recovery_for_Humans_CVPR_2021_paper.pdf",
        "aff": "School of EIC, Huazhong University of Science and Technology; ByteDance Inc.",
        "project": "https://sydney0zq.github.io/ahp/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Human POSEitioning System (HPS): 3D Human Pose Estimation and Self-Localization in Large Scenes From Body-Mounted Sensors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guzov_Human_POSEitioning_System_HPS_3D_Human_Pose_Estimation_and_Self-Localization_CVPR_2021_paper.html",
        "author": "Vladimir Guzov, Aymen Mir, Torsten Sattler, Gerard Pons-Moll",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guzov_Human_POSEitioning_System_HPS_3D_Human_Pose_Estimation_and_Self-Localization_CVPR_2021_paper.pdf",
        "aff": "CIIRC, Czech Technical University in Prague, Czech Republic; University of T\u00fcbingen, Germany; Max Planck Institute for Informatics, Germany",
        "project": "http://virtualhumans.mpi-inf.mpg.de/hps/",
        "github": "",
        "arxiv": "2103.17265"
    },
    {
        "title": "Human-Like Controllable Image Captioning With Verb-Specific Semantic Roles",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Human-Like_Controllable_Image_Captioning_With_Verb-Specific_Semantic_Roles_CVPR_2021_paper.html",
        "author": "Long Chen, Zhihong Jiang, Jun Xiao, Wei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Human-Like_Controllable_Image_Captioning_With_Verb-Specific_Semantic_Roles_CVPR_2021_paper.pdf",
        "aff": "Human-like Controllable Image Captioning with Verb-speci\ufb01c Semantic Roles\nLong Chen2,3\u2217Zhihong Jiang1\u2217Jun Xiao1\u2020Wei Liu4\n1Zhejiang University2Tencent AI Lab3Columbia University4Tencent Data Platform\nzjuchenlong@gmail.com, {zjujiangzhihong, junx }@zju.edu.cn, wl2223@columbia.edu\nCS:\nCap: a man riding a wave on a \nsurfboard.\nCS:\nCap: a man riding a wave on a \nsurfboard in his hand in the sky .\nCS: level 3 (15-19)\nCap: a group of people sitting next \nto each other in front of a tree.\nCS: level 4 (20-25)\nCap: a group of men and two boys \nare standing in front of a refrigerator \nin front of a house.\nCS:sit; Arg1, Arg2\nCap: a man sitting on a bench .\nCS: sit; Arg1, Arg2,LOCCS: read ; <Arg0,\t2>, Arg1\nCap: a man on a playground \nreading a book .\nCS: read ; Arg0, Arg1, <LOC,\t2>\nCap: a man reading a book on a \nbench in a park .Cap: a man sitting on a bench next \nto a playground .\n(a) Content-controlled Signal (b) Structure-controlled Signal\n(c) Verb -specific Semantic Roles \u2713\n\u2717\u2713\n\u2717\n\u2713\n\u2713\u2713\n\u2713\nFigure 1: The CS and Cap in each sample denote the c ontrol s ignal and generated cap tion, respectively. (a):The captions are generated by\nmodel SCT [ 16], which uses a set of visual regions as control signals. When control signals don\u2019t meet the event-compatible requirement\n(e.g., objectshand andsky), SCT generates lower quality captions (red cross). (b): The captions are generated by model LaBERT [ 19],\nwhich uses different length-levels as control signals. When control signals don\u2019t meet the sample-suitable requirement ( e.g., level 4), the\nLaBERT generates lower quality captions. (c): The captions are generated by our framework with VSR as control signals. For brevity, we\nabbreviate <role,1>torole in all samples. Arg andLOC denote \u201cargument\u201d and \u201clocation\u201d, respectively. For verb sit,Arg1 and\nArg2 are \u201cthing sitting\u201d and \u201csitting position\u201d, respectively. For verb read ,Arg0 andArg1 are \u201creader\u201d and \u201cthing read\u201d, respectively.\nAbstract\nControllable Image Captioning (CIC) \u2014 generating im-\nage descriptions following designated control signals \u2014 has\nreceived unprecedented attention over the last few years.\nTo emulate the human ability in controlling caption gener-\nation, current CIC studies focus exclusively on control sig-\nnals concerning objective properties, such as contents of\ninterest or descriptive patterns. However, we argue that al-\nmost all existing objective control signals have overlooked\ntwo indispensable characteristics of an ideal control sig-\nnal: 1) Event-compatible: all visual contents referred to in\na single sentence should be compatible with the described\nactivity. 2) Sample-suitable: the control signals should be\nsuitable for a speci\ufb01c image sample. To this end, we pro-\npose a new control signal for CIC: Verb-speci\ufb01c Seman-\ntic Roles (VSR). VSR consists of a verb and some semantic\n\u2217denotes equal contributions,\u2020denotes the corresponding author.roles, which represents a targeted activity and the roles of\nentities involved in this activity. Given a designated VSR, we\n\ufb01rst train a grounded semantic role labeling (GSRL) model\nto identify and ground all entities for each role. Then, we\npropose a semantic structure planner (SSP) to learn human-\nlike descriptive semantic structures. Lastly, we use a role-\nshift captioning model to generate the captions. Extensive\nexperiments and ablations demonstrate that our framework\ncan achieve better controllability than several strong base-\nlines on two challenging CIC benchmarks. Besides, we can\ngenerate multi-level diverse captions easily. The code is\navailable at: https://github.com/mad-red/VSR-guided-CIC .\n1. Introduction\nImage captioning, i.e., generating \ufb02uent and meaningful\ndescriptions to summarize the salient contents of an image,\nis a classic proxy task for comprehensive scene understand-\n16846\n",
        "project": "",
        "github": "",
        "arxiv": "2103.12204"
    },
    {
        "title": "HumanGPS: Geodesic PreServing Feature for Dense Human Correspondences",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tan_HumanGPS_Geodesic_PreServing_Feature_for_Dense_Human_Correspondences_CVPR_2021_paper.html",
        "author": "Feitong Tan, Danhang Tang, Mingsong Dou, Kaiwen Guo, Rohit Pandey, Cem Keskin, Ruofei Du, Deqing Sun, Sofien Bouaziz, Sean Fanello, Ping Tan, Yinda Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_HumanGPS_Geodesic_PreServing_Feature_for_Dense_Human_Correspondences_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; Google",
        "project": "https://feitongt.github.io/HumanGPS/",
        "github": "",
        "arxiv": "2103.15573"
    },
    {
        "title": "Humble Teachers Teach Better Students for Semi-Supervised Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Humble_Teachers_Teach_Better_Students_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.html",
        "author": "Yihe Tang, Weifeng Chen, Yijun Luo, Yuting Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Humble_Teachers_Teach_Better_Students_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Amazon Web Services; Carnegie Mellon University",
        "project": "http://yihet.com/humble-teacher",
        "github": "",
        "arxiv": "2106.10456"
    },
    {
        "title": "HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D Human Pose and Shape Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_HybrIK_A_Hybrid_Analytical-Neural_Inverse_Kinematics_Solution_for_3D_Human_CVPR_2021_paper.html",
        "author": "Jiefeng Li, Chao Xu, Zhicun Chen, Siyuan Bian, Lixin Yang, Cewu Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_HybrIK_A_Hybrid_Analytical-Neural_Inverse_Kinematics_Solution_for_3D_Human_CVPR_2021_paper.pdf",
        "aff": "Shanghai Jiao Tong University, China",
        "project": "",
        "github": "https://github.com/Jeff-sjtu/HybrIK",
        "arxiv": "2011.14672"
    },
    {
        "title": "Hybrid Message Passing With Performance-Driven Structures for Facial Action Unit Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_Hybrid_Message_Passing_With_Performance-Driven_Structures_for_Facial_Action_Unit_CVPR_2021_paper.html",
        "author": "Tengfei Song, Zijun Cui, Wenming Zheng, Qiang Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Hybrid_Message_Passing_With_Performance-Driven_Structures_for_Facial_Action_Unit_CVPR_2021_paper.pdf",
        "aff": "Rensselaer Polytechnic Institute; Southeast University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Hybrid_Rotation_Averaging_A_Fast_and_Robust_Rotation_Averaging_Approach_CVPR_2021_paper.html",
        "author": "Yu Chen, Ji Zhao, Laurent Kneip",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Hybrid_Rotation_Averaging_A_Fast_and_Robust_Rotation_Averaging_Approach_CVPR_2021_paper.pdf",
        "aff": "Peking University; TuSimple; ShanghaiTech University",
        "project": "",
        "github": "",
        "arxiv": "2101.09116"
    },
    {
        "title": "Hyper-LifelongGAN: Scalable Lifelong Learning for Image Conditioned Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhai_Hyper-LifelongGAN_Scalable_Lifelong_Learning_for_Image_Conditioned_Generation_CVPR_2021_paper.html",
        "author": "Mengyao Zhai, Lei Chen, Greg Mori",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhai_Hyper-LifelongGAN_Scalable_Lifelong_Learning_for_Image_Conditioned_Generation_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "HyperSeg: Patch-Wise Hypernetwork for Real-Time Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nirkin_HyperSeg_Patch-Wise_Hypernetwork_for_Real-Time_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Yuval Nirkin, Lior Wolf, Tal Hassner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nirkin_HyperSeg_Patch-Wise_Hypernetwork_for_Real-Time_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Facebook AI & Bar-Ilan University; Facebook AI; Facebook AI & Tel Aviv University",
        "project": "https://nirkin.com/hyperseg",
        "github": "",
        "arxiv": "2012.11582"
    },
    {
        "title": "Hyperdimensional Computing as a Framework for Systematic Aggregation of Image Descriptors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Neubert_Hyperdimensional_Computing_as_a_Framework_for_Systematic_Aggregation_of_Image_CVPR_2021_paper.html",
        "author": "Peer Neubert, Stefan Schubert",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Neubert_Hyperdimensional_Computing_as_a_Framework_for_Systematic_Aggregation_of_Image_CVPR_2021_paper.pdf",
        "aff": "Chemnitz University of Technology",
        "project": "",
        "github": "",
        "arxiv": "2101.07720"
    },
    {
        "title": "I3Net: Implicit Instance-Invariant Network for Adapting One-Stage Object Detectors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_I3Net_Implicit_Instance-Invariant_Network_for_Adapting_One-Stage_Object_Detectors_CVPR_2021_paper.html",
        "author": "Chaoqi Chen, Zebiao Zheng, Yue Huang, Xinghao Ding, Yizhou Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_I3Net_Implicit_Instance-Invariant_Network_for_Adapting_One-Stage_Object_Detectors_CVPR_2021_paper.pdf",
        "aff": "School of Informatics, Xiamen University, China; The University of Hong Kong; The University of Hong Kong, Deepwise AI Lab",
        "project": "",
        "github": "",
        "arxiv": "2103.13757"
    },
    {
        "title": "IBRNet: Learning Multi-View Image-Based Rendering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_IBRNet_Learning_Multi-View_Image-Based_Rendering_CVPR_2021_paper.html",
        "author": "Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul P. Srinivasan, Howard Zhou, Jonathan T. Barron, Ricardo Martin-Brualla, Noah Snavely, Thomas Funkhouser",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_IBRNet_Learning_Multi-View_Image-Based_Rendering_CVPR_2021_paper.pdf",
        "aff": "Google Research, Cornell Tech, Cornell University; Google Research, Princeton University; Google Research",
        "project": "",
        "github": "https://ibrnet.github.io/",
        "arxiv": "2102.13090"
    },
    {
        "title": "ID-Unet: Iterative Soft and Hard Deformation for View Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yin_ID-Unet_Iterative_Soft_and_Hard_Deformation_for_View_Synthesis_CVPR_2021_paper.html",
        "author": "Mingyu Yin, Li Sun, Qingli Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_ID-Unet_Iterative_Soft_and_Hard_Deformation_for_View_Synthesis_CVPR_2021_paper.pdf",
        "aff": "Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, 200241 Shanghai, China; Key Laboratory of Advanced Theory and Application in Statistics & Data Science, East China Normal University, 200241 Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, 200241 Shanghai, China",
        "project": "",
        "github": "https://github.com/MingyuY/Iterative-view-synthesis",
        "arxiv": ""
    },
    {
        "title": "IIRC: Incremental Implicitly-Refined Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Abdelsalam_IIRC_Incremental_Implicitly-Refined_Classification_CVPR_2021_paper.html",
        "author": "Mohamed Abdelsalam, Mojtaba Faramarzi, Shagun Sodhani, Sarath Chandar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Abdelsalam_IIRC_Incremental_Implicitly-Refined_Classification_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; Mila - Quebec AI Institute, Ecole Polytechnique de Montr\u00b4eal, Canada CIFAR AI Chair; Mila - Quebec AI Institute, University of Montreal",
        "project": "",
        "github": "",
        "arxiv": "2012.12477"
    },
    {
        "title": "IMAGINE: Image Synthesis by Image-Guided Model Inversion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_IMAGINE_Image_Synthesis_by_Image-Guided_Model_Inversion_CVPR_2021_paper.html",
        "author": "Pei Wang, Yijun Li, Krishna Kumar Singh, Jingwan Lu, Nuno Vasconcelos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_IMAGINE_Image_Synthesis_by_Image-Guided_Model_Inversion_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; UC, San Diego",
        "project": "",
        "github": "",
        "arxiv": "2104.05895"
    },
    {
        "title": "IMODAL: Creating Learnable User-Defined Deformation Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lacroix_IMODAL_Creating_Learnable_User-Defined_Deformation_Models_CVPR_2021_paper.html",
        "author": "Leander Lacroix, Benjamin Charlier, Alain Trouve, Barbara Gris",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lacroix_IMODAL_Creating_Learnable_User-Defined_Deformation_Models_CVPR_2021_paper.pdf",
        "aff": "INSERM U1299, Universit\u00e9 Paris-Saclay; IMAG, Univ. Montpellier, France; Centre Borelli, ENS Paris-Saclay; LJLL, Sorbonne Universit\u00e9, CNRS",
        "project": "",
        "github": "https://github.com/imodal",
        "arxiv": ""
    },
    {
        "title": "IQDet: Instance-Wise Quality Distribution Sampling for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_IQDet_Instance-Wise_Quality_Distribution_Sampling_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Yuchen Ma, Songtao Liu, Zeming Li, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_IQDet_Instance-Wise_Quality_Distribution_Sampling_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Megvii Technology",
        "project": "",
        "github": "",
        "arxiv": "2104.06936"
    },
    {
        "title": "Im2Vec: Synthesizing Vector Graphics Without Vector Supervision",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Reddy_Im2Vec_Synthesizing_Vector_Graphics_Without_Vector_Supervision_CVPR_2021_paper.html",
        "author": "Pradyumna Reddy, Michael Gharbi, Michal Lukac, Niloy J. Mitra",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Reddy_Im2Vec_Synthesizing_Vector_Graphics_Without_Vector_Supervision_CVPR_2021_paper.pdf",
        "aff": "University College London; Adobe Research; University College London and Adobe Research",
        "project": "http://geometry.cs.ucl.ac.uk/projects/2021/Im2Vec/",
        "github": "",
        "arxiv": "2102.02798"
    },
    {
        "title": "Image Change Captioning by Learning From an Auxiliary Task",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hosseinzadeh_Image_Change_Captioning_by_Learning_From_an_Auxiliary_Task_CVPR_2021_paper.html",
        "author": "Mehrdad Hosseinzadeh, Yang Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hosseinzadeh_Image_Change_Captioning_by_Learning_From_an_Auxiliary_Task_CVPR_2021_paper.pdf",
        "aff": "University of Manitoba; Huawei Technologies Canada",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Image De-Raining via Continual Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Image_De-Raining_via_Continual_Learning_CVPR_2021_paper.html",
        "author": "Man Zhou, Jie Xiao, Yifan Chang, Xueyang Fu, Aiping Liu, Jinshan Pan, Zheng-Jun Zha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Image_De-Raining_via_Continual_Learning_CVPR_2021_paper.pdf",
        "aff": "University of Science and Technology of China, China; Nanjing University of Science and Technology, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Image Generators With Conditionally-Independent Pixel Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Anokhin_Image_Generators_With_Conditionally-Independent_Pixel_Synthesis_CVPR_2021_paper.html",
        "author": "Ivan Anokhin, Kirill Demochkin, Taras Khakhulin, Gleb Sterkin, Victor Lempitsky, Denis Korzhenkov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Anokhin_Image_Generators_With_Conditionally-Independent_Pixel_Synthesis_CVPR_2021_paper.pdf",
        "aff": "Samsung AI Center, Moscow; Skolkovo Institute of Science and Technology, Moscow; Samsung AI Center, Moscow",
        "project": "",
        "github": "",
        "arxiv": "2011.13775"
    },
    {
        "title": "Image Inpainting Guided by Coherence Priors of Semantics and Textures",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liao_Image_Inpainting_Guided_by_Coherence_Priors_of_Semantics_and_Textures_CVPR_2021_paper.html",
        "author": "Liang Liao, Jing Xiao, Zheng Wang, Chia-Wen Lin, Shin'ichi Satoh",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liao_Image_Inpainting_Guided_by_Coherence_Priors_of_Semantics_and_Textures_CVPR_2021_paper.pdf",
        "aff": "National Tsinghua University; National Institute of Informatics; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University",
        "project": "",
        "github": "",
        "arxiv": "2012.08054"
    },
    {
        "title": "Image Inpainting With External-Internal Learning and Monochromic Bottleneck",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Image_Inpainting_With_External-Internal_Learning_and_Monochromic_Bottleneck_CVPR_2021_paper.html",
        "author": "Tengfei Wang, Hao Ouyang, Qifeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Image_Inpainting_With_External-Internal_Learning_and_Monochromic_Bottleneck_CVPR_2021_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2104.09068"
    },
    {
        "title": "Image Restoration for Under-Display Camera",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Image_Restoration_for_Under-Display_Camera_CVPR_2021_paper.html",
        "author": "Yuqian Zhou, David Ren, Neil Emerton, Sehoon Lim, Timothy Large",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Image_Restoration_for_Under-Display_Camera_CVPR_2021_paper.pdf",
        "aff": "CIL, UC Berkeley; IFP, UIUC; Microsoft",
        "project": "",
        "github": "",
        "arxiv": "2003.04857"
    },
    {
        "title": "Image Super-Resolution With Non-Local Sparse Attention",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mei_Image_Super-Resolution_With_Non-Local_Sparse_Attention_CVPR_2021_paper.html",
        "author": "Yiqun Mei, Yuchen Fan, Yuqian Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mei_Image_Super-Resolution_With_Non-Local_Sparse_Attention_CVPR_2021_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Image-to-Image Translation via Hierarchical Style Disentanglement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Image-to-Image_Translation_via_Hierarchical_Style_Disentanglement_CVPR_2021_paper.html",
        "author": "Xinyang Li, Shengchuan Zhang, Jie Hu, Liujuan Cao, Xiaopeng Hong, Xudong Mao, Feiyue Huang, Yongjian Wu, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Image-to-Image_Translation_via_Hierarchical_Style_Disentanglement_CVPR_2021_paper.pdf",
        "aff": "Image-to-image Translation via Hierarchical Style Disentanglement\nXinyang Li1, Shengchuan Zhang1\u2217, Jie Hu1, Liujuan Cao1, Xiaopeng Hong2,3, Xudong Mao1,\nFeiyue Huang4, Yongjian Wu4, Rongrong Ji1,3,5\n1School of Informatics, Xiamen University,2Xi\u2019an Jiaotong University,3Peng Cheng Laboratory,\n4Tencent Youtu Lab,5Institute of Arti\ufb01cial Intelligence, Xiamen University,\n{imlixinyang, hujie.cpp, xudonmao }@gmail.com, {zsc2016, caoliujuan, rrji }@xmu.edu.cn,\nhongxiaopeng@mail.xjtu.edu.cn, {garyhuang,littlekenwu }@tencent.com\nAbstract\nRecently, image-to-image translation has made signi\ufb01-\ncant progress in achieving both multi-label ( i.e., translation\nconditioned on different labels) and multi-style ( i.e., gener-\nation with diverse styles) tasks. However, due to the unex-\nplored independence and exclusiveness in the labels, exist-\ning endeavors are defeated by involving uncontrolled ma-\nnipulations to the translation results. In this paper, we pro-\npose Hierarchical Style Disentanglement (HiSD) to address\nthis issue. Speci\ufb01cally, we organize the labels into a hierar-\nchical tree structure, in which independent tags, exclusive\nattributes, and disentangled styles are allocated from top to\nbottom. Correspondingly, a new translation process is de-\nsigned to adapt the above structure, in which the styles are\nidenti\ufb01ed for controllable translations. Both qualitative and\nquantitative results on the CelebA-HQ dataset verify the\nability of the proposed HiSD. The code has been released\nathttps://github.com/imlixinyang/HiSD .\n1. Introduction\nRecently, deep learning based methods have achieved\npromising results in image-to-image translation area. Early\nworks [ 47,41,21,35] learn a deterministic mapping be-\ntween two domains, which give rise to two emergent issues:\ntranslating the inputs conditioned on multiple labels, and\ngenerating diverse outputs with multiple styles. The former\nis termed the multi-label task, and the latter is termed the\nmulti-style (or multi-modal) task. For the multi-label task,\nmethods [ 5,11,20,38] combine the labels into the trans-\nlator. For the multi-style task, methods [ 15,18,1,48] in-\ncorporate latent codes drawn from Gaussian noise into the\ntranslator. Recent uni\ufb01ed solutions for these tasks can be\nclassi\ufb01ed into two categories. (i). Works [ 34,36,42,19]\nlearn the shared style by injecting the style code concate-\n\u2217Corresponding Author.With_Glasses\nBlond_Hair\nBlack_Hair\nBrown_HairWith_BangsOriginal Labels\nBangs\nGlasses\nHair colorwith\nwithout\nbrownblackblondwith\nwithout\nAttributes Tags Styles\nunsupervised\nFigure 1: Hierarchical Style Disentanglement. The origi-\nnal labels are organized into independent tags and exclusive\nattributes. We aim to disentangle the styles to represent the\nclear manifestations in attributes, in an unsupervised way.\nnated with the target labels into the generator. The shared\nstyle code does not have an explicit effect on the source im-\nage without changed labels, which is shown in Figure 3(a).\n(ii). StarGANv2 [ 6] learns the mixed style by using the tar-\nget label to index the mapped style code. It continues to\nuse the hypothesis of StarGAN [ 5] that an image domain is\nthe set of images sharing the same labels. The translations\nfrequently involve unnecessary manipulations like changing\nfacial identity and affecting background, as shown in Fig-\nure3(b). In addition, they cannot independently learn the\nrespective styles for bangs, glasses, and hair color. These\nuncontrollable translations severely limit their practical use.\nWe propose a novel framework, called Hierarchical Style\nDisentanglement, to solve the above limitations. We notice\nthe general independence and exclusiveness among most la-\nbel annotations. For example, in CelebA, original binary\nlabels \u2018With Bangs\u2019 and \u2018With Glasses\u2019 are independent,\nwhile \u2018Blond Hair\u2019 and \u2018Black Hair\u2019 are exclusive. Ac-\ncordingly, as shown in Figure 1, we organize the original\nlabels into a hierarchical structure, including independent\ntags and exclusive attributes. The tags represent different\naccordance of attributes, and every image is relabeled to\n8639\n",
        "project": "",
        "github": "",
        "arxiv": "2103.01456"
    },
    {
        "title": "Implicit Feature Alignment: Learn To Convert Text Recognizer to Text Spotter",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Implicit_Feature_Alignment_Learn_To_Convert_Text_Recognizer_to_Text_CVPR_2021_paper.html",
        "author": "Tianwei Wang, Yuanzhi Zhu, Lianwen Jin, Dezhi Peng, Zhe Li, Mengchao He, Yongpan Wang, Canjie Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Implicit_Feature_Alignment_Learn_To_Convert_Text_Recognizer_to_Text_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group; School of Electronic and Information Engineering, South China University of Technology",
        "project": "",
        "github": "https://github.com/Wang-Tianwei/Implicit-feature-alignment",
        "arxiv": "2106.05920"
    },
    {
        "title": "Improved Handling of Motion Blur in Online Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sayed_Improved_Handling_of_Motion_Blur_in_Online_Object_Detection_CVPR_2021_paper.html",
        "author": "Mohamed Sayed, Gabriel Brostow",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sayed_Improved_Handling_of_Motion_Blur_in_Online_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "University College London",
        "project": "http://visual.cs.ucl.ac.uk/pubs/handlingMotionBlur/",
        "github": "",
        "arxiv": "2011.14448"
    },
    {
        "title": "Improved Image Matting via Real-Time User Clicks and Uncertainty Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wei_Improved_Image_Matting_via_Real-Time_User_Clicks_and_Uncertainty_Estimation_CVPR_2021_paper.html",
        "author": "Tianyi Wei, Dongdong Chen, Wenbo Zhou, Jing Liao, Hanqing Zhao, Weiming Zhang, Nenghai Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wei_Improved_Image_Matting_via_Real-Time_User_Clicks_and_Uncertainty_Estimation_CVPR_2021_paper.pdf",
        "aff": "Microsoft Cloud AI; City University of Hong Kong; University of Science and Technology of China",
        "project": "https://youtu.be/pAXydeN-LpQ",
        "github": "",
        "arxiv": "2012.08323"
    },
    {
        "title": "Improving Accuracy of Binary Neural Networks Using Unbalanced Activation Distribution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Improving_Accuracy_of_Binary_Neural_Networks_Using_Unbalanced_Activation_Distribution_CVPR_2021_paper.html",
        "author": "Hyungjun Kim, Jihoon Park, Changhun Lee, Jae-Joon Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Improving_Accuracy_of_Binary_Neural_Networks_Using_Unbalanced_Activation_Distribution_CVPR_2021_paper.pdf",
        "aff": "Department of Convergence IT Engineering, Graduate School of Arti\ufb01cial Intelligence, Pohang University of Science and Technology (POSTECH), Korea; Department of Convergence IT Engineering, Pohang University of Science and Technology (POSTECH), Korea",
        "project": "",
        "github": "",
        "arxiv": "2012.00938"
    },
    {
        "title": "Improving Calibration for Long-Tailed Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Improving_Calibration_for_Long-Tailed_Recognition_CVPR_2021_paper.html",
        "author": "Zhisheng Zhong, Jiequan Cui, Shu Liu, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_Improving_Calibration_for_Long-Tailed_Recognition_CVPR_2021_paper.pdf",
        "aff": "SmartMore; Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/Jia-Research-Lab/MiSLAS",
        "arxiv": "2104.00466"
    },
    {
        "title": "Improving Multiple Object Tracking With Single Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Improving_Multiple_Object_Tracking_With_Single_Object_Tracking_CVPR_2021_paper.html",
        "author": "Linyu Zheng, Ming Tang, Yingying Chen, Guibo Zhu, Jinqiao Wang, Hanqing Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Improving_Multiple_Object_Tracking_With_Single_Object_Tracking_CVPR_2021_paper.pdf",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; ObjectEye Inc.; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Improving Multiple Pedestrian Tracking by Track Management and Occlusion Handling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Stadler_Improving_Multiple_Pedestrian_Tracking_by_Track_Management_and_Occlusion_Handling_CVPR_2021_paper.html",
        "author": "Daniel Stadler, Jurgen Beyerer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Stadler_Improving_Multiple_Pedestrian_Tracking_by_Track_Management_and_Occlusion_Handling_CVPR_2021_paper.pdf",
        "aff": "Karlsruhe Institute of Technology, Fraunhofer IOSB, Fraunhofer Center for Machine Learning; Fraunhofer IOSB, Karlsruhe Institute of Technology, Fraunhofer Center for Machine Learning",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Improving OCR-Based Image Captioning by Incorporating Geometrical Relationship",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Improving_OCR-Based_Image_Captioning_by_Incorporating_Geometrical_Relationship_CVPR_2021_paper.html",
        "author": "Jing Wang, Jinhui Tang, Mingkun Yang, Xiang Bai, Jiebo Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Improving_OCR-Based_Image_Captioning_by_Incorporating_Geometrical_Relationship_CVPR_2021_paper.pdf",
        "aff": "Huazhong University of Science and Technology; Nanjing University of Science and Technology; University of Rochester",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Improving Panoptic Segmentation at All Scales",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Porzi_Improving_Panoptic_Segmentation_at_All_Scales_CVPR_2021_paper.html",
        "author": "Lorenzo Porzi, Samuel Rota Bulo, Peter Kontschieder",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Porzi_Improving_Panoptic_Segmentation_at_All_Scales_CVPR_2021_paper.pdf",
        "aff": "Facebook",
        "project": "",
        "github": "",
        "arxiv": "2012.07717"
    },
    {
        "title": "Improving Sign Language Translation With Monolingual Data by Sign Back-Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Improving_Sign_Language_Translation_With_Monolingual_Data_by_Sign_Back-Translation_CVPR_2021_paper.html",
        "author": "Hao Zhou, Wengang Zhou, Weizhen Qi, Junfu Pu, Houqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Improving_Sign_Language_Translation_With_Monolingual_Data_by_Sign_Back-Translation_CVPR_2021_paper.pdf",
        "aff": "CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China; Institute of Artificial Intelligence, Hefei Comprehensive National Science Center",
        "project": "http://home.ustc.edu.cn/~zhouh156/dataset/csl-daily",
        "github": "",
        "arxiv": "2105.12397"
    },
    {
        "title": "Improving Transferability of Adversarial Patches on Face Recognition With Generative Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_Improving_Transferability_of_Adversarial_Patches_on_Face_Recognition_With_Generative_CVPR_2021_paper.html",
        "author": "Zihao Xiao, Xianfeng Gao, Chilin Fu, Yinpeng Dong, Wei Gao, Xiaolu Zhang, Jun Zhou, Jun Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xiao_Improving_Transferability_of_Adversarial_Patches_on_Face_Recognition_With_Generative_CVPR_2021_paper.pdf",
        "aff": "Ant Financial; Beijing Institute of Technology; Nanyang Technological University; Tsinghua University; RealAI",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Improving Unsupervised Image Clustering With Robust Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Park_Improving_Unsupervised_Image_Clustering_With_Robust_Learning_CVPR_2021_paper.html",
        "author": "Sungwon Park, Sungwon Han, Sundong Kim, Danu Kim, Sungkyu Park, Seunghoon Hong, Meeyoung Cha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Park_Improving_Unsupervised_Image_Clustering_With_Robust_Learning_CVPR_2021_paper.pdf",
        "aff": "School of Computing, KAIST; Data Science Group, Institute for Basic Science; School of Computing, KAIST; Data Science Group, Institute for Basic Science",
        "project": "",
        "github": "",
        "arxiv": "2012.11150"
    },
    {
        "title": "Improving Weakly Supervised Visual Grounding by Contrastive Knowledge Distillation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Improving_Weakly_Supervised_Visual_Grounding_by_Contrastive_Knowledge_Distillation_CVPR_2021_paper.html",
        "author": "Liwei Wang, Jing Huang, Yin Li, Kun Xu, Zhengyuan Yang, Dong Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Improving_Weakly_Supervised_Visual_Grounding_by_Contrastive_Knowledge_Distillation_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong; Tencent AI Lab, Bellevue; University of Rochester; University of Wisconsin-Madison; University of Illinois at Urbana-Champaign",
        "project": "",
        "github": "",
        "arxiv": "2007.01951"
    },
    {
        "title": "Improving the Efficiency and Robustness of Deepfakes Detection Through Precise Geometric Features",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Improving_the_Efficiency_and_Robustness_of_Deepfakes_Detection_Through_Precise_CVPR_2021_paper.html",
        "author": "Zekun Sun, Yujie Han, Zeyu Hua, Na Ruan, Weijia Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Improving_the_Efficiency_and_Robustness_of_Deepfakes_Detection_Through_Precise_CVPR_2021_paper.pdf",
        "aff": "3609",
        "project": "",
        "github": "",
        "arxiv": "2104.04480"
    },
    {
        "title": "Improving the Transferability of Adversarial Samples With Adversarial Transformations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Improving_the_Transferability_of_Adversarial_Samples_With_Adversarial_Transformations_CVPR_2021_paper.html",
        "author": "Weibin Wu, Yuxin Su, Michael R. Lyu, Irwin King",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Improving_the_Transferability_of_Adversarial_Samples_With_Adversarial_Transformations_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "In the Light of Feature Distributions: Moment Matching for Neural Style Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kalischek_In_the_Light_of_Feature_Distributions_Moment_Matching_for_Neural_CVPR_2021_paper.html",
        "author": "Nikolai Kalischek, Jan D. Wegner, Konrad Schindler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kalischek_In_the_Light_of_Feature_Distributions_Moment_Matching_for_Neural_CVPR_2021_paper.pdf",
        "aff": "EcoVision Lab, Photogrammetry and Remote Sensing, ETH Z\u00fcrich",
        "project": "",
        "github": "",
        "arxiv": "2103.07208"
    },
    {
        "title": "Inception Convolution With Efficient Dilation Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Inception_Convolution_With_Efficient_Dilation_Search_CVPR_2021_paper.html",
        "author": "Jie Liu, Chuming Li, Feng Liang, Chen Lin, Ming Sun, Junjie Yan, Wanli Ouyang, Dong Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Inception_Convolution_With_Efficient_Dilation_Search_CVPR_2021_paper.pdf",
        "aff": "Beihang University; University of Oxford; The University of Sydney; SenseTime Research, Shanghai Al Laboratory; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2012.13587"
    },
    {
        "title": "Incremental Few-Shot Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ganea_Incremental_Few-Shot_Instance_Segmentation_CVPR_2021_paper.html",
        "author": "Dan Andrei Ganea, Bas Boom, Ronald Poppe",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ganea_Incremental_Few-Shot_Instance_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Utrecht University; Cyclomedia Technology",
        "project": "",
        "github": "https://github.com/danganea/iMTFA",
        "arxiv": "2105.05312"
    },
    {
        "title": "Incremental Learning via Rate Reduction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Incremental_Learning_via_Rate_Reduction_CVPR_2021_paper.html",
        "author": "Ziyang Wu, Christina Baek, Chong You, Yi Ma",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Incremental_Learning_via_Rate_Reduction_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; Cornell",
        "project": "",
        "github": "",
        "arxiv": "2011.14593"
    },
    {
        "title": "Indoor Lighting Estimation Using an Event Camera",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Indoor_Lighting_Estimation_Using_an_Event_Camera_CVPR_2021_paper.html",
        "author": "Zehao Chen, Qian Zheng, Peisong Niu, Huajin Tang, Gang Pan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Indoor_Lighting_Estimation_Using_an_Event_Camera_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Zhejiang Lab, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Indoor Panorama Planar 3D Reconstruction via Divide and Conquer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Indoor_Panorama_Planar_3D_Reconstruction_via_Divide_and_Conquer_CVPR_2021_paper.html",
        "author": "Cheng Sun, Chi-Wei Hsiao, Ning-Hsu Wang, Min Sun, Hwann-Tzong Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Indoor_Panorama_Planar_3D_Reconstruction_via_Divide_and_Conquer_CVPR_2021_paper.pdf",
        "aff": "1National Tsing Hua University, 2ASUS AICS Department; 1National Tsing Hua University, 4Aeolus Robotics; 1National Tsing Hua University; 1National Tsing Hua University, 3Joint Research Center for AI Technology and All Vista Healthcare",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Inferring CAD Modeling Sequences Using Zone Graphs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Inferring_CAD_Modeling_Sequences_Using_Zone_Graphs_CVPR_2021_paper.html",
        "author": "Xianghao Xu, Wenzhe Peng, Chin-Yi Cheng, Karl D.D. Willis, Daniel Ritchie",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Inferring_CAD_Modeling_Sequences_Using_Zone_Graphs_CVPR_2021_paper.pdf",
        "aff": "Brown University; Autodesk Research; MIT",
        "project": "",
        "github": "",
        "arxiv": "2104.03900"
    },
    {
        "title": "Information Bottleneck Disentanglement for Identity Swapping",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Information_Bottleneck_Disentanglement_for_Identity_Swapping_CVPR_2021_paper.html",
        "author": "Gege Gao, Huaibo Huang, Chaoyou Fu, Zhaoyang Li, Ran He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Information_Bottleneck_Disentanglement_for_Identity_Swapping_CVPR_2021_paper.pdf",
        "aff": "National Laboratory of Pattern Recognition, CASIA; Center for Excellence in Brain Science and Intelligence Technology, CAS; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, CASIA; Center for Excellence in Brain Science and Intelligence Technology, CAS; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, CASIA; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Information-Theoretic Segmentation by Inpainting Error Maximization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Savarese_Information-Theoretic_Segmentation_by_Inpainting_Error_Maximization_CVPR_2021_paper.html",
        "author": "Pedro Savarese, Sunnie S. Y. Kim, Michael Maire, Greg Shakhnarovich, David McAllester",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Savarese_Information-Theoretic_Segmentation_by_Inpainting_Error_Maximization_CVPR_2021_paper.pdf",
        "aff": "University of Chicago; TTI-Chicago; Princeton University",
        "project": "",
        "github": "https://github.com/lolemacs/iem",
        "arxiv": "2012.07287"
    },
    {
        "title": "Informative and Consistent Correspondence Mining for Cross-Domain Weakly Supervised Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Informative_and_Consistent_Correspondence_Mining_for_Cross-Domain_Weakly_Supervised_Object_CVPR_2021_paper.html",
        "author": "Luwei Hou, Yu Zhang, Kui Fu, Jia Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Informative_and_Consistent_Correspondence_Mining_for_Cross-Domain_Weakly_Supervised_Object_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Instance Level Affinity-Based Transfer for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sharma_Instance_Level_Affinity-Based_Transfer_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Astuti Sharma, Tarun Kalluri, Manmohan Chandraker",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sharma_Instance_Level_Affinity-Based_Transfer_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "University of California San Diego",
        "project": "",
        "github": "https://github.com/astuti/ILA-DA",
        "arxiv": "2104.01286"
    },
    {
        "title": "Instance Localization for Self-Supervised Detection Pretraining",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Instance_Localization_for_Self-Supervised_Detection_Pretraining_CVPR_2021_paper.html",
        "author": "Ceyuan Yang, Zhirong Wu, Bolei Zhou, Stephen Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Instance_Localization_for_Self-Supervised_Detection_Pretraining_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; Chinese University of Hong Kong",
        "project": "",
        "github": "Available at the provided link",
        "arxiv": "2102.08318"
    },
    {
        "title": "Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Instant-Teaching_An_End-to-End_Semi-Supervised_Object_Detection_Framework_CVPR_2021_paper.html",
        "author": "Qiang Zhou, Chaohui Yu, Zhibin Wang, Qi Qian, Hao Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Instant-Teaching_An_End-to-End_Semi-Supervised_Object_Detection_Framework_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Intelligent Carpet: Inferring 3D Human Pose From Tactile Signals",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Intelligent_Carpet_Inferring_3D_Human_Pose_From_Tactile_Signals_CVPR_2021_paper.html",
        "author": "Yiyue Luo, Yunzhu Li, Michael Foshey, Wan Shou, Pratyusha Sharma, Tomas Palacios, Antonio Torralba, Wojciech Matusik",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Intelligent_Carpet_Inferring_3D_Human_Pose_From_Tactile_Signals_CVPR_2021_paper.pdf",
        "aff": "Massachusetts Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Intentonomy: A Dataset and Study Towards Human Intent Understanding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jia_Intentonomy_A_Dataset_and_Study_Towards_Human_Intent_Understanding_CVPR_2021_paper.html",
        "author": "Menglin Jia, Zuxuan Wu, Austin Reiter, Claire Cardie, Serge Belongie, Ser-Nam Lim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jia_Intentonomy_A_Dataset_and_Study_Towards_Human_Intent_Understanding_CVPR_2021_paper.pdf",
        "aff": "Cornell University; Facebook AI",
        "project": "",
        "github": "https://github.com/kmnp/intentonomy",
        "arxiv": "2011.05558"
    },
    {
        "title": "Interactive Self-Training With Mean Teachers for Semi-Supervised Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Interactive_Self-Training_With_Mean_Teachers_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.html",
        "author": "Qize Yang, Xihan Wei, Biao Wang, Xian-Sheng Hua, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Interactive_Self-Training_With_Mean_Teachers_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Hong Kong Polytechnic University; Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Interpolation-Based Semi-Supervised Learning for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jeong_Interpolation-Based_Semi-Supervised_Learning_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Jisoo Jeong, Vikas Verma, Minsung Hyun, Juho Kannala, Nojun Kwak",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jeong_Interpolation-Based_Semi-Supervised_Learning_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Aalto University, Finland; Seoul National University, Seoul, Korea",
        "project": "",
        "github": "https://github.com/soo89/ISD-SSD",
        "arxiv": "2006.02158"
    },
    {
        "title": "Interpretable Social Anchors for Human Trajectory Forecasting in Crowds",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kothari_Interpretable_Social_Anchors_for_Human_Trajectory_Forecasting_in_Crowds_CVPR_2021_paper.html",
        "author": "Parth Kothari, Brian Sifringer, Alexandre Alahi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kothari_Interpretable_Social_Anchors_for_Human_Trajectory_Forecasting_in_Crowds_CVPR_2021_paper.pdf",
        "aff": "EPFL VITA lab, CH-1015 Lausanne",
        "project": "",
        "github": "",
        "arxiv": "2105.03136"
    },
    {
        "title": "Interpreting Super-Resolution Networks With Local Attribution Maps",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gu_Interpreting_Super-Resolution_Networks_With_Local_Attribution_Maps_CVPR_2021_paper.html",
        "author": "Jinjin Gu, Chao Dong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gu_Interpreting_Super-Resolution_Networks_With_Local_Attribution_Maps_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Information Engineering, The University of Sydney.; Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences. SIAT Branch, Shenzhen Institute of Arti\ufb01cial Intelligence and Robotics for Society",
        "project": "",
        "github": "",
        "arxiv": "2011.11036"
    },
    {
        "title": "Interventional Video Grounding With Dual Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nan_Interventional_Video_Grounding_With_Dual_Contrastive_Learning_CVPR_2021_paper.html",
        "author": "Guoshun Nan, Rui Qiao, Yao Xiao, Jun Liu, Sicong Leng, Hao Zhang, Wei Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nan_Interventional_Video_Grounding_With_Dual_Contrastive_Learning_CVPR_2021_paper.pdf",
        "aff": "Information Systems Technology and Design, Singapore University of Technology and Design, Singapore; Shanghai Jiao Tong University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; StatNLP Research Group, Singapore University of Technology and Design",
        "project": "",
        "github": "",
        "arxiv": "2106.11013"
    },
    {
        "title": "Intra-Inter Camera Similarity for Unsupervised Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xuan_Intra-Inter_Camera_Similarity_for_Unsupervised_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Shiyu Xuan, Shiliang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xuan_Intra-Inter_Camera_Similarity_for_Unsupervised_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, School of EECS, Peking University, Beijing 100871, China",
        "project": "",
        "github": "https://github.com/SY-Xuan/IICS",
        "arxiv": "2103.11658"
    },
    {
        "title": "Intrinsic Image Harmonization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Intrinsic_Image_Harmonization_CVPR_2021_paper.html",
        "author": "Zonghui Guo, Haiyong Zheng, Yufeng Jiang, Zhaorui Gu, Bing Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Intrinsic_Image_Harmonization_CVPR_2021_paper.pdf",
        "aff": "Underwater Vision Lab (http://ouc.ai), Ocean University of China; Sanya Oceanographic Institution, Ocean University of China; Underwater Vision Lab (http://ouc.ai), Ocean University of China",
        "project": "",
        "github": "https://github.com/zhenglab/IntrinsicHarmony",
        "arxiv": ""
    },
    {
        "title": "Introvert: Human Trajectory Prediction via Conditional 3D Attention",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shafiee_Introvert_Human_Trajectory_Prediction_via_Conditional_3D_Attention_CVPR_2021_paper.html",
        "author": "Nasim Shafiee, Taskin Padir, Ehsan Elhamifar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shafiee_Introvert_Human_Trajectory_Prediction_via_Conditional_3D_Attention_CVPR_2021_paper.pdf",
        "aff": "Northeastern University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Inverse Simulation: Reconstructing Dynamic Geometry of Clothed Humans via Optimal Control",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Inverse_Simulation_Reconstructing_Dynamic_Geometry_of_Clothed_Humans_via_Optimal_CVPR_2021_paper.html",
        "author": "Jingfan Guo, Jie Li, Rahul Narain, Hyun Soo Park",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Inverse_Simulation_Reconstructing_Dynamic_Geometry_of_Clothed_Humans_via_Optimal_CVPR_2021_paper.pdf",
        "aff": "Indian Institute of Technology Delhi; University of Minnesota",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "InverseForm: A Loss Function for Structured Boundary-Aware Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Borse_InverseForm_A_Loss_Function_for_Structured_Boundary-Aware_Segmentation_CVPR_2021_paper.html",
        "author": "Shubhankar Borse, Ying Wang, Yizhe Zhang, Fatih Porikli",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Borse_InverseForm_A_Loss_Function_for_Structured_Boundary-Aware_Segmentation_CVPR_2021_paper.pdf",
        "aff": "; Qualcomm AI Research",
        "project": "",
        "github": "",
        "arxiv": "2104.02745"
    },
    {
        "title": "Invertible Denoising Network: A Light Solution for Real Noise Removal",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Invertible_Denoising_Network_A_Light_Solution_for_Real_Noise_Removal_CVPR_2021_paper.html",
        "author": "Yang Liu, Zhenyue Qin, Saeed Anwar, Pan Ji, Dongwoo Kim, Sabrina Caldwell, Tom Gedeon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Invertible_Denoising_Network_A_Light_Solution_for_Real_Noise_Removal_CVPR_2021_paper.pdf",
        "aff": "GSAI POSTECH4; Australian National University1, Data61-CSIRO2; Australian National University1; OPPO US Research3",
        "project": "",
        "github": "https://github.com/Yang-Liu1082/InvDN.git",
        "arxiv": "2104.10546"
    },
    {
        "title": "Invertible Image Signal Processing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xing_Invertible_Image_Signal_Processing_CVPR_2021_paper.html",
        "author": "Yazhou Xing, Zian Qian, Qifeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xing_Invertible_Image_Signal_Processing_CVPR_2021_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2103.15061"
    },
    {
        "title": "Inverting Generative Adversarial Renderer for Face Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Piao_Inverting_Generative_Adversarial_Renderer_for_Face_Reconstruction_CVPR_2021_paper.html",
        "author": "Jingtan Piao, Keqiang Sun, Quan Wang, Kwan-Yee Lin, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Piao_Inverting_Generative_Adversarial_Renderer_for_Face_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong; SenseTime Research; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong; School of CST, Xidian University; SenseTime Research and Tetras.AI, Shanghai AI Laboratory; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2105.02431"
    },
    {
        "title": "Invisible Perturbations: Physical Adversarial Examples Exploiting the Rolling Shutter Effect",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sayles_Invisible_Perturbations_Physical_Adversarial_Examples_Exploiting_the_Rolling_Shutter_Effect_CVPR_2021_paper.html",
        "author": "Athena Sayles, Ashish Hooda, Mohit Gupta, Rahul Chatterjee, Earlence Fernandes",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sayles_Invisible_Perturbations_Physical_Adversarial_Examples_Exploiting_the_Rolling_Shutter_Effect_CVPR_2021_paper.pdf",
        "aff": "University of Wisconsin\u2013Madison",
        "project": "",
        "github": "",
        "arxiv": "2011.13375"
    },
    {
        "title": "Involution: Inverting the Inherence of Convolution for Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Involution_Inverting_the_Inherence_of_Convolution_for_Visual_Recognition_CVPR_2021_paper.html",
        "author": "Duo Li, Jie Hu, Changhu Wang, Xiangtai Li, Qi She, Lei Zhu, Tong Zhang, Qifeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Involution_Inverting_the_Inherence_of_Convolution_for_Visual_Recognition_CVPR_2021_paper.pdf",
        "aff": "ByteDance AI Lab; Peking University; The Hong Kong University of Science and Technology",
        "project": "",
        "github": "https://github.com/d-li14/involution",
        "arxiv": "2103.06255"
    },
    {
        "title": "IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for Visual Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jia_IoU_Attack_Towards_Temporally_Coherent_Black-Box_Adversarial_Attack_for_Visual_CVPR_2021_paper.html",
        "author": "Shuai Jia, Yibing Song, Chao Ma, Xiaokang Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jia_IoU_Attack_Towards_Temporally_Coherent_Black-Box_Adversarial_Attack_for_Visual_CVPR_2021_paper.pdf",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Tencent AI Lab",
        "project": "",
        "github": "https://github.com/VISION-SJTU/IoUattack",
        "arxiv": "2103.14938"
    },
    {
        "title": "IronMask: Modular Architecture for Protecting Deep Face Template",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_IronMask_Modular_Architecture_for_Protecting_Deep_Face_Template_CVPR_2021_paper.html",
        "author": "Sunpill Kim, Yunseong Jeong, Jinsu Kim, Jungkon Kim, Hyung Tae Lee, Jae Hong Seo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_IronMask_Modular_Architecture_for_Protecting_Deep_Face_Template_CVPR_2021_paper.pdf",
        "aff": "Security Team, Samsung Research, Samsung Electronics; Division of Computer Science and Engineering, College of Engineering, Jeonbuk National University; Department of Mathematics & Research Institute for Natural Sciences, Hanyang University",
        "project": "",
        "github": "",
        "arxiv": "2104.02239"
    },
    {
        "title": "Iso-Points: Optimizing Neural Implicit Surfaces With Hybrid Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yifan_Iso-Points_Optimizing_Neural_Implicit_Surfaces_With_Hybrid_Representations_CVPR_2021_paper.html",
        "author": "Wang Yifan, Shihao Wu, Cengiz Oztireli, Olga Sorkine-Hornung",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yifan_Iso-Points_Optimizing_Neural_Implicit_Surfaces_With_Hybrid_Representations_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; University of Cambridge",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Isometric Multi-Shape Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Isometric_Multi-Shape_Matching_CVPR_2021_paper.html",
        "author": "Maolin Gao, Zorah Lahner, Johan Thunberg, Daniel Cremers, Florian Bernard",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Isometric_Multi-Shape_Matching_CVPR_2021_paper.pdf",
        "aff": "Halmstad University; Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": "2012.02689"
    },
    {
        "title": "Iterative Filter Adaptive Network for Single Image Defocus Deblurring",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Iterative_Filter_Adaptive_Network_for_Single_Image_Defocus_Deblurring_CVPR_2021_paper.html",
        "author": "Junyong Lee, Hyeongseok Son, Jaesung Rim, Sunghyun Cho, Seungyong Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Iterative_Filter_Adaptive_Network_for_Single_Image_Defocus_Deblurring_CVPR_2021_paper.pdf",
        "aff": "POSTECH",
        "project": "",
        "github": "https://github.com/codeslake/IFAN",
        "arxiv": "2108.13610"
    },
    {
        "title": "Iterative Shrinking for Referring Expression Grounding Using Deep Reinforcement Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Iterative_Shrinking_for_Referring_Expression_Grounding_Using_Deep_Reinforcement_Learning_CVPR_2021_paper.html",
        "author": "Mingjie Sun, Jimin Xiao, Eng Gee Lim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Iterative_Shrinking_for_Referring_Expression_Grounding_Using_Deep_Reinforcement_Learning_CVPR_2021_paper.pdf",
        "aff": "Xi\u2019an Jiaotong-Liverpool University, University of Liverpool; Xi\u2019an Jiaotong-Liverpool University",
        "project": "",
        "github": "https://github.com/insomnia94/ISREG",
        "arxiv": "2103.05187"
    },
    {
        "title": "Jigsaw Clustering for Unsupervised Visual Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Jigsaw_Clustering_for_Unsupervised_Visual_Representation_Learning_CVPR_2021_paper.html",
        "author": "Pengguang Chen, Shu Liu, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Jigsaw_Clustering_for_Unsupervised_Visual_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "SmartMore; The Chinese University of Hong Kong and SmartMore; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2104.00323"
    },
    {
        "title": "Jo-SRC: A Contrastive Approach for Combating Noisy Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yao_Jo-SRC_A_Contrastive_Approach_for_Combating_Noisy_Labels_CVPR_2021_paper.html",
        "author": "Yazhou Yao, Zeren Sun, Chuanyi Zhang, Fumin Shen, Qi Wu, Jian Zhang, Zhenmin Tang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yao_Jo-SRC_A_Contrastive_Approach_for_Combating_Noisy_Labels_CVPR_2021_paper.pdf",
        "aff": "The University of Adelaide, Adelaide, Australia; Nanjing University of Science and Technology, Nanjing, China; University of Technology Sydney, Sydney, Australia; University of Electronic Science and Technology of China, Chengdu, China",
        "project": "",
        "github": "https://github.com/NUST-Machine-Intelligence-Laboratory/Jo-SRC",
        "arxiv": ""
    },
    {
        "title": "Joint Deep Model-Based MR Image and Coil Sensitivity Reconstruction Network (Joint-ICNet) for Fast MRI",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jun_Joint_Deep_Model-Based_MR_Image_and_Coil_Sensitivity_Reconstruction_Network_CVPR_2021_paper.html",
        "author": "Yohan Jun, Hyungseob Shin, Taejoon Eo, Dosik Hwang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jun_Joint_Deep_Model-Based_MR_Image_and_Coil_Sensitivity_Reconstruction_Network_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Joint Generative and Contrastive Learning for Unsupervised Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Joint_Generative_and_Contrastive_Learning_for_Unsupervised_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Hao Chen, Yaohui Wang, Benoit Lagadec, Antitza Dantcheva, Francois Bremond",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Joint_Generative_and_Contrastive_Learning_for_Unsupervised_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Inria, Universit \u00b4e C\u02c6ote d\u2019Azur; European Systems Integration",
        "project": "",
        "github": "https://github.com/chenhao2345/GCL",
        "arxiv": "2012.09071"
    },
    {
        "title": "Joint Learning of 3D Shape Retrieval and Deformation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Uy_Joint_Learning_of_3D_Shape_Retrieval_and_Deformation_CVPR_2021_paper.html",
        "author": "Mikaela Angelina Uy, Vladimir G. Kim, Minhyuk Sung, Noam Aigerman, Siddhartha Chaudhuri, Leonidas J. Guibas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Uy_Joint_Learning_of_3D_Shape_Retrieval_and_Deformation_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; Stanford University; Adobe Research, IIT Bombay; KAIST",
        "project": "",
        "github": "",
        "arxiv": "2101.07889"
    },
    {
        "title": "Joint Negative and Positive Learning for Noisy Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Joint_Negative_and_Positive_Learning_for_Noisy_Labels_CVPR_2021_paper.html",
        "author": "Youngdong Kim, Juseung Yun, Hyounguk Shon, Junmo Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Joint_Negative_and_Positive_Learning_for_Noisy_Labels_CVPR_2021_paper.pdf",
        "aff": "School of Electrical Engineering, KAIST, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2104.06574"
    },
    {
        "title": "Joint Noise-Tolerant Learning and Meta Camera Shift Adaptation for Unsupervised Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Joint_Noise-Tolerant_Learning_and_Meta_Camera_Shift_Adaptation_for_Unsupervised_CVPR_2021_paper.html",
        "author": "Fengxiang Yang, Zhun Zhong, Zhiming Luo, Yuanzheng Cai, Yaojin Lin, Shaozi Li, Nicu Sebe",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Joint_Noise-Tolerant_Learning_and_Meta_Camera_Shift_Adaptation_for_Unsupervised_CVPR_2021_paper.pdf",
        "aff": "Department of Information Engineering and Computer Science, University of Trento; Institute of Arti\ufb01cial Intelligence, Xiamen University; Minjiang University; Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University; Minnan Normal University",
        "project": "",
        "github": "https://github.com/FlyingRoastDuck/MetaCam_DSCE",
        "arxiv": "2103.04618"
    },
    {
        "title": "Joint-DetNAS: Upgrade Your Detector With NAS, Pruning and Dynamic Distillation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yao_Joint-DetNAS_Upgrade_Your_Detector_With_NAS_Pruning_and_Dynamic_Distillation_CVPR_2021_paper.html",
        "author": "Lewei Yao, Renjie Pi, Hang Xu, Wei Zhang, Zhenguo Li, Tong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yao_Joint-DetNAS_Upgrade_Your_Detector_With_NAS_Pruning_and_Dynamic_Distillation_CVPR_2021_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; Hong Kong University of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "KOALAnet: Blind Super-Resolution Using Kernel-Oriented Adaptive Local Adjustment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_KOALAnet_Blind_Super-Resolution_Using_Kernel-Oriented_Adaptive_Local_Adjustment_CVPR_2021_paper.html",
        "author": "Soo Ye Kim, Hyeonjun Sim, Munchurl Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_KOALAnet_Blind_Super-Resolution_Using_Kernel-Oriented_Adaptive_Local_Adjustment_CVPR_2021_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2012.08103"
    },
    {
        "title": "KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Marino_KRISP_Integrating_Implicit_and_Symbolic_Knowledge_for_Open-Domain_Knowledge-Based_VQA_CVPR_2021_paper.html",
        "author": "Kenneth Marino, Xinlei Chen, Devi Parikh, Abhinav Gupta, Marcus Rohrbach",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Marino_KRISP_Integrating_Implicit_and_Symbolic_Knowledge_for_Open-Domain_Knowledge-Based_VQA_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/facebookresearch/krisp",
        "arxiv": "2012.11014"
    },
    {
        "title": "KSM: Fast Multiple Task Adaption via Kernel-Wise Soft Mask Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_KSM_Fast_Multiple_Task_Adaption_via_Kernel-Wise_Soft_Mask_Learning_CVPR_2021_paper.html",
        "author": "Li Yang, Zhezhi He, Junshan Zhang, Deliang Fan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_KSM_Fast_Multiple_Task_Adaption_via_Kernel-Wise_Soft_Mask_Learning_CVPR_2021_paper.pdf",
        "aff": "School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ",
        "project": "",
        "github": "",
        "arxiv": "2009.05668"
    },
    {
        "title": "Kaleido-BERT: Vision-Language Pre-Training on Fashion Domain",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhuge_Kaleido-BERT_Vision-Language_Pre-Training_on_Fashion_Domain_CVPR_2021_paper.html",
        "author": "Mingchen Zhuge, Dehong Gao, Deng-Ping Fan, Linbo Jin, Ben Chen, Haoming Zhou, Minghui Qiu, Ling Shao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhuge_Kaleido-BERT_Vision-Language_Pre-Training_on_Fashion_Domain_CVPR_2021_paper.pdf",
        "aff": "Inception Institute of AI (IIAI); Alibaba Group",
        "project": "http://dpfan.net/Kaleido-BERT",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Keep Your Eyes on the Lane: Real-Time Attention-Guided Lane Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tabelini_Keep_Your_Eyes_on_the_Lane_Real-Time_Attention-Guided_Lane_Detection_CVPR_2021_paper.html",
        "author": "Lucas Tabelini, Rodrigo Berriel, Thiago M. Paixao, Claudine Badue, Alberto F. De Souza, Thiago Oliveira-Santos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tabelini_Keep_Your_Eyes_on_the_Lane_Real-Time_Attention-Guided_Lane_Detection_CVPR_2021_paper.pdf",
        "aff": "Instituto Federal do Esp\u00edrito Santo (IFES); Universidade Federal do Esp\u00edrito Santo (UFES)",
        "project": "",
        "github": "https://github.com/lucastabelini/LaneATT",
        "arxiv": "2010.12035"
    },
    {
        "title": "KeepAugment: A Simple Information-Preserving Data Augmentation Approach",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gong_KeepAugment_A_Simple_Information-Preserving_Data_Augmentation_Approach_CVPR_2021_paper.html",
        "author": "Chengyue Gong, Dilin Wang, Meng Li, Vikas Chandra, Qiang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gong_KeepAugment_A_Simple_Information-Preserving_Data_Augmentation_Approach_CVPR_2021_paper.pdf",
        "aff": "Facebook; University of Texas at Austin",
        "project": "",
        "github": "",
        "arxiv": "2011.11778"
    },
    {
        "title": "Keypoint-Graph-Driven Learning Framework for Object Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Keypoint-Graph-Driven_Learning_Framework_for_Object_Pose_Estimation_CVPR_2021_paper.html",
        "author": "Shaobo Zhang, Wanqing Zhao, Ziyu Guan, Xianlin Peng, Jinye Peng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Keypoint-Graph-Driven_Learning_Framework_for_Object_Pose_Estimation_CVPR_2021_paper.pdf",
        "aff": "Northwest University, Xi\u2019an, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "KeypointDeformer: Unsupervised 3D Keypoint Discovery for Shape Control",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jakab_KeypointDeformer_Unsupervised_3D_Keypoint_Discovery_for_Shape_Control_CVPR_2021_paper.html",
        "author": "Tomas Jakab, Richard Tucker, Ameesh Makadia, Jiajun Wu, Noah Snavely, Angjoo Kanazawa",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jakab_KeypointDeformer_Unsupervised_3D_Keypoint_Discovery_for_Shape_Control_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; Stanford University; University of Oxford; Google Research",
        "project": "http://tomasjakab.github.io/KeypointDeformer",
        "github": "",
        "arxiv": "2104.11224"
    },
    {
        "title": "Knowledge Evolution in Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Taha_Knowledge_Evolution_in_Neural_Networks_CVPR_2021_paper.html",
        "author": "Ahmed Taha, Abhinav Shrivastava, Larry S. Davis",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Taha_Knowledge_Evolution_in_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "University of Maryland, College Park",
        "project": "",
        "github": "http://bit.ly/3uLgwYb",
        "arxiv": "2103.05152"
    },
    {
        "title": "L2M-GAN: Learning To Manipulate Latent Space Semantics for Facial Attribute Editing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_L2M-GAN_Learning_To_Manipulate_Latent_Space_Semantics_for_Facial_Attribute_CVPR_2021_paper.html",
        "author": "Guoxing Yang, Nanyi Fei, Mingyu Ding, Guangzhen Liu, Zhiwu Lu, Tao Xiang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_L2M-GAN_Learning_To_Manipulate_Latent_Space_Semantics_for_Facial_Attribute_CVPR_2021_paper.pdf",
        "aff": "1Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China, Beijing, China; 3The University of Hong Kong; 4University of Surrey, UK; 1Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China, Beijing, China; 2Beijing Key Laboratory of Big Data Management and Analysis Methods",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LAFEAT: Piercing Through Adversarial Defenses With Latent Features",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_LAFEAT_Piercing_Through_Adversarial_Defenses_With_Latent_Features_CVPR_2021_paper.html",
        "author": "Yunrui Yu, Xitong Gao, Cheng-Zhong Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_LAFEAT_Piercing_Through_Adversarial_Defenses_With_Latent_Features_CVPR_2021_paper.pdf",
        "aff": "Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China.; University of Macau, Macau SAR, China.",
        "project": "",
        "github": "",
        "arxiv": "2104.09284"
    },
    {
        "title": "LASR: Learning Articulated Shape Reconstruction From a Monocular Video",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_LASR_Learning_Articulated_Shape_Reconstruction_From_a_Monocular_Video_CVPR_2021_paper.html",
        "author": "Gengshan Yang, Deqing Sun, Varun Jampani, Daniel Vlasic, Forrester Cole, Huiwen Chang, Deva Ramanan, William T. Freeman, Ce Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_LASR_Learning_Articulated_Shape_Reconstruction_From_a_Monocular_Video_CVPR_2021_paper.pdf",
        "aff": "Carnegie Mellon University; Google Research",
        "project": "",
        "github": "https://lasr-google.github.io",
        "arxiv": "2105.02976"
    },
    {
        "title": "LAU-Net: Latitude Adaptive Upscaling Network for Omnidirectional Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_LAU-Net_Latitude_Adaptive_Upscaling_Network_for_Omnidirectional_Image_Super-Resolution_CVPR_2021_paper.html",
        "author": "Xin Deng, Hao Wang, Mai Xu, Yichen Guo, Yuhang Song, Li Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_LAU-Net_Latitude_Adaptive_Upscaling_Network_for_Omnidirectional_Image_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "School of Electronic and Information Engineering, Beihang University, Beijing, China; Department of Computer Science, University of Oxford, UK; School of Cyber Science and Technology, Beihang University, Beijing, China",
        "project": "",
        "github": "https://github.com/wangh-allen/LAU-Net",
        "arxiv": ""
    },
    {
        "title": "LEAP: Learning Articulated Occupancy of People",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mihajlovic_LEAP_Learning_Articulated_Occupancy_of_People_CVPR_2021_paper.html",
        "author": "Marko Mihajlovic, Yan Zhang, Michael J. Black, Siyu Tang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mihajlovic_LEAP_Learning_Articulated_Occupancy_of_People_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; ETH Z\u00fcrich, Switzerland",
        "project": "http://neuralbodies.github.io/LEAP",
        "github": "",
        "arxiv": "2104.06849"
    },
    {
        "title": "LED2-Net: Monocular 360deg Layout Estimation via Differentiable Depth Rendering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_LED2-Net_Monocular_360deg_Layout_Estimation_via_Differentiable_Depth_Rendering_CVPR_2021_paper.html",
        "author": "Fu-En Wang, Yu-Hsuan Yeh, Min Sun, Wei-Chen Chiu, Yi-Hsuan Tsai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_LED2-Net_Monocular_360deg_Layout_Estimation_via_Differentiable_Depth_Rendering_CVPR_2021_paper.pdf",
        "aff": "National Chiao Tung University; National Tsing Hua University; National Tsing Hua University, MOST Joint Research Center for AI Technology and All Vista Healthcare; NEC Labs America",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LOHO: Latent Optimization of Hairstyles via Orthogonalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Saha_LOHO_Latent_Optimization_of_Hairstyles_via_Orthogonalization_CVPR_2021_paper.html",
        "author": "Rohit Saha, Brendan Duke, Florian Shkurti, Graham W. Taylor, Parham Aarabi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Saha_LOHO_Latent_Optimization_of_Hairstyles_via_Orthogonalization_CVPR_2021_paper.pdf",
        "aff": "University of Toronto, Modiface, Inc.; University of Toronto, Vector Institute; University of Guelph, Vector Institute",
        "project": "",
        "github": "https://github.com/dukebw/LOHO",
        "arxiv": "2103.03891"
    },
    {
        "title": "LPSNet: A Lightweight Solution for Fast Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_LPSNet_A_Lightweight_Solution_for_Fast_Panoptic_Segmentation_CVPR_2021_paper.html",
        "author": "Weixiang Hong, Qingpei Guo, Wei Zhang, Jingdong Chen, Wei Chu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_LPSNet_A_Lightweight_Solution_for_Fast_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Ant Financial Services Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LQF: Linear Quadratic Fine-Tuning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Achille_LQF_Linear_Quadratic_Fine-Tuning_CVPR_2021_paper.html",
        "author": "Alessandro Achille, Aditya Golatkar, Avinash Ravichandran, Marzia Polito, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Achille_LQF_Linear_Quadratic_Fine-Tuning_CVPR_2021_paper.pdf",
        "aff": "UCLA; Amazon Web Services",
        "project": "",
        "github": "",
        "arxiv": "2012.11140"
    },
    {
        "title": "LaPred: Lane-Aware Prediction of Multi-Modal Future Trajectories of Dynamic Agents",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_LaPred_Lane-Aware_Prediction_of_Multi-Modal_Future_Trajectories_of_Dynamic_Agents_CVPR_2021_paper.html",
        "author": "ByeoungDo Kim, Seong Hyeon Park, Seokhwan Lee, Elbek Khoshimjonov, Dongsuk Kum, Junsoo Kim, Jeong Soo Kim, Jun Won Choi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_LaPred_Lane-Aware_Prediction_of_Multi-Modal_Future_Trajectories_of_Dynamic_Agents_CVPR_2021_paper.pdf",
        "aff": "Hyundai Motor Company; Hanyang University; Korea Advanced Institute of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": "2104.00249"
    },
    {
        "title": "Labeled From Unlabeled: Exploiting Unlabeled Data for Few-Shot Deep HDR Deghosting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Prabhakar_Labeled_From_Unlabeled_Exploiting_Unlabeled_Data_for_Few-Shot_Deep_HDR_CVPR_2021_paper.html",
        "author": "K. Ram Prabhakar, Gowtham Senthil, Susmit Agrawal, R. Venkatesh Babu, Rama Krishna Sai S Gorthi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Prabhakar_Labeled_From_Unlabeled_Exploiting_Unlabeled_Data_for_Few-Shot_Deep_HDR_CVPR_2021_paper.pdf",
        "aff": "Indian Institute of Science, Bangalore; Indian Institute of Technology Tirupati",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Landmark Regularization: Ranking Guided Super-Net Training in Neural Architecture Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Landmark_Regularization_Ranking_Guided_Super-Net_Training_in_Neural_Architecture_Search_CVPR_2021_paper.html",
        "author": "Kaicheng Yu, Rene Ranftl, Mathieu Salzmann",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_Landmark_Regularization_Ranking_Guided_Super-Net_Training_in_Neural_Architecture_Search_CVPR_2021_paper.pdf",
        "aff": "CVLab, EPFL; Intelligent Systems Lab, Intel",
        "project": "",
        "github": "",
        "arxiv": "2104.05309"
    },
    {
        "title": "Large-Capacity Image Steganography Based on Invertible Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Large-Capacity_Image_Steganography_Based_on_Invertible_Neural_Networks_CVPR_2021_paper.html",
        "author": "Shao-Ping Lu, Rong Wang, Tao Zhong, Paul L. Rosin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_Large-Capacity_Image_Steganography_Based_on_Invertible_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science & Informatics, Cardiff University, UK; TKLNDST, CS, Nankai University, Tianjin, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Large-Scale Localization Datasets in Crowded Indoor Spaces",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Large-Scale_Localization_Datasets_in_Crowded_Indoor_Spaces_CVPR_2021_paper.html",
        "author": "Donghwan Lee, Soohyun Ryu, Suyong Yeon, Yonghan Lee, Deokhwa Kim, Cheolho Han, Yohann Cabon, Philippe Weinzaepfel, Nicolas Guerin, Gabriela Csurka, Martin Humenberger",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Large-Scale_Localization_Datasets_in_Crowded_Indoor_Spaces_CVPR_2021_paper.pdf",
        "aff": "NAVER LABS; NAVER LABS Europe",
        "project": "https://naverlabs.com/datasets",
        "github": "",
        "arxiv": "2105.08941"
    },
    {
        "title": "Layer-Wise Searching for 1-Bit Detectors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Layer-Wise_Searching_for_1-Bit_Detectors_CVPR_2021_paper.html",
        "author": "Sheng Xu, Junhe Zhao, Jinhu Lu, Baochang Zhang, Shumin Han, David Doermann",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Layer-Wise_Searching_for_1-Bit_Detectors_CVPR_2021_paper.pdf",
        "aff": "School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Shenzhen Academy of Aerospace Technology, Shenzhen, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, and Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing, China; Department of Computer Vision Technology, Baidu Inc., Beijing, China; University at Buffalo, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Layerwise Optimization by Gradient Decomposition for Continual Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Layerwise_Optimization_by_Gradient_Decomposition_for_Continual_Learning_CVPR_2021_paper.html",
        "author": "Shixiang Tang, Dapeng Chen, Jinguo Zhu, Shijie Yu, Wanli Ouyang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Layerwise_Optimization_by_Gradient_Decomposition_for_Continual_Learning_CVPR_2021_paper.pdf",
        "aff": "Sensetime Group Limited, Hong Kong; Shenzhen Institutes of Advanced Technology, CAS; The University of Sydney, SenseTime Computer Vision Group, Australia; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": "2105.07561"
    },
    {
        "title": "Layout-Guided Novel View Synthesis From a Single Indoor Panorama",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Layout-Guided_Novel_View_Synthesis_From_a_Single_Indoor_Panorama_CVPR_2021_paper.html",
        "author": "Jiale Xu, Jia Zheng, Yanyu Xu, Rui Tang, Shenghua Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Layout-Guided_Novel_View_Synthesis_From_a_Single_Indoor_Panorama_CVPR_2021_paper.pdf",
        "aff": "ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; KooLab, Manycore; Institute of High Performance Computing, A*STAR; ShanghaiTech University",
        "project": "",
        "github": "https://github.com/bluestyle97/PNVS",
        "arxiv": "2103.17022"
    },
    {
        "title": "LayoutGMN: Neural Graph Matching for Structural Layout Similarity",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Patil_LayoutGMN_Neural_Graph_Matching_for_Structural_Layout_Similarity_CVPR_2021_paper.html",
        "author": "Akshay Gadi Patil, Manyi Li, Matthew Fisher, Manolis Savva, Hao Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Patil_LayoutGMN_Neural_Graph_Matching_for_Structural_Layout_Similarity_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; Adobe Research",
        "project": "",
        "github": "",
        "arxiv": "2012.06547"
    },
    {
        "title": "LayoutTransformer: Scene Layout Generation With Conceptual and Spatial Diversity",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_LayoutTransformer_Scene_Layout_Generation_With_Conceptual_and_Spatial_Diversity_CVPR_2021_paper.html",
        "author": "Cheng-Fu Yang, Wan-Cyuan Fan, Fu-En Yang, Yu-Chiang Frank Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_LayoutTransformer_Scene_Layout_Generation_With_Conceptual_and_Spatial_Diversity_CVPR_2021_paper.pdf",
        "aff": "Graduate Institute of Communication Engineering, National Taiwan University, Taiwan; Graduate Institute of Communication Engineering, National Taiwan University, Taiwan; ASUS Intelligent Cloud Services, Taiwan",
        "project": "",
        "github": "https://github.com/LayoutTransformer",
        "arxiv": ""
    },
    {
        "title": "Learnable Companding Quantization for Accurate Low-Bit Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yamamoto_Learnable_Companding_Quantization_for_Accurate_Low-Bit_Neural_Networks_CVPR_2021_paper.html",
        "author": "Kohei Yamamoto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yamamoto_Learnable_Companding_Quantization_for_Accurate_Low-Bit_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "Oki Electric Industry Co., Ltd.",
        "project": "",
        "github": "",
        "arxiv": "2103.07156"
    },
    {
        "title": "Learnable Graph Matching: Incorporating Graph Partitioning With Deep Feature Learning for Multiple Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_Learnable_Graph_Matching_Incorporating_Graph_Partitioning_With_Deep_Feature_Learning_CVPR_2021_paper.html",
        "author": "Jiawei He, Zehao Huang, Naiyan Wang, Zhaoxiang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_Learnable_Graph_Matching_Incorporating_Graph_Partitioning_With_Deep_Feature_Learning_CVPR_2021_paper.pdf",
        "aff": "Institute of Automation, Chinese Academy of Sciences (CASIA); School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences (UCAS); Centre for Arti\ufb01cial Intelligence and Robotics, HKISI CAS; TuSimple",
        "project": "",
        "github": "https://github.com/jiaweihe1996/GMTracker",
        "arxiv": "2103.16178"
    },
    {
        "title": "Learnable Motion Coherence for Correspondence Pruning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Learnable_Motion_Coherence_for_Correspondence_Pruning_CVPR_2021_paper.html",
        "author": "Yuan Liu, Lingjie Liu, Cheng Lin, Zhen Dong, Wenping Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Learnable_Motion_Coherence_for_Correspondence_Pruning_CVPR_2021_paper.pdf",
        "aff": "Wuhan University; The University of Hong Kong, Texas A&M University; The University of Hong Kong; MPI Informatics, Saarland Informatics Campus",
        "project": "https://liuyuan-pal.github.io/LMCNet/",
        "github": "",
        "arxiv": "2011.14563"
    },
    {
        "title": "Learned Initializations for Optimizing Coordinate-Based Neural Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tancik_Learned_Initializations_for_Optimizing_Coordinate-Based_Neural_Representations_CVPR_2021_paper.html",
        "author": "Matthew Tancik, Ben Mildenhall, Terrance Wang, Divi Schmidt, Pratul P. Srinivasan, Jonathan T. Barron, Ren Ng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tancik_Learned_Initializations_for_Optimizing_Coordinate-Based_Neural_Representations_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2012.02189"
    },
    {
        "title": "Learning 3D Shape Feature for Texture-Insensitive Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_3D_Shape_Feature_for_Texture-Insensitive_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Jiaxing Chen, Xinyang Jiang, Fudong Wang, Jun Zhang, Feng Zheng, Xing Sun, Wei-Shi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Learning_3D_Shape_Feature_for_Texture-Insensitive_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Peng Cheng Laboratory, Shenzhen, China; CSE, Southern University of Science and Technology; Youtu Lab, Tencent; School of Computer Science and Engineering, Sun Yat-sen University, China; Pazhou Lab, Guangzhou, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Accurate Dense Correspondences and When To Trust Them",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Truong_Learning_Accurate_Dense_Correspondences_and_When_To_Trust_Them_CVPR_2021_paper.html",
        "author": "Prune Truong, Martin Danelljan, Luc Van Gool, Radu Timofte",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Truong_Learning_Accurate_Dense_Correspondences_and_When_To_Trust_Them_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Zurich, Switzerland",
        "project": "",
        "github": "https://github.com/PruneTruong/PDCNet",
        "arxiv": "2101.01710"
    },
    {
        "title": "Learning Affinity-Aware Upsampling for Deep Image Matting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Learning_Affinity-Aware_Upsampling_for_Deep_Image_Matting_CVPR_2021_paper.html",
        "author": "Yutong Dai, Hao Lu, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Learning_Affinity-Aware_Upsampling_for_Deep_Image_Matting_CVPR_2021_paper.pdf",
        "aff": "Huazhong University of Science and Technology; The University of Adelaide",
        "project": "",
        "github": "",
        "arxiv": "2011.14288"
    },
    {
        "title": "Learning Asynchronous and Sparse Human-Object Interaction in Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Morais_Learning_Asynchronous_and_Sparse_Human-Object_Interaction_in_Videos_CVPR_2021_paper.html",
        "author": "Romero Morais, Vuong Le, Svetha Venkatesh, Truyen Tran",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Morais_Learning_Asynchronous_and_Sparse_Human-Object_Interaction_in_Videos_CVPR_2021_paper.pdf",
        "aff": "Applied Arti\ufb01cial Intelligence Institute, Deakin University, Australia",
        "project": "",
        "github": "",
        "arxiv": "2103.02758"
    },
    {
        "title": "Learning Better Visual Dialog Agents With Pretrained Visual-Linguistic Representation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tu_Learning_Better_Visual_Dialog_Agents_With_Pretrained_Visual-Linguistic_Representation_CVPR_2021_paper.html",
        "author": "Tao Tu, Qing Ping, Govindarajan Thattai, Gokhan Tur, Prem Natarajan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tu_Learning_Better_Visual_Dialog_Agents_With_Pretrained_Visual-Linguistic_Representation_CVPR_2021_paper.pdf",
        "aff": "Amazon Alexa AI; National Taiwan University",
        "project": "",
        "github": "",
        "arxiv": "2105.11541"
    },
    {
        "title": "Learning Calibrated Medical Image Segmentation via Multi-Rater Agreement Modeling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ji_Learning_Calibrated_Medical_Image_Segmentation_via_Multi-Rater_Agreement_Modeling_CVPR_2021_paper.html",
        "author": "Wei Ji, Shuang Yu, Junde Wu, Kai Ma, Cheng Bian, Qi Bi, Jingjing Li, Hanruo Liu, Li Cheng, Yefeng Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Learning_Calibrated_Medical_Image_Segmentation_via_Multi-Rater_Agreement_Modeling_CVPR_2021_paper.pdf",
        "aff": "Beijing Tongren Hospital, Capital Medical University, Beijing, China; Tencent Jarvis Lab, Shenzhen, China; University of Alberta, Canada",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": ""
    },
    {
        "title": "Learning Camera Localization via Dense Scene Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Learning_Camera_Localization_via_Dense_Scene_Matching_CVPR_2021_paper.html",
        "author": "Shitao Tang, Chengzhou Tang, Rui Huang, Siyu Zhu, Ping Tan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Learning_Camera_Localization_via_Dense_Scene_Matching_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; Alibaba A.I Labs",
        "project": "",
        "github": "https://github.com/Tangshitao/Dense-Scene-Matching",
        "arxiv": "2103.16792"
    },
    {
        "title": "Learning Complete 3D Morphable Face Models From Images and Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/R_Learning_Complete_3D_Morphable_Face_Models_From_Images_and_Videos_CVPR_2021_paper.html",
        "author": "Mallikarjun B R, Ayush Tewari, Hans-Peter Seidel, Mohamed Elgharib, Christian Theobalt",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/R_Learning_Complete_3D_Morphable_Face_Models_From_Images_and_Videos_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Informatics, Saarland Informatics Campus",
        "project": "",
        "github": "",
        "arxiv": "2010.01679"
    },
    {
        "title": "Learning Compositional Radiance Fields of Dynamic Human Heads",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Learning_Compositional_Radiance_Fields_of_Dynamic_Human_Heads_CVPR_2021_paper.html",
        "author": "Ziyan Wang, Timur Bagautdinov, Stephen Lombardi, Tomas Simon, Jason Saragih, Jessica Hodgins, Michael Zollhofer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Learning_Compositional_Radiance_Fields_of_Dynamic_Human_Heads_CVPR_2021_paper.pdf",
        "aff": "Facebook Reality Labs Research; Carnegie Mellon University",
        "project": "https://ziyanw1.github.io/hybrid_nerf/",
        "github": "",
        "arxiv": "2012.09955"
    },
    {
        "title": "Learning Compositional Representation for 4D Captures With Neural ODE",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Learning_Compositional_Representation_for_4D_Captures_With_Neural_ODE_CVPR_2021_paper.html",
        "author": "Boyan Jiang, Yinda Zhang, Xingkui Wei, Xiangyang Xue, Yanwei Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jiang_Learning_Compositional_Representation_for_4D_Captures_With_Neural_ODE_CVPR_2021_paper.pdf",
        "aff": "Fudan University; Google; School of Data Science, MOE Frontiers Center for Brain Science, and Shanghai Key Lab of Intelligent Information Processing, Fudan University",
        "project": "",
        "github": "",
        "arxiv": "2103.08271"
    },
    {
        "title": "Learning Continuous Image Representation With Local Implicit Image Function",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_Continuous_Image_Representation_With_Local_Implicit_Image_Function_CVPR_2021_paper.html",
        "author": "Yinbo Chen, Sifei Liu, Xiaolong Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Learning_Continuous_Image_Representation_With_Local_Implicit_Image_Function_CVPR_2021_paper.pdf",
        "aff": "UC San Diego; NVIDIA",
        "project": "https://yinboc.github.io/liif/",
        "github": "https://github.com/yinboc/liif",
        "arxiv": "2012.09161"
    },
    {
        "title": "Learning Cross-Modal Retrieval With Noisy Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Learning_Cross-Modal_Retrieval_With_Noisy_Labels_CVPR_2021_paper.html",
        "author": "Peng Hu, Xi Peng, Hongyuan Zhu, Liangli Zhen, Jie Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Learning_Cross-Modal_Retrieval_With_Noisy_Labels_CVPR_2021_paper.pdf",
        "aff": "College of Computer Science, Sichuan University, Chengdu 610065, China; Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Decision Trees Recurrently Through Communication",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Alaniz_Learning_Decision_Trees_Recurrently_Through_Communication_CVPR_2021_paper.html",
        "author": "Stephan Alaniz, Diego Marcos, Bernt Schiele, Zeynep Akata",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Alaniz_Learning_Decision_Trees_Recurrently_Through_Communication_CVPR_2021_paper.pdf",
        "aff": "Wageningen University; MPI for Informatics; University of T\u00fcbingen, MPI for Informatics; University of T\u00fcbingen, MPI for Informatics, MPI for Intelligent Systems",
        "project": "",
        "github": "https://github.com/ExplainableML/rdtc",
        "arxiv": "1902.01780"
    },
    {
        "title": "Learning Deep Classifiers Consistent With Fine-Grained Novelty Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Learning_Deep_Classifiers_Consistent_With_Fine-Grained_Novelty_Detection_CVPR_2021_paper.html",
        "author": "Jiacheng Cheng, Nuno Vasconcelos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Learning_Deep_Classifiers_Consistent_With_Fine-Grained_Novelty_Detection_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, University of California, San Diego",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Deep Latent Variable Models by Short-Run MCMC Inference With Optimal Transport Correction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/An_Learning_Deep_Latent_Variable_Models_by_Short-Run_MCMC_Inference_With_CVPR_2021_paper.html",
        "author": "Dongsheng An, Jianwen Xie, Ping Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/An_Learning_Deep_Latent_Variable_Models_by_Short-Run_MCMC_Inference_With_CVPR_2021_paper.pdf",
        "aff": "Cognitive Computing Lab, Baidu Research, 10900 NE 8th St. Bellevue, WA 98004, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Delaunay Surface Elements for Mesh Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Rakotosaona_Learning_Delaunay_Surface_Elements_for_Mesh_Reconstruction_CVPR_2021_paper.html",
        "author": "Marie-Julie Rakotosaona, Paul Guerrero, Noam Aigerman, Niloy J. Mitra, Maks Ovsjanikov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Rakotosaona_Learning_Delaunay_Surface_Elements_for_Mesh_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "UCL, Adobe Research; Adobe Research; LIX, Ecole Polytechnique, IP Paris",
        "project": "",
        "github": "https://github.com/mrakotosaon/dse-meshing",
        "arxiv": "2012.01203"
    },
    {
        "title": "Learning Discriminative Prototypes With Dynamic Time Warping",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Learning_Discriminative_Prototypes_With_Dynamic_Time_Warping_CVPR_2021_paper.html",
        "author": "Xiaobin Chang, Frederick Tung, Greg Mori",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chang_Learning_Discriminative_Prototypes_With_Dynamic_Time_Warping_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University1, Borealis AI2; Borealis AI2",
        "project": "",
        "github": "https://github.com/BorealisAI/TSC-Disc-Proto",
        "arxiv": "2103.09458"
    },
    {
        "title": "Learning Dynamic Alignment via Meta-Filter for Few-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Learning_Dynamic_Alignment_via_Meta-Filter_for_Few-Shot_Learning_CVPR_2021_paper.html",
        "author": "Chengming Xu, Yanwei Fu, Chen Liu, Chengjie Wang, Jilin Li, Feiyue Huang, Li Zhang, Xiangyang Xue",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Learning_Dynamic_Alignment_via_Meta-Filter_for_Few-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "Fudan University; Youtu Lab, Tencent",
        "project": "",
        "github": "",
        "arxiv": "2103.13582"
    },
    {
        "title": "Learning Dynamic Network Using a Reuse Gate Function in Semi-Supervised Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Park_Learning_Dynamic_Network_Using_a_Reuse_Gate_Function_in_Semi-Supervised_CVPR_2021_paper.html",
        "author": "Hyojin Park, Jayeon Yoo, Seohyeong Jeong, Ganesh Venkatesh, Nojun Kwak",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Park_Learning_Dynamic_Network_Using_a_Reuse_Gate_Function_in_Semi-Supervised_CVPR_2021_paper.pdf",
        "aff": "Facebook Inc.; Seoul National University; Seoul National University, AIRS Company, Hyundai Motor Group",
        "project": "",
        "github": "https://github.com/HYOJINPARK/ReuseVOS",
        "arxiv": "2012.11655"
    },
    {
        "title": "Learning Dynamics via Graph Neural Networks for Human Pose Estimation and Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Learning_Dynamics_via_Graph_Neural_Networks_for_Human_Pose_Estimation_CVPR_2021_paper.html",
        "author": "Yiding Yang, Zhou Ren, Haoxiang Li, Chunluan Zhou, Xinchao Wang, Gang Hua",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Learning_Dynamics_via_Graph_Neural_Networks_for_Human_Pose_Estimation_CVPR_2021_paper.pdf",
        "aff": "Stevens Institute of Technology; Stevens Institute of Technology, National University of Singapore; Wormpex AI Research",
        "project": "",
        "github": "",
        "arxiv": "2106.03772"
    },
    {
        "title": "Learning Feature Aggregation for Deep 3D Morphable Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_Feature_Aggregation_for_Deep_3D_Morphable_Models_CVPR_2021_paper.html",
        "author": "Zhixiang Chen, Tae-Kyun Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Learning_Feature_Aggregation_for_Deep_3D_Morphable_Models_CVPR_2021_paper.pdf",
        "aff": "Imperial College London; Imperial College London and KAIST",
        "project": "",
        "github": "",
        "arxiv": "2105.02173"
    },
    {
        "title": "Learning Fine-Grained Segmentation of 3D Shapes Without Part Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Learning_Fine-Grained_Segmentation_of_3D_Shapes_Without_Part_Labels_CVPR_2021_paper.html",
        "author": "Xiaogang Wang, Xun Sun, Xinyu Cao, Kai Xu, Bin Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Learning_Fine-Grained_Segmentation_of_3D_Shapes_Without_Part_Labels_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; Southwest University; National University of Defense Technology",
        "project": "",
        "github": "",
        "arxiv": "2103.13030"
    },
    {
        "title": "Learning From the Master: Distilling Cross-Modal Advanced Knowledge for Lip Reading",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ren_Learning_From_the_Master_Distilling_Cross-Modal_Advanced_Knowledge_for_Lip_CVPR_2021_paper.html",
        "author": "Sucheng Ren, Yong Du, Jianming Lv, Guoqiang Han, Shengfeng He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ren_Learning_From_the_Master_Distilling_Cross-Modal_Advanced_Knowledge_for_Lip_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Technology, Ocean University of China; School of Computer Science and Engineering, South China University of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Goals From Failure",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Epstein_Learning_Goals_From_Failure_CVPR_2021_paper.html",
        "author": "Dave Epstein, Carl Vondrick",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Epstein_Learning_Goals_From_Failure_CVPR_2021_paper.pdf",
        "aff": "Columbia University",
        "project": "http://aha.cs.columbia.edu",
        "github": "",
        "arxiv": "2006.15657"
    },
    {
        "title": "Learning Graph Embeddings for Compositional Zero-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Naeem_Learning_Graph_Embeddings_for_Compositional_Zero-Shot_Learning_CVPR_2021_paper.html",
        "author": "Muhammad Ferjad Naeem, Yongqin Xian, Federico Tombari, Zeynep Akata",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Naeem_Learning_Graph_Embeddings_for_Compositional_Zero-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "MPI for Informatics; TUM; MPI for Intelligent Systems; University of T\u00fcbingen",
        "project": "",
        "github": "https://github.com/ExplainableML/czsl",
        "arxiv": "2102.01987"
    },
    {
        "title": "Learning Graphs for Knowledge Transfer With Limited Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ghosh_Learning_Graphs_for_Knowledge_Transfer_With_Limited_Labels_CVPR_2021_paper.html",
        "author": "Pallabi Ghosh, Nirat Saini, Larry S. Davis, Abhinav Shrivastava",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ghosh_Learning_Graphs_for_Knowledge_Transfer_With_Limited_Labels_CVPR_2021_paper.pdf",
        "aff": "University of Maryland, College Park",
        "project": "https://pallabig.github.io/LearningGraphsForGCN/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning High Fidelity Depths of Dressed Humans by Watching Social Media Dance Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jafarian_Learning_High_Fidelity_Depths_of_Dressed_Humans_by_Watching_Social_CVPR_2021_paper.html",
        "author": "Yasamin Jafarian, Hyun Soo Park",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jafarian_Learning_High_Fidelity_Depths_of_Dressed_Humans_by_Watching_Social_CVPR_2021_paper.pdf",
        "aff": "University of Minnesota",
        "project": "",
        "github": "",
        "arxiv": "2103.03319"
    },
    {
        "title": "Learning Invariant Representations and Risks for Semi-Supervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Learning_Invariant_Representations_and_Risks_for_Semi-Supervised_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Bo Li, Yezhen Wang, Shanghang Zhang, Dongsheng Li, Kurt Keutzer, Trevor Darrell, Han Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Learning_Invariant_Representations_and_Risks_for_Semi-Supervised_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "UIUC; Microsoft Research Asia; BAIR, UC Berkeley; UC San Diego",
        "project": "",
        "github": "LIRR@github",
        "arxiv": "2010.04647"
    },
    {
        "title": "Learning Monocular 3D Reconstruction of Articulated Categories From Motion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kokkinos_Learning_Monocular_3D_Reconstruction_of_Articulated_Categories_From_Motion_CVPR_2021_paper.html",
        "author": "Filippos Kokkinos, Iasonas Kokkinos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kokkinos_Learning_Monocular_3D_Reconstruction_of_Articulated_Categories_From_Motion_CVPR_2021_paper.pdf",
        "aff": "University College London; University College London, Snap Inc.",
        "project": "https://fkokkinos.github.io/video_3d_reconstruction/",
        "github": "https://github.com/fkokkinos/video_3d_reconstruction",
        "arxiv": "2103.16352"
    },
    {
        "title": "Learning Multi-Scale Photo Exposure Correction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Afifi_Learning_Multi-Scale_Photo_Exposure_Correction_CVPR_2021_paper.html",
        "author": "Mahmoud Afifi, Konstantinos G. Derpanis, Bjorn Ommer, Michael S. Brown",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Afifi_Learning_Multi-Scale_Photo_Exposure_Correction_CVPR_2021_paper.pdf",
        "aff": "Samsung AI Centre (SAIC), Toronto, Canada; York University, Canada; Samsung AI Centre (SAIC), Toronto, Canada; Heidelberg University, Germany",
        "project": "",
        "github": "",
        "arxiv": "2003.11596"
    },
    {
        "title": "Learning Neural Representation of Camera Pose with Matrix Representation of Pose Shift via View Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Learning_Neural_Representation_of_Camera_Pose_with_Matrix_Representation_of_CVPR_2021_paper.html",
        "author": "Yaxuan Zhu, Ruiqi Gao, Siyuan Huang, Song-Chun Zhu, Ying Nian Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Learning_Neural_Representation_of_Camera_Pose_with_Matrix_Representation_of_CVPR_2021_paper.pdf",
        "aff": "Department of Statistics, University of California, Los Angeles (UCLA)",
        "project": "",
        "github": "",
        "arxiv": "2104.01508"
    },
    {
        "title": "Learning Normal Dynamics in Videos With Meta Prototype Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Learning_Normal_Dynamics_in_Videos_With_Meta_Prototype_Network_CVPR_2021_paper.html",
        "author": "Hui Lv, Chen Chen, Zhen Cui, Chunyan Xu, Yong Li, Jian Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lv_Learning_Normal_Dynamics_in_Videos_With_Meta_Prototype_Network_CVPR_2021_paper.pdf",
        "aff": "1PCALab, Nanjing University of Science and Technology; 2University of North Carolina at Charlotte",
        "project": "",
        "github": "https://github.com/ktr-hubrt/MPN",
        "arxiv": "2104.06689"
    },
    {
        "title": "Learning Optical Flow From Still Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Aleotti_Learning_Optical_Flow_From_Still_Images_CVPR_2021_paper.html",
        "author": "Filippo Aleotti, Matteo Poggi, Stefano Mattoccia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Aleotti_Learning_Optical_Flow_From_Still_Images_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Engineering (DISI), University of Bologna, Italy",
        "project": "",
        "github": "",
        "arxiv": "2104.03965"
    },
    {
        "title": "Learning Optical Flow From a Few Matches",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Learning_Optical_Flow_From_a_Few_Matches_CVPR_2021_paper.html",
        "author": "Shihao Jiang, Yao Lu, Hongdong Li, Richard Hartley",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jiang_Learning_Optical_Flow_From_a_Few_Matches_CVPR_2021_paper.pdf",
        "aff": "Australian National University, ACRV, Data61, CSIRO; Australian National University, ACRV",
        "project": "",
        "github": "",
        "arxiv": "2104.02166"
    },
    {
        "title": "Learning Parallel Dense Correspondence From Spatio-Temporal Descriptors for Efficient and Robust 4D Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Learning_Parallel_Dense_Correspondence_From_Spatio-Temporal_Descriptors_for_Efficient_and_CVPR_2021_paper.html",
        "author": "Jiapeng Tang, Dan Xu, Kui Jia, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Learning_Parallel_Dense_Correspondence_From_Spatio-Temporal_Descriptors_for_Efficient_and_CVPR_2021_paper.pdf",
        "aff": "Department of Computing, The Hong Kong Polytechnic University, HK; DAMO Academy, Alibaba Group; School of Electronic and Information Engineering, South China University of Technology; Pazhou Lab, Guangzhou, China; Peng Cheng Laboratory, Shenzhen, China; School of Electronic and Information Engineering, South China University of Technology; DAMO Academy, Alibaba Group; Department of Computer Science and Engineering, HKUST, HK",
        "project": "",
        "github": "https://github.com/tangjiapeng/LPDC-Net",
        "arxiv": "2103.16341"
    },
    {
        "title": "Learning Placeholders for Open-Set Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Learning_Placeholders_for_Open-Set_Recognition_CVPR_2021_paper.html",
        "author": "Da-Wei Zhou, Han-Jia Ye, De-Chuan Zhan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Learning_Placeholders_for_Open-Set_Recognition_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University",
        "project": "",
        "github": "",
        "arxiv": "2103.15086"
    },
    {
        "title": "Learning Position and Target Consistency for Memory-Based Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Learning_Position_and_Target_Consistency_for_Memory-Based_Video_Object_Segmentation_CVPR_2021_paper.html",
        "author": "Li Hu, Peng Zhang, Bang Zhang, Pan Pan, Yinghui Xu, Rong Jin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Learning_Position_and_Target_Consistency_for_Memory-Based_Video_Object_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Machine Intelligence Technology Lab, Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": "2104.04329"
    },
    {
        "title": "Learning Probabilistic Ordinal Embeddings for Uncertainty-Aware Regression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Learning_Probabilistic_Ordinal_Embeddings_for_Uncertainty-Aware_Regression_CVPR_2021_paper.html",
        "author": "Wanhua Li, Xiaoke Huang, Jiwen Lu, Jianjiang Feng, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Learning_Probabilistic_Ordinal_Embeddings_for_Uncertainty-Aware_Regression_CVPR_2021_paper.pdf",
        "aff": "Department of Automation, Tsinghua University, China; Beijing National Research Center for Information Science and Technology, China; School of Arti\ufb01cial Intelligence, Beijing Normal University; Department of Automation, Tsinghua University, China; Beijing National Research Center for Information Science and Technology, China",
        "project": "",
        "github": "https://github.com/Li-Wanhua/POEs",
        "arxiv": "2103.13629"
    },
    {
        "title": "Learning Progressive Point Embeddings for 3D Point Cloud Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Learning_Progressive_Point_Embeddings_for_3D_Point_Cloud_Generation_CVPR_2021_paper.html",
        "author": "Cheng Wen, Baosheng Yu, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wen_Learning_Progressive_Point_Embeddings_for_3D_Point_Cloud_Generation_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, Faculty of Engineering, The University of Sydney, 6 Cleveland St, Darlington, NSW 2008, Australia",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Salient Boundary Feature for Anchor-free Temporal Action Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Learning_Salient_Boundary_Feature_for_Anchor-free_Temporal_Action_Localization_CVPR_2021_paper.html",
        "author": "Chuming Lin, Chengming Xu, Donghao Luo, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, Yanwei Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Learning_Salient_Boundary_Feature_for_Anchor-free_Temporal_Action_Localization_CVPR_2021_paper.pdf",
        "aff": "Fudan University; Youtu Lab, Tencent",
        "project": "",
        "github": "https://github.com/TencentYoutuResearch/ActionDetection-AFSD",
        "arxiv": "2103.13137"
    },
    {
        "title": "Learning Scalable lY=-Constrained Near-Lossless Image Compression via Joint Lossy Image and Residual Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bai_Learning_Scalable_lY-Constrained_Near-Lossless_Image_Compression_via_Joint_Lossy_Image_CVPR_2021_paper.html",
        "author": "Yuanchao Bai, Xianming Liu, Wangmeng Zuo, Yaowei Wang, Xiangyang Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bai_Learning_Scalable_lY-Constrained_Near-Lossless_Image_Compression_via_Joint_Lossy_Image_CVPR_2021_paper.pdf",
        "aff": "Peng Cheng Laboratory, Harbin Institute of Technology; Tsinghua University; Peng Cheng Laboratory",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Scene Structure Guidance via Cross-Task Knowledge Transfer for Single Depth Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Learning_Scene_Structure_Guidance_via_Cross-Task_Knowledge_Transfer_for_Single_CVPR_2021_paper.html",
        "author": "Baoli Sun, Xinchen Ye, Baopu Li, Haojie Li, Zhihui Wang, Rui Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Learning_Scene_Structure_Guidance_via_Cross-Task_Knowledge_Transfer_for_Single_CVPR_2021_paper.pdf",
        "aff": "Baidu Research, USA; International School of Information Science & Engineering, Dalian University of Technology, China; International School of Information Science & Engineering, Dalian University of Technology, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China",
        "project": "",
        "github": "",
        "arxiv": "2103.12955"
    },
    {
        "title": "Learning Semantic Person Image Generation by Region-Adaptive Normalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Learning_Semantic_Person_Image_Generation_by_Region-Adaptive_Normalization_CVPR_2021_paper.html",
        "author": "Zhengyao Lv, Xiaoming Li, Xin Li, Fu Li, Tianwei Lin, Dongliang He, Wangmeng Zuo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lv_Learning_Semantic_Person_Image_Generation_by_Region-Adaptive_Normalization_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Vision Technology (VIS), Baidu Inc.; School of Computer Science and Technology, Harbin Institute of Technology, China; Pazhou Lab, Guangzhou, China; School of Computer Science and Technology, Harbin Institute of Technology, China",
        "project": "",
        "github": "https://github.com/cszy98/SPGNet.git",
        "arxiv": "2104.06650"
    },
    {
        "title": "Learning Semantic-Aware Dynamics for Video Prediction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bei_Learning_Semantic-Aware_Dynamics_for_Video_Prediction_CVPR_2021_paper.html",
        "author": "Xinzhu Bei, Yanchao Yang, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bei_Learning_Semantic-Aware_Dynamics_for_Video_Prediction_CVPR_2021_paper.pdf",
        "aff": "Stanford University; UCLA Vision Lab",
        "project": "",
        "github": "",
        "arxiv": "2104.09762"
    },
    {
        "title": "Learning Spatial-Semantic Relationship for Facial Attribute Recognition With Limited Labeled Data",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shu_Learning_Spatial-Semantic_Relationship_for_Facial_Attribute_Recognition_With_Limited_Labeled_CVPR_2021_paper.html",
        "author": "Ying Shu, Yan Yan, Si Chen, Jing-Hao Xue, Chunhua Shen, Hanzi Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shu_Learning_Spatial-Semantic_Relationship_for_Facial_Attribute_Recognition_With_Limited_Labeled_CVPR_2021_paper.pdf",
        "aff": "The University of Adelaide, Australia; Xiamen University, China; University College London, UK; Xiamen University of Technology, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Spatially-Variant MAP Models for Non-Blind Image Deblurring",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dong_Learning_Spatially-Variant_MAP_Models_for_Non-Blind_Image_Deblurring_CVPR_2021_paper.html",
        "author": "Jiangxin Dong, Stefan Roth, Bernt Schiele",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dong_Learning_Spatially-Variant_MAP_Models_for_Non-Blind_Image_Deblurring_CVPR_2021_paper.pdf",
        "aff": "TU Darmstadt; MPI Informatics, Saarland Informatics Campus",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Statistical Texture for Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Learning_Statistical_Texture_for_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Lanyun Zhu, Deyi Ji, Shiping Zhu, Weihao Gan, Wei Wu, Junjie Yan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Learning_Statistical_Texture_for_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Beihang University; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2103.04133"
    },
    {
        "title": "Learning Student Networks in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_Student_Networks_in_the_Wild_CVPR_2021_paper.html",
        "author": "Hanting Chen, Tianyu Guo, Chang Xu, Wenshuo Li, Chunjing Xu, Chao Xu, Yunhe Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Learning_Student_Networks_in_the_Wild_CVPR_2021_paper.pdf",
        "aff": "1. Key Lab of Machine Perception (MOE), Dept. of Machine Intelligence, Peking University; 2. Noah\u2019s Ark Lab, Huawei Technologies; Key Lab of Machine Perception (MOE), Dept. of Machine Intelligence, Peking University; Noah\u2019s Ark Lab, Huawei Technologies; School of Computer Science, Faculty of Engineering, The University of Sydney",
        "project": "",
        "github": "https://github.com/huawei-noah/Data-Efficient-Model-Compression",
        "arxiv": ""
    },
    {
        "title": "Learning Temporal Consistency for Low Light Video Enhancement From Single Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_Temporal_Consistency_for_Low_Light_Video_Enhancement_From_Single_CVPR_2021_paper.html",
        "author": "Fan Zhang, Yu Li, Shaodi You, Ying Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Learning_Temporal_Consistency_for_Low_Light_Video_Enhancement_From_Single_CVPR_2021_paper.pdf",
        "aff": "Applied Research Center (ARC), Tencent PCG; Beijing Institute of Technology; University of Amsterdam",
        "project": "",
        "github": "https://github.com/zkawfanx/StableLLVE",
        "arxiv": ""
    },
    {
        "title": "Learning Tensor Low-Rank Prior for Hyperspectral Image Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_Tensor_Low-Rank_Prior_for_Hyperspectral_Image_Reconstruction_CVPR_2021_paper.html",
        "author": "Shipeng Zhang, Lizhi Wang, Lei Zhang, Hua Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Learning_Tensor_Low-Rank_Prior_for_Hyperspectral_Image_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "Beijing Institute of Technology; Beijing Normal University; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning To Aggregate and Personalize 3D Face From In-the-Wild Photo Collection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_To_Aggregate_and_Personalize_3D_Face_From_In-the-Wild_Photo_CVPR_2021_paper.html",
        "author": "Zhenyu Zhang, Yanhao Ge, Renwang Chen, Ying Tai, Yan Yan, Jian Yang, Chengjie Wang, Jilin Li, Feiyue Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Learning_To_Aggregate_and_Personalize_3D_Face_From_In-the-Wild_Photo_CVPR_2021_paper.pdf",
        "aff": "Tencent Youtu Lab, Shanghai, China; Nanjing University of Science and Technology, Nanjing, China; Nanjing University of Science and Technology, Nanjing, China; Tencent Youtu Lab, Shanghai, China",
        "project": "",
        "github": "",
        "arxiv": "2106.07852"
    },
    {
        "title": "Learning To Associate Every Segment for Video Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Woo_Learning_To_Associate_Every_Segment_for_Video_Panoptic_Segmentation_CVPR_2021_paper.html",
        "author": "Sanghyun Woo, Dahun Kim, Joon-Young Lee, In So Kweon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Woo_Learning_To_Associate_Every_Segment_for_Video_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "KAIST; Adobe Research",
        "project": "",
        "github": "",
        "arxiv": "2106.09453"
    },
    {
        "title": "Learning To Count Everything",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ranjan_Learning_To_Count_Everything_CVPR_2021_paper.html",
        "author": "Viresh Ranjan, Udbhav Sharma, Thu Nguyen, Minh Hoai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ranjan_Learning_To_Count_Everything_CVPR_2021_paper.pdf",
        "aff": "VinAI Research, Hanoi, Vietnam; Stony Brook University, USA",
        "project": "",
        "github": "https://github.com/cvlab-stonybrook/LearningToCountEverything",
        "arxiv": "2104.08391"
    },
    {
        "title": "Learning To Filter: Siamese Relation Network for Robust Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Learning_To_Filter_Siamese_Relation_Network_for_Robust_Tracking_CVPR_2021_paper.html",
        "author": "Siyuan Cheng, Bineng Zhong, Guorong Li, Xin Liu, Zhenjun Tang, Xianxian Li, Jing Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Learning_To_Filter_Siamese_Relation_Network_for_Robust_Tracking_CVPR_2021_paper.pdf",
        "aff": "Learning to Filter: Siamese Relation Network for Robust Tracking\nSiyuan Cheng1,2, Bineng Zhong1*, Guorong Li3, Xin Liu4, Zhenjun Tang1, Xianxian Li1*, Jing Wang2\n1Guangxi Key Lab of Multi-Source Information Mining & Security,\nGuangxi Normal University, Guilin 541004, China\n2Department of Computer Science and Technology, Huaqiao University, China\n3School of Computer Science and Technology, University of Chinese Academy of Sciences, China,\n4Seetatech Technology, Beijing, China\nsiyuancheng@stu.hqu.edu.cn ,bnzhong@gxnu.edu.cn ,liguorong@ucas.ac.cn\nxin.liu@seetatech.com ,rrji@xmu.edu.cn ,tangzj230@163.com ,\nlixx@gxnu.edu.cn ,wroaring@hqu.edu.cn\nAbstract\nDespite the great success of Siamese-based trackers,\ntheir performance under complicated scenarios is still not\nsatisfying, especially when there are distractors. To this\nend, we propose a novel Siamese relation network, which\nintroduces two ef\ufb01cient modules, i.e. Relation Detector\n(RD) and Re\ufb01nement Module (RM). RD performs in a meta-\nlearning way to obtain a learning ability to \ufb01lter the dis-\ntractors from the background while RM aims to effectively\nintegrate the proposed RD into the Siamese framework to\ngenerate accurate tracking result. Moreover, to further im-\nprove the discriminability and robustness of the tracker, we\nintroduce a contrastive training strategy that attempts not\nonly to learn matching the same target but also to learn\nhow to distinguish the different objects. Therefore, our\ntracker can achieve accurate tracking results when fac-\ning background clutters, fast motion, and occlusion. Ex-\nperimental results on \ufb01ve popular benchmarks, including\nVOT2018, VOT2019, OTB100, LaSOT, and UAV123, show\nthat the proposed method is effective and can achieve state-\nof-the-art results. The code will be available at https:\n//github.com/hqucv/siamrn\n1. Introduction\nVisual object tracking, which is the fundamental task\nin computer vision, has received much attention over the\nlast decades [ 17,64,63,65]. It aims to capture the posi-\ntion of an arbitrary target accurately by given only its ini-\ntial state [ 29]. With the increasing demand for the prac-\ntical application such as autonomous driving [ 30], robotics,\n*Corresponding author.\nSiamBAN DiMP Ours\n Ground-truth#9 #473 #491\n#280 #316 #378\n#269\n #290\n #245\nFigure 1. Tracking Result of our Siamese relation network with\ntwo state-of-the-art trackers in VOT2018 [ 22]. Bene\ufb01ting from\nour Relation Detector and Re\ufb01nement Module, when facing sim-\nilar distractors, appearance change and complex background, our\ntracker is more robust to these challenges and gets more accurate\nresults. Figure 4further shows the ability to \ufb01ltering distractors\nfrom the target region.\nsurveillance [ 56] and human-computer interaction [ 33], cur-\nrent trackers require not only accuracy but also speed and\nrobustness to overcome the existing challenges, such as oc-\nclusions, fast motions, appearance deformations, illumina-\ntion change, and background clutters [ 55], etc.\nOwing to the development of CNN and the various net-\nwork architectures, we can unveil the powerful deep feature\nfor computer vision tasks [ 24]. In recent years, the Siamese\nnetwork based trackers [ 6,3,27,66,26] have drawn great\n4421\n",
        "project": "",
        "github": "",
        "arxiv": "2104.00829"
    },
    {
        "title": "Learning To Fuse Asymmetric Feature Maps in Siamese Trackers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Han_Learning_To_Fuse_Asymmetric_Feature_Maps_in_Siamese_Trackers_CVPR_2021_paper.html",
        "author": "Wencheng Han, Xingping Dong, Fahad Shahbaz Khan, Ling Shao, Jianbing Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Han_Learning_To_Fuse_Asymmetric_Feature_Maps_in_Siamese_Trackers_CVPR_2021_paper.pdf",
        "aff": "Mohamed Bin Zayed University of Arti\ufb01cial Intelligence, UAE; Inception Institute of Arti\ufb01cial Intelligence; Beijing Institute of Technology; Beijing Institute of Technology, Inception Institute of Arti\ufb01cial Intelligence",
        "project": "",
        "github": "https://github.com/wencheng256/SiamBAN-ACM",
        "arxiv": "2012.02776"
    },
    {
        "title": "Learning To Identify Correct 2D-2D Line Correspondences on Sphere",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Learning_To_Identify_Correct_2D-2D_Line_Correspondences_on_Sphere_CVPR_2021_paper.html",
        "author": "Haoang Li, Kai Chen, Ji Zhao, Jiangliu Wang, Pyojin Kim, Zhe Liu, Yun-Hui Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Learning_To_Identify_Correct_2D-2D_Line_Correspondences_on_Sphere_CVPR_2021_paper.pdf",
        "aff": "Learning to Identify Correct 2D-2D Line Correspondences on Sphere\nHaoang Li1Kai Chen1Ji Zhao2Jiangliu Wang1Pyojin Kim3Zhe Liu4Yun-Hui Liu1\n1The Chinese University of Hong Kong, Hong Kong, China2TuSimple, China\n3Sookmyung Women\u2019s University, South Korea4University of Cambridge, United Kingdom\nAbstract\nGiven a set of putative 2D-2D line correspondences,\nwe aim to identify correct matches. Existing methods ex-\nploit the geometric constraints. They are only applica-\nble to structured scenes with orthogonality, parallelism and\ncoplanarity. In contrast, we propose the \ufb01rst approach suit-\nable for both structured and unstructured scenes. Instead\nof geometric constraint, we leverage the spatial regularity\non sphere. Speci\ufb01cally, we propose to map line correspon-\ndences into vectors tangent to sphere. We use these vectors\nto encode both angular and positional variations of image\nlines, which is more reliable and concise than directly using\ninclinations, midpoints or endpoints of image lines. Neigh-\nboring vectors mapped from correct matches exhibit a spa-\ntial regularity called local trend consistency, regardless of\nthe type of scenes. To encode this regularity, we design a\nneural network and also propose a novel loss function that\nenforces the smoothness constraint of vector \ufb01eld. In addi-\ntion, we establish a large real-world dataset for image line\nmatching. Experiments showed that our approach outper-\nforms state-of-the-art ones in terms of accuracy, ef\ufb01ciency\nand robustness, and also leads to high generalization.\n1. Introduction\n2D-2D correspondences of points and lines1are the ba-\nsis of numerous computer vision algorithms [ 1,4,34]. Pu-\ntative correspondences can be obtained by various meth-\nods [ 26,41,15]. In practice, these correspondences con-\nsist of correct matches, i.e., inliers and mismatches, i.e.,\noutliers. Outliers are caused by viewpoint differences and\nrepetitive patterns. Since outliers drastically affect the al-\ngorithm robustness, it is important to identify inliers. Iden-\ntifying inlier point correspondences has been widely stud-\nied. Most existing methods are based on geometric con-\nstraint [ 31,38] or spatial regularity [ 44,42]. The geometric\nconstraint-based methods leverage the fact that all the in-\nliers can be \ufb01tted by the same parametric model, e.g., essen-\n\u2217Pyojin Kim and Yun-Hui Liu are co-corresponding authors.\n1We use \u201cline\u201d to represent \u201cline segment\u201d for writing simpli\ufb01cation.\nNatural Object\nMan-made Object\n(a) Putative 2D-2D Line Correspondences\nNon-associated Midpoints\nLocal Trend Consistency\nTangent \nVectorNon-associated Endpoints Image-to-sphere\nMapping\nInclinations\n(b) Zoom View of Fig. 1(a) (c) Spatial Regularity of Vectors\nFigure 1. (a) A pair of lines with the same number represents a\n2D-2D line correspondence. Putative correspondences consist of\ninliers (blue) and outliers (red). (b) Baseline methods use the incli-\nnations, midpoints, or endpoints to encode the angular, positional,\nor both angular and positional variations of image lines, respec-\ntively. (c) We map line correspondences into vectors tangent to\nsphere. Neighboring vectors mapped from inliers exhibit a local\ntrend consistency (analogous to \u201ca school of \ufb01sh\u201d).\ntial matrix [ 12]. The spatial regularity-based methods gen-\nerate 2D displacement vectors, i.e., optical \ufb02ow [ 27] by con-\nnecting point correspondences. They leverage the fact that\nvectors generated by inliers are regular. The above methods\nare all applicable to both structured (typically man-made)\nscenes with orthogonality, parallelism and coplanarity [ 21],\nand unstructured (typical natural) scenes [ 40].\nCompared with the above point problem, identifying in-\nlierlinecorrespondences (see Fig. 1(a)) is more challeng-\ning and has not been well studied. Existing geometric\nconstraint-based methods [ 9,43] are only suitable for struc-\ntured scenes since inliers are only geometrically constrained\nin these scenes. A spatial regularity-based method can the-\noretically handle both structured and unstructured scenes,\nbut how to design such a method remains an open question.\nSpeci\ufb01cally, we express the spatial regularity of line cor-\nrespondences by both angular and positional variations of\nimage lines. As shown in Fig. 1(b), it is straightforward to\nuse the inclinations, midpoints, or endpoints to encode the\nangular, positional, or both angular and positional variations\n11743\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning To Predict Visual Attributes in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pham_Learning_To_Predict_Visual_Attributes_in_the_Wild_CVPR_2021_paper.html",
        "author": "Khoi Pham, Kushal Kafle, Zhe Lin, Zhihong Ding, Scott Cohen, Quan Tran, Abhinav Shrivastava",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pham_Learning_To_Predict_Visual_Attributes_in_the_Wild_CVPR_2021_paper.pdf",
        "aff": "University of Maryland, College Park; Adobe Research",
        "project": "https://vawdataset.com/",
        "github": "",
        "arxiv": "2106.09707"
    },
    {
        "title": "Learning To Recommend Frame for Interactive Video Object Segmentation in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Learning_To_Recommend_Frame_for_Interactive_Video_Object_Segmentation_in_CVPR_2021_paper.html",
        "author": "Zhaoyuan Yin, Jia Zheng, Weixin Luo, Shenhan Qian, Hanling Zhang, Shenghua Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_Learning_To_Recommend_Frame_for_Interactive_Video_Object_Segmentation_in_CVPR_2021_paper.pdf",
        "aff": "Meituan Group; School of Design, Hunan University; ShanghaiTech University; Shanghai Engineering Research Center of Intelligent Vision and Imaging; KooLab, Manycore3Meituan Group; College of Computer Science and Electronic Engineering, Hunan University",
        "project": "",
        "github": "https://github.com/svip-lab/IVOS-W",
        "arxiv": "2103.10391"
    },
    {
        "title": "Learning To Reconstruct High Speed and High Dynamic Range Videos From Events",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zou_Learning_To_Reconstruct_High_Speed_and_High_Dynamic_Range_Videos_CVPR_2021_paper.html",
        "author": "Yunhao Zou, Yinqiang Zheng, Tsuyoshi Takatani, Ying Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zou_Learning_To_Reconstruct_High_Speed_and_High_Dynamic_Range_Videos_CVPR_2021_paper.pdf",
        "aff": "The University of Tokyo; National Institute of Informatics; Beijing Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning To Recover 3D Scene Shape From a Single Image",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Learning_To_Recover_3D_Scene_Shape_From_a_Single_Image_CVPR_2021_paper.html",
        "author": "Wei Yin, Jianming Zhang, Oliver Wang, Simon Niklaus, Long Mai, Simon Chen, Chunhua Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_Learning_To_Recover_3D_Scene_Shape_From_a_Single_Image_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; The University of Adelaide, Australia",
        "project": "",
        "github": "https://git.io/Depth",
        "arxiv": "2012.09365"
    },
    {
        "title": "Learning To Relate Depth and Semantics for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Saha_Learning_To_Relate_Depth_and_Semantics_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Suman Saha, Anton Obukhov, Danda Pani Paudel, Menelaos Kanakis, Yuhua Chen, Stamatios Georgoulis, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Saha_Learning_To_Relate_Depth_and_Semantics_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; ETH Zurich, KU Leuven",
        "project": "",
        "github": "https://github.com/susaha/ctrl-uda",
        "arxiv": "2105.07830"
    },
    {
        "title": "Learning To Restore Hazy Video: A New Real-World Dataset and a New Method",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_To_Restore_Hazy_Video_A_New_Real-World_Dataset_and_CVPR_2021_paper.html",
        "author": "Xinyi Zhang, Hang Dong, Jinshan Pan, Chao Zhu, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, Fei Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Learning_To_Restore_Hazy_Video_A_New_Real-World_Dataset_and_CVPR_2021_paper.pdf",
        "aff": "Nanjing University of Science and Technology; Tencent Youtu Lab; ByteDance Intelligent Creation Lab; College of Artificial Intelligence, Xi'an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning To Segment Actions From Visual and Language Instructions via Differentiable Weak Sequence Alignment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Learning_To_Segment_Actions_From_Visual_and_Language_Instructions_via_CVPR_2021_paper.html",
        "author": "Yuhan Shen, Lu Wang, Ehsan Elhamifar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_Learning_To_Segment_Actions_From_Visual_and_Language_Instructions_via_CVPR_2021_paper.pdf",
        "aff": "Northeastern University; University of Michigan",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning To Segment Rigid Motions From Two Frames",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Learning_To_Segment_Rigid_Motions_From_Two_Frames_CVPR_2021_paper.html",
        "author": "Gengshan Yang, Deva Ramanan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Learning_To_Segment_Rigid_Motions_From_Two_Frames_CVPR_2021_paper.pdf",
        "aff": "Carnegie Mellon University, Argo AI; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/gengshan-y/rigidmask",
        "arxiv": "2101.03694"
    },
    {
        "title": "Learning To Warp for Style Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Learning_To_Warp_for_Style_Transfer_CVPR_2021_paper.html",
        "author": "Xiao-Chang Liu, Yong-Liang Yang, Peter Hall",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Learning_To_Warp_for_Style_Transfer_CVPR_2021_paper.pdf",
        "aff": "University of Bath",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning Triadic Belief Dynamics in Nonverbal Communication From Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Learning_Triadic_Belief_Dynamics_in_Nonverbal_Communication_From_Videos_CVPR_2021_paper.html",
        "author": "Lifeng Fan, Shuwen Qiu, Zilong Zheng, Tao Gao, Song-Chun Zhu, Yixin Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_Learning_Triadic_Belief_Dynamics_in_Nonverbal_Communication_From_Videos_CVPR_2021_paper.pdf",
        "aff": "UCLA Center for Vision, Cognition, Learning, and Autonomy; UCLA Center for Statistics",
        "project": "",
        "github": "https://github.com/LifengFan/Triadic-Belief-Dynamics",
        "arxiv": "2104.02841"
    },
    {
        "title": "Learning View Selection for 3D Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Learning_View_Selection_for_3D_Scenes_CVPR_2021_paper.html",
        "author": "Yifan Sun, Qixing Huang, Dun-Yu Hsiao, Li Guan, Gang Hua",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Learning_View_Selection_for_3D_Scenes_CVPR_2021_paper.pdf",
        "aff": "The University of Texas at Austin; Wormpex AI Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning View-Disentangled Human Pose Representation by Contrastive Cross-View Mutual Information Maximization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Learning_View-Disentangled_Human_Pose_Representation_by_Contrastive_Cross-View_Mutual_Information_CVPR_2021_paper.html",
        "author": "Long Zhao, Yuxiao Wang, Jiaping Zhao, Liangzhe Yuan, Jennifer J. Sun, Florian Schroff, Hartwig Adam, Xi Peng, Dimitris Metaxas, Ting Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Learning_View-Disentangled_Human_Pose_Representation_by_Contrastive_Cross-View_Mutual_Information_CVPR_2021_paper.pdf",
        "aff": "Rutgers University; Caltech; University of Delaware; Google Research",
        "project": "",
        "github": "https://github.com/google-research/google-research/tree/master/poem",
        "arxiv": "2012.01405"
    },
    {
        "title": "Learning a Facial Expression Embedding Disentangled From Identity",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_a_Facial_Expression_Embedding_Disentangled_From_Identity_CVPR_2021_paper.html",
        "author": "Wei Zhang, Xianpeng Ji, Keyu Chen, Yu Ding, Changjie Fan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Learning_a_Facial_Expression_Embedding_Disentangled_From_Identity_CVPR_2021_paper.pdf",
        "aff": "Virtual Human Group, Netease Fuxi AI Lab; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning a Non-Blind Deblurring Network for Night Blurry Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_a_Non-Blind_Deblurring_Network_for_Night_Blurry_Images_CVPR_2021_paper.html",
        "author": "Liang Chen, Jiawei Zhang, Jinshan Pan, Songnan Lin, Faming Fang, Jimmy S. Ren",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Learning_a_Non-Blind_Deblurring_Network_for_Night_Blurry_Images_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research, Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, School of Computer Science and Technology, East China Normal University; Nanjing University of Science and Technology; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning a Proposal Classifier for Multiple Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Learning_a_Proposal_Classifier_for_Multiple_Object_Tracking_CVPR_2021_paper.html",
        "author": "Peng Dai, Renliang Weng, Wongun Choi, Changshui Zhang, Zhangping He, Wei Ding",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Learning_a_Proposal_Classifier_for_Multiple_Object_Tracking_CVPR_2021_paper.pdf",
        "aff": "Tsinghua University, Beijng, China; Aibee Inc",
        "project": "",
        "github": "https://github.com/daip13/LPC_MOT.git",
        "arxiv": "2103.07889"
    },
    {
        "title": "Learning a Self-Expressive Network for Subspace Clustering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_a_Self-Expressive_Network_for_Subspace_Clustering_CVPR_2021_paper.html",
        "author": "Shangzhi Zhang, Chong You, Rene Vidal, Chun-Guang Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Learning_a_Self-Expressive_Network_for_Subspace_Clustering_CVPR_2021_paper.pdf",
        "aff": "Department of EECS, University of California, Berkeley, CA; School of Arti\ufb01cial Intelligence, Beijing University of Posts and Telecommunications; Mathematical Institute for Data Science, Johns Hopkins University, Baltimore, MD",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning an Explicit Weighting Scheme for Adapting Complex HSI Noise",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Rui_Learning_an_Explicit_Weighting_Scheme_for_Adapting_Complex_HSI_Noise_CVPR_2021_paper.html",
        "author": "Xiangyu Rui, Xiangyong Cao, Qi Xie, Zongsheng Yue, Qian Zhao, Deyu Meng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Rui_Learning_an_Explicit_Weighting_Scheme_for_Adapting_Complex_HSI_Noise_CVPR_2021_paper.pdf",
        "aff": "Xi\u2019an Jiaotong University; Pazhou Lab, Guangzhou; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning by Aligning Videos in Time",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Haresh_Learning_by_Aligning_Videos_in_Time_CVPR_2021_paper.html",
        "author": "Sanjay Haresh, Sateesh Kumar, Huseyin Coskun, Shahram N. Syed, Andrey Konin, Zeeshan Zia, Quoc-Huy Tran",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Haresh_Learning_by_Aligning_Videos_in_Time_CVPR_2021_paper.pdf",
        "aff": "Retrocausal, Inc., Seattle, WA",
        "project": "www.retrocausal.ai",
        "github": "",
        "arxiv": "2103.17260"
    },
    {
        "title": "Learning by Planning: Language-Guided Global Image Editing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Learning_by_Planning_Language-Guided_Global_Image_Editing_CVPR_2021_paper.html",
        "author": "Jing Shi, Ning Xu, Yihang Xu, Trung Bui, Franck Dernoncourt, Chenliang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_Learning_by_Planning_Language-Guided_Global_Image_Editing_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; University of Rochester",
        "project": "",
        "github": "https://github.com/jshi31/T2ONet",
        "arxiv": ""
    },
    {
        "title": "Learning by Watching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_by_Watching_CVPR_2021_paper.html",
        "author": "Jimuyang Zhang, Eshed Ohn-Bar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Learning_by_Watching_CVPR_2021_paper.pdf",
        "aff": "Boston University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning the Best Pooling Strategy for Visual Semantic Embedding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_the_Best_Pooling_Strategy_for_Visual_Semantic_Embedding_CVPR_2021_paper.html",
        "author": "Jiacheng Chen, Hexiang Hu, Hao Wu, Yuning Jiang, Changhu Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Learning_the_Best_Pooling_Strategy_for_Visual_Semantic_Embedding_CVPR_2021_paper.pdf",
        "aff": "ByteDance AI Lab; Alibaba Inc; University of Southern California",
        "project": "",
        "github": "http://jcchen.me/vse_infty/",
        "arxiv": "2011.04305"
    },
    {
        "title": "Learning the Non-Differentiable Optimization for Blind Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hui_Learning_the_Non-Differentiable_Optimization_for_Blind_Super-Resolution_CVPR_2021_paper.html",
        "author": "Zheng Hui, Jie Li, Xiumei Wang, Xinbo Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hui_Learning_the_Non-Differentiable_Optimization_for_Blind_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "Visual Information Processing Lab, Xidian University, China; The Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, China; Visual Information Processing Lab, Xidian University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Learning the Predictability of the Future",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Suris_Learning_the_Predictability_of_the_Future_CVPR_2021_paper.html",
        "author": "Didac Suris, Ruoshi Liu, Carl Vondrick",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Suris_Learning_the_Predictability_of_the_Future_CVPR_2021_paper.pdf",
        "aff": "Columbia University",
        "project": "http://hyperfuture.cs.columbia.edu",
        "github": "",
        "arxiv": "2101.01600"
    },
    {
        "title": "Learning the Superpixel in a Non-Iterative and Lifelong Manner",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Learning_the_Superpixel_in_a_Non-Iterative_and_Lifelong_Manner_CVPR_2021_paper.html",
        "author": "Lei Zhu, Qi She, Bin Zhang, Yanye Lu, Zhilin Lu, Duo Li, Jie Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Learning_the_Superpixel_in_a_Non-Iterative_and_Lifelong_Manner_CVPR_2021_paper.pdf",
        "aff": "Institute of Medical Technology, Peking University Health Science Center, Peking University; Beijing University of Posts and Telecommunications; Bytedance AI Lab; Department of Biomedical Engineering, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2103.10681"
    },
    {
        "title": "Learning to Generalize Unseen Domains via Memory-based Multi-Source Meta-Learning for Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Learning_to_Generalize_Unseen_Domains_via_Memory-based_Multi-Source_Meta-Learning_for_CVPR_2021_paper.html",
        "author": "Yuyang Zhao, Zhun Zhong, Fengxiang Yang, Zhiming Luo, Yaojin Lin, Shaozi Li, Nicu Sebe",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Learning_to_Generalize_Unseen_Domains_via_Memory-based_Multi-Source_Meta-Learning_for_CVPR_2021_paper.pdf",
        "aff": "Minnan Normal University; Department of Information Engineering and Computer Science, University of Trento; Institute of Artificial Intelligence, Xiamen University; Department of Artificial Intelligence, School of Informatics, Xiamen University",
        "project": "",
        "github": "https://github.com/HeliosZhao/M3L",
        "arxiv": "2012.00417"
    },
    {
        "title": "Learning to Track Instances without Video Annotations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Learning_to_Track_Instances_without_Video_Annotations_CVPR_2021_paper.html",
        "author": "Yang Fu, Sifei Liu, Umar Iqbal, Shalini De Mello, Humphrey Shi, Jan Kautz",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fu_Learning_to_Track_Instances_without_Video_Annotations_CVPR_2021_paper.pdf",
        "aff": "University of Oregon; NVIDIA; University of Illinois at Urbana-Champaign",
        "project": "https://oasisyang.github.io/projects/semi-track/index.html",
        "github": "",
        "arxiv": "2104.00287"
    },
    {
        "title": "Learning-Based Image Registration With Meta-Regularization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Safadi_Learning-Based_Image_Registration_With_Meta-Regularization_CVPR_2021_paper.html",
        "author": "Ebrahim Al Safadi, Xubo Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Safadi_Learning-Based_Image_Registration_With_Meta-Regularization_CVPR_2021_paper.pdf",
        "aff": "Oregon Health & Science University; Oregon Health & Science University, Amazon",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Lesion-Aware Transformers for Diabetic Retinopathy Grading",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Lesion-Aware_Transformers_for_Diabetic_Retinopathy_Grading_CVPR_2021_paper.html",
        "author": "Rui Sun, Yihao Li, Tianzhu Zhang, Zhendong Mao, Feng Wu, Yongdong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Lesion-Aware_Transformers_for_Diabetic_Retinopathy_Grading_CVPR_2021_paper.pdf",
        "aff": "University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Less Is More: ClipBERT for Video-and-Language Learning via Sparse Sampling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lei_Less_Is_More_ClipBERT_for_Video-and-Language_Learning_via_Sparse_Sampling_CVPR_2021_paper.html",
        "author": "Jie Lei, Linjie Li, Luowei Zhou, Zhe Gan, Tamara L. Berg, Mohit Bansal, Jingjing Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lei_Less_Is_More_ClipBERT_for_Video-and-Language_Learning_via_Sparse_Sampling_CVPR_2021_paper.pdf",
        "aff": "Microsoft Dynamics 365 AI Research; UNC Chapel Hill",
        "project": "",
        "github": "https://github.com/jayleicn/ClipBERTVision",
        "arxiv": "2102.06183"
    },
    {
        "title": "Leveraging Large-Scale Weakly Labeled Data for Semi-Supervised Mass Detection in Mammograms",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Leveraging_Large-Scale_Weakly_Labeled_Data_for_Semi-Supervised_Mass_Detection_in_CVPR_2021_paper.html",
        "author": "Yuxing Tang, Zhenjie Cao, Yanbo Zhang, Zhicheng Yang, Zongcheng Ji, Yiwei Wang, Mei Han, Jie Ma, Jing Xiao, Peng Chang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Leveraging_Large-Scale_Weakly_Labeled_Data_for_Semi-Supervised_Mass_Detection_in_CVPR_2021_paper.pdf",
        "aff": "PAII Inc., USA; Shenzhen People\u2019s Hospital, China; Ping An Technology, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Leveraging Line-Point Consistence To Preserve Structures for Wide Parallax Image Stitching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jia_Leveraging_Line-Point_Consistence_To_Preserve_Structures_for_Wide_Parallax_Image_CVPR_2021_paper.html",
        "author": "Qi Jia, ZhengJun Li, Xin Fan, Haotian Zhao, Shiyu Teng, Xinchen Ye, Longin Jan Latecki",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jia_Leveraging_Line-Point_Consistence_To_Preserve_Structures_for_Wide_Parallax_Image_CVPR_2021_paper.pdf",
        "aff": "International School of Information Science & Engineering, Dalian University of Technology; Computer & Information Sciences, Temple University",
        "project": "",
        "github": "https://github.com/dut-media-lab/Image-Stitching",
        "arxiv": ""
    },
    {
        "title": "Leveraging the Availability of Two Cameras for Illuminant Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Abdelhamed_Leveraging_the_Availability_of_Two_Cameras_for_Illuminant_Estimation_CVPR_2021_paper.html",
        "author": "Abdelrahman Abdelhamed, Abhijith Punnappurath, Michael S. Brown",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Abdelhamed_Leveraging_the_Availability_of_Two_Cameras_for_Illuminant_Estimation_CVPR_2021_paper.pdf",
        "aff": "Samsung AI Center \u2013 Toronto",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LiBRe: A Practical Bayesian Approach to Adversarial Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_LiBRe_A_Practical_Bayesian_Approach_to_Adversarial_Detection_CVPR_2021_paper.html",
        "author": "Zhijie Deng, Xiao Yang, Shizhen Xu, Hang Su, Jun Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_LiBRe_A_Practical_Bayesian_Approach_to_Adversarial_Detection_CVPR_2021_paper.pdf",
        "aff": "Dept. of Comp. Sci. and Tech., BNRist Center, Institute for AI, Tsinghua-Bosch Joint ML Center, THBI Lab, Tsinghua University, Beijing, 100084, China; RealAI",
        "project": "",
        "github": "https://github.com/thudzj/ScalableBDL",
        "arxiv": "2103.14835"
    },
    {
        "title": "LiDAR R-CNN: An Efficient and Universal 3D Object Detector",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_LiDAR_R-CNN_An_Efficient_and_Universal_3D_Object_Detector_CVPR_2021_paper.html",
        "author": "Zhichao Li, Feng Wang, Naiyan Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_LiDAR_R-CNN_An_Efficient_and_Universal_3D_Object_Detector_CVPR_2021_paper.pdf",
        "aff": "TuSimple",
        "project": "",
        "github": "https://github.com/tusimple/LiDAR_RCNN",
        "arxiv": ""
    },
    {
        "title": "LiDAR-Aug: A General Rendering-Based Augmentation Framework for 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fang_LiDAR-Aug_A_General_Rendering-Based_Augmentation_Framework_for_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "Jin Fang, Xinxin Zuo, Dingfu Zhou, Shengze Jin, Sen Wang, Liangjun Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fang_LiDAR-Aug_A_General_Rendering-Based_Augmentation_Framework_for_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "ETH Z\u00fcrich, Switzerland; University of Guelph, Canada; Baidu Research, National Engineering Laboratory of Deep Learning Technology and Application, China; University of Alberta, Canada",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LiDAR-Based Panoptic Segmentation via Dynamic Shifting Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_LiDAR-Based_Panoptic_Segmentation_via_Dynamic_Shifting_Network_CVPR_2021_paper.html",
        "author": "Fangzhou Hong, Hui Zhou, Xinge Zhu, Hongsheng Li, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_LiDAR-Based_Panoptic_Segmentation_via_Dynamic_Shifting_Network_CVPR_2021_paper.pdf",
        "aff": "Sensetime Research; School of CST, Xidian University; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/hongfz16/DS-Net",
        "arxiv": "2011.11964"
    },
    {
        "title": "Lifelong Person Re-Identification via Adaptive Knowledge Accumulation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pu_Lifelong_Person_Re-Identification_via_Adaptive_Knowledge_Accumulation_CVPR_2021_paper.html",
        "author": "Nan Pu, Wei Chen, Yu Liu, Erwin M. Bakker, Michael S. Lew",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pu_Lifelong_Person_Re-Identification_via_Adaptive_Knowledge_Accumulation_CVPR_2021_paper.pdf",
        "aff": "International School of Information Science & Engineering, Dalian University of Technology, China; LIACS Media Lab, Leiden University, The Netherlands",
        "project": "",
        "github": "https://github.com/TPCD/LifelongReID",
        "arxiv": "2103.12462"
    },
    {
        "title": "Lifting 2D StyleGAN for 3D-Aware Face Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Lifting_2D_StyleGAN_for_3D-Aware_Face_Generation_CVPR_2021_paper.html",
        "author": "Yichun Shi, Divyansh Aggarwal, Anil K. Jain",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_Lifting_2D_StyleGAN_for_3D-Aware_Face_Generation_CVPR_2021_paper.pdf",
        "aff": "Michigan State University",
        "project": "",
        "github": "",
        "arxiv": "2011.13126"
    },
    {
        "title": "Light Field Super-Resolution With Zero-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Light_Field_Super-Resolution_With_Zero-Shot_Learning_CVPR_2021_paper.html",
        "author": "Zhen Cheng, Zhiwei Xiong, Chang Chen, Dong Liu, Zheng-Jun Zha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Light_Field_Super-Resolution_With_Zero-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_LightTrack_Finding_Lightweight_Neural_Networks_for_Object_Tracking_via_One-Shot_CVPR_2021_paper.html",
        "author": "Bin Yan, Houwen Peng, Kan Wu, Dong Wang, Jianlong Fu, Huchuan Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_LightTrack_Finding_Lightweight_Neural_Networks_for_Object_Tracking_via_One-Shot_CVPR_2021_paper.pdf",
        "aff": "Dalian University of Technology; Microsoft Research Asia, Sun Yat-sen University; Microsoft Research Asia; Dalian University of Technology, Peng Cheng Laboratory; Microsoft Research Asia, Dalian University of Technology",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2104.14545"
    },
    {
        "title": "Lighting, Reflectance and Geometry Estimation From 360deg Panoramic Stereo",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Lighting_Reflectance_and_Geometry_Estimation_From_360deg_Panoramic_Stereo_CVPR_2021_paper.html",
        "author": "Junxuan Li, Hongdong Li, Yasuyuki Matsushita",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Lighting_Reflectance_and_Geometry_Estimation_From_360deg_Panoramic_Stereo_CVPR_2021_paper.pdf",
        "aff": "Osaka University, Japan; Australian National University, Data61-CSIRO, Australia; Australian National University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Limitations of Post-Hoc Feature Alignment for Robustness",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Burns_Limitations_of_Post-Hoc_Feature_Alignment_for_Robustness_CVPR_2021_paper.html",
        "author": "Collin Burns, Jacob Steinhardt",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Burns_Limitations_of_Post-Hoc_Feature_Alignment_for_Robustness_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley",
        "project": "",
        "github": "",
        "arxiv": "2103.05898"
    },
    {
        "title": "Line Segment Detection Using Transformers Without Edges",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Line_Segment_Detection_Using_Transformers_Without_Edges_CVPR_2021_paper.html",
        "author": "Yifan Xu, Weijian Xu, David Cheung, Zhuowen Tu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Line_Segment_Detection_Using_Transformers_Without_Edges_CVPR_2021_paper.pdf",
        "aff": "University of California San Diego",
        "project": "",
        "github": "https://github.com/mlpc-ucsd/LETR",
        "arxiv": "2101.01909"
    },
    {
        "title": "Linear Semantics in Generative Adversarial Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Linear_Semantics_in_Generative_Adversarial_Networks_CVPR_2021_paper.html",
        "author": "Jianjin Xu, Changxi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Linear_Semantics_in_Generative_Adversarial_Networks_CVPR_2021_paper.pdf",
        "aff": "Columbia University",
        "project": "",
        "github": "https://github.com/AtlantixJJ/LinearGAN",
        "arxiv": "2104.00487"
    },
    {
        "title": "Linguistic Structures As Weak Supervision for Visual Scene Graph Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Linguistic_Structures_As_Weak_Supervision_for_Visual_Scene_Graph_Generation_CVPR_2021_paper.html",
        "author": "Keren Ye, Adriana Kovashka",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ye_Linguistic_Structures_As_Weak_Supervision_for_Visual_Scene_Graph_Generation_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, University of Pittsburgh",
        "project": "",
        "github": "https://github.com/yekeren/WSSGG",
        "arxiv": "2105.13994"
    },
    {
        "title": "LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces From Video Using Pose and Lighting Normalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lahiri_LipSync3D_Data-Efficient_Learning_of_Personalized_3D_Talking_Faces_From_Video_CVPR_2021_paper.html",
        "author": "Avisek Lahiri, Vivek Kwatra, Christian Frueh, John Lewis, Chris Bregler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lahiri_LipSync3D_Data-Efficient_Learning_of_Personalized_3D_Talking_Faces_From_Video_CVPR_2021_paper.pdf",
        "aff": "Google Research, Indian Institute of Technology Kharagpur; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2106.04185"
    },
    {
        "title": "Lips Don't Lie: A Generalisable and Robust Approach To Face Forgery Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Haliassos_Lips_Dont_Lie_A_Generalisable_and_Robust_Approach_To_Face_CVPR_2021_paper.html",
        "author": "Alexandros Haliassos, Konstantinos Vougioukas, Stavros Petridis, Maja Pantic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Haliassos_Lips_Dont_Lie_A_Generalisable_and_Robust_Approach_To_Face_CVPR_2021_paper.pdf",
        "aff": "Imperial College London, Facebook London; Imperial College London",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Lipstick Ain't Enough: Beyond Color Matching for In-the-Wild Makeup Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_Lipstick_Aint_Enough_Beyond_Color_Matching_for_In-the-Wild_Makeup_Transfer_CVPR_2021_paper.html",
        "author": "Thao Nguyen, Anh Tuan Tran, Minh Hoai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nguyen_Lipstick_Aint_Enough_Beyond_Color_Matching_for_In-the-Wild_Makeup_Transfer_CVPR_2021_paper.pdf",
        "aff": "Stony Brook University, Stony Brook, NY 11790, USA; VinAI Research, Hanoi, Vietnam; VinUniversity, Hanoi, Vietnam",
        "project": "",
        "github": "https://github.com/VinAIResearch/CPM",
        "arxiv": ""
    },
    {
        "title": "Lite-HRNet: A Lightweight High-Resolution Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Lite-HRNet_A_Lightweight_High-Resolution_Network_CVPR_2021_paper.html",
        "author": "Changqian Yu, Bin Xiao, Changxin Gao, Lu Yuan, Lei Zhang, Nong Sang, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_Lite-HRNet_A_Lightweight_High-Resolution_Network_CVPR_2021_paper.pdf",
        "aff": "Key Laboratory of Image Processing and Intelligent Control, School of Arti\ufb01cial Intelligence and Automation, Huazhong University of Science and Technology; Microsoft",
        "project": "",
        "github": "https://github.com/HRNet/Lite-HRNet",
        "arxiv": ""
    },
    {
        "title": "LoFTR: Detector-Free Local Feature Matching With Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_LoFTR_Detector-Free_Local_Feature_Matching_With_Transformers_CVPR_2021_paper.html",
        "author": "Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, Xiaowei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_LoFTR_Detector-Free_Local_Feature_Matching_With_Transformers_CVPR_2021_paper.pdf",
        "aff": "Zhejiang University, SenseTime Research; Zhejiang University",
        "project": "https://zju3dv.github.io/loftr/",
        "github": "",
        "arxiv": "2104.00680"
    },
    {
        "title": "Localizing Visual Sounds the Hard Way",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Localizing_Visual_Sounds_the_Hard_Way_CVPR_2021_paper.html",
        "author": "Honglie Chen, Weidi Xie, Triantafyllos Afouras, Arsha Nagrani, Andrea Vedaldi, Andrew Zisserman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Localizing_Visual_Sounds_the_Hard_Way_CVPR_2021_paper.pdf",
        "aff": "VGG, Department of Engineering Science, University of Oxford, UK",
        "project": "http://www.robots.ox.ac.uk/~vgg/research/lvs/",
        "github": "",
        "arxiv": "2104.02691"
    },
    {
        "title": "Locally Aware Piecewise Transformation Fields for 3D Human Mesh Registration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Locally_Aware_Piecewise_Transformation_Fields_for_3D_Human_Mesh_Registration_CVPR_2021_paper.html",
        "author": "Shaofei Wang, Andreas Geiger, Siyu Tang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Locally_Aware_Piecewise_Transformation_Fields_for_3D_Human_Mesh_Registration_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen; ETH Z\u00fcrich",
        "project": "",
        "github": "",
        "arxiv": "2104.08160"
    },
    {
        "title": "Locate Then Segment: A Strong Pipeline for Referring Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jing_Locate_Then_Segment_A_Strong_Pipeline_for_Referring_Image_Segmentation_CVPR_2021_paper.html",
        "author": "Ya Jing, Tao Kong, Wei Wang, Liang Wang, Lei Li, Tieniu Tan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jing_Locate_Then_Segment_A_Strong_Pipeline_for_Referring_Image_Segmentation_CVPR_2021_paper.pdf",
        "aff": "ByteDance AI Lab; Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA), School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences (UCAS)",
        "project": "",
        "github": "",
        "arxiv": "2103.16284"
    },
    {
        "title": "Long-Tailed Multi-Label Visual Recognition by Collaborative Training on Uniform and Re-Balanced Samplings",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Long-Tailed_Multi-Label_Visual_Recognition_by_Collaborative_Training_on_Uniform_and_CVPR_2021_paper.html",
        "author": "Hao Guo, Song Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Long-Tailed_Multi-Label_Visual_Recognition_by_Collaborative_Training_on_Uniform_and_CVPR_2021_paper.pdf",
        "aff": "University of South Carolina, Columbia, SC 29201, US",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Look Before You Leap: Learning Landmark Features for One-Stage Visual Grounding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Look_Before_You_Leap_Learning_Landmark_Features_for_One-Stage_Visual_CVPR_2021_paper.html",
        "author": "Binbin Huang, Dongze Lian, Weixin Luo, Shenghua Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Look_Before_You_Leap_Learning_Landmark_Features_for_One-Stage_Visual_CVPR_2021_paper.pdf",
        "aff": "ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; ShanghaiTech University",
        "project": "",
        "github": "https://github.com/svip-lab/LBYLNet",
        "arxiv": "2104.04386"
    },
    {
        "title": "Look Before You Speak: Visually Contextualized Utterances",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Seo_Look_Before_You_Speak_Visually_Contextualized_Utterances_CVPR_2021_paper.html",
        "author": "Paul Hongsuck Seo, Arsha Nagrani, Cordelia Schmid",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Seo_Look_Before_You_Speak_Visually_Contextualized_Utterances_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "",
        "arxiv": "2012.05710"
    },
    {
        "title": "Look Closer To Segment Better: Boundary Patch Refinement for Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Look_Closer_To_Segment_Better_Boundary_Patch_Refinement_for_Instance_CVPR_2021_paper.html",
        "author": "Chufeng Tang, Hang Chen, Xiao Li, Jianmin Li, Zhaoxiang Zhang, Xiaolin Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Look_Closer_To_Segment_Better_Boundary_Patch_Refinement_for_Instance_CVPR_2021_paper.pdf",
        "aff": "Institute of Automation, CAS & University of Chinese Academy of Sciences & Centre for Arti\ufb01cial Intelligence and Robotics, HKISI CAS; State Key Laboratory of Intelligent Technology and Systems, THU-Bosch JCML Center, BNRist, Institute for AI, Department of Computer Science and Technology, Tsinghua University",
        "project": "",
        "github": "https://github.com/tinyalpha/BPR",
        "arxiv": "2104.05239"
    },
    {
        "title": "Looking Into Your Speech: Learning Cross-Modal Affinity for Audio-Visual Speech Separation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Looking_Into_Your_Speech_Learning_Cross-Modal_Affinity_for_Audio-Visual_Speech_CVPR_2021_paper.html",
        "author": "Jiyoung Lee, Soo-Whan Chung, Sunok Kim, Hong-Goo Kang, Kwanghoon Sohn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Looking_Into_Your_Speech_Learning_Cross-Modal_Affinity_for_Audio-Visual_Speech_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical & Electronic Engineering, Yonsei University, Korea; Naver Corporation, Korea; Department of Electrical & Electronic Engineering, Yonsei University, Korea; Korea Aerospace University, Korea",
        "project": "https://caffnet.github.io/",
        "github": "https://github.com/caffnet",
        "arxiv": "2104.02775"
    },
    {
        "title": "M3DSSD: Monocular 3D Single Stage Object Detector",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_M3DSSD_Monocular_3D_Single_Stage_Object_Detector_CVPR_2021_paper.html",
        "author": "Shujie Luo, Hang Dai, Ling Shao, Yong Ding",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_M3DSSD_Monocular_3D_Single_Stage_Object_Detector_CVPR_2021_paper.pdf",
        "aff": "Mohamed bin Zayed University of Arti\ufb01cial Intelligence, Abu Dhabi, UAE; College of Information Science and Electronic Engineering, Zhejiang University; School of Micro-Nano Electronics, Zhejiang University",
        "project": "",
        "github": "https://github.com/mumianyuxin/M3DSSD",
        "arxiv": "2103.13164"
    },
    {
        "title": "M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ni_M3P_Learning_Universal_Representations_via_Multitask_Multilingual_Multimodal_Pre-Training_CVPR_2021_paper.html",
        "author": "Minheng Ni, Haoyang Huang, Lin Su, Edward Cui, Taroon Bharti, Lijuan Wang, Dongdong Zhang, Nan Duan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ni_M3P_Learning_Universal_Representations_via_Multitask_Multilingual_Multimodal_Pre-Training_CVPR_2021_paper.pdf",
        "aff": "Cloud+AI, Microsoft, United States; Natural Language Computing, Microsoft Research Asia, China; Bing Multimedia Team, Microsoft, China; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China",
        "project": "",
        "github": "",
        "arxiv": "2006.02635"
    },
    {
        "title": "MASA-SR: Matching Acceleration and Spatial Adaptation for Reference-Based Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lu_MASA-SR_Matching_Acceleration_and_Spatial_Adaptation_for_Reference-Based_Image_Super-Resolution_CVPR_2021_paper.html",
        "author": "Liying Lu, Wenbo Li, Xin Tao, Jiangbo Lu, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_MASA-SR_Matching_Acceleration_and_Spatial_Adaptation_for_Reference-Based_Image_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "SmartMore; The Chinese University of Hong Kong and SmartMore; Kuaishou; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kariyappa_MAZE_Data-Free_Model_Stealing_Attack_Using_Zeroth-Order_Gradient_Estimation_CVPR_2021_paper.html",
        "author": "Sanjay Kariyappa, Atul Prakash, Moinuddin K Qureshi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kariyappa_MAZE_Data-Free_Model_Stealing_Attack_Using_Zeroth-Order_Gradient_Estimation_CVPR_2021_paper.pdf",
        "aff": "University of Michigan, Ann Arbor MI, USA; Georgia Institute of Technology, Atlanta GA, USA",
        "project": "",
        "github": "",
        "arxiv": "2005.03161"
    },
    {
        "title": "MIST: Multiple Instance Self-Training Framework for Video Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Feng_MIST_Multiple_Instance_Self-Training_Framework_for_Video_Anomaly_Detection_CVPR_2021_paper.html",
        "author": "Jia-Chang Feng, Fa-Ting Hong, Wei-Shi Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_MIST_Multiple_Instance_Self-Training_Framework_for_Video_Anomaly_Detection_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Sun Yat-Sen University; Pazhou Lab, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-Sen University; School of Computer Science and Engineering, Sun Yat-Sen University; Peng Cheng Laboratory, Shenzhen, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China",
        "project": "",
        "github": "",
        "arxiv": "2104.01633"
    },
    {
        "title": "MIST: Multiple Instance Spatial Transformer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Angles_MIST_Multiple_Instance_Spatial_Transformer_CVPR_2021_paper.html",
        "author": "Baptiste Angles, Yuhe Jin, Simon Kornblith, Andrea Tagliasacchi, Kwang Moo Yi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Angles_MIST_Multiple_Instance_Spatial_Transformer_CVPR_2021_paper.pdf",
        "aff": "University of Victoria; University of Victoria, University of British Columbia; University of British Columbia; Google Research",
        "project": "",
        "github": "https://github.com/ubc-vision/mist",
        "arxiv": "1811.10725"
    },
    {
        "title": "MOOD: Multi-Level Out-of-Distribution Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_MOOD_Multi-Level_Out-of-Distribution_Detection_CVPR_2021_paper.html",
        "author": "Ziqian Lin, Sreya Dutta Roy, Yixuan Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_MOOD_Multi-Level_Out-of-Distribution_Detection_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Sciences, University of Wisconsin-Madison",
        "project": "",
        "github": "",
        "arxiv": "2104.14726"
    },
    {
        "title": "MOS: Towards Scaling Out-of-Distribution Detection for Large Semantic Space",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_MOS_Towards_Scaling_Out-of-Distribution_Detection_for_Large_Semantic_Space_CVPR_2021_paper.html",
        "author": "Rui Huang, Yixuan Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_MOS_Towards_Scaling_Out-of-Distribution_Detection_for_Large_Semantic_Space_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Sciences, University of Wisconsin-Madison",
        "project": "",
        "github": "",
        "arxiv": "2105.01879"
    },
    {
        "title": "MOST: A Multi-Oriented Scene Text Detector With Localization Refinement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_MOST_A_Multi-Oriented_Scene_Text_Detector_With_Localization_Refinement_CVPR_2021_paper.html",
        "author": "Minghang He, Minghui Liao, Zhibo Yang, Humen Zhong, Jun Tang, Wenqing Cheng, Cong Yao, Yongpan Wang, Xiang Bai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_MOST_A_Multi-Oriented_Scene_Text_Detector_With_Localization_Refinement_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group; Huazhong University of Science and Technology; Nanjing University",
        "project": "",
        "github": "",
        "arxiv": "2104.01070"
    },
    {
        "title": "MP3: A Unified Model To Map, Perceive, Predict and Plan",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Casas_MP3_A_Unified_Model_To_Map_Perceive_Predict_and_Plan_CVPR_2021_paper.html",
        "author": "Sergio Casas, Abbas Sadat, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Casas_MP3_A_Unified_Model_To_Map_Perceive_Predict_and_Plan_CVPR_2021_paper.pdf",
        "aff": "Uber ATG, University of Toronto",
        "project": "",
        "github": "",
        "arxiv": "2101.06806"
    },
    {
        "title": "MR Image Super-Resolution With Squeeze and Excitation Reasoning Attention Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_MR_Image_Super-Resolution_With_Squeeze_and_Excitation_Reasoning_Attention_Network_CVPR_2021_paper.html",
        "author": "Yulun Zhang, Kai Li, Kunpeng Li, Yun Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_MR_Image_Super-Resolution_With_Squeeze_and_Excitation_Reasoning_Attention_Network_CVPR_2021_paper.pdf",
        "aff": "Khoury College of Computer Science, Northeastern University, USA; Department of ECE, Northeastern University, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MUST-GAN: Multi-Level Statistics Transfer for Self-Driven Person Image Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_MUST-GAN_Multi-Level_Statistics_Transfer_for_Self-Driven_Person_Image_Generation_CVPR_2021_paper.html",
        "author": "Tianxiang Ma, Bo Peng, Wei Wang, Jing Dong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_MUST-GAN_Multi-Level_Statistics_Transfer_for_Self-Driven_Person_Image_Generation_CVPR_2021_paper.pdf",
        "aff": "School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; Center for Research on Intelligent Perception and Computing, CASIA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MaX-DeepLab: End-to-End Panoptic Segmentation With Mask Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_MaX-DeepLab_End-to-End_Panoptic_Segmentation_With_Mask_Transformers_CVPR_2021_paper.html",
        "author": "Huiyu Wang, Yukun Zhu, Hartwig Adam, Alan Yuille, Liang-Chieh Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_MaX-DeepLab_End-to-End_Panoptic_Segmentation_With_Mask_Transformers_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Google Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MagDR: Mask-Guided Detection and Reconstruction for Defending Deepfakes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_MagDR_Mask-Guided_Detection_and_Reconstruction_for_Defending_Deepfakes_CVPR_2021_paper.html",
        "author": "Zhikai Chen, Lingxi Xie, Shanmin Pang, Yong He, Bo Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_MagDR_Mask-Guided_Detection_and_Reconstruction_for_Defending_Deepfakes_CVPR_2021_paper.pdf",
        "aff": "Tencent Blade Team; Huawei Inc.; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": "2103.14211"
    },
    {
        "title": "MagFace: A Universal Representation for Face Recognition and Quality Assessment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Meng_MagFace_A_Universal_Representation_for_Face_Recognition_and_Quality_Assessment_CVPR_2021_paper.html",
        "author": "Qiang Meng, Shichao Zhao, Zhida Huang, Feng Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Meng_MagFace_A_Universal_Representation_for_Face_Recognition_and_Quality_Assessment_CVPR_2021_paper.pdf",
        "aff": "Algorithm Research, Aibee Inc.",
        "project": "",
        "github": "https://github.com/IrvingMeng/MagFace",
        "arxiv": "2103.06627"
    },
    {
        "title": "Magic Layouts: Structural Prior for Component Detection in User Interface Designs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Manandhar_Magic_Layouts_Structural_Prior_for_Component_Detection_in_User_Interface_CVPR_2021_paper.html",
        "author": "Dipu Manandhar, Hailin Jin, John Collomosse",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Manandhar_Magic_Layouts_Structural_Prior_for_Component_Detection_in_User_Interface_CVPR_2021_paper.pdf",
        "aff": "CVSSP, University of Surrey, Guildford, UK; CVSSP, University of Surrey, Guildford, UK; Adobe Research, Creative Intelligence Lab, San Jose, CA; Adobe Research, Creative Intelligence Lab, San Jose, CA",
        "project": "",
        "github": "",
        "arxiv": "2106.07615"
    },
    {
        "title": "Manifold Regularized Dynamic Network Pruning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Manifold_Regularized_Dynamic_Network_Pruning_CVPR_2021_paper.html",
        "author": "Yehui Tang, Yunhe Wang, Yixing Xu, Yiping Deng, Chao Xu, Dacheng Tao, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Manifold_Regularized_Dynamic_Network_Pruning_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, Faculty of Engineering, University of Sydney; Noah\u2019s Ark Lab, Huawei Technologies; Key Lab of Machine Perception (MOE), Dept. of Machine Intelligence, Peking University; Central Software Institution, Huawei Technologies",
        "project": "",
        "github": "https://github.com/huawei-noah/Pruning/tree/master/ManiDP",
        "arxiv": "2103.05861"
    },
    {
        "title": "ManipulaTHOR: A Framework for Visual Object Manipulation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ehsani_ManipulaTHOR_A_Framework_for_Visual_Object_Manipulation_CVPR_2021_paper.html",
        "author": "Kiana Ehsani, Winson Han, Alvaro Herrasti, Eli VanderBilt, Luca Weihs, Eric Kolve, Aniruddha Kembhavi, Roozbeh Mottaghi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ehsani_ManipulaTHOR_A_Framework_for_Visual_Object_Manipulation_CVPR_2021_paper.pdf",
        "aff": "Allen Institute for AI; Allen Institute for AI, University of Washington",
        "project": "https://ai2thor.allenai.org/manipulathor",
        "github": "",
        "arxiv": "2104.11213"
    },
    {
        "title": "Mask Guided Matting via Progressive Refinement Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Mask_Guided_Matting_via_Progressive_Refinement_Network_CVPR_2021_paper.html",
        "author": "Qihang Yu, Jianming Zhang, He Zhang, Yilin Wang, Zhe Lin, Ning Xu, Yutong Bai, Alan Yuille",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_Mask_Guided_Matting_via_Progressive_Refinement_Network_CVPR_2021_paper.pdf",
        "aff": "Adobe; The Johns Hopkins University",
        "project": "",
        "github": "https://github.com/yucornetto/MGMatting",
        "arxiv": "2012.06722"
    },
    {
        "title": "Mask-Embedded Discriminator With Region-Based Semantic Regularization for Semi-Supervised Class-Conditional Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Mask-Embedded_Discriminator_With_Region-Based_Semantic_Regularization_for_Semi-Supervised_Class-Conditional_Image_CVPR_2021_paper.html",
        "author": "Yi Liu, Xiaoyang Huo, Tianyi Chen, Xiangping Zeng, Si Wu, Zhiwen Yu, Hau-San Wong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Mask-Embedded_Discriminator_With_Region-Based_Semantic_Regularization_for_Semi-Supervised_Class-Conditional_Image_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, City University of Hong Kong; School of Computer Science and Engineering, South China University of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Mask-ToF: Learning Microlens Masks for Flying Pixel Correction in Time-of-Flight Imaging",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chugunov_Mask-ToF_Learning_Microlens_Masks_for_Flying_Pixel_Correction_in_Time-of-Flight_CVPR_2021_paper.html",
        "author": "Ilya Chugunov, Seung-Hwan Baek, Qiang Fu, Wolfgang Heidrich, Felix Heide",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chugunov_Mask-ToF_Learning_Microlens_Masks_for_Flying_Pixel_Correction_in_Time-of-Flight_CVPR_2021_paper.pdf",
        "aff": "King Abdullah University of Science and Technology; Princeton University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Masksembles for Uncertainty Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Durasov_Masksembles_for_Uncertainty_Estimation_CVPR_2021_paper.html",
        "author": "Nikita Durasov, Timur Bagautdinov, Pierre Baque, Pascal Fua",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Durasov_Masksembles_for_Uncertainty_Estimation_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Laboratory, EPFL; Neural Concept SA",
        "project": "",
        "github": "",
        "arxiv": "2012.08334"
    },
    {
        "title": "MaxUp: Lightweight Adversarial Training With Data Augmentation Improves Neural Network Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gong_MaxUp_Lightweight_Adversarial_Training_With_Data_Augmentation_Improves_Neural_Network_CVPR_2021_paper.html",
        "author": "Chengyue Gong, Tongzheng Ren, Mao Ye, Qiang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gong_MaxUp_Lightweight_Adversarial_Training_With_Data_Augmentation_Improves_Neural_Network_CVPR_2021_paper.pdf",
        "aff": "University of Texas, Austin",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MeGA-CDA: Memory Guided Attention for Category-Aware Unsupervised Domain Adaptive Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/VS_MeGA-CDA_Memory_Guided_Attention_for_Category-Aware_Unsupervised_Domain_Adaptive_Object_CVPR_2021_paper.html",
        "author": "Vibashan VS, Vikram Gupta, Poojan Oza, Vishwanath A. Sindagi, Vishal M. Patel",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/VS_MeGA-CDA_Memory_Guided_Attention_for_Category-Aware_Unsupervised_Domain_Adaptive_Object_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University, Baltimore, MD, USA; Mercedes-Benz Research and Development India",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MeanShift++: Extremely Fast Mode-Seeking With Applications to Segmentation and Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jang_MeanShift_Extremely_Fast_Mode-Seeking_With_Applications_to_Segmentation_and_Object_CVPR_2021_paper.html",
        "author": "Jennifer Jang, Heinrich Jiang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jang_MeanShift_Extremely_Fast_Mode-Seeking_With_Applications_to_Segmentation_and_Object_CVPR_2021_paper.pdf",
        "aff": "Waymo; Google Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Memory Oriented Transfer Learning for Semi-Supervised Image Deraining",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Memory_Oriented_Transfer_Learning_for_Semi-Supervised_Image_Deraining_CVPR_2021_paper.html",
        "author": "Huaibo Huang, Aijing Yu, Ran He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Memory_Oriented_Transfer_Learning_for_Semi-Supervised_Image_Deraining_CVPR_2021_paper.pdf",
        "aff": "Center for Excellence in Brain Science and Intelligence Technology, CAS; Center for Research on Intelligent Perception and Computing, CASIA; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, CASIA; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Memory-Efficient Network for Large-Scale Video Compressive Sensing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Memory-Efficient_Network_for_Large-Scale_Video_Compressive_Sensing_CVPR_2021_paper.html",
        "author": "Ziheng Cheng, Bo Chen, Guanliang Liu, Hao Zhang, Ruiying Lu, Zhengjue Wang, Xin Yuan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Memory-Efficient_Network_for_Large-Scale_Video_Compressive_Sensing_CVPR_2021_paper.pdf",
        "aff": "Xidian University; Bell Labs",
        "project": "",
        "github": "https://github.com/BoChenGroup/RevSCI-net",
        "arxiv": "2103.03089"
    },
    {
        "title": "Memory-Guided Unsupervised Image-to-Image Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jeong_Memory-Guided_Unsupervised_Image-to-Image_Translation_CVPR_2021_paper.html",
        "author": "Somi Jeong, Youngjung Kim, Eungbean Lee, Kwanghoon Sohn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jeong_Memory-Guided_Unsupervised_Image-to-Image_Translation_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical & Electronic Engineering, Yonsei University, Seoul, Korea; Agency for Defense Development (ADD), Daejeon, Korea",
        "project": "",
        "github": "",
        "arxiv": "2104.05170"
    },
    {
        "title": "Mesh Saliency: An Independent Perceptual Measure or a Derivative of Image Saliency?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_Mesh_Saliency_An_Independent_Perceptual_Measure_or_a_Derivative_of_CVPR_2021_paper.html",
        "author": "Ran Song, Wei Zhang, Yitian Zhao, Yonghuai Liu, Paul L. Rosin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Mesh_Saliency_An_Independent_Perceptual_Measure_or_a_Derivative_of_CVPR_2021_paper.pdf",
        "aff": "Mesh Saliency: An Independent Perceptual Measure\nor A Derivative of Image Saliency?\nRan Song1,2Wei Zhang1,2,* Yitian Zhao3Yonghuai Liu4Paul L. Rosin5\n1School of Control Science and Engineering, Shandong University, China\n2Institute of Brain and Brain-Inspired Science, Shandong University, China\n3Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, China\n4Department of Computer Science, Edge Hill University, UK\n5School of Computer Science and Informatics, Cardiff University, UK\n{ransong,davidzhang }@sdu.edu.cn,yitian.zhao@nimte.ac.cn,liuyo@edgehill.ac.uk,RosinPL@cardiff.ac.uk\nAbstract\nWhile mesh saliency aims to predict regional importance\nof 3D surfaces in agreement with human visual perception\nand is well researched in computer vision and graphics, lat-\nest work with eye-tracking experiments shows that state-of-\nthe-art mesh saliency methods remain poor at predicting\nhuman \ufb01xations. Cues emerging prominently from these ex-\nperiments suggest that mesh saliency might associate with\nthe saliency of 2D natural images. This paper proposes a\nnovel deep neural network for learning mesh saliency using\nimage saliency ground truth to 1) investigate whether mesh\nsaliency is an independent perceptual measure or just a\nderivative of image saliency and 2) provide a weakly super-\nvised method for more accurately predicting mesh saliency.\nThrough extensive experiments, we not only demonstrate\nthat our method outperforms the current state-of-the-art\nmesh saliency method by 116% and21% in terms of linear\ncorrelation coef\ufb01cient and AUC respectively, but also re-\nveal that mesh saliency is intrinsically related with both im-\nage saliency and object categorical information. Codes are\navailable at https://github.com/rsong/MIMO-GAN .\n1. Introduction\nMesh saliency, \ufb01rst proposed by the seminal paper of\nLeeet al. [16], measures regional importance of 3D surfaces\nin accordance with human visual perception. While many\nmethods [ 5,23,25,26,17] for mesh saliency have been\npresented since then, recent eye-tracking work [ 34,33,15]\nshows that state-of-the-art mesh saliency methods are poor\nat predicting human \ufb01xations. In particular, Lavou \u00b4eet al.\n[15] found that even a simple centre-bias model, a prior\n*Corresponding authorwidely used for predicting saliency of 2D natural images,\ngenerated better results for various 3D meshes than the\nstate-of-the-art mesh saliency methods including [ 16,26,\n19,17]. Apart from the centre bias, mesh saliency and im-\nage saliency also have other characteristics in common. For\ninstance, it was found that some features such as facial areas\nof people or animals always attract human \ufb01xations no mat-\nter whether they are expressed by 2D images or 3D meshes.\nImage saliency is mainly driven by colour and texture\nwhile the detection of mesh saliency relies largely on object\ngeometry. But the \ufb01ndings above give us an impression that\ndespite such a fundamental difference, mesh saliency might\nbe a derivative of image saliency rather than an independent\nperceptual measure. To explore this proposition, we pro-\nposes to learn mesh saliency from ground-truth saliency of\ngeneral 2D images. In addition, it has been shown that 3D\nobjects of the same category usually have similar saliency\ndistributions [ 2,15]. One explanation is that the information\nvital for object classi\ufb01cation is usually also important for\nsaliency as it can help humans to recognise an object swiftly\nwithout the need for scrutinizing its details [ 27]. There-\nfore, considering that there already exist large-scale public\ndatasets for image saliency (e.g. SALICON Dataset [ 10],\nMIT Saliency Benchmark [ 1] and DUT-OMRON Dataset\n[38]) and 3D object classi\ufb01cation (e.g. ModelNet [ 37] and\nShapeNet [ 21]), we present a weakly supervised deep neu-\nral network for mesh saliency trained jointly with saliency\nmaps of 2D images and category labels of 3D objects.\nImportantly, such a weakly supervised method is poten-\ntially of broad interest as gathering eye-\ufb01xation data for 3D\nobjects is a notoriously laborious task [ 12,34,33,15]. To\nthe best of our knowledge, all existing \ufb01xation datasets for\nmesh saliency are very small (e.g. 5 objects in [ 12], 15 ob-\njects in [ 34], 16 objects in [ 33] and 32 objects in [ 15]). The\n8853\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Mesoscopic Photogrammetry With an Unstabilized Phone Camera",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Mesoscopic_Photogrammetry_With_an_Unstabilized_Phone_Camera_CVPR_2021_paper.html",
        "author": "Kevin C. Zhou, Colin Cooke, Jaehee Park, Ruobing Qian, Roarke Horstmeyer, Joseph A. Izatt, Sina Farsiu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Mesoscopic_Photogrammetry_With_an_Unstabilized_Phone_Camera_CVPR_2021_paper.pdf",
        "aff": "Duke University, Durham, NC",
        "project": "",
        "github": "",
        "arxiv": "2012.06044"
    },
    {
        "title": "Meta Batch-Instance Normalization for Generalizable Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Choi_Meta_Batch-Instance_Normalization_for_Generalizable_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Seokeon Choi, Taekyung Kim, Minki Jeong, Hyoungseob Park, Changick Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Choi_Meta_Batch-Instance_Normalization_for_Generalizable_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "project": "",
        "github": "https://github.com/bismex/MetaBIN",
        "arxiv": "2011.14670"
    },
    {
        "title": "Meta Pseudo Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pham_Meta_Pseudo_Labels_CVPR_2021_paper.html",
        "author": "Hieu Pham, Zihang Dai, Qizhe Xie, Quoc V. Le",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pham_Meta_Pseudo_Labels_CVPR_2021_paper.pdf",
        "aff": "Google AI, Brain Team, Mountain View, CA 94043",
        "project": "",
        "github": "https://github.com/google-research/google-research/tree/master/meta_pseudo_labels",
        "arxiv": "2003.10580"
    },
    {
        "title": "Meta-Mining Discriminative Samples for Kinship Verification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Meta-Mining_Discriminative_Samples_for_Kinship_Verification_CVPR_2021_paper.html",
        "author": "Wanhua Li, Shiwei Wang, Jiwen Lu, Jianjiang Feng, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Meta-Mining_Discriminative_Samples_for_Kinship_Verification_CVPR_2021_paper.pdf",
        "aff": "School of Modern Post, Beijing University of Posts and Telecommunications; Department of Automation, Tsinghua University, China; Beijing National Research Center for Information Science and Technology, China",
        "project": "",
        "github": "",
        "arxiv": "2103.15108"
    },
    {
        "title": "MetaAlign: Coordinating Domain Alignment and Classification for Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wei_MetaAlign_Coordinating_Domain_Alignment_and_Classification_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Guoqiang Wei, Cuiling Lan, Wenjun Zeng, Zhibo Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wei_MetaAlign_Coordinating_Domain_Alignment_and_Classification_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2103.13575"
    },
    {
        "title": "MetaCorrection: Domain-Aware Meta Loss Correction for Unsupervised Domain Adaptation in Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_MetaCorrection_Domain-Aware_Meta_Loss_Correction_for_Unsupervised_Domain_Adaptation_in_CVPR_2021_paper.html",
        "author": "Xiaoqing Guo, Chen Yang, Baopu Li, Yixuan Yuan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_MetaCorrection_Domain-Aware_Meta_Loss_Correction_for_Unsupervised_Domain_Adaptation_in_CVPR_2021_paper.pdf",
        "aff": "City University of Hong Kong; Baidu USA",
        "project": "",
        "github": "https://github.com/cyang-cityu/MetaCorrection",
        "arxiv": "2103.05254"
    },
    {
        "title": "MetaHTR: Towards Writer-Adaptive Handwritten Text Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bhunia_MetaHTR_Towards_Writer-Adaptive_Handwritten_Text_Recognition_CVPR_2021_paper.html",
        "author": "Ayan Kumar Bhunia, Shuvozit Ghose, Amandeep Kumar, Pinaki Nath Chowdhury, Aneeshan Sain, Yi-Zhe Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bhunia_MetaHTR_Towards_Writer-Adaptive_Handwritten_Text_Recognition_CVPR_2021_paper.pdf",
        "aff": "SketchX, CVSSP, University of Surrey, United Kingdom. iFlyTek-Surrey Joint Research Centre on Arti\ufb01cial Intelligence.; SketchX, CVSSP, University of Surrey, United Kingdom.",
        "project": "",
        "github": "",
        "arxiv": "2104.01876"
    },
    {
        "title": "MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_MetaSAug_Meta_Semantic_Augmentation_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.html",
        "author": "Shuang Li, Kaixiong Gong, Chi Harold Liu, Yulin Wang, Feng Qiao, Xinjing Cheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_MetaSAug_Meta_Semantic_Augmentation_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.pdf",
        "aff": "Beijing Institute of Technology; Tsinghua University; Inceptio Tech",
        "project": "",
        "github": "",
        "arxiv": "2103.12579"
    },
    {
        "title": "MetaSCI: Scalable and Adaptive Reconstruction for Video Compressive Sensing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_MetaSCI_Scalable_and_Adaptive_Reconstruction_for_Video_Compressive_Sensing_CVPR_2021_paper.html",
        "author": "Zhengjue Wang, Hao Zhang, Ziheng Cheng, Bo Chen, Xin Yuan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_MetaSCI_Scalable_and_Adaptive_Reconstruction_for_Video_Compressive_Sensing_CVPR_2021_paper.pdf",
        "aff": "National Laboratory of Radar Signal Processing, Xidian University, Xian, China; Bell Labs, NJ USA",
        "project": "",
        "github": "https://github.com/xyvirtualgroup/MetaSCI-CVPR2021",
        "arxiv": "2103.01786"
    },
    {
        "title": "MetaSets: Meta-Learning on Point Sets for Generalizable Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_MetaSets_Meta-Learning_on_Point_Sets_for_Generalizable_Representations_CVPR_2021_paper.html",
        "author": "Chao Huang, Zhangjie Cao, Yunbo Wang, Jianmin Wang, Mingsheng Long",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_MetaSets_Meta-Learning_on_Point_Sets_for_Generalizable_Representations_CVPR_2021_paper.pdf",
        "aff": "School of Software, BNRist, Tsinghua University, China",
        "project": "",
        "github": "",
        "arxiv": "2204.07311"
    },
    {
        "title": "Metadata Normalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Metadata_Normalization_CVPR_2021_paper.html",
        "author": "Mandy Lu, Qingyu Zhao, Jiequan Zhang, Kilian M. Pohl, Li Fei-Fei, Juan Carlos Niebles, Ehsan Adeli",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_Metadata_Normalization_CVPR_2021_paper.pdf",
        "aff": "Stanford University, Stanford, CA 94305",
        "project": "",
        "github": "",
        "arxiv": "2104.09052"
    },
    {
        "title": "MetricOpt: Learning To Optimize Black-Box Evaluation Metrics",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_MetricOpt_Learning_To_Optimize_Black-Box_Evaluation_Metrics_CVPR_2021_paper.html",
        "author": "Chen Huang, Shuangfei Zhai, Pengsheng Guo, Josh Susskind",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_MetricOpt_Learning_To_Optimize_Black-Box_Evaluation_Metrics_CVPR_2021_paper.pdf",
        "aff": "Apple Inc.",
        "project": "",
        "github": "",
        "arxiv": "2104.10631"
    },
    {
        "title": "Minimally Invasive Surgery for Sparse Neural Networks in Contrastive Manner",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Minimally_Invasive_Surgery_for_Sparse_Neural_Networks_in_Contrastive_Manner_CVPR_2021_paper.html",
        "author": "Chong Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_Minimally_Invasive_Surgery_for_Sparse_Neural_Networks_in_Contrastive_Manner_CVPR_2021_paper.pdf",
        "aff": "NVIDIA, Fudan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Mining Better Samples for Contrastive Learning of Temporal Correspondence",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jeon_Mining_Better_Samples_for_Contrastive_Learning_of_Temporal_Correspondence_CVPR_2021_paper.html",
        "author": "Sangryul Jeon, Dongbo Min, Seungryong Kim, Kwanghoon Sohn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jeon_Mining_Better_Samples_for_Contrastive_Learning_of_Temporal_Correspondence_CVPR_2021_paper.pdf",
        "aff": "Yonsei University; Korea University; Ewha Womans University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Mirror3D: Depth Refinement for Mirror Surfaces",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tan_Mirror3D_Depth_Refinement_for_Mirror_Surfaces_CVPR_2021_paper.html",
        "author": "Jiaqi Tan, Weijie Lin, Angel X. Chang, Manolis Savva",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_Mirror3D_Depth_Refinement_for_Mirror_Surfaces_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University",
        "project": "https://3dlg-hcvc.github.io/mirror3d/",
        "github": "",
        "arxiv": "2106.06629"
    },
    {
        "title": "Mitigating Face Recognition Bias via Group Adaptive Classifier",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gong_Mitigating_Face_Recognition_Bias_via_Group_Adaptive_Classifier_CVPR_2021_paper.html",
        "author": "Sixue Gong, Xiaoming Liu, Anil K. Jain",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gong_Mitigating_Face_Recognition_Bias_via_Group_Adaptive_Classifier_CVPR_2021_paper.pdf",
        "aff": "Michigan State University, East Lansing MI 48824",
        "project": "",
        "github": "https://github.com/gongsixue/GAC",
        "arxiv": "2006.07576"
    },
    {
        "title": "Mixed-Privacy Forgetting in Deep Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Golatkar_Mixed-Privacy_Forgetting_in_Deep_Networks_CVPR_2021_paper.html",
        "author": "Aditya Golatkar, Alessandro Achille, Avinash Ravichandran, Marzia Polito, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Golatkar_Mixed-Privacy_Forgetting_in_Deep_Networks_CVPR_2021_paper.pdf",
        "aff": "UCLA; Amazon Web Services",
        "project": "",
        "github": "",
        "arxiv": "2012.13431"
    },
    {
        "title": "MoViNets: Mobile Video Networks for Efficient Video Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kondratyuk_MoViNets_Mobile_Video_Networks_for_Efficient_Video_Recognition_CVPR_2021_paper.html",
        "author": "Dan Kondratyuk, Liangzhe Yuan, Yandong Li, Li Zhang, Mingxing Tan, Matthew Brown, Boqing Gong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kondratyuk_MoViNets_Mobile_Video_Networks_for_Efficient_Video_Recognition_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "https://github.com/google-research/movinet",
        "arxiv": "2103.11511"
    },
    {
        "title": "MobileDets: Searching for Object Detection Architectures for Mobile Accelerators",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xiong_MobileDets_Searching_for_Object_Detection_Architectures_for_Mobile_Accelerators_CVPR_2021_paper.html",
        "author": "Yunyang Xiong, Hanxiao Liu, Suyog Gupta, Berkin Akin, Gabriel Bender, Yongzhe Wang, Pieter-Jan Kindermans, Mingxing Tan, Vikas Singh, Bo Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xiong_MobileDets_Searching_for_Object_Detection_Architectures_for_Mobile_Accelerators_CVPR_2021_paper.pdf",
        "aff": "Google; University of Wisconsin-Madison",
        "project": "",
        "github": "https://github.com/tensorflow/models/tree/master/research/object_detection",
        "arxiv": "2004.14525"
    },
    {
        "title": "Model-Aware Gesture-to-Gesture Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Model-Aware_Gesture-to-Gesture_Translation_CVPR_2021_paper.html",
        "author": "Hezhen Hu, Weilun Wang, Wengang Zhou, Weichao Zhao, Houqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Model-Aware_Gesture-to-Gesture_Translation_CVPR_2021_paper.pdf",
        "aff": "CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China (USTC); Institute of Arti\ufb01cial Intelligence, Hefei Comprehensive National Science Center; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China (USTC)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Model-Based 3D Hand Reconstruction via Self-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Model-Based_3D_Hand_Reconstruction_via_Self-Supervised_Learning_CVPR_2021_paper.html",
        "author": "Yujin Chen, Zhigang Tu, Di Kang, Linchao Bao, Ying Zhang, Xuefei Zhe, Ruizhi Chen, Junsong Yuan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Model-Based_3D_Hand_Reconstruction_via_Self-Supervised_Learning_CVPR_2021_paper.pdf",
        "aff": "Wuhan University; Tencent; Tencent AI Lab; State University of New York at Buffalo",
        "project": "",
        "github": "https://github.com/TerenceCYJ/S2HAND",
        "arxiv": "2103.11703"
    },
    {
        "title": "Model-Contrastive Federated Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Model-Contrastive_Federated_Learning_CVPR_2021_paper.html",
        "author": "Qinbin Li, Bingsheng He, Dawn Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Model-Contrastive_Federated_Learning_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": "2103.16257"
    },
    {
        "title": "Modeling Multi-Label Action Dependencies for Temporal Action Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tirupattur_Modeling_Multi-Label_Action_Dependencies_for_Temporal_Action_Localization_CVPR_2021_paper.html",
        "author": "Praveen Tirupattur, Kevin Duarte, Yogesh S Rawat, Mubarak Shah",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tirupattur_Modeling_Multi-Label_Action_Dependencies_for_Temporal_Action_Localization_CVPR_2021_paper.pdf",
        "aff": "Center for Research in Computer Vision, University of Central Florida, Orlando, Florida, USA",
        "project": "",
        "github": "https://github.com/ptirupat/MLAD",
        "arxiv": "2103.03027"
    },
    {
        "title": "Modular Interactive Video Object Segmentation: Interaction-to-Mask, Propagation and Difference-Aware Fusion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Modular_Interactive_Video_Object_Segmentation_Interaction-to-Mask_Propagation_and_Difference-Aware_Fusion_CVPR_2021_paper.html",
        "author": "Ho Kei Cheng, Yu-Wing Tai, Chi-Keung Tang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Modular_Interactive_Video_Object_Segmentation_Interaction-to-Mask_Propagation_and_Difference-Aware_Fusion_CVPR_2021_paper.pdf",
        "aff": "HKUST; Kuaishou Technology; UIUC/HKUST",
        "project": "https://hkchengrex.github.io/MiVOS",
        "github": "https://github.com/hkchengrex/MiVOS",
        "arxiv": "2103.07941"
    },
    {
        "title": "Mol2Image: Improved Conditional Flow Models for Molecule to Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Mol2Image_Improved_Conditional_Flow_Models_for_Molecule_to_Image_Synthesis_CVPR_2021_paper.html",
        "author": "Karren Yang, Samuel Goldman, Wengong Jin, Alex X. Lu, Regina Barzilay, Tommi Jaakkola, Caroline Uhler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Mol2Image_Improved_Conditional_Flow_Models_for_Molecule_to_Image_Synthesis_CVPR_2021_paper.pdf",
        "aff": "University of Toronto; Massachusetts Institute of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "MongeNet: Efficient Sampler for Geometric Deep Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lebrat_MongeNet_Efficient_Sampler_for_Geometric_Deep_Learning_CVPR_2021_paper.html",
        "author": "Leo Lebrat, Rodrigo Santa Cruz, Clinton Fookes, Olivier Salvado",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lebrat_MongeNet_Efficient_Sampler_for_Geometric_Deep_Learning_CVPR_2021_paper.pdf",
        "aff": "CSIRO, Queensland University of Technology; Queensland University of Technology",
        "project": "https://lebrat.github.io/MongeNet",
        "github": "https://github.com/lebrat/MongeNet",
        "arxiv": "2104.14554"
    },
    {
        "title": "MonoRUn: Monocular 3D Object Detection by Reconstruction and Uncertainty Propagation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_MonoRUn_Monocular_3D_Object_Detection_by_Reconstruction_and_Uncertainty_Propagation_CVPR_2021_paper.html",
        "author": "Hansheng Chen, Yuyao Huang, Wei Tian, Zhong Gao, Lu Xiong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_MonoRUn_Monocular_3D_Object_Detection_by_Reconstruction_and_Uncertainty_Propagation_CVPR_2021_paper.pdf",
        "aff": "Institute of Intelligent Vehicles, School of Automotive Studies, Tongji University",
        "project": "",
        "github": "https://github.com/tjiiv-cprg/MonoRUn",
        "arxiv": "2103.12605"
    },
    {
        "title": "MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments From a Single Moving Camera",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wimbauer_MonoRec_Semi-Supervised_Dense_Reconstruction_in_Dynamic_Environments_From_a_Single_CVPR_2021_paper.html",
        "author": "Felix Wimbauer, Nan Yang, Lukas von Stumberg, Niclas Zeller, Daniel Cremers",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wimbauer_MonoRec_Semi-Supervised_Dense_Reconstruction_in_Dynamic_Environments_From_a_Single_CVPR_2021_paper.pdf",
        "aff": "Technical University of Munich; Technical University of Munich, Artisense",
        "project": "https://vision.in.tum.de/research/monorec",
        "github": "",
        "arxiv": "2011.11814"
    },
    {
        "title": "Monocular 3D Multi-Person Pose Estimation by Integrating Top-Down and Bottom-Up Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Monocular_3D_Multi-Person_Pose_Estimation_by_Integrating_Top-Down_and_Bottom-Up_CVPR_2021_paper.html",
        "author": "Yu Cheng, Bo Wang, Bo Yang, Robby T. Tan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Monocular_3D_Multi-Person_Pose_Estimation_by_Integrating_Top-Down_and_Bottom-Up_CVPR_2021_paper.pdf",
        "aff": "National University of Singapore, Yale-NUS College; Tencent Game AI Research Center; National University of Singapore",
        "project": "",
        "github": "https://github.com/3dpose/3D-Multi-Person-Pose",
        "arxiv": "2104.01797"
    },
    {
        "title": "Monocular 3D Object Detection: An Extrinsic Parameter Free Approach",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Monocular_3D_Object_Detection_An_Extrinsic_Parameter_Free_Approach_CVPR_2021_paper.html",
        "author": "Yunsong Zhou, Yuan He, Hongzi Zhu, Cheng Wang, Hongyang Li, Qinhong Jiang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Monocular_3D_Object_Detection_An_Extrinsic_Parameter_Free_Approach_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research; Shanghai Jiao Tong University; Shanghai AI Laboratory",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Monocular Depth Estimation via Listwise Ranking Using the Plackett-Luce Model",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lienen_Monocular_Depth_Estimation_via_Listwise_Ranking_Using_the_Plackett-Luce_Model_CVPR_2021_paper.html",
        "author": "Julian Lienen, Eyke Hullermeier, Ralph Ewerth, Nils Nommensen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lienen_Monocular_Depth_Estimation_via_Listwise_Ranking_Using_the_Plackett-Luce_Model_CVPR_2021_paper.pdf",
        "aff": "TIB Hannover; L3S Research Center, Leibniz University Hannover; Paderborn University; University of Munich (LMU)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Monocular Real-Time Full Body Capture With Inter-Part Correlations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Monocular_Real-Time_Full_Body_Capture_With_Inter-Part_Correlations_CVPR_2021_paper.html",
        "author": "Yuxiao Zhou, Marc Habermann, Ikhsanul Habibie, Ayush Tewari, Christian Theobalt, Feng Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Monocular_Real-Time_Full_Body_Capture_With_Inter-Part_Correlations_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Informatics; BNRist and School of Software, Tsinghua University; Saarland Informatics Campus",
        "project": "",
        "github": "",
        "arxiv": "2012.06087"
    },
    {
        "title": "Monocular Reconstruction of Neural Face Reflectance Fields",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/R_Monocular_Reconstruction_of_Neural_Face_Reflectance_Fields_CVPR_2021_paper.html",
        "author": "Mallikarjun B R, Ayush Tewari, Tae-Hyun Oh, Tim Weyrich, Bernd Bickel, Hans-Peter Seidel, Hanspeter Pfister, Wojciech Matusik, Mohamed Elgharib, Christian Theobalt",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/R_Monocular_Reconstruction_of_Neural_Face_Reflectance_Fields_CVPR_2021_paper.pdf",
        "aff": "University College London; IST Austria; Harvard University; MIT CSAIL; POSTECH; Max Planck Institute for Informatics, Saarland Informatics Campus",
        "project": "",
        "github": "",
        "arxiv": "2008.10247"
    },
    {
        "title": "Monte Carlo Scene Search for 3D Scene Understanding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hampali_Monte_Carlo_Scene_Search_for_3D_Scene_Understanding_CVPR_2021_paper.html",
        "author": "Shreyas Hampali, Sinisa Stekovic, Sayan Deb Sarkar, Chetan S. Kumar, Friedrich Fraundorfer, Vincent Lepetit",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hampali_Monte_Carlo_Scene_Search_for_3D_Scene_Understanding_CVPR_2021_paper.pdf",
        "aff": "Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Universit \u00b4e Paris-Est, \u00b4Ecole des Ponts ParisTech, Paris, France; Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria",
        "project": "https://www.tugraz.at/index.php?id=50484",
        "github": "",
        "arxiv": "2103.07969"
    },
    {
        "title": "More Photos Are All You Need: Semi-Supervised Learning for Fine-Grained Sketch Based Image Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bhunia_More_Photos_Are_All_You_Need_Semi-Supervised_Learning_for_Fine-Grained_CVPR_2021_paper.html",
        "author": "Ayan Kumar Bhunia, Pinaki Nath Chowdhury, Aneeshan Sain, Yongxin Yang, Tao Xiang, Yi-Zhe Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bhunia_More_Photos_Are_All_You_Need_Semi-Supervised_Learning_for_Fine-Grained_CVPR_2021_paper.pdf",
        "aff": "SketchX, CVSSP, University of Surrey, United Kingdom",
        "project": "",
        "github": "",
        "arxiv": "2103.13990"
    },
    {
        "title": "Motion Representations for Articulated Animation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Siarohin_Motion_Representations_for_Articulated_Animation_CVPR_2021_paper.html",
        "author": "Aliaksandr Siarohin, Oliver J. Woodford, Jian Ren, Menglei Chai, Sergey Tulyakov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Siarohin_Motion_Representations_for_Articulated_Animation_CVPR_2021_paper.pdf",
        "aff": "Snap Inc., Santa Monica, CA; DISI, University of Trento, Italy",
        "project": "",
        "github": "https://github.com/snap-research/articulated-animation",
        "arxiv": "2104.11280"
    },
    {
        "title": "MotionRNN: A Flexible Model for Video Prediction With Spacetime-Varying Motions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_MotionRNN_A_Flexible_Model_for_Video_Prediction_With_Spacetime-Varying_Motions_CVPR_2021_paper.html",
        "author": "Haixu Wu, Zhiyu Yao, Jianmin Wang, Mingsheng Long",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_MotionRNN_A_Flexible_Model_for_Video_Prediction_With_Spacetime-Varying_Motions_CVPR_2021_paper.pdf",
        "aff": "School of Software, BNRist, Tsinghua University, China",
        "project": "",
        "github": "",
        "arxiv": "2103.02243"
    },
    {
        "title": "Multi-Attentional Deepfake Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Multi-Attentional_Deepfake_Detection_CVPR_2021_paper.html",
        "author": "Hanqing Zhao, Wenbo Zhou, Dongdong Chen, Tianyi Wei, Weiming Zhang, Nenghai Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Multi-Attentional_Deepfake_Detection_CVPR_2021_paper.pdf",
        "aff": "Microsoft Cloud AI; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/yoctta/multiple-attention",
        "arxiv": "2103.02406"
    },
    {
        "title": "Multi-Decoding Deraining Network and Quasi-Sparsity Based Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Multi-Decoding_Deraining_Network_and_Quasi-Sparsity_Based_Training_CVPR_2021_paper.html",
        "author": "Yinglong Wang, Chao Ma, Bing Zeng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Multi-Decoding_Deraining_Network_and_Quasi-Sparsity_Based_Training_CVPR_2021_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multi-Institutional Collaborations for Improving Deep Learning-Based Magnetic Resonance Image Reconstruction Using Federated Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Multi-Institutional_Collaborations_for_Improving_Deep_Learning-Based_Magnetic_Resonance_Image_Reconstruction_CVPR_2021_paper.html",
        "author": "Pengfei Guo, Puyang Wang, Jinyuan Zhou, Shanshan Jiang, Vishal M. Patel",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Multi-Institutional_Collaborations_for_Improving_Deep_Learning-Based_Magnetic_Resonance_Image_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Johns Hopkins Medicine",
        "project": "",
        "github": "https://github.com/guopengf/FL-MRCM",
        "arxiv": "2103.02148"
    },
    {
        "title": "Multi-Label Activity Recognition Using Activity-Specific Features and Activity Correlations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Multi-Label_Activity_Recognition_Using_Activity-Specific_Features_and_Activity_Correlations_CVPR_2021_paper.html",
        "author": "Yanyi Zhang, Xinyu Li, Ivan Marsic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Multi-Label_Activity_Recognition_Using_Activity-Specific_Features_and_Activity_Correlations_CVPR_2021_paper.pdf",
        "aff": "Amazon Web Services; Rutgers University\u2013New Brunswick, Electrical and Computer Engineering Department",
        "project": "",
        "github": "",
        "arxiv": "2009.07420"
    },
    {
        "title": "Multi-Label Learning From Single Positive Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cole_Multi-Label_Learning_From_Single_Positive_Labels_CVPR_2021_paper.html",
        "author": "Elijah Cole, Oisin Mac Aodha, Titouan Lorieul, Pietro Perona, Dan Morris, Nebojsa Jojic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cole_Multi-Label_Learning_From_Single_Positive_Labels_CVPR_2021_paper.pdf",
        "aff": "Microsoft AI for Earth; Caltech; Inria; Microsoft Research; University of Edinburgh",
        "project": "",
        "github": "",
        "arxiv": "2106.09708"
    },
    {
        "title": "Multi-Modal Fusion Transformer for End-to-End Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Prakash_Multi-Modal_Fusion_Transformer_for_End-to-End_Autonomous_Driving_CVPR_2021_paper.html",
        "author": "Aditya Prakash, Kashyap Chitta, Andreas Geiger",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Prakash_Multi-Modal_Fusion_Transformer_for_End-to-End_Autonomous_Driving_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen and University of T\u00fcbingen; Max Planck Institute for Intelligent Systems, T\u00fcbingen",
        "project": "",
        "github": "",
        "arxiv": "2104.09224"
    },
    {
        "title": "Multi-Modal Relational Graph for Cross-Modal Video Moment Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zeng_Multi-Modal_Relational_Graph_for_Cross-Modal_Video_Moment_Retrieval_CVPR_2021_paper.html",
        "author": "Yawen Zeng, Da Cao, Xiaochi Wei, Meng Liu, Zhou Zhao, Zheng Qin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zeng_Multi-Modal_Relational_Graph_for_Cross-Modal_Video_Moment_Retrieval_CVPR_2021_paper.pdf",
        "aff": "Shandong Jianzhu University; Hunan University; Baidu Inc.; Zhejiang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multi-Objective Interpolation Training for Robustness To Label Noise",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ortego_Multi-Objective_Interpolation_Training_for_Robustness_To_Label_Noise_CVPR_2021_paper.html",
        "author": "Diego Ortego, Eric Arazo, Paul Albert, Noel E. O'Connor, Kevin McGuinness",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ortego_Multi-Objective_Interpolation_Training_for_Robustness_To_Label_Noise_CVPR_2021_paper.pdf",
        "aff": "Insight Centre for Data Analytics, Dublin City University (DCU)",
        "project": "",
        "github": "https://git.io/JI40X",
        "arxiv": "2012.04462"
    },
    {
        "title": "Multi-Person Implicit Reconstruction From a Single Image",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mustafa_Multi-Person_Implicit_Reconstruction_From_a_Single_Image_CVPR_2021_paper.html",
        "author": "Armin Mustafa, Akin Caliskan, Lourdes Agapito, Adrian Hilton",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mustafa_Multi-Person_Implicit_Reconstruction_From_a_Single_Image_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, University College London; CVSSP, University of Surrey",
        "project": "",
        "github": "",
        "arxiv": "2104.09283"
    },
    {
        "title": "Multi-Perspective LSTM for Joint Visual Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sepas-Moghaddam_Multi-Perspective_LSTM_for_Joint_Visual_Representation_Learning_CVPR_2021_paper.html",
        "author": "Alireza Sepas-Moghaddam, Fernando Pereira, Paulo Lobato Correia, Ali Etemad",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sepas-Moghaddam_Multi-Perspective_LSTM_for_Joint_Visual_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Instituto de Telecomunicac\u00f5es, Instituto Superior T\u00e9cnico - Universidade de Lisboa, Lisbon, Portugal; Dept. ECE and Ingenuity Labs Research Institute, Queen\u2019s University, Kingston, Ontario, Canada",
        "project": "",
        "github": "https://github.com/arsm/MPLSTM",
        "arxiv": ""
    },
    {
        "title": "Multi-Scale Aligned Distillation for Low-Resolution Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qi_Multi-Scale_Aligned_Distillation_for_Low-Resolution_Detection_CVPR_2021_paper.html",
        "author": "Lu Qi, Jason Kuen, Jiuxiang Gu, Zhe Lin, Yi Wang, Yukang Chen, Yanwei Li, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qi_Multi-Scale_Aligned_Distillation_for_Low-Resolution_Detection_CVPR_2021_paper.pdf",
        "aff": "SmartMore; Adobe Research; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/Jia-Research-Lab/MSAD",
        "arxiv": ""
    },
    {
        "title": "Multi-Shot Temporal Event Localization: A Benchmark",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Multi-Shot_Temporal_Event_Localization_A_Benchmark_CVPR_2021_paper.html",
        "author": "Xiaolong Liu, Yao Hu, Song Bai, Fei Ding, Xiang Bai, Philip H. S. Torr",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Multi-Shot_Temporal_Event_Localization_A_Benchmark_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group; Huazhong University of Science and Technology; University of Oxford",
        "project": "https://songbai.site/muses/",
        "github": "",
        "arxiv": "2012.09434"
    },
    {
        "title": "Multi-Source Domain Adaptation With Collaborative Learning for Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_Multi-Source_Domain_Adaptation_With_Collaborative_Learning_for_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Jianzhong He, Xu Jia, Shuaijun Chen, Jianzhuang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_Multi-Source_Domain_Adaptation_With_Collaborative_Learning_for_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Dalian University of Technology; Data Storage and Intelligent Vision Technical Research Dept, Huawei Cloud; Noah\u2019s Ark Lab, Huawei Technologies",
        "project": "",
        "github": "",
        "arxiv": "2103.04717"
    },
    {
        "title": "Multi-Stage Aggregated Transformer Network for Temporal Language Localization in Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Multi-Stage_Aggregated_Transformer_Network_for_Temporal_Language_Localization_in_Videos_CVPR_2021_paper.html",
        "author": "Mingxing Zhang, Yang Yang, Xinghan Chen, Yanli Ji, Xing Xu, Jingjing Li, Heng Tao Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Multi-Stage_Aggregated_Transformer_Network_for_Temporal_Language_Localization_in_Videos_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering and Digital Media Technology Key Laboratory of Sichuan Province, UESTC; School of Computer Science and Engineering and Digital Media Technology Key Laboratory of Sichuan Province, UESTC; Institute of Electronic and Information Engineering of UESTC in Guangdong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Multi-Stage Progressive Image Restoration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zamir_Multi-Stage_Progressive_Image_Restoration_CVPR_2021_paper.html",
        "author": "Syed Waqas Zamir, Aditya Arora, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Ming-Hsuan Yang, Ling Shao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zamir_Multi-Stage_Progressive_Image_Restoration_CVPR_2021_paper.pdf",
        "aff": "Inception Institute of AI; University of California, Merced; Mohamed bin Zayed University of AI; Monash University",
        "project": "",
        "github": "https://github.com/swz30/MPRNet",
        "arxiv": "2102.02808"
    },
    {
        "title": "Multi-Target Domain Adaptation With Collaborative Consistency Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Isobe_Multi-Target_Domain_Adaptation_With_Collaborative_Consistency_Learning_CVPR_2021_paper.html",
        "author": "Takashi Isobe, Xu Jia, Shuaijun Chen, Jianzhong He, Yongjie Shi, Jianzhuang Liu, Huchuan Lu, Shengjin Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Isobe_Multi-Target_Domain_Adaptation_With_Collaborative_Consistency_Learning_CVPR_2021_paper.pdf",
        "aff": "Dalian University of Technology; Department of Electronic Engineering, Tsinghua University; Noah\u2019s Ark Lab, Huawei Technologies; Key Laboratory of Machine Perception (MOE), Peking University",
        "project": "",
        "github": "https://github.com/junpan19/MTDA",
        "arxiv": "2106.03418"
    },
    {
        "title": "Multi-View 3D Reconstruction of a Texture-Less Smooth Surface of Unknown Generic Reflectance",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Multi-View_3D_Reconstruction_of_a_Texture-Less_Smooth_Surface_of_Unknown_CVPR_2021_paper.html",
        "author": "Ziang Cheng, Hongdong Li, Yuta Asano, Yinqiang Zheng, Imari Sato",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Multi-View_3D_Reconstruction_of_a_Texture-Less_Smooth_Surface_of_Unknown_CVPR_2021_paper.pdf",
        "aff": "National Institute of Informatics; Australian National University; The University of Tokyo, Japan",
        "project": "",
        "github": "",
        "arxiv": "2105.11599"
    },
    {
        "title": "Multi-View Multi-Person 3D Pose Estimation With Plane Sweep Stereo",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Multi-View_Multi-Person_3D_Pose_Estimation_With_Plane_Sweep_Stereo_CVPR_2021_paper.html",
        "author": "Jiahao Lin, Gim Hee Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Multi-View_Multi-Person_3D_Pose_Estimation_With_Plane_Sweep_Stereo_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, National University of Singapore",
        "project": "",
        "github": "https://github.com/jiahaoLjh/PlaneSweepPose",
        "arxiv": "2104.02273"
    },
    {
        "title": "Multi-view Depth Estimation using Epipolar Spatio-Temporal Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Long_Multi-view_Depth_Estimation_using_Epipolar_Spatio-Temporal_Networks_CVPR_2021_paper.html",
        "author": "Xiaoxiao Long, Lingjie Liu, Wei Li, Christian Theobalt, Wenping Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Long_Multi-view_Depth_Estimation_using_Epipolar_Spatio-Temporal_Networks_CVPR_2021_paper.pdf",
        "aff": "Texas A&M University; Max Planck Institute for Informatics; The University of Hong Kong; Inceptio",
        "project": "",
        "github": "",
        "arxiv": "2011.13118"
    },
    {
        "title": "MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan Synchronization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_MultiBodySync_Multi-Body_Segmentation_and_Motion_Estimation_via_3D_Scan_Synchronization_CVPR_2021_paper.html",
        "author": "Jiahui Huang, He Wang, Tolga Birdal, Minhyuk Sung, Federica Arrigoni, Shi-Min Hu, Leonidas J. Guibas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_MultiBodySync_Multi-Body_Segmentation_and_Motion_Estimation_via_3D_Scan_Synchronization_CVPR_2021_paper.pdf",
        "aff": "KAIST; Stanford University; University of Trento; Tsinghua University",
        "project": "",
        "github": "https://github.com/huangjh-pub/multibody-sync",
        "arxiv": "2101.06605"
    },
    {
        "title": "MultiLink: Multi-Class Structure Recovery via Agglomerative Clustering and Model Selection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Magri_MultiLink_Multi-Class_Structure_Recovery_via_Agglomerative_Clustering_and_Model_Selection_CVPR_2021_paper.html",
        "author": "Luca Magri, Filippo Leveni, Giacomo Boracchi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Magri_MultiLink_Multi-Class_Structure_Recovery_via_Agglomerative_Clustering_and_Model_Selection_CVPR_2021_paper.pdf",
        "aff": "Politecnico di Milano, DEIB",
        "project": "",
        "github": "https://github.com/magrilu/multilink.git",
        "arxiv": ""
    },
    {
        "title": "Multimodal Contrastive Training for Visual Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_Multimodal_Contrastive_Training_for_Visual_Representation_Learning_CVPR_2021_paper.html",
        "author": "Xin Yuan, Zhe Lin, Jason Kuen, Jianming Zhang, Yilin Wang, Michael Maire, Ajinkya Kale, Baldo Faieta",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_Multimodal_Contrastive_Training_for_Visual_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; University of Chicago",
        "project": "",
        "github": "",
        "arxiv": "2104.12836"
    },
    {
        "title": "Multimodal Motion Prediction With Stacked Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Multimodal_Motion_Prediction_With_Stacked_Transformers_CVPR_2021_paper.html",
        "author": "Yicheng Liu, Jinghuai Zhang, Liangji Fang, Qinhong Jiang, Bolei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Multimodal_Motion_Prediction_With_Stacked_Transformers_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://decisionforce.github.io/mmTransformer",
        "arxiv": "2103.11624"
    },
    {
        "title": "Multiple Instance Active Learning for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_Multiple_Instance_Active_Learning_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Tianning Yuan, Fang Wan, Mengying Fu, Jianzhuang Liu, Songcen Xu, Xiangyang Ji, Qixiang Ye",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_Multiple_Instance_Active_Learning_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Noah\u2019s Ark Lab, Huawei Technologies, Shenzhen, China; Tsinghua University, Beijing, China; University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "https://github.com/yuantn/MI-AOD",
        "arxiv": "2104.02324"
    },
    {
        "title": "Multiple Instance Captioning: Learning Representations From Histopathology Textbooks and Articles",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gamper_Multiple_Instance_Captioning_Learning_Representations_From_Histopathology_Textbooks_and_Articles_CVPR_2021_paper.html",
        "author": "Jevgenij Gamper, Nasir Rajpoot",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gamper_Multiple_Instance_Captioning_Learning_Representations_From_Histopathology_Textbooks_and_Articles_CVPR_2021_paper.pdf",
        "aff": "University of Warwick, UK",
        "project": "",
        "github": "",
        "arxiv": "2103.05121"
    },
    {
        "title": "Multiple Object Tracking With Correlation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Multiple_Object_Tracking_With_Correlation_Learning_CVPR_2021_paper.html",
        "author": "Qiang Wang, Yun Zheng, Pan Pan, Yinghui Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Multiple_Object_Tracking_With_Correlation_Learning_CVPR_2021_paper.pdf",
        "aff": "Machine Intelligence Technology Lab, Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": "2104.03541"
    },
    {
        "title": "Multiresolution Knowledge Distillation for Anomaly Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Salehi_Multiresolution_Knowledge_Distillation_for_Anomaly_Detection_CVPR_2021_paper.html",
        "author": "Mohammadreza Salehi, Niousha Sadjadi, Soroosh Baselizadeh, Mohammad H. Rohban, Hamid R. Rabiee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Salehi_Multiresolution_Knowledge_Distillation_for_Anomaly_Detection_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Engineering, Sharif University of Technology",
        "project": "",
        "github": "",
        "arxiv": "2011.11108"
    },
    {
        "title": "Multispectral Photometric Stereo for Spatially-Varying Spectral Reflectances: A Well Posed Problem?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Multispectral_Photometric_Stereo_for_Spatially-Varying_Spectral_Reflectances_A_Well_Posed_CVPR_2021_paper.html",
        "author": "Heng Guo, Fumio Okura, Boxin Shi, Takuya Funatomi, Yasuhiro Mukaigawa, Yasuyuki Matsushita",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Multispectral_Photometric_Stereo_for_Spatially-Varying_Spectral_Reflectances_A_Well_Posed_CVPR_2021_paper.pdf",
        "aff": "Peking University; Osaka University; Nara Institute of Science and Technology",
        "project": "",
        "github": "https://github.com/GH-HOME/MultispectralPS.git",
        "arxiv": ""
    },
    {
        "title": "Mutual CRF-GNN for Few-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Mutual_CRF-GNN_for_Few-Shot_Learning_CVPR_2021_paper.html",
        "author": "Shixiang Tang, Dapeng Chen, Lei Bai, Kaijian Liu, Yixiao Ge, Wanli Ouyang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Mutual_CRF-GNN_for_Few-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "Sensetime Group Limited, Hong Kong; The University of Sydney, SenseTime Computer Vision Group, Australia; The Chinese University of Hong Kong, Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Mutual Graph Learning for Camouflaged Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhai_Mutual_Graph_Learning_for_Camouflaged_Object_Detection_CVPR_2021_paper.html",
        "author": "Qiang Zhai, Xin Li, Fan Yang, Chenglizhao Chen, Hong Cheng, Deng-Ping Fan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhai_Mutual_Graph_Learning_for_Camouflaged_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Group 42 (G42); UESTC; Qingdao University; Inception Institute of AI (IIAI)",
        "project": "",
        "github": "https://github.com/fanyang587/MGL",
        "arxiv": "2104.02613"
    },
    {
        "title": "NBNet: Noise Basis Learning for Image Denoising With Subspace Projection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_NBNet_Noise_Basis_Learning_for_Image_Denoising_With_Subspace_Projection_CVPR_2021_paper.html",
        "author": "Shen Cheng, Yuzhi Wang, Haibin Huang, Donghao Liu, Haoqiang Fan, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_NBNet_Noise_Basis_Learning_for_Image_Denoising_With_Subspace_Projection_CVPR_2021_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; Kuaishou Technology; Megvii Technology",
        "project": "",
        "github": "https://github.com/megvii-research/NBNet",
        "arxiv": "2012.15028"
    },
    {
        "title": "NExT-QA: Next Phase of Question-Answering to Explaining Temporal Actions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_NExT-QA_Next_Phase_of_Question-Answering_to_Explaining_Temporal_Actions_CVPR_2021_paper.html",
        "author": "Junbin Xiao, Xindi Shang, Angela Yao, Tat-Seng Chua",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xiao_NExT-QA_Next_Phase_of_Question-Answering_to_Explaining_Temporal_Actions_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, National University of Singapore",
        "project": "",
        "github": "https://github.com/doc-doc/NExT-QA.git",
        "arxiv": ""
    },
    {
        "title": "NPAS: A Compiler-Aware Framework of Unified Network Pruning and Architecture Search for Beyond Real-Time Mobile Acceleration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_NPAS_A_Compiler-Aware_Framework_of_Unified_Network_Pruning_and_Architecture_CVPR_2021_paper.html",
        "author": "Zhengang Li, Geng Yuan, Wei Niu, Pu Zhao, Yanyu Li, Yuxuan Cai, Xuan Shen, Zheng Zhan, Zhenglun Kong, Qing Jin, Zhiyu Chen, Sijia Liu, Kaiyuan Yang, Bin Ren, Yanzhi Wang, Xue Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_NPAS_A_Compiler-Aware_Framework_of_Unified_Network_Pruning_and_Architecture_CVPR_2021_paper.pdf",
        "aff": "NPAS: A Compiler-aware Framework of Uni\ufb01ed Network Pruning and\nArchitecture Search for Beyond Real-Time Mobile Acceleration\nZhengang Li\u22c61, Geng Yuan\u22c61, Wei Niu\u22c62, Pu Zhao\u22c61*, Yanyu Li1, Yuxuan Cai1, Xuan Shen1, Zheng Zhan1,\nZhenglun Kong1, Qing Jin1, Zhiyu Chen3, Sijia Liu4, Kaiyuan Yang3, Bin Ren2, Yanzhi Wang1, Xue Lin1\n1Northeastern University,2College of William and Mary,\n3Rice University,4Michigan State University\n1{li.zhen, yuan.geng, zhao.pu, li.yanyu, cai.yuxu, shen.xu, zhan.zhe, kong.zhe,\njinqingking, yanz.wang, xue.lin }@northeastern.edu\n2wniu@email.wm.edu, bren@cs.wm.edu ,3{zc37, kyang}@rice.edu ,4liusiji5@msu.edu\nAbstract\nWith the increasing demand to ef\ufb01ciently deploy DNNs\non mobile edge devices, it becomes much more important\nto reduce unnecessary computation and increase the exe-\ncution speed. Prior methods towards this goal, including\nmodel compression and network architecture search (NAS),\nare largely performed independently, and do not fully con-\nsider compiler-level optimizations which is a must-do for\nmobile acceleration. In this work, we \ufb01rst propose (i) a gen-\neral category of \ufb01ne-grained structured pruning applicable\nto various DNN layers, and (ii) a comprehensive, compiler\nautomatic code generation framework supporting different\nDNNs and different pruning schemes, which bridge the gap\nof model compression and NAS. We further propose NPAS,\na compiler-aware uni\ufb01ed network pruning and architec-\nture search. To deal with large search space, we propose\na meta-modeling procedure based on reinforcement learn-\ning with fast evaluation and Bayesian optimization, ensur-\ning the total number of training epochs comparable with\nrepresentative NAS frameworks. Our framework achieves\n6.7ms, 5.9ms, and 3.9ms ImageNet inference times with\n78.2%, 75% (MobileNet-V3 level), and 71% (MobileNet-V2\nlevel) Top-1 accuracy respectively on an off-the-shelf mo-\nbile phone, consistently outperforming prior work.\n1. Introduction\nThe growing popularity of mobile AI applications and\nthe demand for real-time Deep Neural Network (DNN) ex-\necutions raise signi\ufb01cant challenges for DNN accelerations.\nHowever, the ever-growing size of DNN models causes in-\ntensive computation and memory cost, which impedes the\n*\u22c6These authors contributed equally.deployment on resource limited mobile devices.\nDNN weight pruning [71,21,54,27,28] has\nbeen proved as an effective model compression technique\nthat can remove redundant weights of the DNN models,\nthereby reducing storage and computation costs simultane-\nously. Existing work mainly focus on unstructured pruning\nscheme [ 24,21,46] where arbitrary weight can be removed,\nand (coarse-grained) structured pruning scheme [ 54,85,84,\n50,82,45] to eliminate whole \ufb01lters/channels. The former\nresults in high accuracy but limited hardware parallelism\n(and acceleration), while the latter is the opposite. Another\nactive research area is the Neural Architecture Search\n(NAS) [ 86], which designs more ef\ufb01cient DNN architec-\ntures using automatic searching algorithms. Ef\ufb01cientNet\n[69] and MobileNetV3 [ 30] are representative lightweight\nnetworks obtained by using NAS approaches. Recently,\nhardware-aware NAS [ 68,73,8,33] has been investigated\ntargeting acceleration on actual hardware platforms.\nDifferent from the prior work on coarse-grained pruning\nand NAS that \ufb01nd a smaller, yet regular, DNN structure,\nrecent work [ 48,58,16] propose to prune the weights in a\nmore \ufb01ne-grained manner, e.g., assigning potentially differ-\nent patterns to kernels. Higher accuracy can be achieved\nas a result of the intra-kernel \ufb02exibility, while high hard-\nware parallelism (and mobile inference acceleration) can be\nachieved with the assist of compiler-level code generation\ntechniques [ 58]. This work reveals a new dimension of opti-\nmization: With the aid of advanced compiler optimizations ,\nit is possible to achieve high accuracy and high acceleration\nsimultaneously by injecting a proper degree of \ufb01ne gran-\nularity in weight pruning. Despite the promising results,\npattern-based pruning [ 48,58] is only applied to 3 \u00d73 con-\nvolutional (CONV) layers, which limits the applicability.\nAs the \ufb01rst contribution , we propose a general cate-\ngory of \ufb01ne-grained structured pruning schemes that can be\n14255\n",
        "project": "",
        "github": "",
        "arxiv": "2012.00596"
    },
    {
        "title": "Natural Adversarial Examples",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hendrycks_Natural_Adversarial_Examples_CVPR_2021_paper.html",
        "author": "Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, Dawn Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hendrycks_Natural_Adversarial_Examples_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; UChicago; University of Washington",
        "project": "",
        "github": "",
        "arxiv": "1907.07174"
    },
    {
        "title": "Navigating the GAN Parameter Space for Semantic Image Editing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cherepkov_Navigating_the_GAN_Parameter_Space_for_Semantic_Image_Editing_CVPR_2021_paper.html",
        "author": "Anton Cherepkov, Andrey Voynov, Artem Babenko",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cherepkov_Navigating_the_GAN_Parameter_Space_for_Semantic_Image_Editing_CVPR_2021_paper.pdf",
        "aff": "Yandex, Russia; Moscow Institute of Physics and Technology; Yandex, Russia; HSE University; Yandex, Russia",
        "project": "",
        "github": "https://github.com/yandex-research/navigan",
        "arxiv": "2011.13786"
    },
    {
        "title": "NeRD: Neural 3D Reflection Symmetry Detector",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_NeRD_Neural_3D_Reflection_Symmetry_Detector_CVPR_2021_paper.html",
        "author": "Yichao Zhou, Shichen Liu, Yi Ma",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_NeRD_Neural_3D_Reflection_Symmetry_Detector_CVPR_2021_paper.pdf",
        "aff": "Univ. of Southern California; Univ. of California, Berkeley",
        "project": "",
        "github": "https://github.com/zhou13/nerd",
        "arxiv": "2105.03211"
    },
    {
        "title": "NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Martin-Brualla_NeRF_in_the_Wild_Neural_Radiance_Fields_for_Unconstrained_Photo_CVPR_2021_paper.html",
        "author": "Ricardo Martin-Brualla, Noha Radwan, Mehdi S. M. Sajjadi, Jonathan T. Barron, Alexey Dosovitskiy, Daniel Duckworth",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Martin-Brualla_NeRF_in_the_Wild_Neural_Radiance_Fields_for_Unconstrained_Photo_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Srinivasan_NeRV_Neural_Reflectance_and_Visibility_Fields_for_Relighting_and_View_CVPR_2021_paper.html",
        "author": "Pratul P. Srinivasan, Boyang Deng, Xiuming Zhang, Matthew Tancik, Ben Mildenhall, Jonathan T. Barron",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Srinivasan_NeRV_Neural_Reflectance_and_Visibility_Fields_for_Relighting_and_View_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; MIT; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2012.03927"
    },
    {
        "title": "NeX: Real-Time View Synthesis With Neural Basis Expansion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wizadwongsa_NeX_Real-Time_View_Synthesis_With_Neural_Basis_Expansion_CVPR_2021_paper.html",
        "author": "Suttisak Wizadwongsa, Pakkapon Phongthawee, Jiraphon Yenphraphai, Supasorn Suwajanakorn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wizadwongsa_NeX_Real-Time_View_Synthesis_With_Neural_Basis_Expansion_CVPR_2021_paper.pdf",
        "aff": "VISTEC, Thailand",
        "project": "https://nex-mpi.github.io/",
        "github": "https://github.com/nex-mpi",
        "arxiv": "2103.05606"
    },
    {
        "title": "Nearest Neighbor Matching for Deep Clustering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dang_Nearest_Neighbor_Matching_for_Deep_Clustering_CVPR_2021_paper.html",
        "author": "Zhiyuan Dang, Cheng Deng, Xu Yang, Kun Wei, Heng Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dang_Nearest_Neighbor_Matching_for_Deep_Clustering_CVPR_2021_paper.pdf",
        "aff": "School of Electronic Engineering, Xidian University, Xi'an 710071, China; JD Tech, Beijing 100176, China; Department of Electrical and Computer Engineering, University of Pittsburgh, PA 15260, USA; JD Finance America Corporation, Mountain View, CA 94043, USA; School of Electronic Engineering, Xidian University, Xi'an 710071, China",
        "project": "",
        "github": "https://github.com/ZhiyuanDang/NNM",
        "arxiv": ""
    },
    {
        "title": "Neighbor2Neighbor: Self-Supervised Denoising From Single Noisy Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Neighbor2Neighbor_Self-Supervised_Denoising_From_Single_Noisy_Images_CVPR_2021_paper.html",
        "author": "Tao Huang, Songjiang Li, Xu Jia, Huchuan Lu, Jianzhuang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Neighbor2Neighbor_Self-Supervised_Denoising_From_Single_Noisy_Images_CVPR_2021_paper.pdf",
        "aff": "Dalian University of Technology; Noah\u2019s Ark Lab, Huawei Technologies, Dalian University of Technology; Noah\u2019s Ark Lab, Huawei Technologies; Renmin University of China, Noah\u2019s Ark Lab, Huawei Technologies",
        "project": "",
        "github": "",
        "arxiv": "2101.02824"
    },
    {
        "title": "Neighborhood Contrastive Learning for Novel Class Discovery",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Neighborhood_Contrastive_Learning_for_Novel_Class_Discovery_CVPR_2021_paper.html",
        "author": "Zhun Zhong, Enrico Fini, Subhankar Roy, Zhiming Luo, Elisa Ricci, Nicu Sebe",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_Neighborhood_Contrastive_Learning_for_Novel_Class_Discovery_CVPR_2021_paper.pdf",
        "aff": "Xiamen University; University of Trento; Fondazione Bruno Kessler",
        "project": "",
        "github": "",
        "arxiv": "2106.10731"
    },
    {
        "title": "Neighborhood Normalization for Robust Geometric Feature Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Neighborhood_Normalization_for_Robust_Geometric_Feature_Learning_CVPR_2021_paper.html",
        "author": "Xingtong Liu, Benjamin D. Killeen, Ayushi Sinha, Masaru Ishii, Gregory D. Hager, Russell H. Taylor, Mathias Unberath",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Neighborhood_Normalization_for_Robust_Geometric_Feature_Learning_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Johns Hopkins Medical Institutions",
        "project": "",
        "github": "https://github.com/lppllppl920/NeighborhoodNormalization-Pytorch",
        "arxiv": ""
    },
    {
        "title": "NetAdaptV2: Efficient Neural Architecture Search With Fast Super-Network Training and Architecture Optimization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_NetAdaptV2_Efficient_Neural_Architecture_Search_With_Fast_Super-Network_Training_and_CVPR_2021_paper.html",
        "author": "Tien-Ju Yang, Yi-Lun Liao, Vivienne Sze",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_NetAdaptV2_Efficient_Neural_Architecture_Search_With_Fast_Super-Network_Training_and_CVPR_2021_paper.pdf",
        "aff": "Massachusetts Institute of Technology",
        "project": "http://netadapt.mit.edu",
        "github": "",
        "arxiv": "2104.00031"
    },
    {
        "title": "Network Pruning via Performance Maximization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Network_Pruning_via_Performance_Maximization_CVPR_2021_paper.html",
        "author": "Shangqian Gao, Feihu Huang, Weidong Cai, Heng Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Network_Pruning_via_Performance_Maximization_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, The University of Sydney, NSW 2006, Australia; Electrical and Computer Engineering Department, University of Pittsburgh, PA, USA; JD Finance America Corporation, Mountain View, CA, USA; Electrical and Computer Engineering Department, University of Pittsburgh, PA, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Network Quantization With Element-Wise Gradient Scaling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Network_Quantization_With_Element-Wise_Gradient_Scaling_CVPR_2021_paper.html",
        "author": "Junghyup Lee, Dohyung Kim, Bumsub Ham",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Network_Quantization_With_Element-Wise_Gradient_Scaling_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University",
        "project": "",
        "github": "",
        "arxiv": "2104.00903"
    },
    {
        "title": "NeuTex: Neural Texture Mapping for Volumetric Neural Rendering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xiang_NeuTex_Neural_Texture_Mapping_for_Volumetric_Neural_Rendering_CVPR_2021_paper.html",
        "author": "Fanbo Xiang, Zexiang Xu, Milos Hasan, Yannick Hold-Geoffroy, Kalyan Sunkavalli, Hao Su",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xiang_NeuTex_Neural_Texture_Mapping_for_Volumetric_Neural_Rendering_CVPR_2021_paper.pdf",
        "aff": "University of California, San Diego; Adobe Research",
        "project": "",
        "github": "",
        "arxiv": "2103.00762"
    },
    {
        "title": "Neural Architecture Search With Random Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Neural_Architecture_Search_With_Random_Labels_CVPR_2021_paper.html",
        "author": "Xuanyang Zhang, Pengfei Hou, Xiangyu Zhang, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Neural_Architecture_Search_With_Random_Labels_CVPR_2021_paper.pdf",
        "aff": "MEGVII Technology",
        "project": "",
        "github": "",
        "arxiv": "2101.11834"
    },
    {
        "title": "Neural Auto-Exposure for High-Dynamic Range Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Onzon_Neural_Auto-Exposure_for_High-Dynamic_Range_Object_Detection_CVPR_2021_paper.html",
        "author": "Emmanuel Onzon, Fahim Mannan, Felix Heide",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Onzon_Neural_Auto-Exposure_for_High-Dynamic_Range_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Algolux; Princeton University, Algolux",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Neural Body: Implicit Neural Representations With Structured Latent Codes for Novel View Synthesis of Dynamic Humans",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Peng_Neural_Body_Implicit_Neural_Representations_With_Structured_Latent_Codes_for_CVPR_2021_paper.html",
        "author": "Sida Peng, Yuanqing Zhang, Yinghao Xu, Qianqian Wang, Qing Shuai, Hujun Bao, Xiaowei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Peng_Neural_Body_Implicit_Neural_Representations_With_Structured_Latent_Codes_for_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong; Zhejiang University; Cornell University",
        "project": "",
        "github": "https://zju3dv.github.io/neuralbody/",
        "arxiv": "2012.15838"
    },
    {
        "title": "Neural Camera Simulators",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ouyang_Neural_Camera_Simulators_CVPR_2021_paper.html",
        "author": "Hao Ouyang, Zifan Shi, Chenyang Lei, Ka Lung Law, Qifeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ouyang_Neural_Camera_Simulators_CVPR_2021_paper.pdf",
        "aff": "HKUST; SenseTime",
        "project": "",
        "github": "https://github.com/ken-ouyang/neural-image-simulator",
        "arxiv": "2104.05237"
    },
    {
        "title": "Neural Cellular Automata Manifold",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hernandez_Neural_Cellular_Automata_Manifold_CVPR_2021_paper.html",
        "author": "Alejandro Hernandez, Armand Vilalta, Francesc Moreno-Noguer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hernandez_Neural_Cellular_Automata_Manifold_CVPR_2021_paper.pdf",
        "aff": "Barcelona Supercomputing Center, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Spain",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Neural Deformation Graphs for Globally-Consistent Non-Rigid Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bozic_Neural_Deformation_Graphs_for_Globally-Consistent_Non-Rigid_Reconstruction_CVPR_2021_paper.html",
        "author": "Aljaz Bozic, Pablo Palafox, Michael Zollhofer, Justus Thies, Angela Dai, Matthias Niessner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bozic_Neural_Deformation_Graphs_for_Globally-Consistent_Non-Rigid_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "Technical University of Munich; Facebook Reality Labs Research",
        "project": "",
        "github": "https://aljazbozic.github.io/neural deformation graphs",
        "arxiv": "2012.01451"
    },
    {
        "title": "Neural Descent for Visual 3D Human Pose and Shape",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zanfir_Neural_Descent_for_Visual_3D_Human_Pose_and_Shape_CVPR_2021_paper.html",
        "author": "Andrei Zanfir, Eduard Gabriel Bazavan, Mihai Zanfir, William T. Freeman, Rahul Sukthankar, Cristian Sminchisescu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zanfir_Neural_Descent_for_Visual_3D_Human_Pose_and_Shape_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "",
        "arxiv": "2008.06910"
    },
    {
        "title": "Neural Feature Search for RGB-Infrared Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Neural_Feature_Search_for_RGB-Infrared_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Yehansen Chen, Lin Wan, Zhihang Li, Qianyan Jing, Zongyuan Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Neural_Feature_Search_for_RGB-Infrared_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China",
        "project": "",
        "github": "",
        "arxiv": "2104.02366"
    },
    {
        "title": "Neural Geometric Level of Detail: Real-Time Rendering With Implicit 3D Shapes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Takikawa_Neural_Geometric_Level_of_Detail_Real-Time_Rendering_With_Implicit_3D_CVPR_2021_paper.html",
        "author": "Towaki Takikawa, Joey Litalien, Kangxue Yin, Karsten Kreis, Charles Loop, Derek Nowrouzezahrai, Alec Jacobson, Morgan McGuire, Sanja Fidler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Takikawa_Neural_Geometric_Level_of_Detail_Real-Time_Rendering_With_Implicit_3D_CVPR_2021_paper.pdf",
        "aff": "University of Toronto; NVIDIA, University of Toronto, Vector Institute; NVIDIA; NVIDIA, McGill University; McGill University",
        "project": "nv-tlabs.github.io/nglod",
        "github": "",
        "arxiv": "2101.10994"
    },
    {
        "title": "Neural Lumigraph Rendering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kellnhofer_Neural_Lumigraph_Rendering_CVPR_2021_paper.html",
        "author": "Petr Kellnhofer, Lars C. Jebe, Andrew Jones, Ryan Spicer, Kari Pulli, Gordon Wetzstein",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kellnhofer_Neural_Lumigraph_Rendering_CVPR_2021_paper.pdf",
        "aff": "Stanford University, Raxium; Raxium, Stanford University; Raxium",
        "project": "",
        "github": "",
        "arxiv": "2103.11571"
    },
    {
        "title": "Neural Parts: Learning Expressive 3D Shape Abstractions With Invertible Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Paschalidou_Neural_Parts_Learning_Expressive_3D_Shape_Abstractions_With_Invertible_Neural_CVPR_2021_paper.html",
        "author": "Despoina Paschalidou, Angelos Katharopoulos, Andreas Geiger, Sanja Fidler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Paschalidou_Neural_Parts_Learning_Expressive_3D_Shape_Abstractions_With_Invertible_Neural_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems T\u00fcbingen, University of T\u00fcbingen; Idiap Research Institute, Switzerland, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL); Max Planck Institute for Intelligent Systems T\u00fcbingen, University of T\u00fcbingen, Max Planck ETH Center for Learning Systems; NVIDIA, University of Toronto, Vector Institute",
        "project": "",
        "github": "",
        "arxiv": "2103.10429"
    },
    {
        "title": "Neural Prototype Trees for Interpretable Fine-Grained Image Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html",
        "author": "Meike Nauta, Ron van Bree, Christin Seifert",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.pdf",
        "aff": "University of Twente, the Netherlands; University of Duisburg-Essen, Germany",
        "project": "",
        "github": "github.com/M-Nauta/ProtoTree",
        "arxiv": "2012.02046"
    },
    {
        "title": "Neural Reprojection Error: Merging Feature Learning and Camera Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Germain_Neural_Reprojection_Error_Merging_Feature_Learning_and_Camera_Pose_Estimation_CVPR_2021_paper.html",
        "author": "Hugo Germain, Vincent Lepetit, Guillaume Bourmaud",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Germain_Neural_Reprojection_Error_Merging_Feature_Learning_and_Camera_Pose_Estimation_CVPR_2021_paper.pdf",
        "aff": "IMS, University of Bordeaux, Bordeaux INP, CNRS, France; LIGM, Ecole des Ponts, Univ Gustave Eiffel, CNRS, Marne-la-vall\u00e9e, France",
        "project": "hugogermain.com/nre",
        "github": "",
        "arxiv": "2103.07153"
    },
    {
        "title": "Neural Response Interpretation Through the Lens of Critical Pathways",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Khakzar_Neural_Response_Interpretation_Through_the_Lens_of_Critical_Pathways_CVPR_2021_paper.html",
        "author": "Ashkan Khakzar, Soroosh Baselizadeh, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, Nassir Navab",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Khakzar_Neural_Response_Interpretation_Through_the_Lens_of_Critical_Pathways_CVPR_2021_paper.pdf",
        "aff": "VGG @ University of Oxford; CAMP @ Technical University of Munich",
        "project": "",
        "github": "https://github.com/CAMP-eXplain-AI/PathwayGrad",
        "arxiv": "2103.16886"
    },
    {
        "title": "Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Neural_Scene_Flow_Fields_for_Space-Time_View_Synthesis_of_Dynamic_CVPR_2021_paper.html",
        "author": "Zhengqi Li, Simon Niklaus, Noah Snavely, Oliver Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Neural_Scene_Flow_Fields_for_Space-Time_View_Synthesis_of_Dynamic_CVPR_2021_paper.pdf",
        "aff": "Cornell Tech; Adobe Research",
        "project": "",
        "github": "",
        "arxiv": "2011.13084"
    },
    {
        "title": "Neural Scene Graphs for Dynamic Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ost_Neural_Scene_Graphs_for_Dynamic_Scenes_CVPR_2021_paper.html",
        "author": "Julian Ost, Fahim Mannan, Nils Thuerey, Julian Knodt, Felix Heide",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ost_Neural_Scene_Graphs_for_Dynamic_Scenes_CVPR_2021_paper.pdf",
        "aff": "Algolux; Technical University of Munich; Princeton University",
        "project": "http://light.princeton.edu/neural-scene-graphs",
        "github": "",
        "arxiv": "2011.10379"
    },
    {
        "title": "Neural Side-by-Side: Predicting Human Preferences for No-Reference Super-Resolution Evaluation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Khrulkov_Neural_Side-by-Side_Predicting_Human_Preferences_for_No-Reference_Super-Resolution_Evaluation_CVPR_2021_paper.html",
        "author": "Valentin Khrulkov, Artem Babenko",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Khrulkov_Neural_Side-by-Side_Predicting_Human_Preferences_for_No-Reference_Super-Resolution_Evaluation_CVPR_2021_paper.pdf",
        "aff": "Yandex, Russia; National Research University Higher School of Economics, Moscow, Russia; Yandex, Russia",
        "project": "",
        "github": "https://github.com/KhrulkovV/NeuralSBS",
        "arxiv": ""
    },
    {
        "title": "Neural Splines: Fitting 3D Surfaces With Infinitely-Wide Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Williams_Neural_Splines_Fitting_3D_Surfaces_With_Infinitely-Wide_Neural_Networks_CVPR_2021_paper.html",
        "author": "Francis Williams, Matthew Trager, Joan Bruna, Denis Zorin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Williams_Neural_Splines_Fitting_3D_Surfaces_With_Infinitely-Wide_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "New York University, Amazon; New York University",
        "project": "",
        "github": "",
        "arxiv": "2006.13782"
    },
    {
        "title": "Neural Surface Maps",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Morreale_Neural_Surface_Maps_CVPR_2021_paper.html",
        "author": "Luca Morreale, Noam Aigerman, Vladimir G. Kim, Niloy J. Mitra",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Morreale_Neural_Surface_Maps_CVPR_2021_paper.pdf",
        "aff": "University College London; Adobe Research; University College London and Adobe Research",
        "project": "",
        "github": "",
        "arxiv": "2103.16942"
    },
    {
        "title": "NeuralFusion: Online Depth Fusion in Latent Space",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Weder_NeuralFusion_Online_Depth_Fusion_in_Latent_Space_CVPR_2021_paper.html",
        "author": "Silvan Weder, Johannes L. Schonberger, Marc Pollefeys, Martin R. Oswald",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Weder_NeuralFusion_Online_Depth_Fusion_in_Latent_Space_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich; Microsoft Mixed Reality and AI Zurich Lab",
        "project": "",
        "github": "https://github.com/weders/NeuralFusion",
        "arxiv": "2011.14791"
    },
    {
        "title": "NeuralHumanFVV: Real-Time Neural Volumetric Human Performance Rendering Using RGB Cameras",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Suo_NeuralHumanFVV_Real-Time_Neural_Volumetric_Human_Performance_Rendering_Using_RGB_Cameras_CVPR_2021_paper.html",
        "author": "Xin Suo, Yuheng Jiang, Pei Lin, Yingliang Zhang, Minye Wu, Kaiwen Guo, Lan Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Suo_NeuralHumanFVV_Real-Time_Neural_Volumetric_Human_Performance_Rendering_Using_RGB_Cameras_CVPR_2021_paper.pdf",
        "aff": "Dgene; Google; ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; ShanghaiTech University",
        "project": "",
        "github": "",
        "arxiv": "2103.07700"
    },
    {
        "title": "NeuralRecon: Real-Time Coherent 3D Reconstruction From Monocular Video",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_NeuralRecon_Real-Time_Coherent_3D_Reconstruction_From_Monocular_Video_CVPR_2021_paper.html",
        "author": "Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, Hujun Bao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_NeuralRecon_Real-Time_Coherent_3D_Reconstruction_From_Monocular_Video_CVPR_2021_paper.pdf",
        "aff": "Zhejiang University, SenseTime Research; Zhejiang University",
        "project": "https://zju3dv.github.io/neuralrecon/",
        "github": "",
        "arxiv": "2104.00681"
    },
    {
        "title": "NeuroMorph: Unsupervised Shape Interpolation and Correspondence in One Go",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Eisenberger_NeuroMorph_Unsupervised_Shape_Interpolation_and_Correspondence_in_One_Go_CVPR_2021_paper.html",
        "author": "Marvin Eisenberger, David Novotny, Gael Kerchenbaum, Patrick Labatut, Natalia Neverova, Daniel Cremers, Andrea Vedaldi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Eisenberger_NeuroMorph_Unsupervised_Shape_Interpolation_and_Correspondence_in_One_Go_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research\u2217, Technical University of Munich\u2020; Technical University of Munich\u2020; Facebook AI Research\u2217",
        "project": "",
        "github": "",
        "arxiv": "2106.09431"
    },
    {
        "title": "NewtonianVAE: Proportional Control and Goal Identification From Pixels via Physical Latent Spaces",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jaques_NewtonianVAE_Proportional_Control_and_Goal_Identification_From_Pixels_via_Physical_CVPR_2021_paper.html",
        "author": "Miguel Jaques, Michael Burke, Timothy M. Hospedales",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jaques_NewtonianVAE_Proportional_Control_and_Goal_Identification_From_Pixels_via_Physical_CVPR_2021_paper.pdf",
        "aff": "University of Edinburgh, Edinburgh, UK; Monash University, Melbourne, AU",
        "project": "",
        "github": "",
        "arxiv": "2006.01959"
    },
    {
        "title": "Nighttime Visibility Enhancement by Increasing the Dynamic Range and Suppression of Light Effects",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sharma_Nighttime_Visibility_Enhancement_by_Increasing_the_Dynamic_Range_and_Suppression_CVPR_2021_paper.html",
        "author": "Aashish Sharma, Robby T. Tan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sharma_Nighttime_Visibility_Enhancement_by_Increasing_the_Dynamic_Range_and_Suppression_CVPR_2021_paper.pdf",
        "aff": "National University of Singapore, Yale-NUS College; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "No Frame Left Behind: Full Video Action Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_No_Frame_Left_Behind_Full_Video_Action_Recognition_CVPR_2021_paper.html",
        "author": "Xin Liu, Silvia L. Pintea, Fatemeh Karimi Nejadasl, Olaf Booij, Jan C. van Gemert",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_No_Frame_Left_Behind_Full_Video_Action_Recognition_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, Delft University of Technology; TomTom",
        "project": "",
        "github": "",
        "arxiv": "2103.15395"
    },
    {
        "title": "No Shadow Left Behind: Removing Objects and Their Shadows Using Approximate Lighting and Geometry",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_No_Shadow_Left_Behind_Removing_Objects_and_Their_Shadows_Using_CVPR_2021_paper.html",
        "author": "Edward Zhang, Ricardo Martin-Brualla, Janne Kontkanen, Brian L. Curless",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_No_Shadow_Left_Behind_Removing_Objects_and_Their_Shadows_Using_CVPR_2021_paper.pdf",
        "aff": "Google; University of Washington; University of Washington, Google",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Noise-Resistant Deep Metric Learning With Ranking-Based Instance Selection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Noise-Resistant_Deep_Metric_Learning_With_Ranking-Based_Instance_Selection_CVPR_2021_paper.html",
        "author": "Chang Liu, Han Yu, Boyang Li, Zhiqi Shen, Zhanning Gao, Peiran Ren, Xuansong Xie, Lizhen Cui, Chunyan Miao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Noise-Resistant_Deep_Metric_Learning_With_Ranking-Based_Instance_Selection_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University (NTU), Singapore; School of Software, Shandong University (SDU), Jinan, China; Alibaba Group, Hangzhou, China",
        "project": "",
        "github": "",
        "arxiv": "2103.16047"
    },
    {
        "title": "Non-Salient Region Object Mining for Weakly Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yao_Non-Salient_Region_Object_Mining_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Yazhou Yao, Tao Chen, Guo-Sen Xie, Chuanyi Zhang, Fumin Shen, Qi Wu, Zhenmin Tang, Jian Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yao_Non-Salient_Region_Object_Mining_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Nanjing University of Science and Technology; University of Technology Sydney; University of Electronic Science and Technology of China; Mohamed bin Zayed University of AI; University of Adelaide",
        "project": "",
        "github": "https://github.com/NUST-Machine-Intelligence-Laboratory/nsrom",
        "arxiv": "2103.14581"
    },
    {
        "title": "Normal Integration via Inverse Plane Fitting With Minimum Point-to-Plane Distance",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cao_Normal_Integration_via_Inverse_Plane_Fitting_With_Minimum_Point-to-Plane_Distance_CVPR_2021_paper.html",
        "author": "Xu Cao, Boxin Shi, Fumio Okura, Yasuyuki Matsushita",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cao_Normal_Integration_via_Inverse_Plane_Fitting_With_Minimum_Point-to-Plane_Distance_CVPR_2021_paper.pdf",
        "aff": "Peking University; Osaka University",
        "project": "",
        "github": "https://github.com/hoshino042/NormalIntegration",
        "arxiv": ""
    },
    {
        "title": "NormalFusion: Real-Time Acquisition of Surface Normals for High-Resolution RGB-D Scanning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ha_NormalFusion_Real-Time_Acquisition_of_Surface_Normals_for_High-Resolution_RGB-D_Scanning_CVPR_2021_paper.html",
        "author": "Hyunho Ha, Joo Ho Lee, Andreas Meuleman, Min H. Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ha_NormalFusion_Real-Time_Acquisition_of_Surface_Normals_for_High-Resolution_RGB-D_Scanning_CVPR_2021_paper.pdf",
        "aff": "University of Tuebingen; KAIST",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Normalized Avatar Synthesis Using StyleGAN and Perceptual Refinement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Normalized_Avatar_Synthesis_Using_StyleGAN_and_Perceptual_Refinement_CVPR_2021_paper.html",
        "author": "Huiwen Luo, Koki Nagano, Han-Wei Kung, Qingguo Xu, Zejian Wang, Lingyu Wei, Liwen Hu, Hao Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Normalized_Avatar_Synthesis_Using_StyleGAN_and_Perceptual_Refinement_CVPR_2021_paper.pdf",
        "aff": "NVIDIA; Pinscreen and UC Berkeley; Pinscreen",
        "project": "",
        "github": "",
        "arxiv": "2106.11423"
    },
    {
        "title": "Not Just Compete, but Collaborate: Local Image-to-Image Translation via Cooperative Mask Prediction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Not_Just_Compete_but_Collaborate_Local_Image-to-Image_Translation_via_Cooperative_CVPR_2021_paper.html",
        "author": "Daejin Kim, Mohammad Azam Khan, Jaegul Choo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Not_Just_Compete_but_Collaborate_Local_Image-to-Image_Translation_via_Cooperative_CVPR_2021_paper.pdf",
        "aff": "KAIST; Dhaka Power Distribution Company Ltd.",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Nutrition5k: Towards Automatic Nutritional Understanding of Generic Food",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Thames_Nutrition5k_Towards_Automatic_Nutritional_Understanding_of_Generic_Food_CVPR_2021_paper.html",
        "author": "Quin Thames, Arjun Karpur, Wade Norris, Fangting Xia, Liviu Panait, Tobias Weyand, Jack Sim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Thames_Nutrition5k_Towards_Automatic_Nutritional_Understanding_of_Generic_Food_CVPR_2021_paper.pdf",
        "aff": "Google Research, USA; Perception Labs\u2217",
        "project": "",
        "github": "https://github.com/google-research-datasets/Nutrition5k",
        "arxiv": "2103.03375"
    },
    {
        "title": "OBoW: Online Bag-of-Visual-Words Generation for Self-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gidaris_OBoW_Online_Bag-of-Visual-Words_Generation_for_Self-Supervised_Learning_CVPR_2021_paper.html",
        "author": "Spyros Gidaris, Andrei Bursuc, Gilles Puy, Nikos Komodakis, Matthieu Cord, Patrick Perez",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gidaris_OBoW_Online_Bag-of-Visual-Words_Generation_for_Self-Supervised_Learning_CVPR_2021_paper.pdf",
        "aff": "valeo.ai; University of Crete; Sorbonne Universit\u00e9",
        "project": "",
        "github": "https://github.com/valeoai/obow",
        "arxiv": ""
    },
    {
        "title": "OCONet: Image Extrapolation by Object Completion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bowen_OCONet_Image_Extrapolation_by_Object_Completion_CVPR_2021_paper.html",
        "author": "Richard Strong Bowen, Huiwen Chang, Charles Herrmann, Piotr Teterwak, Ce Liu, Ramin Zabih",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bowen_OCONet_Image_Extrapolation_by_Object_Completion_CVPR_2021_paper.pdf",
        "aff": "Cornell Tech; Boston University; Google Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "OPANAS: One-Shot Path Aggregation Network Architecture Search for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liang_OPANAS_One-Shot_Path_Aggregation_Network_Architecture_Search_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Tingting Liang, Yongtao Wang, Zhi Tang, Guosheng Hu, Haibin Ling",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liang_OPANAS_One-Shot_Path_Aggregation_Network_Architecture_Search_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Wangxuan Institute of Computer Technology, Peking University; Department of Computer Science, Stony Brook University; Anyvision",
        "project": "",
        "github": "https://github.com/VDIGPKU/OPANAS",
        "arxiv": "2103.04507"
    },
    {
        "title": "ORDisCo: Effective and Efficient Usage of Incremental Unlabeled Data for Semi-Supervised Continual Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_ORDisCo_Effective_and_Efficient_Usage_of_Incremental_Unlabeled_Data_for_CVPR_2021_paper.html",
        "author": "Liyuan Wang, Kuo Yang, Chongxuan Li, Lanqing Hong, Zhenguo Li, Jun Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_ORDisCo_Effective_and_Efficient_Usage_of_Incremental_Unlabeled_Data_for_CVPR_2021_paper.pdf",
        "aff": "Dept. of Comp. Sci. & Tech., Institute for AI, BNRist Center, THBI Lab, Tsinghua University, Beijing, China; Huawei Noah's Ark Lab",
        "project": "",
        "github": "",
        "arxiv": "2101.00407"
    },
    {
        "title": "OSTeC: One-Shot Texture Completion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gecer_OSTeC_One-Shot_Texture_Completion_CVPR_2021_paper.html",
        "author": "Baris Gecer, Jiankang Deng, Stefanos Zafeiriou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gecer_OSTeC_One-Shot_Texture_Completion_CVPR_2021_paper.pdf",
        "aff": "Imperial College London, Huawei CBG",
        "project": "",
        "github": "https://github.com/barisgecer/OSTeC",
        "arxiv": "2012.15370"
    },
    {
        "title": "OTA: Optimal Transport Assignment for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ge_OTA_Optimal_Transport_Assignment_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Zheng Ge, Songtao Liu, Zeming Li, Osamu Yoshie, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_OTA_Optimal_Transport_Assignment_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Waseda University; Megvii Technology",
        "project": "",
        "github": "https://github.com/Megvii-BaseDetection/OTA",
        "arxiv": "2103.14259"
    },
    {
        "title": "OTCE: A Transferability Metric for Cross-Domain Cross-Task Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tan_OTCE_A_Transferability_Metric_for_Cross-Domain_Cross-Task_Representations_CVPR_2021_paper.html",
        "author": "Yang Tan, Yang Li, Shao-Lun Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_OTCE_A_Transferability_Metric_for_Cross-Domain_Cross-Task_Representations_CVPR_2021_paper.pdf",
        "aff": "Tsinghua-Berkeley Shenzhen Institute, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2103.13843"
    },
    {
        "title": "Object Classification From Randomized EEG Trials",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ahmed_Object_Classification_From_Randomized_EEG_Trials_CVPR_2021_paper.html",
        "author": "Hamad Ahmed, Ronnie B. Wilbur, Hari M. Bharadwaj, Jeffrey Mark Siskind",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ahmed_Object_Classification_From_Randomized_EEG_Trials_CVPR_2021_paper.pdf",
        "aff": "Purdue University, West Lafayette, IN, 47907",
        "project": "",
        "github": "",
        "arxiv": "2004.06046"
    },
    {
        "title": "Objectron: A Large Scale Dataset of Object-Centric Videos in the Wild With Pose Annotations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ahmadyan_Objectron_A_Large_Scale_Dataset_of_Object-Centric_Videos_in_the_CVPR_2021_paper.html",
        "author": "Adel Ahmadyan, Liangkai Zhang, Artsiom Ablavatski, Jianing Wei, Matthias Grundmann",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ahmadyan_Objectron_A_Large_Scale_Dataset_of_Object-Centric_Videos_in_the_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "https://github.com/google-research-datasets/Objectron",
        "arxiv": "2012.09988"
    },
    {
        "title": "Objects Are Different: Flexible Monocular 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Objects_Are_Different_Flexible_Monocular_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "Yunpeng Zhang, Jiwen Lu, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Objects_Are_Different_Flexible_Monocular_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Beijing National Research Center for Information Science and Technology, China; Department of Automation, Tsinghua University, China",
        "project": "",
        "github": "https://github.com/zhangyp15/MonoFlex",
        "arxiv": "2104.02323"
    },
    {
        "title": "Offboard 3D Object Detection From Point Cloud Sequences",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qi_Offboard_3D_Object_Detection_From_Point_Cloud_Sequences_CVPR_2021_paper.html",
        "author": "Charles R. Qi, Yin Zhou, Mahyar Najibi, Pei Sun, Khoa Vo, Boyang Deng, Dragomir Anguelov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qi_Offboard_3D_Object_Detection_From_Point_Cloud_Sequences_CVPR_2021_paper.pdf",
        "aff": "Waymo LLC",
        "project": "",
        "github": "",
        "arxiv": "2103.05073"
    },
    {
        "title": "Omni-Supervised Point Cloud Segmentation via Gradual Receptive Field Component Reasoning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gong_Omni-Supervised_Point_Cloud_Segmentation_via_Gradual_Receptive_Field_Component_Reasoning_CVPR_2021_paper.html",
        "author": "Jingyu Gong, Jiachen Xu, Xin Tan, Haichuan Song, Yanyun Qu, Yuan Xie, Lizhuang Ma",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gong_Omni-Supervised_Point_Cloud_Segmentation_via_Gradual_Receptive_Field_Component_Reasoning_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Technology, East China Normal University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China and School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Informatics, Xiamen University, Fujian, China",
        "project": "",
        "github": "https://github.com/azuki-miho/RFCR",
        "arxiv": "2105.10203"
    },
    {
        "title": "Omnimatte: Associating Objects and Their Effects in Video",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Omnimatte_Associating_Objects_and_Their_Effects_in_Video_CVPR_2021_paper.html",
        "author": "Erika Lu, Forrester Cole, Tali Dekel, Andrew Zisserman, William T. Freeman, Michael Rubinstein",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_Omnimatte_Associating_Objects_and_Their_Effects_in_Video_CVPR_2021_paper.pdf",
        "aff": "Weizmann Institute of Science; University of Oxford; Google Research",
        "project": "https://omnimatte.github.io/",
        "github": "",
        "arxiv": "2105.06993"
    },
    {
        "title": "On Feature Normalization and Data Augmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_On_Feature_Normalization_and_Data_Augmentation_CVPR_2021_paper.html",
        "author": "Boyi Li, Felix Wu, Ser-Nam Lim, Serge Belongie, Kilian Q. Weinberger",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_On_Feature_Normalization_and_Data_Augmentation_CVPR_2021_paper.pdf",
        "aff": "Cornell University, Cornell Tech; ASAPP; Facebook AI",
        "project": "",
        "github": "",
        "arxiv": "2002.11102"
    },
    {
        "title": "On Focal Loss for Class-Posterior Probability Estimation: A Theoretical Perspective",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Charoenphakdee_On_Focal_Loss_for_Class-Posterior_Probability_Estimation_A_Theoretical_Perspective_CVPR_2021_paper.html",
        "author": "Nontawat Charoenphakdee, Jayakorn Vongkulbhisal, Nuttapong Chairatanakul, Masashi Sugiyama",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Charoenphakdee_On_Focal_Loss_for_Class-Posterior_Probability_Estimation_A_Theoretical_Perspective_CVPR_2021_paper.pdf",
        "aff": "IBM Research; Tokyo Institute of Technology / RWBC-OIL, AIST; The University of Tokyo / RIKEN AIP; RIKEN AIP / The University of Tokyo",
        "project": "",
        "github": "",
        "arxiv": "2011.09172"
    },
    {
        "title": "On Learning the Geodesic Path for Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Simon_On_Learning_the_Geodesic_Path_for_Incremental_Learning_CVPR_2021_paper.html",
        "author": "Christian Simon, Piotr Koniusz, Mehrtash Harandi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Simon_On_Learning_the_Geodesic_Path_for_Incremental_Learning_CVPR_2021_paper.pdf",
        "aff": "The Australian National University; Data61-CSIRO; Monash University",
        "project": "",
        "github": "https://github.com/chrysts/geodesic_continual_learning",
        "arxiv": "2104.08572"
    },
    {
        "title": "On Robustness and Transferability of Convolutional Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Djolonga_On_Robustness_and_Transferability_of_Convolutional_Neural_Networks_CVPR_2021_paper.html",
        "author": "Josip Djolonga, Jessica Yung, Michael Tschannen, Rob Romijnders, Lucas Beyer, Alexander Kolesnikov, Joan Puigcerver, Matthias Minderer, Alexander D'Amour, Dan Moldovan, Sylvain Gelly, Neil Houlsby, Xiaohua Zhai, Mario Lucic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Djolonga_On_Robustness_and_Transferability_of_Convolutional_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "Google Research, Brain Team",
        "project": "",
        "github": "",
        "arxiv": "2007.08558"
    },
    {
        "title": "On Self-Contact and Human Pose",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Muller_On_Self-Contact_and_Human_Pose_CVPR_2021_paper.html",
        "author": "Lea Muller, Ahmed A. A. Osman, Siyu Tang, Chun-Hao P. Huang, Michael J. Black",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Muller_On_Self-Contact_and_Human_Pose_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T \u00a8ubingen; ETH Z \u00a8urich",
        "project": "https://tuch.is.tue.mpg.de",
        "github": "",
        "arxiv": "2104.03176"
    },
    {
        "title": "On Semantic Similarity in Video Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wray_On_Semantic_Similarity_in_Video_Retrieval_CVPR_2021_paper.html",
        "author": "Michael Wray, Hazel Doughty, Dima Damen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wray_On_Semantic_Similarity_in_Video_Retrieval_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, University of Bristol, UK; Now at University of Amsterdam",
        "project": "",
        "github": "",
        "arxiv": "2103.10095"
    },
    {
        "title": "On the Difficulty of Membership Inference Attacks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Rezaei_On_the_Difficulty_of_Membership_Inference_Attacks_CVPR_2021_paper.html",
        "author": "Shahbaz Rezaei, Xin Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Rezaei_On_the_Difficulty_of_Membership_Inference_Attacks_CVPR_2021_paper.pdf",
        "aff": "University of California, Davis, CA, USA",
        "project": "",
        "github": "https://github.com/shrezaei/MI-Attack",
        "arxiv": "2005.13702"
    },
    {
        "title": "One Shot Face Swapping on Megapixels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_One_Shot_Face_Swapping_on_Megapixels_CVPR_2021_paper.html",
        "author": "Yuhao Zhu, Qi Li, Jian Wang, Cheng-Zhong Xu, Zhenan Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_One_Shot_Face_Swapping_on_Megapixels_CVPR_2021_paper.pdf",
        "aff": "School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; State Key Laboratory of IoTSC, Faculty of Science and Technology, University of Macau; Center for Research on Intelligent Perception and Computing, NLPR, CASIA",
        "project": "",
        "github": "",
        "arxiv": "2105.04932"
    },
    {
        "title": "One Thing One Click: A Self-Training Approach for Weakly Supervised 3D Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_One_Thing_One_Click_A_Self-Training_Approach_for_Weakly_Supervised_CVPR_2021_paper.html",
        "author": "Zhengzhe Liu, Xiaojuan Qi, Chi-Wing Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_One_Thing_One_Click_A_Self-Training_Approach_for_Weakly_Supervised_CVPR_2021_paper.pdf",
        "aff": "The University of Hong Kong; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2104.02246"
    },
    {
        "title": "One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_One-Shot_Free-View_Neural_Talking-Head_Synthesis_for_Video_Conferencing_CVPR_2021_paper.html",
        "author": "Ting-Chun Wang, Arun Mallya, Ming-Yu Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_One-Shot_Free-View_Neural_Talking-Head_Synthesis_for_Video_Conferencing_CVPR_2021_paper.pdf",
        "aff": "NVIDIA Corporation",
        "project": "https://nvlabs.github.io/face-vid2vid",
        "github": "",
        "arxiv": "2011.15126"
    },
    {
        "title": "One-Shot Neural Ensemble Architecture Search by Diversity-Guided Search Space Shrinking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_One-Shot_Neural_Ensemble_Architecture_Search_by_Diversity-Guided_Search_Space_Shrinking_CVPR_2021_paper.html",
        "author": "Minghao Chen, Jianlong Fu, Haibin Ling",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_One-Shot_Neural_Ensemble_Architecture_Search_by_Diversity-Guided_Search_Space_Shrinking_CVPR_2021_paper.pdf",
        "aff": "Stony Brook University; Microsoft Research Asia",
        "project": "Not provided",
        "github": "Not provided",
        "arxiv": "2104.00597"
    },
    {
        "title": "Online Learning of a Probabilistic and Adaptive Scene Representation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Online_Learning_of_a_Probabilistic_and_Adaptive_Scene_Representation_CVPR_2021_paper.html",
        "author": "Zike Yan, Xin Wang, Hongbin Zha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Online_Learning_of_a_Probabilistic_and_Adaptive_Scene_Representation_CVPR_2021_paper.pdf",
        "aff": "PKU-SenseTime Machine Vision Joint Lab; Key Laboratory of Machine Perception (MOE), School of EECS, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2103.16832"
    },
    {
        "title": "Online Multiple Object Tracking With Cross-Task Synergy",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Online_Multiple_Object_Tracking_With_Cross-Task_Synergy_CVPR_2021_paper.html",
        "author": "Song Guo, Jingya Wang, Xinchao Wang, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Online_Multiple_Object_Tracking_With_Cross-Task_Synergy_CVPR_2021_paper.pdf",
        "aff": "ShanghaiTech University; National University of Singapore; The University of Sydney",
        "project": "",
        "github": "https://github.com/songguocode/TADAM",
        "arxiv": "2104.00380"
    },
    {
        "title": "Open Domain Generalization with Domain-Augmented Meta-Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shu_Open_Domain_Generalization_with_Domain-Augmented_Meta-Learning_CVPR_2021_paper.html",
        "author": "Yang Shu, Zhangjie Cao, Chenyu Wang, Jianmin Wang, Mingsheng Long",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shu_Open_Domain_Generalization_with_Domain-Augmented_Meta-Learning_CVPR_2021_paper.pdf",
        "aff": "School of Software, BNRist, Tsinghua University, China",
        "project": "",
        "github": "",
        "arxiv": "2104.03620"
    },
    {
        "title": "Open World Compositional Zero-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mancini_Open_World_Compositional_Zero-Shot_Learning_CVPR_2021_paper.html",
        "author": "Massimiliano Mancini, Muhammad Ferjad Naeem, Yongqin Xian, Zeynep Akata",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mancini_Open_World_Compositional_Zero-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "MPI for Informatics; University of T\u00fcbingen, MPI for Informatics, MPI for Intelligent Systems; TU M\u00fcnchen; University of T\u00fcbingen",
        "project": "",
        "github": "https://github.com/ExplainableML/czsl",
        "arxiv": ""
    },
    {
        "title": "Open-Book Video Captioning With Retrieve-Copy-Generate Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Open-Book_Video_Captioning_With_Retrieve-Copy-Generate_Network_CVPR_2021_paper.html",
        "author": "Ziqi Zhang, Zhongang Qi, Chunfeng Yuan, Ying Shan, Bing Li, Ying Deng, Weiming Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Open-Book_Video_Captioning_With_Retrieve-Copy-Generate_Network_CVPR_2021_paper.pdf",
        "aff": "5School of Aeronautical Manufacturing Engineering, Nanchang Hangkong University; 1NLPR, Institute of Automation, Chinese Academy of Sciences; 2Applied Research Center (ARC), Tencent PCG",
        "project": "",
        "github": "",
        "arxiv": "2103.05284"
    },
    {
        "title": "Open-Vocabulary Object Detection Using Captions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zareian_Open-Vocabulary_Object_Detection_Using_Captions_CVPR_2021_paper.html",
        "author": "Alireza Zareian, Kevin Dela Rosa, Derek Hao Hu, Shih-Fu Chang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zareian_Open-Vocabulary_Object_Detection_Using_Captions_CVPR_2021_paper.pdf",
        "aff": "Snap Inc., Seattle, WA; Columbia University, New York, NY",
        "project": "",
        "github": "https://github.com/alirezazareian/ovr-cnn",
        "arxiv": "2011.10678"
    },
    {
        "title": "OpenMix: Reviving Known Knowledge for Discovering Novel Visual Categories in an Open World",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_OpenMix_Reviving_Known_Knowledge_for_Discovering_Novel_Visual_Categories_in_CVPR_2021_paper.html",
        "author": "Zhun Zhong, Linchao Zhu, Zhiming Luo, Shaozi Li, Yi Yang, Nicu Sebe",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_OpenMix_Reviving_Known_Knowledge_for_Discovering_Novel_Visual_Categories_in_CVPR_2021_paper.pdf",
        "aff": "IMT, Xiamen University; ReLER, University of Technology Sydney; MHUG, University of Trento",
        "project": "",
        "github": "",
        "arxiv": "2004.05551"
    },
    {
        "title": "OpenRooms: An Open Framework for Photorealistic Indoor Scene Datasets",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_OpenRooms_An_Open_Framework_for_Photorealistic_Indoor_Scene_Datasets_CVPR_2021_paper.html",
        "author": "Zhengqin Li, Ting-Wei Yu, Shen Sang, Sarah Wang, Meng Song, Yuhan Liu, Yu-Ying Yeh, Rui Zhu, Nitesh Gundavarapu, Jia Shi, Sai Bi, Hong-Xing Yu, Zexiang Xu, Kalyan Sunkavalli, Milos Hasan, Ravi Ramamoorthi, Manmohan Chandraker",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_OpenRooms_An_Open_Framework_for_Photorealistic_Indoor_Scene_Datasets_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; UC San Diego",
        "project": "https://ucsd-openrooms.github.io/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Optimal Gradient Checkpoint Search for Arbitrary Computation Graphs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Optimal_Gradient_Checkpoint_Search_for_Arbitrary_Computation_Graphs_CVPR_2021_paper.html",
        "author": "Jianwei Feng, Dong Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Optimal_Gradient_Checkpoint_Search_for_Arbitrary_Computation_Graphs_CVPR_2021_paper.pdf",
        "aff": "Robotics Institute, Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/lordfjw/OptimalGradCheckpointing",
        "arxiv": "1808.00079"
    },
    {
        "title": "Optimal Quantization Using Scaled Codebook",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Idelbayev_Optimal_Quantization_Using_Scaled_Codebook_CVPR_2021_paper.html",
        "author": "Yerlan Idelbayev, Pavlo Molchanov, Maying Shen, Hongxu Yin, Miguel A. Carreira-Perpinan, Jose M. Alvarez",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Idelbayev_Optimal_Quantization_Using_Scaled_Codebook_CVPR_2021_paper.pdf",
        "aff": "NVIDIA Corporation; University of California, Merced",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Orthogonal Over-Parameterized Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Orthogonal_Over-Parameterized_Training_CVPR_2021_paper.html",
        "author": "Weiyang Liu, Rongmei Lin, Zhen Liu, James M. Rehg, Liam Paull, Li Xiong, Le Song, Adrian Weller",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Orthogonal_Over-Parameterized_Training_CVPR_2021_paper.pdf",
        "aff": "Orthogonal Over-Parameterized Training\nWeiyang Liu1,2,*Rongmei Lin3,*Zhen Liu4James M. Rehg5Liam Paull4Li Xiong3Le Song5Adrian Weller1,6\n1University of Cambridge2Max Planck Institute for Intelligent Systems3Emory University\n4Mila, Universit \u00b4e de Montr \u00b4eal5Georgia Institute of Technology6Alan Turing Institute*Equal Contribution\nAbstract\nThe inductive bias of a neural network is largely deter-\nmined by the architecture and the training algorithm. To\nachieve good generalization, how to effectively train a neural\nnetwork is of great importance. We propose a novel orthogo-\nnal over-parameterized training (OPT) framework that can\nprovably minimize the hyperspherical energy which charac-\nterizes the diversity of neurons on a hypersphere. By main-\ntaining the minimum hyperspherical energy during train-\ning, OPT can greatly improve the empirical generalization.\nSpeci\ufb01cally, OPT \ufb01xes the randomly initialized weights of\nthe neurons and learns an orthogonal transformation that\napplies to these neurons. We consider multiple ways to learn\nsuch an orthogonal transformation, including unrolling or-\nthogonalization algorithms, applying orthogonal parame-\nterization, and designing orthogonality-preserving gradient\ndescent. For better scalability, we propose the stochastic\nOPT which performs orthogonal transformation stochasti-\ncally for partial dimensions of neurons. Interestingly, OPT\nreveals that learning a proper coordinate system for neurons\nis crucial to generalization. We provide some insights on\nwhy OPT yields better generalization. Extensive experiments\nvalidate the superiority of OPT over the standard training.\n1. Introduction\nThe inductive bias encoded in a neural network is gen-\nerally determined by two major aspects: how the neural\nnetwork is structured ( i.e., network architecture) and how\nthe neural network is optimized ( i.e., training algorithm). For\nthe same network architecture, using different training algo-\nrithms could lead to a dramatic difference in generalization\nperformance [ 36,60] even if the training loss is close to zero,\nimplying that different training procedures lead to different\ninductive biases. Therefore, how to effectively train a neural\nnetwork that generalize well remains an open challenge.\nRecent theories [ 16,15,34,45] suggest the importance\nof over-parameterization in linear neural networks. For\nexample, [ 16] shows that optimizing an underdetermined\nquadratic objective over a matrix Mwith gradient descent\nRandom initialized neurons \nin the same layerHyperspherical energy \ncharacterizes relative positions\nLearnable \northogonalR\nLearning the coordinate systemFinal neurons\nin the same layer{v1,...,vn}{Rv1,...,Rvn}{v1,...,vn}\nstay fixed \nInput OutputFigure 1: Overview of the orthogonal over-parameterized training frame-\nwork. OPT learns an orthogonal transformation for each layer in the neural\nnetwork, while keeping the randomly initialized neuron weights \ufb01xed.\non a factorization of Mleads to an implicit regularization\nthat may improve generalization. There is also strong em-\npirical evidence [ 11,51] that over-parameterzing the con-\nvolutional \ufb01lters under some regularity is bene\ufb01cial to gen-\neralization. Our paper aims to leverage the power of over-\nparameterization and explore more intrinsic structural priors\nin order to train a well-performing neural network.\nMotivated by this goal, we propose a generic orthogo-\nnal over-parameterized training (OPT) framework for neu-\nral networks. Different from conventional neural training,\nOPT over-parameterizes a neuron w\u2208Rdwith the mul-\ntiplication of a learnable layer-shared orthogonal matrix\nR\u2208Rd\u00d7dand a \ufb01xed randomly-initialized weight vector\nv\u2208Rd, and it follows that the equivalent weight for the neu-\nron isw=Rv. Once each element of the neuron weight\nvhas been randomly initialized by a zero-mean Gaussian\ndistribution [ 20,14], we \ufb01x them throughout the entire train-\ning process. Then OPT learns a layer-shared orthogonal\ntransformation Rthat is applied to all the neurons (in the\nsame layer). An illustration of OPT is given in Fig. 1. In\ncontrast to standard neural training, OPT decomposes the\nneuron into an orthogonal transformation Rthat learns a\nproper coordinate system, and a weight vector vthat con-\ntrols the speci\ufb01c position of the neuron. Essentially, the\nweights{v1,\u00b7\u00b7\u00b7,vn\u2208Rd}of different neurons determine\nthe relative positions, while the layer-shared orthogonal ma-\ntrixRspeci\ufb01es the coordinate system. Such a decoupled\nparameterization enables strong modeling \ufb02exibility.\nAnother motivation of OPT comes from an empirical ob-\nservation that neural networks with lower hyperspherical\n7251\n",
        "project": "",
        "github": "",
        "arxiv": "2004.04690"
    },
    {
        "title": "Out-of-Distribution Detection Using Union of 1-Dimensional Subspaces",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zaeemzadeh_Out-of-Distribution_Detection_Using_Union_of_1-Dimensional_Subspaces_CVPR_2021_paper.html",
        "author": "Alireza Zaeemzadeh, Niccolo Bisagno, Zeno Sambugaro, Nicola Conci, Nazanin Rahnavard, Mubarak Shah",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zaeemzadeh_Out-of-Distribution_Detection_Using_Union_of_1-Dimensional_Subspaces_CVPR_2021_paper.pdf",
        "aff": "University of Central Florida; University of Trento",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Over-the-Air Adversarial Flickering Attacks Against Video Recognition Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pony_Over-the-Air_Adversarial_Flickering_Attacks_Against_Video_Recognition_Networks_CVPR_2021_paper.html",
        "author": "Roi Pony, Itay Naeh, Shie Mannor",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pony_Over-the-Air_Adversarial_Flickering_Attacks_Against_Video_Recognition_Networks_CVPR_2021_paper.pdf",
        "aff": "Rafael - Advanced Defense Systems Ltd., Israel; Department of Electrical Engineering, Technion Institute of Technology, Haifa, Israel; Nvidia Research",
        "project": "",
        "github": "",
        "arxiv": "2002.05123"
    },
    {
        "title": "PAConv: Position Adaptive Convolution With Dynamic Kernel Assembling on Point Clouds",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_PAConv_Position_Adaptive_Convolution_With_Dynamic_Kernel_Assembling_on_Point_CVPR_2021_paper.html",
        "author": "Mutian Xu, Runyu Ding, Hengshuang Zhao, Xiaojuan Qi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_PAConv_Position_Adaptive_Convolution_With_Dynamic_Kernel_Assembling_on_Point_CVPR_2021_paper.pdf",
        "aff": "The University of Hong Kong; University of Oxford",
        "project": "",
        "github": "https://github.com/CVMI-Lab/PAConv",
        "arxiv": "2103.14635"
    },
    {
        "title": "PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Reiss_PANDA_Adapting_Pretrained_Features_for_Anomaly_Detection_and_Segmentation_CVPR_2021_paper.html",
        "author": "Tal Reiss, Niv Cohen, Liron Bergman, Yedid Hoshen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Reiss_PANDA_Adapting_Pretrained_Features_for_Anomaly_Detection_and_Segmentation_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, The Hebrew University of Jerusalem, Israel",
        "project": "",
        "github": "github.com/talreiss/PANDA",
        "arxiv": "2010.05903"
    },
    {
        "title": "PAUL: Procrustean Autoencoder for Unsupervised Lifting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PAUL_Procrustean_Autoencoder_for_Unsupervised_Lifting_CVPR_2021_paper.html",
        "author": "Chaoyang Wang, Simon Lucey",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_PAUL_Procrustean_Autoencoder_for_Unsupervised_Lifting_CVPR_2021_paper.pdf",
        "aff": "Carnegie Mellon University, University of Adelaide; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2103.16773"
    },
    {
        "title": "PCLs: Geometry-Aware Neural Reconstruction of 3D Pose With Perspective Crop Layers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_PCLs_Geometry-Aware_Neural_Reconstruction_of_3D_Pose_With_Perspective_Crop_CVPR_2021_paper.html",
        "author": "Frank Yu, Mathieu Salzmann, Pascal Fua, Helge Rhodin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_PCLs_Geometry-Aware_Neural_Reconstruction_of_3D_Pose_With_Perspective_Crop_CVPR_2021_paper.pdf",
        "aff": "EPFL, Lausanne, Switzerland; UBC, Vancouver, Canada",
        "project": "",
        "github": "github.com/yu-frank/PerspectiveCropLayers",
        "arxiv": "2011.13607"
    },
    {
        "title": "PD-GAN: Probabilistic Diverse GAN for Image Inpainting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_PD-GAN_Probabilistic_Diverse_GAN_for_Image_Inpainting_CVPR_2021_paper.html",
        "author": "Hongyu Liu, Ziyu Wan, Wei Huang, Yibing Song, Xintong Han, Jing Liao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_PD-GAN_Probabilistic_Diverse_GAN_for_Image_Inpainting_CVPR_2021_paper.pdf",
        "aff": "City University of Hong Kong; Hunan University; Tencent AI Lab; Huya Inc",
        "project": "",
        "github": "https://github.com/KumapowerLIU/PD-GAN",
        "arxiv": ""
    },
    {
        "title": "PGT: A Progressive Method for Training Models on Long Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pang_PGT_A_Progressive_Method_for_Training_Models_on_Long_Videos_CVPR_2021_paper.html",
        "author": "Bo Pang, Gao Peng, Yizhuo Li, Cewu Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pang_PGT_A_Progressive_Method_for_Training_Models_on_Long_Videos_CVPR_2021_paper.pdf",
        "aff": "Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/BoPang1996/PGT",
        "arxiv": "2103.11313"
    },
    {
        "title": "PISE: Person Image Synthesis and Editing With Decoupled GAN",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_PISE_Person_Image_Synthesis_and_Editing_With_Decoupled_GAN_CVPR_2021_paper.html",
        "author": "Jinsong Zhang, Kun Li, Yu-Kun Lai, Jingyu Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_PISE_Person_Image_Synthesis_and_Editing_With_Decoupled_GAN_CVPR_2021_paper.pdf",
        "aff": "Cardiff University, United Kingdom; Tianjin University, China",
        "project": "",
        "github": "https://github.com/Zhangjinso/PISE",
        "arxiv": "2103.04023"
    },
    {
        "title": "PLADE-Net: Towards Pixel-Level Accuracy for Self-Supervised Single-View Depth Estimation With Neural Positional Encoding and Distilled Matting Loss",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gonzalez_PLADE-Net_Towards_Pixel-Level_Accuracy_for_Self-Supervised_Single-View_Depth_Estimation_With_CVPR_2021_paper.html",
        "author": "Juan Luis Gonzalez, Munchurl Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gonzalez_PLADE-Net_Towards_Pixel-Level_Accuracy_for_Self-Supervised_Single-View_Depth_Estimation_With_CVPR_2021_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PLOP: Learning Without Forgetting for Continual Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Douillard_PLOP_Learning_Without_Forgetting_for_Continual_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Arthur Douillard, Yifu Chen, Arnaud Dapogny, Matthieu Cord",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Douillard_PLOP_Learning_Without_Forgetting_for_Continual_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Sorbonne Universit \u00b4e; Sorbonne Universit \u00b4e, valeo.ai; Sorbonne Universit \u00b4e, Heuritech; Datakalab",
        "project": "",
        "github": "https://github.com/arthurdouillard/CVPR2021_PLOP",
        "arxiv": "2011.11390"
    },
    {
        "title": "PML: Progressive Margin Loss for Long-Tailed Age Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_PML_Progressive_Margin_Loss_for_Long-Tailed_Age_Classification_CVPR_2021_paper.html",
        "author": "Zongyong Deng, Hao Liu, Yaoxing Wang, Chenyang Wang, Zekuan Yu, Xuehong Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_PML_Progressive_Margin_Loss_for_Long-Tailed_Age_Classification_CVPR_2021_paper.pdf",
        "aff": "School of Information Engineering, Ningxia University, Yinchuan, 750021, China; Collaborative Innovation Center for Ningxia Big Data and Artificial Intelligence Co-founded by Ningxia Municipality and Ministry of Education, Yinchuan, 750021, China; Academy for Engineering and Technology, Fudan University, Shanghai, 200433, China; School of Information Engineering, Ningxia University, Yinchuan, 750021, China",
        "project": "",
        "github": "",
        "arxiv": "2103.02140"
    },
    {
        "title": "PMP-Net: Point Cloud Completion by Learning Multi-Step Point Moving Paths",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wen_PMP-Net_Point_Cloud_Completion_by_Learning_Multi-Step_Point_Moving_Paths_CVPR_2021_paper.html",
        "author": "Xin Wen, Peng Xiang, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, Yu-Shen Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wen_PMP-Net_Point_Cloud_Completion_by_Learning_Multi-Step_Point_Moving_Paths_CVPR_2021_paper.pdf",
        "aff": "Y-tech, Kuaishou Technology, Beijing, China; Department of Computer Science, Wayne State University, USA; School of Software, BNRist, Tsinghua University, Beijing, China",
        "project": "",
        "github": "https://github.com/diviswen/PMP-Net",
        "arxiv": ""
    },
    {
        "title": "POSEFusion: Pose-Guided Selective Fusion for Single-View Human Volumetric Capture",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_POSEFusion_Pose-Guided_Selective_Fusion_for_Single-View_Human_Volumetric_Capture_CVPR_2021_paper.html",
        "author": "Zhe Li, Tao Yu, Zerong Zheng, Kaiwen Guo, Yebin Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_POSEFusion_Pose-Guided_Selective_Fusion_for_Single-View_Human_Volumetric_Capture_CVPR_2021_paper.pdf",
        "aff": "Google, Switzerland; Department of Automation, Tsinghua University, China",
        "project": "",
        "github": "",
        "arxiv": "2103.15331"
    },
    {
        "title": "PPR10K: A Large-Scale Portrait Photo Retouching Dataset With Human-Region Mask and Group-Level Consistency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liang_PPR10K_A_Large-Scale_Portrait_Photo_Retouching_Dataset_With_Human-Region_Mask_CVPR_2021_paper.html",
        "author": "Jie Liang, Hui Zeng, Miaomiao Cui, Xuansong Xie, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liang_PPR10K_A_Large-Scale_Portrait_Photo_Retouching_Dataset_With_Human-Region_Mask_CVPR_2021_paper.pdf",
        "aff": "The Hong Kong Polytechnic University, DAMO Academy, Alibaba Group; DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/csjliang/PPR10K",
        "arxiv": "2105.09180"
    },
    {
        "title": "PQA: Perceptual Question Answering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qi_PQA_Perceptual_Question_Answering_CVPR_2021_paper.html",
        "author": "Yonggang Qi, Kai Zhang, Aneeshan Sain, Yi-Zhe Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qi_PQA_Perceptual_Question_Answering_CVPR_2021_paper.pdf",
        "aff": "SketchX, CVSSP, University of Surrey, UK; Beijing University of Posts and Telecommunications, CN",
        "project": "",
        "github": "",
        "arxiv": "2104.03589"
    },
    {
        "title": "PSD: Principled Synthetic-to-Real Dehazing Guided by Physical Priors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_PSD_Principled_Synthetic-to-Real_Dehazing_Guided_by_Physical_Priors_CVPR_2021_paper.html",
        "author": "Zeyuan Chen, Yangchao Wang, Yang Yang, Dong Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_PSD_Principled_Synthetic-to-Real_Dehazing_Guided_by_Physical_Priors_CVPR_2021_paper.pdf",
        "aff": "University of Science and Technology of China, Hefei, China; University of Electronic Science and Technology of China, Chengdu, China",
        "project": "",
        "github": "https://github.com/zychen-ustc/PSD-Principled-Synthetic-to-Real-Dehazing-Guided-by-Physical-Priors",
        "arxiv": ""
    },
    {
        "title": "PSRR-MaxpoolNMS: Pyramid Shifted MaxpoolNMS With Relationship Recovery",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_PSRR-MaxpoolNMS_Pyramid_Shifted_MaxpoolNMS_With_Relationship_Recovery_CVPR_2021_paper.html",
        "author": "Tianyi Zhang, Jie Lin, Peng Hu, Bin Zhao, Mohamed M. Sabry Aly",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_PSRR-MaxpoolNMS_Pyramid_Shifted_MaxpoolNMS_With_Relationship_Recovery_CVPR_2021_paper.pdf",
        "aff": "I2R, A*star, Singapore; IME, A*star, Singapore; Sichuan University, China; NTU, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PU-GCN: Point Cloud Upsampling Using Graph Convolutional Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qian_PU-GCN_Point_Cloud_Upsampling_Using_Graph_Convolutional_Networks_CVPR_2021_paper.html",
        "author": "Guocheng Qian, Abdulellah Abualshour, Guohao Li, Ali Thabet, Bernard Ghanem",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qian_PU-GCN_Point_Cloud_Upsampling_Using_Graph_Convolutional_Networks_CVPR_2021_paper.pdf",
        "aff": "King Abdullah University of Science and Technology (KAUST)",
        "project": "",
        "github": "https://github.com/guochengqian/PU-GCN",
        "arxiv": ""
    },
    {
        "title": "PV-RAFT: Point-Voxel Correlation Fields for Scene Flow Estimation of Point Clouds",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wei_PV-RAFT_Point-Voxel_Correlation_Fields_for_Scene_Flow_Estimation_of_Point_CVPR_2021_paper.html",
        "author": "Yi Wei, Ziyi Wang, Yongming Rao, Jiwen Lu, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wei_PV-RAFT_Point-Voxel_Correlation_Fields_for_Scene_Flow_Estimation_of_Point_CVPR_2021_paper.pdf",
        "aff": "Department of Automation, Tsinghua University, China; State Key Lab of Intelligent Technologies and Systems, China; Beijing National Research Center for Information Science and Technology, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, China; Department of Automation, Tsinghua University, China; State Key Lab of Intelligent Technologies and Systems, China; Beijing National Research Center for Information Science and Technology, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PVGNet: A Bottom-Up One-Stage 3D Object Detector With Integrated Multi-Level Features",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Miao_PVGNet_A_Bottom-Up_One-Stage_3D_Object_Detector_With_Integrated_Multi-Level_CVPR_2021_paper.html",
        "author": "Zhenwei Miao, Jikai Chen, Hongyu Pan, Ruiwen Zhang, Kaixuan Liu, Peihan Hao, Jun Zhu, Yang Wang, Xin Zhan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Miao_PVGNet_A_Bottom-Up_One-Stage_3D_Object_Detector_With_Integrated_Multi-Level_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group, Tsinghua University; Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PWCLO-Net: Deep LiDAR Odometry in 3D Point Clouds Using Hierarchical Embedding Mask Optimization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PWCLO-Net_Deep_LiDAR_Odometry_in_3D_Point_Clouds_Using_Hierarchical_CVPR_2021_paper.html",
        "author": "Guangming Wang, Xinrui Wu, Zhe Liu, Hesheng Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_PWCLO-Net_Deep_LiDAR_Odometry_in_3D_Point_Clouds_Using_Hierarchical_CVPR_2021_paper.pdf",
        "aff": "Department of Automation, Insititue of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Shanghai Jiao Tong University; Department of Computer Science and Technology, University of Cambridge",
        "project": "",
        "github": "https://github.com/IRMVLab/PWCLONet",
        "arxiv": ""
    },
    {
        "title": "Panoptic Segmentation Forecasting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Graber_Panoptic_Segmentation_Forecasting_CVPR_2021_paper.html",
        "author": "Colin Graber, Grace Tsai, Michael Firman, Gabriel Brostow, Alexander G. Schwing",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Graber_Panoptic_Segmentation_Forecasting_CVPR_2021_paper.pdf",
        "aff": "Niantic; University College London; University of Illinois at Urbana-Champaign",
        "project": "",
        "github": "",
        "arxiv": "2104.03962"
    },
    {
        "title": "Panoptic-PolarNet: Proposal-Free LiDAR Point Cloud Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Panoptic-PolarNet_Proposal-Free_LiDAR_Point_Cloud_Panoptic_Segmentation_CVPR_2021_paper.html",
        "author": "Zixiang Zhou, Yang Zhang, Hassan Foroosh",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Panoptic-PolarNet_Proposal-Free_LiDAR_Point_Cloud_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, University of Central Florida",
        "project": "",
        "github": "https://github.com/edwardzhou130/Panoptic-PolarNet",
        "arxiv": ""
    },
    {
        "title": "Panoramic Image Reflection Removal",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Panoramic_Image_Reflection_Removal_CVPR_2021_paper.html",
        "author": "Yuchen Hong, Qian Zheng, Lingran Zhao, Xudong Jiang, Alex C. Kot, Boxin Shi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Panoramic_Image_Reflection_Removal_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; NELVT, Department of Computer Science and Technology, Peking University, Beijing, China; Institute for Artificial Intelligence, Peking University, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; NELVT, Department of Computer Science and Technology, Peking University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Pareidolia Face Reenactment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_Pareidolia_Face_Reenactment_CVPR_2021_paper.html",
        "author": "Linsen Song, Wayne Wu, Chaoyou Fu, Chen Qian, Chen Change Loy, Ran He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Pareidolia_Face_Reenactment_CVPR_2021_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; NLPR & CRIPAC, CASIA; SenseTime Research",
        "project": "https://wywu.github.io/projects/ETT/ETT.html",
        "github": "",
        "arxiv": "2104.03061"
    },
    {
        "title": "Pareto Self-Supervised Training for Few-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Pareto_Self-Supervised_Training_for_Few-Shot_Learning_CVPR_2021_paper.html",
        "author": "Zhengyu Chen, Jixie Ge, Heshen Zhan, Siteng Huang, Donglin Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Pareto_Self-Supervised_Training_for_Few-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "Machine Intelligence Lab (MiLAB), AI Division, School of Engineering, Westlake University; College of Computer Science & Technology, Zhejiang University; Machine Intelligence Lab (MiLAB), AI Division, School of Engineering, Westlake University; Institute of Advanced Technology, Westlake Institute for Advanced Study",
        "project": "",
        "github": "",
        "arxiv": "2104.07841"
    },
    {
        "title": "Parser-Free Virtual Try-On via Distilling Appearance Flows",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ge_Parser-Free_Virtual_Try-On_via_Distilling_Appearance_Flows_CVPR_2021_paper.html",
        "author": "Yuying Ge, Yibing Song, Ruimao Zhang, Chongjian Ge, Wei Liu, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_Parser-Free_Virtual_Try-On_via_Distilling_Appearance_Flows_CVPR_2021_paper.pdf",
        "aff": "Tencent Data Platform; The University of Hong Kong; Tencent AI Lab; The Chinese University of Hong Kong (Shenzhen)",
        "project": "",
        "github": "https://github.com/geyuying/PF-AFN",
        "arxiv": "2103.04559"
    },
    {
        "title": "Part-Aware Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/de_Geus_Part-Aware_Panoptic_Segmentation_CVPR_2021_paper.html",
        "author": "Daan de Geus, Panagiotis Meletis, Chenyang Lu, Xiaoxiao Wen, Gijs Dubbelman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/de_Geus_Part-Aware_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Eindhoven University of Technology; University of Amsterdam",
        "project": "",
        "github": "",
        "arxiv": "2106.06351"
    },
    {
        "title": "Partial Feature Selection and Alignment for Multi-Source Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Partial_Feature_Selection_and_Alignment_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Yangye Fu, Ming Zhang, Xing Xu, Zuo Cao, Chao Ma, Yanli Ji, Kai Zuo, Huimin Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fu_Partial_Feature_Selection_and_Alignment_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "Department of Mechanical and Control Engineering, Kyushu Institute of Technology, Japan; MeiTuan; Center for Future Media & School of Computer Science and Engineering, University of Electronic Science and Technology of China, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Partial Person Re-Identification With Part-Part Correspondence Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_Partial_Person_Re-Identification_With_Part-Part_Correspondence_Learning_CVPR_2021_paper.html",
        "author": "Tianyu He, Xu Shen, Jianqiang Huang, Zhibo Chen, Xian-Sheng Hua",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_Partial_Person_Re-Identification_With_Part-Part_Correspondence_Learning_CVPR_2021_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Partially View-Aligned Representation Learning With Noise-Robust Contrastive Loss",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Partially_View-Aligned_Representation_Learning_With_Noise-Robust_Contrastive_Loss_CVPR_2021_paper.html",
        "author": "Mouxing Yang, Yunfan Li, Zhenyu Huang, Zitao Liu, Peng Hu, Xi Peng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Partially_View-Aligned_Representation_Learning_With_Noise-Robust_Contrastive_Loss_CVPR_2021_paper.pdf",
        "aff": "TAL Education Group, Beijing China; College of Computer Science, Sichuan University",
        "project": "",
        "github": "https://pengxi.me",
        "arxiv": ""
    },
    {
        "title": "Partition-Guided GANs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Armandpour_Partition-Guided_GANs_CVPR_2021_paper.html",
        "author": "Mohammadreza Armandpour, Ali Sadeghian, Chunyuan Li, Mingyuan Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Armandpour_Partition-Guided_GANs_CVPR_2021_paper.pdf",
        "aff": "Texas A&M University; Microsoft Research; University of Florida; The University of Texas at Austin",
        "project": "",
        "github": "",
        "arxiv": "2104.00816"
    },
    {
        "title": "Passive Inter-Photon Imaging",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ingle_Passive_Inter-Photon_Imaging_CVPR_2021_paper.html",
        "author": "Atul Ingle, Trevor Seets, Mauro Buttafava, Shantanu Gupta, Alberto Tosi, Mohit Gupta, Andreas Velten",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ingle_Passive_Inter-Photon_Imaging_CVPR_2021_paper.pdf",
        "aff": "Politecnico di Milano; University of Wisconsin-Madison",
        "project": "",
        "github": "",
        "arxiv": "2104.00059"
    },
    {
        "title": "Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hausler_Patch-NetVLAD_Multi-Scale_Fusion_of_Locally-Global_Descriptors_for_Place_Recognition_CVPR_2021_paper.html",
        "author": "Stephen Hausler, Sourav Garg, Ming Xu, Michael Milford, Tobias Fischer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hausler_Patch-NetVLAD_Multi-Scale_Fusion_of_Locally-Global_Descriptors_for_Place_Recognition_CVPR_2021_paper.pdf",
        "aff": "QUT Centre for Robotics, Queensland University of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Patch-VQ: 'Patching Up' the Video Quality Problem",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ying_Patch-VQ_Patching_Up_the_Video_Quality_Problem_CVPR_2021_paper.html",
        "author": "Zhenqiang Ying, Maniratnam Mandal, Deepti Ghadiyaram, Alan Bovik",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ying_Patch-VQ_Patching_Up_the_Video_Quality_Problem_CVPR_2021_paper.pdf",
        "aff": "Facebook AI; University of Texas at Austin",
        "project": "https://live.ece.utexas.edu/research.php",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Patch2Pix: Epipolar-Guided Pixel-Level Correspondences",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Patch2Pix_Epipolar-Guided_Pixel-Level_Correspondences_CVPR_2021_paper.html",
        "author": "Qunjie Zhou, Torsten Sattler, Laura Leal-Taixe",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Patch2Pix_Epipolar-Guided_Pixel-Level_Correspondences_CVPR_2021_paper.pdf",
        "aff": "CIIRC, Czech Technical University in Prague; Technical University of Munich",
        "project": "",
        "github": "https://github.com/GrumpyZhou/patch2pix",
        "arxiv": ""
    },
    {
        "title": "PatchMatch-Based Neighborhood Consensus for Semantic Correspondence",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_PatchMatch-Based_Neighborhood_Consensus_for_Semantic_Correspondence_CVPR_2021_paper.html",
        "author": "Jae Yong Lee, Joseph DeGol, Victor Fragoso, Sudipta N. Sinha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_PatchMatch-Based_Neighborhood_Consensus_for_Semantic_Correspondence_CVPR_2021_paper.pdf",
        "aff": "University of Illinois; Microsoft",
        "project": "",
        "github": "http://github.com/leejaeyong7/PMNC",
        "arxiv": ""
    },
    {
        "title": "PatchmatchNet: Learned Multi-View Patchmatch Stereo",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PatchmatchNet_Learned_Multi-View_Patchmatch_Stereo_CVPR_2021_paper.html",
        "author": "Fangjinhua Wang, Silvano Galliani, Christoph Vogel, Pablo Speciale, Marc Pollefeys",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_PatchmatchNet_Learned_Multi-View_Patchmatch_Stereo_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich; Microsoft Mixed Reality & AI Zurich Lab",
        "project": "",
        "github": "https://github.com/FangjinhuaWang/PatchmatchNet",
        "arxiv": "2012.01411"
    },
    {
        "title": "Patchwise Generative ConvNet: Training Energy-Based Models From a Single Natural Image for Internal Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Patchwise_Generative_ConvNet_Training_Energy-Based_Models_From_a_Single_Natural_CVPR_2021_paper.html",
        "author": "Zilong Zheng, Jianwen Xie, Ping Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Patchwise_Generative_ConvNet_Training_Energy-Based_Models_From_a_Single_Natural_CVPR_2021_paper.pdf",
        "aff": "University of California, Los Angeles, CA; Cognitive Computing Lab, Baidu Research, Bellevue, WA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Pedestrian and Ego-Vehicle Trajectory Prediction From Monocular Camera",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Neumann_Pedestrian_and_Ego-Vehicle_Trajectory_Prediction_From_Monocular_Camera_CVPR_2021_paper.html",
        "author": "Lukas Neumann, Andrea Vedaldi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Neumann_Pedestrian_and_Ego-Vehicle_Trajectory_Prediction_From_Monocular_Camera_CVPR_2021_paper.pdf",
        "aff": "Visual Geometry Group, Department of Engineering Science, University of Oxford; Visual Recognition Group, Faculty of Electrical Engineering, Czech Technical University in Prague",
        "project": "",
        "github": "https://gitlab.com/lukeN86/pedFutureTracking",
        "arxiv": ""
    },
    {
        "title": "Perception Matters: Detecting Perception Failures of VQA Models Using Metamorphic Testing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_Perception_Matters_Detecting_Perception_Failures_of_VQA_Models_Using_Metamorphic_CVPR_2021_paper.html",
        "author": "Yuanyuan Yuan, Shuai Wang, Mingyue Jiang, Tsong Yueh Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_Perception_Matters_Detecting_Perception_Failures_of_VQA_Models_Using_Metamorphic_CVPR_2021_paper.pdf",
        "aff": "Swinburne University of Technology; HKUST; Zhejiang Sci-Tech University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Perceptual Indistinguishability-Net (PI-Net): Facial Image Obfuscation With Manipulable Semantics",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Perceptual_Indistinguishability-Net_PI-Net_Facial_Image_Obfuscation_With_Manipulable_Semantics_CVPR_2021_paper.html",
        "author": "Jia-Wei Chen, Li-Ju Chen, Chia-Mu Yu, Chun-Shien Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Perceptual_Indistinguishability-Net_PI-Net_Facial_Image_Obfuscation_With_Manipulable_Semantics_CVPR_2021_paper.pdf",
        "aff": "Research Center for Information Technology Innovation, Academia Sinica; National Yang Ming Chiao Tung University; Institute of Information Science, Academia Sinica",
        "project": "",
        "github": "",
        "arxiv": "2104.01753"
    },
    {
        "title": "Permute, Quantize, and Fine-Tune: Efficient Compression of Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Martinez_Permute_Quantize_and_Fine-Tune_Efficient_Compression_of_Neural_Networks_CVPR_2021_paper.html",
        "author": "Julieta Martinez, Jashan Shewakramani, Ting Wei Liu, Ioan Andrei Barsan, Wenyuan Zeng, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Martinez_Permute_Quantize_and_Fine-Tune_Efficient_Compression_of_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "Uber Advanced Technologies Group, University of Toronto; Uber Advanced Technologies Group, University of Waterloo; Uber Advanced Technologies Group",
        "project": "",
        "github": "https://github.com/uber-research/permute-quantize-finetune",
        "arxiv": ""
    },
    {
        "title": "Permuted AdaIN: Reducing the Bias Towards Global Statistics in Image Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nuriel_Permuted_AdaIN_Reducing_the_Bias_Towards_Global_Statistics_in_Image_CVPR_2021_paper.html",
        "author": "Oren Nuriel, Sagie Benaim, Lior Wolf",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nuriel_Permuted_AdaIN_Reducing_the_Bias_Towards_Global_Statistics_in_Image_CVPR_2021_paper.pdf",
        "aff": "Tel Aviv University",
        "project": "",
        "github": "",
        "arxiv": "2010.05785"
    },
    {
        "title": "Person Re-Identification Using Heterogeneous Local Graph Attention Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Person_Re-Identification_Using_Heterogeneous_Local_Graph_Attention_Networks_CVPR_2021_paper.html",
        "author": "Zhong Zhang, Haijia Zhang, Shuang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Person_Re-Identification_Using_Heterogeneous_Local_Graph_Attention_Networks_CVPR_2021_paper.pdf",
        "aff": "Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Person30K: A Dual-Meta Generalization Network for Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bai_Person30K_A_Dual-Meta_Generalization_Network_for_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Yan Bai, Jile Jiao, Wang Ce, Jun Liu, Yihang Lou, Xuetao Feng, Ling-Yu Duan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bai_Person30K_A_Dual-Meta_Generalization_Network_for_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group, Beijing, China; Peking University, Beijing, China; Singapore University of Technology and Design; Peking University, Beijing, China and Peng Cheng Laboratory, Shenzhen, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Personalized Outfit Recommendation With Learnable Anchors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Personalized_Outfit_Recommendation_With_Learnable_Anchors_CVPR_2021_paper.html",
        "author": "Zhi Lu, Yang Hu, Yan Chen, Bing Zeng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_Personalized_Outfit_Recommendation_With_Learnable_Anchors_CVPR_2021_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PhD Learning: Learning With Pompeiu-Hausdorff Distances for Video-Based Vehicle Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_PhD_Learning_Learning_With_Pompeiu-Hausdorff_Distances_for_Video-Based_Vehicle_Re-Identification_CVPR_2021_paper.html",
        "author": "Jianan Zhao, Fengliang Qi, Guangyu Ren, Lin Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_PhD_Learning_Learning_With_Pompeiu-Hausdorff_Distances_for_Video-Based_Vehicle_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Shanghai Em-Data Technology Co., Ltd.; Imperial College London",
        "project": "",
        "github": "https://github.com/emdata-ailab/PhD-Learning",
        "arxiv": ""
    },
    {
        "title": "PhySG: Inverse Rendering With Spherical Gaussians for Physics-Based Material Editing and Relighting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_PhySG_Inverse_Rendering_With_Spherical_Gaussians_for_Physics-Based_Material_Editing_CVPR_2021_paper.html",
        "author": "Kai Zhang, Fujun Luan, Qianqian Wang, Kavita Bala, Noah Snavely",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_PhySG_Inverse_Rendering_With_Spherical_Gaussians_for_Physics-Based_Material_Editing_CVPR_2021_paper.pdf",
        "aff": "Cornell University",
        "project": "https://kai-46.github.io/PhySG-website/",
        "github": "",
        "arxiv": "2104.00674"
    },
    {
        "title": "Physically-Aware Generative Network for 3D Shape Modeling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mezghanni_Physically-Aware_Generative_Network_for_3D_Shape_Modeling_CVPR_2021_paper.html",
        "author": "Mariem Mezghanni, Malika Boulkenafed, Andre Lieutier, Maks Ovsjanikov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mezghanni_Physically-Aware_Generative_Network_for_3D_Shape_Modeling_CVPR_2021_paper.pdf",
        "aff": "LIX, Ecole Polytechnique, IP Paris",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Physics-Based Iterative Projection Complex Neural Network for Phase Retrieval in Lensless Microscopy Imaging",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Physics-Based_Iterative_Projection_Complex_Neural_Network_for_Phase_Retrieval_in_CVPR_2021_paper.html",
        "author": "Feilong Zhang, Xianming Liu, Cheng Guo, Shiyi Lin, Junjun Jiang, Xiangyang Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Physics-Based_Iterative_Projection_Complex_Neural_Network_for_Phase_Retrieval_in_CVPR_2021_paper.pdf",
        "aff": "Harbin Institute of Technology; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chan_Pi-GAN_Periodic_Implicit_Generative_Adversarial_Networks_for_3D-Aware_Image_Synthesis_CVPR_2021_paper.html",
        "author": "Eric R. Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu, Gordon Wetzstein",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chan_Pi-GAN_Periodic_Implicit_Generative_Adversarial_Networks_for_3D-Aware_Image_Synthesis_CVPR_2021_paper.pdf",
        "aff": "Stanford University",
        "project": "https://marcoamonteiro.github.io/pi-GAN-website/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PiCIE: Unsupervised Semantic Segmentation Using Invariance and Equivariance in Clustering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cho_PiCIE_Unsupervised_Semantic_Segmentation_Using_Invariance_and_Equivariance_in_Clustering_CVPR_2021_paper.html",
        "author": "Jang Hyun Cho, Utkarsh Mall, Kavita Bala, Bharath Hariharan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cho_PiCIE_Unsupervised_Semantic_Segmentation_Using_Invariance_and_Equivariance_in_Clustering_CVPR_2021_paper.pdf",
        "aff": "Cornell University; University of Texas at Austin",
        "project": "",
        "github": "https://github.com/janghyuncho/PiCIE",
        "arxiv": "2103.17070"
    },
    {
        "title": "Picasso: A CUDA-Based Library for Deep Learning Over 3D Meshes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lei_Picasso_A_CUDA-Based_Library_for_Deep_Learning_Over_3D_Meshes_CVPR_2021_paper.html",
        "author": "Huan Lei, Naveed Akhtar, Ajmal Mian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lei_Picasso_A_CUDA-Based_Library_for_Deep_Learning_Over_3D_Meshes_CVPR_2021_paper.pdf",
        "aff": "The University of Western Australia",
        "project": "",
        "github": "https://github.com/hlei-ziyan/Picasso",
        "arxiv": "2103.15076"
    },
    {
        "title": "PixMatch: Unsupervised Domain Adaptation via Pixelwise Consistency Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Melas-Kyriazi_PixMatch_Unsupervised_Domain_Adaptation_via_Pixelwise_Consistency_Training_CVPR_2021_paper.html",
        "author": "Luke Melas-Kyriazi, Arjun K. Manrai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Melas-Kyriazi_PixMatch_Unsupervised_Domain_Adaptation_via_Pixelwise_Consistency_Training_CVPR_2021_paper.pdf",
        "aff": "Harvard University, Boston Children\u2019s Hospital, Boston, MA, ArjunManrai@hms.harvard.edu; Harvard University, Cambridge, MA, lmelaskyriazi@college.harvard.edu",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Pixel Codec Avatars",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Pixel_Codec_Avatars_CVPR_2021_paper.html",
        "author": "Shugao Ma, Tomas Simon, Jason Saragih, Dawei Wang, Yuecheng Li, Fernando De la Torre, Yaser Sheikh",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_Pixel_Codec_Avatars_CVPR_2021_paper.pdf",
        "aff": "Facebook Reality Labs Research",
        "project": "",
        "github": "",
        "arxiv": "2104.04638"
    },
    {
        "title": "Pixel-Aligned Volumetric Avatars",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Raj_Pixel-Aligned_Volumetric_Avatars_CVPR_2021_paper.html",
        "author": "Amit Raj, Michael Zollhofer, Tomas Simon, Jason Saragih, Shunsuke Saito, James Hays, Stephen Lombardi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Raj_Pixel-Aligned_Volumetric_Avatars_CVPR_2021_paper.pdf",
        "aff": "Georgia Institute of Technology; Facebook Reality Labs Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Pixel-Wise Anomaly Detection in Complex Driving Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Di_Biase_Pixel-Wise_Anomaly_Detection_in_Complex_Driving_Scenes_CVPR_2021_paper.html",
        "author": "Giancarlo Di Biase, Hermann Blum, Roland Siegwart, Cesar Cadena",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Di_Biase_Pixel-Wise_Anomaly_Detection_in_Complex_Driving_Scenes_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich",
        "project": "",
        "github": "",
        "arxiv": "2103.05445"
    },
    {
        "title": "Plan2Scene: Converting Floorplans to 3D Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Vidanapathirana_Plan2Scene_Converting_Floorplans_to_3D_Scenes_CVPR_2021_paper.html",
        "author": "Madhawa Vidanapathirana, Qirui Wu, Yasutaka Furukawa, Angel X. Chang, Manolis Savva",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Vidanapathirana_Plan2Scene_Converting_Floorplans_to_3D_Scenes_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University",
        "project": "",
        "github": "https://3dlg-hcvc.github.io/plan2scene/",
        "arxiv": "2106.05375"
    },
    {
        "title": "Playable Video Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Menapace_Playable_Video_Generation_CVPR_2021_paper.html",
        "author": "Willi Menapace, Stephane Lathuiliere, Sergey Tulyakov, Aliaksandr Siarohin, Elisa Ricci",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Menapace_Playable_Video_Generation_CVPR_2021_paper.pdf",
        "aff": "University of Trento, Fondazione Bruno Kessler; Snap Inc.; University of Trento; LTCI, T \u00b4el\u00b4ecom Paris, Institut Polytechnique de Paris",
        "project": "http://willi-menapace.github.io/playable-video-generation-website",
        "github": "https://github.com/willi-menapace/playable-video-generation-website",
        "arxiv": "2101.12195"
    },
    {
        "title": "PluckerNet: Learn To Register 3D Line Reconstructions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_PluckerNet_Learn_To_Register_3D_Line_Reconstructions_CVPR_2021_paper.html",
        "author": "Liu Liu, Hongdong Li, Haodong Yao, Ruyi Zha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_PluckerNet_Learn_To_Register_3D_Line_Reconstructions_CVPR_2021_paper.pdf",
        "aff": "Australian National University, Canberra, Australia",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Point 4D Transformer Networks for Spatio-Temporal Modeling in Point Cloud Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Point_4D_Transformer_Networks_for_Spatio-Temporal_Modeling_in_Point_Cloud_CVPR_2021_paper.html",
        "author": "Hehe Fan, Yi Yang, Mohan Kankanhalli",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_Point_4D_Transformer_Networks_for_Spatio-Temporal_Modeling_in_Point_Cloud_CVPR_2021_paper.pdf",
        "aff": "School of Computing, National University of Singapore; ReLER, University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Point Cloud Instance Segmentation Using Probabilistic Embeddings",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Point_Cloud_Instance_Segmentation_Using_Probabilistic_Embeddings_CVPR_2021_paper.html",
        "author": "Biao Zhang, Peter Wonka",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Point_Cloud_Instance_Segmentation_Using_Probabilistic_Embeddings_CVPR_2021_paper.pdf",
        "aff": "KAUST",
        "project": "",
        "github": "",
        "arxiv": "1912.00145"
    },
    {
        "title": "Point Cloud Upsampling via Disentangled Refinement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Point_Cloud_Upsampling_via_Disentangled_Refinement_CVPR_2021_paper.html",
        "author": "Ruihui Li, Xianzhi Li, Pheng-Ann Heng, Chi-Wing Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Point_Cloud_Upsampling_via_Disentangled_Refinement_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/liruihui/Dis-PU",
        "arxiv": "2106.04779"
    },
    {
        "title": "Point2Skeleton: Learning Skeletal Representations from Point Clouds",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Point2Skeleton_Learning_Skeletal_Representations_from_Point_Clouds_CVPR_2021_paper.html",
        "author": "Cheng Lin, Changjian Li, Yuan Liu, Nenglun Chen, Yi-King Choi, Wenping Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Point2Skeleton_Learning_Skeletal_Representations_from_Point_Clouds_CVPR_2021_paper.pdf",
        "aff": "The University of Hong Kong, Texas A&M University; University College London; The University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2012.00230"
    },
    {
        "title": "PointAugmenting: Cross-Modal Augmentation for 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PointAugmenting_Cross-Modal_Augmentation_for_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "Chunwei Wang, Chao Ma, Ming Zhu, Xiaokang Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_PointAugmenting_Cross-Modal_Augmentation_for_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "MoE Key Lab of Arti\ufb01cial Intelligence, AI Institute, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "PointDSC: Robust Point Cloud Registration Using Deep Spatial Consistency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bai_PointDSC_Robust_Point_Cloud_Registration_Using_Deep_Spatial_Consistency_CVPR_2021_paper.html",
        "author": "Xuyang Bai, Zixin Luo, Lei Zhou, Hongkai Chen, Lei Li, Zeyu Hu, Hongbo Fu, Chiew-Lan Tai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bai_PointDSC_Robust_Point_Cloud_Registration_Using_Deep_Spatial_Consistency_CVPR_2021_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; Hong Kong University of Science and Technology and Ecole Polytechnique; City University of Hong Kong",
        "project": "",
        "github": "code release mentioned but no direct link provided",
        "arxiv": "2103.05465"
    },
    {
        "title": "PointFlow: Flowing Semantics Through Points for Aerial Image Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_PointFlow_Flowing_Semantics_Through_Points_for_Aerial_Image_Segmentation_CVPR_2021_paper.html",
        "author": "Xiangtai Li, Hao He, Xia Li, Duo Li, Guangliang Cheng, Jianping Shi, Lubin Weng, Yunhai Tong, Zhouchen Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_PointFlow_Flowing_Semantics_Through_Points_for_Aerial_Image_Segmentation_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; HKUST; Key Laboratory of Machine Perception (MOE), Peking University; NLPR, Institute of Automation, Chinese Academy of Sciences; Qing Yuan Research Institute, SJTU; SenseTime Research",
        "project": "",
        "github": "https://github.com/lxtGH/PFSegNets",
        "arxiv": "2103.06564"
    },
    {
        "title": "PointGuard: Provably Robust 3D Point Cloud Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_PointGuard_Provably_Robust_3D_Point_Cloud_Classification_CVPR_2021_paper.html",
        "author": "Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_PointGuard_Provably_Robust_3D_Point_Cloud_Classification_CVPR_2021_paper.pdf",
        "aff": "Duke University",
        "project": "",
        "github": "",
        "arxiv": "2103.03046"
    },
    {
        "title": "PointNetLK Revisited",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_PointNetLK_Revisited_CVPR_2021_paper.html",
        "author": "Xueqian Li, Jhony Kaesemodel Pontes, Simon Lucey",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_PointNetLK_Revisited_CVPR_2021_paper.pdf",
        "aff": "Argo AI; The University of Adelaide, Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/Lilac-Lee/PointNetLK-Revisited.git",
        "arxiv": "2008.09527"
    },
    {
        "title": "Points As Queries: Weakly Semi-Supervised Object Detection by Points",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Points_As_Queries_Weakly_Semi-Supervised_Object_Detection_by_Points_CVPR_2021_paper.html",
        "author": "Liangyu Chen, Tong Yang, Xiangyu Zhang, Wei Zhang, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Points_As_Queries_Weakly_Semi-Supervised_Object_Detection_by_Points_CVPR_2021_paper.pdf",
        "aff": "Fudan University; MEGVII Technology",
        "project": "",
        "github": "",
        "arxiv": "2104.07434"
    },
    {
        "title": "Polarimetric Normal Stereo",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fukao_Polarimetric_Normal_Stereo_CVPR_2021_paper.html",
        "author": "Yoshiki Fukao, Ryo Kawahara, Shohei Nobuhara, Ko Nishino",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fukao_Polarimetric_Normal_Stereo_CVPR_2021_paper.pdf",
        "aff": "Graduate School of Informatics, Kyoto University",
        "project": "https://vision.ist.i.kyoto-u.ac.jp/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Polka Lines: Learning Structured Illumination and Reconstruction for Active Stereo",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Baek_Polka_Lines_Learning_Structured_Illumination_and_Reconstruction_for_Active_Stereo_CVPR_2021_paper.html",
        "author": "Seung-Hwan Baek, Felix Heide",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Baek_Polka_Lines_Learning_Structured_Illumination_and_Reconstruction_for_Active_Stereo_CVPR_2021_paper.pdf",
        "aff": "Princeton University",
        "project": "",
        "github": "",
        "arxiv": "2011.13117"
    },
    {
        "title": "Polygonal Building Extraction by Frame Field Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Girard_Polygonal_Building_Extraction_by_Frame_Field_Learning_CVPR_2021_paper.html",
        "author": "Nicolas Girard, Dmitriy Smirnov, Justin Solomon, Yuliya Tarabalka",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Girard_Polygonal_Building_Extraction_by_Frame_Field_Learning_CVPR_2021_paper.pdf",
        "aff": "Universit \u00b4e C\u02c6ote d\u2019Azur, Inria; LuxCarta Technology; Massachusetts Institute of Technology",
        "project": "",
        "github": "https://github.com/Lydorn/Polygonization-by-Frame-Field-Learning",
        "arxiv": ""
    },
    {
        "title": "Polygonal Point Set Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nam_Polygonal_Point_Set_Tracking_CVPR_2021_paper.html",
        "author": "Gunhee Nam, Miran Heo, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nam_Polygonal_Point_Set_Tracking_CVPR_2021_paper.pdf",
        "aff": "Yonsei University; Adobe Research; Lunit Inc.",
        "project": "",
        "github": "",
        "arxiv": "2105.14584"
    },
    {
        "title": "Populating 3D Scenes by Learning Human-Scene Interaction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hassan_Populating_3D_Scenes_by_Learning_Human-Scene_Interaction_CVPR_2021_paper.html",
        "author": "Mohamed Hassan, Partha Ghosh, Joachim Tesch, Dimitrios Tzionas, Michael J. Black",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hassan_Populating_3D_Scenes_by_Learning_Human-Scene_Interaction_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "project": "https://posa.is.tue.mpg.de",
        "github": "",
        "arxiv": "2012.11581"
    },
    {
        "title": "Pose Recognition With Cascade Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Pose_Recognition_With_Cascade_Transformers_CVPR_2021_paper.html",
        "author": "Ke Li, Shijie Wang, Xiang Zhang, Yifan Xu, Weijian Xu, Zhuowen Tu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Pose_Recognition_With_Cascade_Transformers_CVPR_2021_paper.pdf",
        "aff": "University of California San Diego, San Diego, USA; Tsinghua University, Beijing, China; University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "https://github.com/mlpc-ucsd/PRTR",
        "arxiv": "2104.06976"
    },
    {
        "title": "Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Pose-Controllable_Talking_Face_Generation_by_Implicitly_Modularized_Audio-Visual_Representation_CVPR_2021_paper.html",
        "author": "Hang Zhou, Yasheng Sun, Wayne Wu, Chen Change Loy, Xiaogang Wang, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Pose-Controllable_Talking_Face_Generation_by_Implicitly_Modularized_Audio-Visual_Representation_CVPR_2021_paper.pdf",
        "aff": "Pose-Controllable Talking Face Generation by\nImplicitly Modularized Audio-Visual Representation\nHang Zhou1, Yasheng Sun2,3, Wayne Wu2,4, Chen Change Loy4, Xiaogang Wang1, Ziwei Liu4 \u0000\n1CUHK - SenseTime Joint Lab, The Chinese University of Hong Kong2SenseTime Research\n3Tokyo Institute of Technology4S-Lab, Nanyang Technological University\n{zhouhang@link,xgwang@ee}.cuhk.edu.hk, wuwenyan@sensetime.com, {ccloy,ziwei.liu}@ntu.edu.sg\nIdentity\nReference\nAudio\nSource\nGenerated\nResults\nPose\nSource\nSynced\nVideo\nFigure 1: Illustration of Pose-Controllable Audio-Visual System (PC-A VS). Our approach takes one frame as identity reference and\ngenerates audio-driven talking faces with pose controlled by another pose source video. The mouth shapes of the generated frames are\nmatched with the \ufb01rst row (synced video with audio) while the pose is matched with the bottom row (pose source).\nAbstract\nWhile accurate lip synchronization has been achieved\nfor arbitrary-subject audio-driven talking face generation,\nthe problem of how to ef\ufb01ciently drive the head pose re-\nmains. Previous methods rely on pre-estimated structural\ninformation such as landmarks and 3D parameters, aiming\nto generate personalized rhythmic movements. However, the\ninaccuracy of such estimated information under extreme con-\nditions would lead to degradation problems. In this paper,\nwe propose a clean yet effective framework to generate pose-\ncontrollable talking faces. We operate on non-aligned raw\nface images, using only a single photo as an identity refer-\nence. The key is to modularize audio-visual representations\nby devising an implicit low-dimension pose code. Substan-\ntially, both speech content and head pose information lie in\na joint non-identity embedding space. While speech content\ninformation can be de\ufb01ned by learning the intrinsic synchro-\nnization between audio-visual modalities, we identify that apose code will be complementarily learned in a modulated\nconvolution-based reconstruction framework.\nExtensive experiments show that our method generates\naccurately lip-synced talking faces whose poses are con-\ntrollable by other videos. Moreover, our model has multiple\nadvanced capabilities including extreme view robustness and\ntalking face frontalization.1\n1. Introduction\nDriving a static portrait with audio is of great impor-\ntance to a variety of applications in the \ufb01eld of enter-\ntainment, such as digital human animation, visual dub-\nbing in movies, and fast creation of short videos. Armed\nwith deep learning, previous researchers take two differ-\nent paths towards analyzing audio-driven talking human\n1Code, models, and demo videos are available at https://hangz-\nnju-cuhk.github.io/projects/PC-AVS .\n4176\n",
        "project": "",
        "github": "",
        "arxiv": "2104.11116"
    },
    {
        "title": "Pose-Guided Human Animation From a Single Image in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yoon_Pose-Guided_Human_Animation_From_a_Single_Image_in_the_Wild_CVPR_2021_paper.html",
        "author": "Jae Shin Yoon, Lingjie Liu, Vladislav Golyanik, Kripasindhu Sarkar, Hyun Soo Park, Christian Theobalt",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yoon_Pose-Guided_Human_Animation_From_a_Single_Image_in_the_Wild_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Informatics, SIC; University of Minnesota",
        "project": "",
        "github": "",
        "arxiv": "2012.03796"
    },
    {
        "title": "PoseAug: A Differentiable Pose Augmentation Framework for 3D Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gong_PoseAug_A_Differentiable_Pose_Augmentation_Framework_for_3D_Human_Pose_CVPR_2021_paper.html",
        "author": "Kehong Gong, Jianfeng Zhang, Jiashi Feng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gong_PoseAug_A_Differentiable_Pose_Augmentation_Framework_for_3D_Human_Pose_CVPR_2021_paper.pdf",
        "aff": "National University of Singapore",
        "project": "",
        "github": "https://github.com/jfzhang95/PoseAug",
        "arxiv": "2105.02465"
    },
    {
        "title": "Positional Encoding As Spatial Inductive Bias in GANs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Positional_Encoding_As_Spatial_Inductive_Bias_in_GANs_CVPR_2021_paper.html",
        "author": "Rui Xu, Xintao Wang, Kai Chen, Bolei Zhou, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Positional_Encoding_As_Spatial_Inductive_Bias_in_GANs_CVPR_2021_paper.pdf",
        "aff": "CUHK-SenseTime Joint Lab, The Chinese University of Hong Kong; Applied Research Center, Tencent PCG; S-Lab, Nanyang Technological University; SenseTime Research",
        "project": "https://nbei.github.io/gan-pos-encoding.html",
        "github": "",
        "arxiv": "2012.05217"
    },
    {
        "title": "Positive Sample Propagation Along the Audio-Visual Event Line",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Positive_Sample_Propagation_Along_the_Audio-Visual_Event_Line_CVPR_2021_paper.html",
        "author": "Jinxing Zhou, Liang Zheng, Yiran Zhong, Shijie Hao, Meng Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Positive_Sample_Propagation_Along_the_Audio-Visual_Event_Line_CVPR_2021_paper.pdf",
        "aff": "Hefei University of Technology, Intelligent Interconnected Systems Laboratory of Anhui Province; Australian National University",
        "project": "",
        "github": "",
        "arxiv": "2104.00239"
    },
    {
        "title": "Positive-Congruent Training: Towards Regression-Free Model Updates",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Positive-Congruent_Training_Towards_Regression-Free_Model_Updates_CVPR_2021_paper.html",
        "author": "Sijie Yan, Yuanjun Xiong, Kaustav Kundu, Shuo Yang, Siqi Deng, Meng Wang, Wei Xia, Stefano Soatto",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Positive-Congruent_Training_Towards_Regression-Free_Model_Updates_CVPR_2021_paper.pdf",
        "aff": "The Chinese University of Hong Kong (Work conducted while at AWS/Amazon AI); AWS/Amazon AI",
        "project": "",
        "github": "",
        "arxiv": "2011.09161"
    },
    {
        "title": "Positive-Unlabeled Data Purification in the Wild for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Positive-Unlabeled_Data_Purification_in_the_Wild_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Jianyuan Guo, Kai Han, Han Wu, Chao Zhang, Xinghao Chen, Chunjing Xu, Chang Xu, Yunhe Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Positive-Unlabeled_Data_Purification_in_the_Wild_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Key Lab of Machine Perception (MOE), Dept. of Machine Intelligence, Peking University; Noah\u2019s Ark Lab, Huawei Technologies; School of Computer Science, Faculty of Engineering, University of Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Post-Hoc Uncertainty Calibration for Domain Drift Scenarios",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tomani_Post-Hoc_Uncertainty_Calibration_for_Domain_Drift_Scenarios_CVPR_2021_paper.html",
        "author": "Christian Tomani, Sebastian Gruber, Muhammed Ebrar Erdem, Daniel Cremers, Florian Buettner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tomani_Post-Hoc_Uncertainty_Calibration_for_Domain_Drift_Scenarios_CVPR_2021_paper.pdf",
        "aff": "Siemens AG; Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": "2012.10988"
    },
    {
        "title": "Posterior Promoted GAN With Distribution Discriminator for Unsupervised Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Posterior_Promoted_GAN_With_Distribution_Discriminator_for_Unsupervised_Image_Synthesis_CVPR_2021_paper.html",
        "author": "Xianchao Zhang, Ziyang Cheng, Xiaotong Zhang, Han Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Posterior_Promoted_GAN_With_Distribution_Discriminator_for_Unsupervised_Image_Synthesis_CVPR_2021_paper.pdf",
        "aff": "School of Software, Dalian University of Technology, Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Practical Single-Image Super-Resolution Using Look-Up Table",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jo_Practical_Single-Image_Super-Resolution_Using_Look-Up_Table_CVPR_2021_paper.html",
        "author": "Younghyun Jo, Seon Joo Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jo_Practical_Single-Image_Super-Resolution_Using_Look-Up_Table_CVPR_2021_paper.pdf",
        "aff": "Yonsei University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Practical Wide-Angle Portraits Correction With Deep Structured Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tan_Practical_Wide-Angle_Portraits_Correction_With_Deep_Structured_Models_CVPR_2021_paper.html",
        "author": "Jing Tan, Shan Zhao, Pengfei Xiong, Jiangyu Liu, Haoqiang Fan, Shuaicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_Practical_Wide-Angle_Portraits_Correction_With_Deep_Structured_Models_CVPR_2021_paper.pdf",
        "aff": "Megvii Research; Tencent; University of Electronic Science and Technology of China",
        "project": "",
        "github": "https://github.com/TanJing94/Deep_Portraits_Correction",
        "arxiv": "2104.12464"
    },
    {
        "title": "Pre-Trained Image Processing Transformer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Pre-Trained_Image_Processing_Transformer_CVPR_2021_paper.html",
        "author": "Hanting Chen, Yunhe Wang, Tianyu Guo, Chang Xu, Yiping Deng, Zhenhua Liu, Siwei Ma, Chunjing Xu, Chao Xu, Wen Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Pre-Trained_Image_Processing_Transformer_CVPR_2021_paper.pdf",
        "aff": "1Key Lab of Machine Perception (MOE), Dept. of Machine Intelligence, Peking University; 6Peng Cheng Laboratory; 2Noah\u2019s Ark Lab, Huawei Technologies; 4Central Software Institution, Huawei Technologies; 5Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University; 3School of Computer Science, Faculty of Engineering, The University of Sydney",
        "project": "",
        "github": "https://github.com/huawei-noah/Pretrained-IPT",
        "arxiv": "2012.00364"
    },
    {
        "title": "Predator: Registration of 3D Point Clouds With Low Overlap",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Predator_Registration_of_3D_Point_Clouds_With_Low_Overlap_CVPR_2021_paper.html",
        "author": "Shengyu Huang, Zan Gojcic, Mikhail Usvyatsov, Andreas Wieser, Konrad Schindler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Predator_Registration_of_3D_Point_Clouds_With_Low_Overlap_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich",
        "project": "https://overlappredator.github.io",
        "github": "https://github.com/overlappredator",
        "arxiv": "2011.13005"
    },
    {
        "title": "Predicting Human Scanpaths in Visual Question Answering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Predicting_Human_Scanpaths_in_Visual_Question_Answering_CVPR_2021_paper.html",
        "author": "Xianyu Chen, Ming Jiang, Qi Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Predicting_Human_Scanpaths_in_Visual_Question_Answering_CVPR_2021_paper.pdf",
        "aff": "University of Minnesota",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Primitive Representation Learning for Scene Text Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Primitive_Representation_Learning_for_Scene_Text_Recognition_CVPR_2021_paper.html",
        "author": "Ruijie Yan, Liangrui Peng, Shanyu Xiao, Gang Yao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Primitive_Representation_Learning_for_Scene_Text_Recognition_CVPR_2021_paper.pdf",
        "aff": "Beijing National Research Center for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": "2105.04286"
    },
    {
        "title": "Prior Based Human Completion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Prior_Based_Human_Completion_CVPR_2021_paper.html",
        "author": "Zibo Zhao, Wen Liu, Yanyu Xu, Xianing Chen, Weixin Luo, Lei Jin, Bohui Zhu, Tong Liu, Binqiang Zhao, Shenghua Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Prior_Based_Human_Completion_CVPR_2021_paper.pdf",
        "aff": "Taobao; Institute of High Performance Computing, A*STAR; ShanghaiTech University; ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Prioritized Architecture Sampling With Monto-Carlo Tree Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Su_Prioritized_Architecture_Sampling_With_Monto-Carlo_Tree_Search_CVPR_2021_paper.html",
        "author": "Xiu Su, Tao Huang, Yanxi Li, Shan You, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Su_Prioritized_Architecture_Sampling_With_Monto-Carlo_Tree_Search_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research, Department of Automation, Tsinghua University, Institute for Arti\ufb01cial Intelligence, Tsinghua University (THUAI), Beijing National Research Center for Information Science and Technology (BNRist); Department of Automation, Tsinghua University, Institute for Arti\ufb01cial Intelligence, Tsinghua University (THUAI), Beijing National Research Center for Information Science and Technology (BNRist); School of Computer Science, Faculty of Engineering, The University of Sydney, Australia; SenseTime Research",
        "project": "",
        "github": "https://github.com/xiusu/NAS-Bench-Macro",
        "arxiv": "2103.11922"
    },
    {
        "title": "Privacy Preserving Localization and Mapping From Uncalibrated Cameras",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Geppert_Privacy_Preserving_Localization_and_Mapping_From_Uncalibrated_Cameras_CVPR_2021_paper.html",
        "author": "Marcel Geppert, Viktor Larsson, Pablo Speciale, Johannes L. Schonberger, Marc Pollefeys",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Geppert_Privacy_Preserving_Localization_and_Mapping_From_Uncalibrated_Cameras_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich; Microsoft",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Privacy-Preserving Collaborative Learning With Automatic Transformation Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Privacy-Preserving_Collaborative_Learning_With_Automatic_Transformation_Search_CVPR_2021_paper.html",
        "author": "Wei Gao, Shangwei Guo, Tianwei Zhang, Han Qiu, Yonggang Wen, Yang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Privacy-Preserving_Collaborative_Learning_With_Automatic_Transformation_Search_CVPR_2021_paper.pdf",
        "aff": "Chongqing University; Nanyang Technological University; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2011.12505"
    },
    {
        "title": "Privacy-Preserving Image Features via Adversarial Affine Subspace Embeddings",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dusmanu_Privacy-Preserving_Image_Features_via_Adversarial_Affine_Subspace_Embeddings_CVPR_2021_paper.html",
        "author": "Mihai Dusmanu, Johannes L. Schonberger, Sudipta N. Sinha, Marc Pollefeys",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dusmanu_Privacy-Preserving_Image_Features_via_Adversarial_Affine_Subspace_Embeddings_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, ETH Z\u00fcrich; Microsoft",
        "project": "",
        "github": "",
        "arxiv": "2006.06634"
    },
    {
        "title": "ProSelfLC: Progressive Self Label Correction for Training Robust Deep Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_ProSelfLC_Progressive_Self_Label_Correction_for_Training_Robust_Deep_Neural_CVPR_2021_paper.html",
        "author": "Xinshao Wang, Yang Hua, Elyor Kodirov, David A. Clifton, Neil M. Robertson",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_ProSelfLC_Progressive_Self_Label_Correction_for_Training_Robust_Deep_Neural_CVPR_2021_paper.pdf",
        "aff": "Institute of Electronics, Communications and Information Technology, Queen\u2019s University Belfast, UK; Institute of Biomedical Engineering, University of Oxford, UK; Zenith Ai, UK",
        "project": "",
        "github": "https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021",
        "arxiv": "2005.03788"
    },
    {
        "title": "Probabilistic 3D Human Shape and Pose Estimation From Multiple Unconstrained Images in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sengupta_Probabilistic_3D_Human_Shape_and_Pose_Estimation_From_Multiple_Unconstrained_CVPR_2021_paper.html",
        "author": "Akash Sengupta, Ignas Budvytis, Roberto Cipolla",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sengupta_Probabilistic_3D_Human_Shape_and_Pose_Estimation_From_Multiple_Unconstrained_CVPR_2021_paper.pdf",
        "aff": "University of Cambridge",
        "project": "",
        "github": "",
        "arxiv": "2103.10978"
    },
    {
        "title": "Probabilistic Embeddings for Cross-Modal Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chun_Probabilistic_Embeddings_for_Cross-Modal_Retrieval_CVPR_2021_paper.html",
        "author": "Sanghyuk Chun, Seong Joon Oh, Rafael Sampaio de Rezende, Yannis Kalantidis, Diane Larlus",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chun_Probabilistic_Embeddings_for_Cross-Modal_Retrieval_CVPR_2021_paper.pdf",
        "aff": "NAVER AI Lab; NAVER LABS Europe",
        "project": "",
        "github": "https://github.com/naver-ai/pcme",
        "arxiv": "2101.05068"
    },
    {
        "title": "Probabilistic Model Distillation for Semantic Correspondence",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Probabilistic_Model_Distillation_for_Semantic_Correspondence_CVPR_2021_paper.html",
        "author": "Xin Li, Deng-Ping Fan, Fan Yang, Ao Luo, Hong Cheng, Zicheng Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Probabilistic_Model_Distillation_for_Semantic_Correspondence_CVPR_2021_paper.pdf",
        "aff": "Inception Institute of AI; Microsoft; Group 42 (G42); Megvii Technology; UESTC",
        "project": "",
        "github": "https://github.com/fanyang587/PMD",
        "arxiv": ""
    },
    {
        "title": "Probabilistic Modeling of Semantic Ambiguity for Scene Graph Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Probabilistic_Modeling_of_Semantic_Ambiguity_for_Scene_Graph_Generation_CVPR_2021_paper.html",
        "author": "Gengcong Yang, Jingyi Zhang, Yong Zhang, Baoyuan Wu, Yujiu Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Probabilistic_Modeling_of_Semantic_Ambiguity_for_Scene_Graph_Generation_CVPR_2021_paper.pdf",
        "aff": "Tencent AI Lab; Secure Computing Lab of Big Data, Shenzhen Research Institute of Big Data; Ascend Lab, Huawei Technologies; School of Data Science, The Chinese University of Hong Kong, Shenzhen; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2103.05271"
    },
    {
        "title": "Probabilistic Selective Encryption of Convolutional Neural Networks for Hierarchical Services",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Probabilistic_Selective_Encryption_of_Convolutional_Neural_Networks_for_Hierarchical_Services_CVPR_2021_paper.html",
        "author": "Jinyu Tian, Jiantao Zhou, Jia Duan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_Probabilistic_Selective_Encryption_of_Convolutional_Neural_Networks_for_Hierarchical_Services_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory of Internet of Things for Smart City, Department of Computer and Information Science, University of Macau; JD Explore, JD",
        "project": "",
        "github": "",
        "arxiv": "2105.12344"
    },
    {
        "title": "Probabilistic Tracklet Scoring and Inpainting for Multiple Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Saleh_Probabilistic_Tracklet_Scoring_and_Inpainting_for_Multiple_Object_Tracking_CVPR_2021_paper.html",
        "author": "Fatemeh Saleh, Sadegh Aliakbarian, Hamid Rezatofighi, Mathieu Salzmann, Stephen Gould",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Saleh_Probabilistic_Tracklet_Scoring_and_Inpainting_for_Multiple_Object_Tracking_CVPR_2021_paper.pdf",
        "aff": "Monash University; CVLab, EPFL, ClearSpace; Australian National University, ACRV",
        "project": "",
        "github": "",
        "arxiv": "2012.02337"
    },
    {
        "title": "Progressive Contour Regression for Arbitrary-Shape Scene Text Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Progressive_Contour_Regression_for_Arbitrary-Shape_Scene_Text_Detection_CVPR_2021_paper.html",
        "author": "Pengwen Dai, Sanyi Zhang, Hua Zhang, Xiaochun Cao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Progressive_Contour_Regression_for_Arbitrary-Shape_Scene_Text_Detection_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Information Engineering, Tianjin University, Tianjin, China; SKLOIS, Institute of Information Engineering, CAS, Beijing, China; SKLOIS, Institute of Information Engineering, CAS, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen, China; SKLOIS, Institute of Information Engineering, CAS, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "https://github.com/dpengwen/PCR",
        "arxiv": ""
    },
    {
        "title": "Progressive Domain Expansion Network for Single Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Progressive_Domain_Expansion_Network_for_Single_Domain_Generalization_CVPR_2021_paper.html",
        "author": "Lei Li, Ke Gao, Juan Cao, Ziyao Huang, Yepeng Weng, Xiaoyue Mi, Zhengze Yu, Xiaoya Li, Boyang Xia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Progressive_Domain_Expansion_Network_for_Single_Domain_Generalization_CVPR_2021_paper.pdf",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "https://github.com/lileicv/PDEN",
        "arxiv": "2103.16050"
    },
    {
        "title": "Progressive Modality Reinforcement for Human Multimodal Emotion Recognition From Unaligned Multimodal Sequences",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Progressive_Modality_Reinforcement_for_Human_Multimodal_Emotion_Recognition_From_Unaligned_CVPR_2021_paper.html",
        "author": "Fengmao Lv, Xiang Chen, Yanyong Huang, Lixin Duan, Guosheng Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lv_Progressive_Modality_Reinforcement_for_Human_Multimodal_Emotion_Recognition_From_Unaligned_CVPR_2021_paper.pdf",
        "aff": "Nanyang Technological University; Platform and Content Group, Tencent; University of Electronic Science and Technology of China; Center of Statistical Research, Southwestern University of Finance and Economics; Southwest Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Progressive Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huynh_Progressive_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Chuong Huynh, Anh Tuan Tran, Khoa Luu, Minh Hoai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huynh_Progressive_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Stony Brook University, Stony Brook, NY 11790, USA; VinAI Research, Hanoi, Vietnam; University of Arkansas, Fayetteville, AR 72701, USA; VinUniversity, Hanoi, Vietnam",
        "project": "",
        "github": "https://github.com/VinAIResearch/MagNet",
        "arxiv": "2104.03778"
    },
    {
        "title": "Progressive Semantic-Aware Style Transformation for Blind Face Restoration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Progressive_Semantic-Aware_Style_Transformation_for_Blind_Face_Restoration_CVPR_2021_paper.html",
        "author": "Chaofeng Chen, Xiaoming Li, Lingbo Yang, Xianhui Lin, Lei Zhang, Kwan-Yee K. Wong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Progressive_Semantic-Aware_Style_Transformation_for_Blind_Face_Restoration_CVPR_2021_paper.pdf",
        "aff": "Institute of Digital Media, Peking University; Department of Computing, The Hong Kong Polytechnic University; Faculty of Computing, Harbin Institute of Technology; DAMO Academy, Alibaba Group; Department of Computer Science, The University of Hong Kong",
        "project": "",
        "github": "https://github.com/chaofengc/PSFRGAN",
        "arxiv": "2009.08709"
    },
    {
        "title": "Progressive Stage-Wise Learning for Unsupervised Feature Representation Enhancement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Progressive_Stage-Wise_Learning_for_Unsupervised_Feature_Representation_Enhancement_CVPR_2021_paper.html",
        "author": "Zefan Li, Chenxi Liu, Alan Yuille, Bingbing Ni, Wenjun Zhang, Wen Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Progressive_Stage-Wise_Learning_for_Unsupervised_Feature_Representation_Enhancement_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Peking University; Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": "2106.05554"
    },
    {
        "title": "Progressive Temporal Feature Alignment Network for Video Inpainting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zou_Progressive_Temporal_Feature_Alignment_Network_for_Video_Inpainting_CVPR_2021_paper.html",
        "author": "Xueyan Zou, Linjie Yang, Ding Liu, Yong Jae Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zou_Progressive_Temporal_Feature_Alignment_Network_for_Video_Inpainting_CVPR_2021_paper.pdf",
        "aff": "University of California, Davis; ByteDance Inc.",
        "project": "",
        "github": "https://github.com/MaureenZOU/TSAM",
        "arxiv": "2104.03507"
    },
    {
        "title": "Progressive Unsupervised Learning for Visual Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Progressive_Unsupervised_Learning_for_Visual_Object_Tracking_CVPR_2021_paper.html",
        "author": "Qiangqiang Wu, Jia Wan, Antoni B. Chan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Progressive_Unsupervised_Learning_for_Visual_Object_Tracking_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, City University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Progressively Complementary Network for Fisheye Image Rectification Using Appearance Flow",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Progressively_Complementary_Network_for_Fisheye_Image_Rectification_Using_Appearance_Flow_CVPR_2021_paper.html",
        "author": "Shangrong Yang, Chunyu Lin, Kang Liao, Chunjie Zhang, Yao Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Progressively_Complementary_Network_for_Fisheye_Image_Rectification_Using_Appearance_Flow_CVPR_2021_paper.pdf",
        "aff": "Institute of Information Science, Beijing Jiaotong University, Beijing Key Laboratory of Advanced Information Science and Network, Beijing, 100044, China",
        "project": "",
        "github": "",
        "arxiv": "2103.16026"
    },
    {
        "title": "Projecting Your View Attentively: Monocular Road Scene Layout Estimation via Cross-View Transformation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Projecting_Your_View_Attentively_Monocular_Road_Scene_Layout_Estimation_via_CVPR_2021_paper.html",
        "author": "Weixiang Yang, Qi Li, Wenxi Liu, Yuanlong Yu, Yuexin Ma, Shengfeng He, Jia Pan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Projecting_Your_View_Attentively_Monocular_Road_Scene_Layout_Estimation_via_CVPR_2021_paper.pdf",
        "aff": "College of Mathematics and Computer Science, Fuzhou University; Department of Computer Science, The University of Hong Kong; ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; School of Computer Science and Engineering, South China University of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Propagate_Yourself_Exploring_Pixel-Level_Consistency_for_Unsupervised_Visual_Representation_Learning_CVPR_2021_paper.html",
        "author": "Zhenda Xie, Yutong Lin, Zheng Zhang, Yue Cao, Stephen Lin, Han Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xie_Propagate_Yourself_Exploring_Pixel-Level_Consistency_for_Unsupervised_Visual_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; Tsinghua University; Xi\u2019an Jiaotong University",
        "project": "",
        "github": "https://github.com/zdaxie/PixPro",
        "arxiv": "2011.10043"
    },
    {
        "title": "Protecting Intellectual Property of Generative Adversarial Networks From Ambiguity Attacks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ong_Protecting_Intellectual_Property_of_Generative_Adversarial_Networks_From_Ambiguity_Attacks_CVPR_2021_paper.html",
        "author": "Ding Sheng Ong, Chee Seng Chan, Kam Woh Ng, Lixin Fan, Qiang Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ong_Protecting_Intellectual_Property_of_Generative_Adversarial_Networks_From_Ambiguity_Attacks_CVPR_2021_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; University of Malaya; WeBank AI Lab",
        "project": "",
        "github": "https://github.com/dingsheng-ong/ipr-gan",
        "arxiv": "2102.04362"
    },
    {
        "title": "Prototype Augmentation and Self-Supervision for Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Prototype_Augmentation_and_Self-Supervision_for_Incremental_Learning_CVPR_2021_paper.html",
        "author": "Fei Zhu, Xu-Yao Zhang, Chuang Wang, Fei Yin, Cheng-Lin Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Prototype_Augmentation_and_Self-Supervision_for_Incremental_Learning_CVPR_2021_paper.pdf",
        "aff": "NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China; NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China; CAS Center for Excellence of Brain Science and Intelligence Technology, Beijing 100190, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Prototype Completion With Primitive Knowledge for Few-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Prototype_Completion_With_Primitive_Knowledge_for_Few-Shot_Learning_CVPR_2021_paper.html",
        "author": "Baoquan Zhang, Xutao Li, Yunming Ye, Zhichao Huang, Lisai Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Prototype_Completion_With_Primitive_Knowledge_for_Few-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "Harbin Institute of Technology, Shenzhen",
        "project": "",
        "github": "https://github.com/zhangbq-research/Prototype_Completion_for_FSL",
        "arxiv": "2009.04960"
    },
    {
        "title": "Prototype-Guided Saliency Feature Learning for Person Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Prototype-Guided_Saliency_Feature_Learning_for_Person_Search_CVPR_2021_paper.html",
        "author": "Hanjae Kim, Sunghun Joung, Ig-Jae Kim, Kwanghoon Sohn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Prototype-Guided_Saliency_Feature_Learning_for_Person_Search_CVPR_2021_paper.pdf",
        "aff": "Yonsei University; Korea Institute of Science and Technology (KIST)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Prototype-Supervised Adversarial Network for Targeted Attack of Deep Hashing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Prototype-Supervised_Adversarial_Network_for_Targeted_Attack_of_Deep_Hashing_CVPR_2021_paper.html",
        "author": "Xunguang Wang, Zheng Zhang, Baoyuan Wu, Fumin Shen, Guangming Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Prototype-Supervised_Adversarial_Network_for_Targeted_Attack_of_Deep_Hashing_CVPR_2021_paper.pdf",
        "aff": "Peng Cheng Laboratory; School of Data Science, The Chinese University of Hong Kong, Shenzhen; University of Electronic Science and Technology of China; Harbin Institute of Technology, Shenzhen",
        "project": "",
        "github": "",
        "arxiv": "2105.07553"
    },
    {
        "title": "Prototypical Cross-Domain Self-Supervised Learning for Few-Shot Unsupervised Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yue_Prototypical_Cross-Domain_Self-Supervised_Learning_for_Few-Shot_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Xiangyu Yue, Zangwei Zheng, Shanghang Zhang, Yang Gao, Trevor Darrell, Kurt Keutzer, Alberto Sangiovanni Vincentelli",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yue_Prototypical_Cross-Domain_Self-Supervised_Learning_for_Few-Shot_Unsupervised_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; Nanjing University; Tsinghua University",
        "project": "http://xyue.io/pcs-fuda",
        "github": "",
        "arxiv": "2103.16765"
    },
    {
        "title": "Prototypical Pseudo Label Denoising and Target Structure Learning for Domain Adaptive Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Prototypical_Pseudo_Label_Denoising_and_Target_Structure_Learning_for_Domain_CVPR_2021_paper.html",
        "author": "Pan Zhang, Bo Zhang, Ting Zhang, Dong Chen, Yong Wang, Fang Wen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Prototypical_Pseudo_Label_Denoising_and_Target_Structure_Learning_for_Domain_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/microsoft/ProDA",
        "arxiv": "2101.10979"
    },
    {
        "title": "Pseudo 3D Auto-Correlation Network for Real Image Denoising",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Pseudo_3D_Auto-Correlation_Network_for_Real_Image_Denoising_CVPR_2021_paper.html",
        "author": "Xiaowan Hu, Ruijun Ma, Zhihong Liu, Yuanhao Cai, Xiaole Zhao, Yulun Zhang, Haoqian Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Pseudo_3D_Auto-Correlation_Network_for_Real_Image_Denoising_CVPR_2021_paper.pdf",
        "aff": "University of Macau, China; The Shenzhen International Graduate School, Tsinghua University, China; The Shenzhen Institute of Future Media Technology, Shenzhen 518071, China; The Shenzhen International Graduate School, Tsinghua University, China; Southwest Jiaotong University, China; Northeastern University, US",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Pseudo Facial Generation With Extreme Poses for Face Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Pseudo_Facial_Generation_With_Extreme_Poses_for_Face_Recognition_CVPR_2021_paper.html",
        "author": "Guoli Wang, Jiaqi Ma, Qian Zhang, Jiwen Lu, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Pseudo_Facial_Generation_With_Extreme_Poses_for_Face_Recognition_CVPR_2021_paper.pdf",
        "aff": "Wuhan University; Horizon Robotics; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Pulsar: Efficient Sphere-Based Neural Rendering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lassner_Pulsar_Efficient_Sphere-Based_Neural_Rendering_CVPR_2021_paper.html",
        "author": "Christoph Lassner, Michael Zollhofer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lassner_Pulsar_Efficient_Sphere-Based_Neural_Rendering_CVPR_2021_paper.pdf",
        "aff": "Facebook Reality Labs",
        "project": "",
        "github": "",
        "arxiv": "2004.07484"
    },
    {
        "title": "Pushing It Out of the Way: Interactive Visual Navigation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zeng_Pushing_It_Out_of_the_Way_Interactive_Visual_Navigation_CVPR_2021_paper.html",
        "author": "Kuo-Hao Zeng, Luca Weihs, Ali Farhadi, Roozbeh Mottaghi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zeng_Pushing_It_Out_of_the_Way_Interactive_Visual_Navigation_CVPR_2021_paper.pdf",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; PRIOR @ Allen Institute for AI",
        "project": "",
        "github": "github.com/KuoHaoZeng/Interactive_Visual_Navigation",
        "arxiv": "2104.14040"
    },
    {
        "title": "QAIR: Practical Query-Efficient Black-Box Attacks for Image Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_QAIR_Practical_Query-Efficient_Black-Box_Attacks_for_Image_Retrieval_CVPR_2021_paper.html",
        "author": "Xiaodan Li, Jinfeng Li, Yuefeng Chen, Shaokai Ye, Yuan He, Shuhui Wang, Hang Su, Hui Xue",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_QAIR_Practical_Query-Efficient_Black-Box_Attacks_for_Image_Retrieval_CVPR_2021_paper.pdf",
        "aff": "EPFL; Alibaba Group; Inst. of Comput. Tech., CAS, China; Institute for AI, THBI Lab, Tsinghua University, Beijing, 100084, China",
        "project": "",
        "github": "",
        "arxiv": "2103.02927"
    },
    {
        "title": "QPIC: Query-Based Pairwise Human-Object Interaction Detection With Image-Wide Contextual Information",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tamura_QPIC_Query-Based_Pairwise_Human-Object_Interaction_Detection_With_Image-Wide_Contextual_Information_CVPR_2021_paper.html",
        "author": "Masato Tamura, Hiroki Ohashi, Tomoaki Yoshinaga",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tamura_QPIC_Query-Based_Pairwise_Human-Object_Interaction_Detection_With_Image-Wide_Contextual_Information_CVPR_2021_paper.pdf",
        "aff": "Center for Technology Innovation - Artificial Intelligence, Hitachi, Ltd.; Lumada Data Science Lab., Hitachi, Ltd.",
        "project": "",
        "github": "https://github.com/hitachi-rd-cv/qpic",
        "arxiv": "2103.05399"
    },
    {
        "title": "QPP: Real-Time Quantization Parameter Prediction for Deep Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kryzhanovskiy_QPP_Real-Time_Quantization_Parameter_Prediction_for_Deep_Neural_Networks_CVPR_2021_paper.html",
        "author": "Vladimir Kryzhanovskiy, Gleb Balitskiy, Nikolay Kozyrskiy, Aleksandr Zuruev",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kryzhanovskiy_QPP_Real-Time_Quantization_Parameter_Prediction_for_Deep_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; Novosibirsk State University; Skolkovo Institute of Science and Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Quality-Agnostic Image Recognition via Invertible Decoder",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Quality-Agnostic_Image_Recognition_via_Invertible_Decoder_CVPR_2021_paper.html",
        "author": "Insoo Kim, Seungju Han, Ji-won Baek, Seong-Jin Park, Jae-Joon Han, Jinwoo Shin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Quality-Agnostic_Image_Recognition_via_Invertible_Decoder_CVPR_2021_paper.pdf",
        "aff": "Samsung Advanced Institute of Technology (SAIT), South Korea; Korea Advanced Institute of Science and Technology (KAIST), South Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Quantifying Explainers of Graph Neural Networks in Computational Pathology",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jaume_Quantifying_Explainers_of_Graph_Neural_Networks_in_Computational_Pathology_CVPR_2021_paper.html",
        "author": "Guillaume Jaume, Pushpak Pati, Behzad Bozorgtabar, Antonio Foncubierta, Anna Maria Anniciello, Florinda Feroce, Tilman Rau, Jean-Philippe Thiran, Maria Gabrani, Orcun Goksel",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jaume_Quantifying_Explainers_of_Graph_Neural_Networks_in_Computational_Pathology_CVPR_2021_paper.pdf",
        "aff": "University of Bern; IBM Research Zurich, EPFL Lausanne; IBM Research Zurich, ETH Zurich; ETH Zurich, Uppsala University; Fondazione Pascale; EPFL Lausanne; IBM Research Zurich",
        "project": "",
        "github": "https://github.com/histocartography/patho-quant-explainer",
        "arxiv": "2011.12646"
    },
    {
        "title": "Quantum Permutation Synchronization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Birdal_Quantum_Permutation_Synchronization_CVPR_2021_paper.html",
        "author": "Tolga Birdal, Vladislav Golyanik, Christian Theobalt, Leonidas J. Guibas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Birdal_Quantum_Permutation_Synchronization_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Informatics, SIC; Stanford University",
        "project": "",
        "github": "",
        "arxiv": "2101.07755"
    },
    {
        "title": "Quasi-Dense Similarity Learning for Multiple Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pang_Quasi-Dense_Similarity_Learning_for_Multiple_Object_Tracking_CVPR_2021_paper.html",
        "author": "Jiangmiao Pang, Linlu Qiu, Xia Li, Haofeng Chen, Qi Li, Trevor Darrell, Fisher Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pang_Quasi-Dense_Similarity_Learning_for_Multiple_Object_Tracking_CVPR_2021_paper.pdf",
        "aff": "Georgia Institute of Technology; ETH Z\u00fcrich; UC Berkeley; Stanford University; Zhejiang University",
        "project": "",
        "github": "https://github.com/SysCV/qdtrack",
        "arxiv": "2006.06664"
    },
    {
        "title": "RAFT-3D: Scene Flow Using Rigid-Motion Embeddings",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Teed_RAFT-3D_Scene_Flow_Using_Rigid-Motion_Embeddings_CVPR_2021_paper.html",
        "author": "Zachary Teed, Jia Deng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Teed_RAFT-3D_Scene_Flow_Using_Rigid-Motion_Embeddings_CVPR_2021_paper.pdf",
        "aff": "Princeton University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RGB-D Local Implicit Function for Depth Completion of Transparent Objects",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_RGB-D_Local_Implicit_Function_for_Depth_Completion_of_Transparent_Objects_CVPR_2021_paper.html",
        "author": "Luyang Zhu, Arsalan Mousavian, Yu Xiang, Hammad Mazhar, Jozef van Eenbergen, Shoubhik Debnath, Dieter Fox",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_RGB-D_Local_Implicit_Function_for_Depth_Completion_of_Transparent_Objects_CVPR_2021_paper.pdf",
        "aff": "University of Washington, NVIDIA; NVIDIA",
        "project": "https://research.nvidia.com/publication/2021-03_RGB-D-Local-Implicit",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RPN Prototype Alignment for Domain Adaptive Object Detector",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_RPN_Prototype_Alignment_for_Domain_Adaptive_Object_Detector_CVPR_2021_paper.html",
        "author": "Yixin Zhang, Zilei Wang, Yushi Mao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_RPN_Prototype_Alignment_for_Domain_Adaptive_Object_Detector_CVPR_2021_paper.pdf",
        "aff": "Department of Automation, University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RPSRNet: End-to-End Trainable Rigid Point Set Registration Network Using Barnes-Hut 2D-Tree Representation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ali_RPSRNet_End-to-End_Trainable_Rigid_Point_Set_Registration_Network_Using_Barnes-Hut_CVPR_2021_paper.html",
        "author": "Sk Aziz Ali, Kerem Kahraman, Gerd Reis, Didier Stricker",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ali_RPSRNet_End-to-End_Trainable_Rigid_Point_Set_Registration_Network_Using_Barnes-Hut_CVPR_2021_paper.pdf",
        "aff": "German Research Center for Arti\ufb01cial Intelligence (DFKI GmbH), Kaiserslautern; TU Kaiserslautern, German Research Center for Arti\ufb01cial Intelligence (DFKI GmbH); TU Kaiserslautern",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RSG: A Simple but Effective Module for Learning Imbalanced Datasets",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_RSG_A_Simple_but_Effective_Module_for_Learning_Imbalanced_Datasets_CVPR_2021_paper.html",
        "author": "Jianfeng Wang, Thomas Lukasiewicz, Xiaolin Hu, Jianfei Cai, Zhenghua Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_RSG_A_Simple_but_Effective_Module_for_Learning_Imbalanced_Datasets_CVPR_2021_paper.pdf",
        "aff": "Hebei University of Technology; Monash University; University of Oxford; Tsinghua University",
        "project": "",
        "github": "https://github.com/Jianf-Wang/RSG",
        "arxiv": "2106.09859"
    },
    {
        "title": "RSN: Range Sparse Net for Efficient, Accurate LiDAR 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_RSN_Range_Sparse_Net_for_Efficient_Accurate_LiDAR_3D_Object_CVPR_2021_paper.html",
        "author": "Pei Sun, Weiyue Wang, Yuning Chai, Gamaleldin Elsayed, Alex Bewley, Xiao Zhang, Cristian Sminchisescu, Dragomir Anguelov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_RSN_Range_Sparse_Net_for_Efficient_Accurate_LiDAR_3D_Object_CVPR_2021_paper.pdf",
        "aff": "Google; Waymo LLC",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RSTNet: Captioning With Adaptive Attention on Visual and Non-Visual Words",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_RSTNet_Captioning_With_Adaptive_Attention_on_Visual_and_Non-Visual_Words_CVPR_2021_paper.html",
        "author": "Xuying Zhang, Xiaoshuai Sun, Yunpeng Luo, Jiayi Ji, Yiyi Zhou, Yongjian Wu, Feiyue Huang, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_RSTNet_Captioning_With_Adaptive_Attention_on_Visual_and_Non-Visual_Words_CVPR_2021_paper.pdf",
        "aff": "Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China; Institute of Arti\ufb01cial Intelligence, Xiamen University",
        "project": "",
        "github": "https://github.com/zhangxuying1004/RSTNet",
        "arxiv": ""
    },
    {
        "title": "RaScaNet: Learning Tiny Models by Raster-Scanning Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yoo_RaScaNet_Learning_Tiny_Models_by_Raster-Scanning_Images_CVPR_2021_paper.html",
        "author": "Jaehyoung Yoo, Dongwook Lee, Changyong Son, Sangil Jung, ByungIn Yoo, Changkyu Choi, Jae-Joon Han, Bohyung Han",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yoo_RaScaNet_Learning_Tiny_Models_by_Raster-Scanning_Images_CVPR_2021_paper.pdf",
        "aff": "Samsung Advanced Institute of Technology (SAIT), South Korea; Computer Vision Lab., Seoul National University, South Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Radar-Camera Pixel Depth Association for Depth Completion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Long_Radar-Camera_Pixel_Depth_Association_for_Depth_Completion_CVPR_2021_paper.html",
        "author": "Yunfei Long, Daniel Morris, Xiaoming Liu, Marcos Castro, Punarjay Chakravarty, Praveen Narayanan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Long_Radar-Camera_Pixel_Depth_Association_for_Depth_Completion_CVPR_2021_paper.pdf",
        "aff": "Ford Motor Company; Michigan State University",
        "project": "",
        "github": "https://github.com/longyunf/rc-pda",
        "arxiv": "2106.02778"
    },
    {
        "title": "Railroad Is Not a Train: Saliency As Pseudo-Pixel Supervision for Weakly Supervised Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Railroad_Is_Not_a_Train_Saliency_As_Pseudo-Pixel_Supervision_for_CVPR_2021_paper.html",
        "author": "Seungho Lee, Minhyun Lee, Jongwuk Lee, Hyunjung Shim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Railroad_Is_Not_a_Train_Saliency_As_Pseudo-Pixel_Supervision_for_CVPR_2021_paper.pdf",
        "aff": "Yonsei University; Sungkyunkwan University",
        "project": "",
        "github": "https://github.com/halbielee/EPS",
        "arxiv": "2105.08965"
    },
    {
        "title": "Rainbow Memory: Continual Learning With a Memory of Diverse Samples",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bang_Rainbow_Memory_Continual_Learning_With_a_Memory_of_Diverse_Samples_CVPR_2021_paper.html",
        "author": "Jihwan Bang, Heesu Kim, YoungJoon Yoo, Jung-Woo Ha, Jonghyun Choi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bang_Rainbow_Memory_Continual_Learning_With_a_Memory_of_Diverse_Samples_CVPR_2021_paper.pdf",
        "aff": "NAVER CLOVA, NAVER AI Lab; Search Solutions, Inc; GIST",
        "project": "",
        "github": "https://github.com/clovaai/rainbow-memory",
        "arxiv": "2103.17230"
    },
    {
        "title": "RangeIoUDet: Range Image Based Real-Time 3D Object Detector Optimized by Intersection Over Union",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liang_RangeIoUDet_Range_Image_Based_Real-Time_3D_Object_Detector_Optimized_by_CVPR_2021_paper.html",
        "author": "Zhidong Liang, Zehan Zhang, Ming Zhang, Xian Zhao, Shiliang Pu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liang_RangeIoUDet_Range_Image_Based_Real-Time_3D_Object_Detector_Optimized_by_CVPR_2021_paper.pdf",
        "aff": "Hikvision Research Institute",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Rank-One Prior: Toward Real-Time Scene Recovery",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Rank-One_Prior_Toward_Real-Time_Scene_Recovery_CVPR_2021_paper.html",
        "author": "Jun Liu, Wen Liu, Jianing Sun, Tieyong Zeng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Rank-One_Prior_Toward_Real-Time_Scene_Recovery_CVPR_2021_paper.pdf",
        "aff": "Department of Mathematics, The Chinese University of Hong Kong, Shatin, NT, Hong Kong; School of Mathematics and Statistics, Northeast Normal University, Changchun, China; School of Navigation, Wuhan University of Technology, Wuhan, China",
        "project": "",
        "github": "",
        "arxiv": "2103.17126"
    },
    {
        "title": "RankDetNet: Delving Into Ranking Constraints for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_RankDetNet_Delving_Into_Ranking_Constraints_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Ji Liu, Dong Li, Rongzhang Zheng, Lu Tian, Yi Shan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_RankDetNet_Delving_Into_Ranking_Constraints_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Xilinx Inc., Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Ranking Neural Checkpoints",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Ranking_Neural_Checkpoints_CVPR_2021_paper.html",
        "author": "Yandong Li, Xuhui Jia, Ruoxin Sang, Yukun Zhu, Bradley Green, Liqiang Wang, Boqing Gong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Ranking_Neural_Checkpoints_CVPR_2021_paper.pdf",
        "aff": "Google; University of Central Florida",
        "project": "",
        "github": "",
        "arxiv": "2011.11200"
    },
    {
        "title": "Re-Labeling ImageNet: From Single to Multi-Labels, From Global to Localized Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yun_Re-Labeling_ImageNet_From_Single_to_Multi-Labels_From_Global_to_Localized_CVPR_2021_paper.html",
        "author": "Sangdoo Yun, Seong Joon Oh, Byeongho Heo, Dongyoon Han, Junsuk Choe, Sanghyuk Chun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yun_Re-Labeling_ImageNet_From_Single_to_Multi-Labels_From_Global_to_Localized_CVPR_2021_paper.pdf",
        "aff": "NAVER AI Lab",
        "project": "",
        "github": "https://github.com/naver-ai/relabel_imagenet",
        "arxiv": "2101.05022"
    },
    {
        "title": "ReAgent: Point Cloud Registration Using Imitation and Reinforcement Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bauer_ReAgent_Point_Cloud_Registration_Using_Imitation_and_Reinforcement_Learning_CVPR_2021_paper.html",
        "author": "Dominik Bauer, Timothy Patten, Markus Vincze",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bauer_ReAgent_Point_Cloud_Registration_Using_Imitation_and_Reinforcement_Learning_CVPR_2021_paper.pdf",
        "aff": "TU Wien, Vienna, Austria",
        "project": "",
        "github": "github.com/dornik/reagent",
        "arxiv": "2103.15231"
    },
    {
        "title": "ReDet: A Rotation-Equivariant Detector for Aerial Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Han_ReDet_A_Rotation-Equivariant_Detector_for_Aerial_Object_Detection_CVPR_2021_paper.html",
        "author": "Jiaming Han, Jian Ding, Nan Xue, Gui-Song Xia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Han_ReDet_A_Rotation-Equivariant_Detector_for_Aerial_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Wuhan University, Wuhan, China",
        "project": "",
        "github": "https://github.com/csuhan/ReDet",
        "arxiv": "2103.07733"
    },
    {
        "title": "ReMix: Towards Image-to-Image Translation With Limited Data",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cao_ReMix_Towards_Image-to-Image_Translation_With_Limited_Data_CVPR_2021_paper.html",
        "author": "Jie Cao, Luanxuan Hou, Ming-Hsuan Yang, Ran He, Zhenan Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cao_ReMix_Towards_Image-to-Image_Translation_With_Limited_Data_CVPR_2021_paper.pdf",
        "aff": "University of California at Merced, Google Research, Yonsei University; NLPR, CRIPAC & CEBSIT, CASIA, AIR, UCAS",
        "project": "",
        "github": "",
        "arxiv": "2103.16835"
    },
    {
        "title": "ReNAS: Relativistic Evaluation of Neural Architecture Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_ReNAS_Relativistic_Evaluation_of_Neural_Architecture_Search_CVPR_2021_paper.html",
        "author": "Yixing Xu, Yunhe Wang, Kai Han, Yehui Tang, Shangling Jui, Chunjing Xu, Chang Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_ReNAS_Relativistic_Evaluation_of_Neural_Architecture_Search_CVPR_2021_paper.pdf",
        "aff": "Peking University; Huawei Technologies; Noah\u2019s Ark Lab, Huawei Technologies; The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": "1910.01523"
    },
    {
        "title": "Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fang_Read_Like_Humans_Autonomous_Bidirectional_and_Iterative_Language_Modeling_for_CVPR_2021_paper.html",
        "author": "Shancheng Fang, Hongtao Xie, Yuxin Wang, Zhendong Mao, Yongdong Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fang_Read_Like_Humans_Autonomous_Bidirectional_and_Iterative_Language_Modeling_for_CVPR_2021_paper.pdf",
        "aff": "University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/FangShancheng/ABINet",
        "arxiv": "2103.06495"
    },
    {
        "title": "Read and Attend: Temporal Localisation in Sign Language Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Varol_Read_and_Attend_Temporal_Localisation_in_Sign_Language_Videos_CVPR_2021_paper.html",
        "author": "Gul Varol, Liliane Momeni, Samuel Albanie, Triantafyllos Afouras, Andrew Zisserman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Varol_Read_and_Attend_Temporal_Localisation_in_Sign_Language_Videos_CVPR_2021_paper.pdf",
        "aff": "Visual Geometry Group, University of Oxford, UK and LIGM, \u00b4Ecole des Ponts, Univ Gustave Eiffel, CNRS, France; Visual Geometry Group, University of Oxford, UK",
        "project": "https://www.robots.ox.ac.uk/~vgg/research/bslattend/",
        "github": "",
        "arxiv": "2103.16481"
    },
    {
        "title": "Real-Time High-Resolution Background Matting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Real-Time_High-Resolution_Background_Matting_CVPR_2021_paper.html",
        "author": "Shanchuan Lin, Andrey Ryabtsev, Soumyadip Sengupta, Brian L. Curless, Steven M. Seitz, Ira Kemelmacher-Shlizerman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Real-Time_High-Resolution_Background_Matting_CVPR_2021_paper.pdf",
        "aff": "University of Washington",
        "project": "",
        "github": "",
        "arxiv": "2012.07810"
    },
    {
        "title": "Real-Time Selfie Video Stabilization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Real-Time_Selfie_Video_Stabilization_CVPR_2021_paper.html",
        "author": "Jiyang Yu, Ravi Ramamoorthi, Keli Cheng, Michel Sarkis, Ning Bi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_Real-Time_Selfie_Video_Stabilization_CVPR_2021_paper.pdf",
        "aff": "University of California, San Diego; University of California, San Diego; JD AI Research, Mountain View; Qualcomm Technologies Inc.",
        "project": "",
        "github": "https://github.com/jiy173/selfievideostabilization",
        "arxiv": "2009.02007"
    },
    {
        "title": "Real-Time Sphere Sweeping Stereo From Multiview Fisheye Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Meuleman_Real-Time_Sphere_Sweeping_Stereo_From_Multiview_Fisheye_Images_CVPR_2021_paper.html",
        "author": "Andreas Meuleman, Hyeonjoong Jang, Daniel S. Jeon, Min H. Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Meuleman_Real-Time_Sphere_Sweeping_Stereo_From_Multiview_Fisheye_Images_CVPR_2021_paper.pdf",
        "aff": "KAIST",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Reciprocal Landmark Detection and Tracking With Extremely Few Annotations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Reciprocal_Landmark_Detection_and_Tracking_With_Extremely_Few_Annotations_CVPR_2021_paper.html",
        "author": "Jianzhe Lin, Ghazal Sahebzamani, Christina Luong, Fatemeh Taheri Dezaki, Mohammad Jafari, Purang Abolmaesumi, Teresa Tsang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Reciprocal_Landmark_Detection_and_Tracking_With_Extremely_Few_Annotations_CVPR_2021_paper.pdf",
        "aff": "Vancouver General Hospital, Canada; The Division of Cardiology, The University of British Columbia; Department of Electrical and Computer Engineering, The University of British Columbia, Canada",
        "project": "",
        "github": "",
        "arxiv": "2101.11224"
    },
    {
        "title": "Reciprocal Transformations for Unsupervised Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ren_Reciprocal_Transformations_for_Unsupervised_Video_Object_Segmentation_CVPR_2021_paper.html",
        "author": "Sucheng Ren, Wenxi Liu, Yongtuo Liu, Haoxin Chen, Guoqiang Han, Shengfeng He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ren_Reciprocal_Transformations_for_Unsupervised_Video_Object_Segmentation_CVPR_2021_paper.pdf",
        "aff": "College of Mathematics and Computer Science, Fuzhou University; School of Computer Science and Engineering, South China University of Technology",
        "project": "",
        "github": "https://github.com/OliverRensu/RTNet",
        "arxiv": ""
    },
    {
        "title": "Recognizing Actions in Videos From Unseen Viewpoints",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Piergiovanni_Recognizing_Actions_in_Videos_From_Unseen_Viewpoints_CVPR_2021_paper.html",
        "author": "AJ Piergiovanni, Michael S. Ryoo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Piergiovanni_Recognizing_Actions_in_Videos_From_Unseen_Viewpoints_CVPR_2021_paper.pdf",
        "aff": "Stony Brook University; Indiana University",
        "project": "",
        "github": "",
        "arxiv": "2103.16516"
    },
    {
        "title": "Reconsidering Representation Alignment for Multi-View Clustering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Trosten_Reconsidering_Representation_Alignment_for_Multi-View_Clustering_CVPR_2021_paper.html",
        "author": "Daniel J. Trosten, Sigurd Lokse, Robert Jenssen, Michael Kampffmeyer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Trosten_Reconsidering_Representation_Alignment_for_Multi-View_Clustering_CVPR_2021_paper.pdf",
        "aff": "Department of Physics and Technology, UiT The Arctic University of Norway",
        "project": "",
        "github": "https://github.com/DanielTrosten/mvc",
        "arxiv": "2103.07738"
    },
    {
        "title": "Reconstructing 3D Human Pose by Watching Humans in the Mirror",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fang_Reconstructing_3D_Human_Pose_by_Watching_Humans_in_the_Mirror_CVPR_2021_paper.html",
        "author": "Qi Fang, Qing Shuai, Junting Dong, Hujun Bao, Xiaowei Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fang_Reconstructing_3D_Human_Pose_by_Watching_Humans_in_the_Mirror_CVPR_2021_paper.pdf",
        "aff": "State Key Lab of CAD&CG, Zhejiang University",
        "project": "",
        "github": "https://zju3dv.github.io/Mirrored-Human/",
        "arxiv": "2104.00340"
    },
    {
        "title": "Recorrupted-to-Recorrupted: Unsupervised Deep Learning for Image Denoising",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pang_Recorrupted-to-Recorrupted_Unsupervised_Deep_Learning_for_Image_Denoising_CVPR_2021_paper.html",
        "author": "Tongyao Pang, Huan Zheng, Yuhui Quan, Hui Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pang_Recorrupted-to-Recorrupted_Unsupervised_Deep_Learning_for_Image_Denoising_CVPR_2021_paper.pdf",
        "aff": "Department of Mathematics, National University of Singapore, 119076, Singapore; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Rectification-Based Knowledge Retention for Continual Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Singh_Rectification-Based_Knowledge_Retention_for_Continual_Learning_CVPR_2021_paper.html",
        "author": "Pravendra Singh, Pratik Mazumder, Piyush Rai, Vinay P. Namboodiri",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Singh_Rectification-Based_Knowledge_Retention_for_Continual_Learning_CVPR_2021_paper.pdf",
        "aff": "University of Bath, United Kingdom; IIT Kanpur, India; Independent Researcher, India",
        "project": "",
        "github": "",
        "arxiv": "2103.16597"
    },
    {
        "title": "Recurrent Multi-View Alignment Network for Unsupervised Surface Registration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Recurrent_Multi-View_Alignment_Network_for_Unsupervised_Surface_Registration_CVPR_2021_paper.html",
        "author": "Wanquan Feng, Juyong Zhang, Hongrui Cai, Haofei Xu, Junhui Hou, Hujun Bao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Recurrent_Multi-View_Alignment_Network_for_Unsupervised_Surface_Registration_CVPR_2021_paper.pdf",
        "aff": "City University of Hong Kong; Zhejiang University; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2011.12104"
    },
    {
        "title": "Reducing Domain Gap by Reducing Style Bias",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nam_Reducing_Domain_Gap_by_Reducing_Style_Bias_CVPR_2021_paper.html",
        "author": "Hyeonseob Nam, HyunJae Lee, Jongchan Park, Wonjun Yoon, Donggeun Yoo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nam_Reducing_Domain_Gap_by_Reducing_Style_Bias_CVPR_2021_paper.pdf",
        "aff": "Lunit Inc.",
        "project": "",
        "github": "https://github.com/hyeonseobnam/sagnet",
        "arxiv": "1910.11645"
    },
    {
        "title": "Refer-It-in-RGBD: A Bottom-Up Approach for 3D Visual Grounding in RGBD Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Refer-It-in-RGBD_A_Bottom-Up_Approach_for_3D_Visual_Grounding_in_RGBD_CVPR_2021_paper.html",
        "author": "Haolin Liu, Anran Lin, Xiaoguang Han, Lei Yang, Yizhou Yu, Shuguang Cui",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Refer-It-in-RGBD_A_Bottom-Up_Approach_for_3D_Visual_Grounding_in_RGBD_CVPR_2021_paper.pdf",
        "aff": "Deepwise AI Lab; The University of Hong Kong; SRIBD, CUHK-Shenzhen\u2020; FNii, CUHK-Shenzhen\u2021; The University of Hong Kong; SRIBD, CUHK-Shenzhen\u2020",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Refine Myself by Teaching Myself: Feature Refinement via Self-Knowledge Distillation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ji_Refine_Myself_by_Teaching_Myself_Feature_Refinement_via_Self-Knowledge_Distillation_CVPR_2021_paper.html",
        "author": "Mingi Ji, Seungjae Shin, Seunghyun Hwang, Gibeom Park, Il-Chul Moon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Refine_Myself_by_Teaching_Myself_Feature_Refinement_via_Self-Knowledge_Distillation_CVPR_2021_paper.pdf",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST); Korea Advanced Institute of Science and Technology (KAIST), Summary.AI; Looko Inc.",
        "project": "",
        "github": "https://github.com/MingiJi/FRSKD",
        "arxiv": "2103.08273"
    },
    {
        "title": "RefineMask: Towards High-Quality Instance Segmentation With Fine-Grained Features",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_RefineMask_Towards_High-Quality_Instance_Segmentation_With_Fine-Grained_Features_CVPR_2021_paper.html",
        "author": "Gang Zhang, Xin Lu, Jingru Tan, Jianmin Li, Zhaoxiang Zhang, Quanquan Li, Xiaolin Hu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_RefineMask_Towards_High-Quality_Instance_Segmentation_With_Fine-Grained_Features_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory of Intelligent Technology and Systems, Institute for AI, BNRist, Department of Computer Science and Technology, Tsinghua University; Tongji University; SenseTime Research; Institute of Automation, CAS & UCAS",
        "project": "",
        "github": "https://github.com/zhanggang001/Re\ufb01neMask",
        "arxiv": "2104.08569"
    },
    {
        "title": "Refining Pseudo Labels With Clustering Consensus Over Generations for Unsupervised Object Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Refining_Pseudo_Labels_With_Clustering_Consensus_Over_Generations_for_Unsupervised_CVPR_2021_paper.html",
        "author": "Xiao Zhang, Yixiao Ge, Yu Qiao, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Refining_Pseudo_Labels_With_Clustering_Consensus_Over_Generations_for_Unsupervised_CVPR_2021_paper.pdf",
        "aff": "School of CST, Xidian University; SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": "2106.06133"
    },
    {
        "title": "Reformulating HOI Detection As Adaptive Set Prediction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Reformulating_HOI_Detection_As_Adaptive_Set_Prediction_CVPR_2021_paper.html",
        "author": "Mingfei Chen, Yue Liao, Si Liu, Zhiyuan Chen, Fei Wang, Chen Qian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Reformulating_HOI_Detection_As_Adaptive_Set_Prediction_CVPR_2021_paper.pdf",
        "aff": "Reformulating HOI Detection as Adaptive Set Prediction\nMingfei Chen1,3*Yue Liao2*Si Liu2\u2020Zhiyuan Chen3Fei Wang3Chen Qian3\n1Huazhong University of Science and Technology\n2Institute of Arti\ufb01cial Intelligence, Beihang University3SenseTime Research\nAbstract\nDetermining which image regions to concentrate is crit-\nical for Human-Object Interaction (HOI) detection. Con-\nventional HOI detectors focus on either detected human and\nobject pairs or pre-de\ufb01ned interaction locations, which lim-\nits learning of the effective features. In this paper, we refor-\nmulate HOI detection as an adaptive set prediction prob-\nlem, with this novel formulation, we propose an Adaptive\nSet-based one-stage framework (AS-Net) with parallel in-\nstance and interaction branches. To attain this, we map a\ntrainable interaction query set to an interaction prediction\nset with transformer. Each query adaptively aggregates the\ninteraction-relevant features from global contexts through\nmulti-head co-attention. Besides, the training process is\nsupervised adaptively by matching each ground-truth with\nthe interaction prediction. Furthermore, we design an ef-\nfective instance-aware attention module to introduce in-\nstructive features from the instance branch into the inter-\naction branch. Our method outperforms previous state-\nof-the-art methods without any extra human pose and lan-\nguage features on three challenging HOI detection datasets.\nEspecially, we achieve over 31% relative improvement on\na large scale HICO-DET dataset. Code is available at\nhttps://github.com/yoyomimi/AS-Net .\n1. Introduction\nHuman-Object Interaction (HOI) detection aims to iden-\ntify HOI triplets <human, verb, object >from a given im-\nage, it is an important step toward the high-level semantic\nunderstanding [ 8,26,46,18,17,19,6,7,44]. Conven-\ntional HOI methods can be divided into two-stage meth-\nods [ 38,3,10,25,24,14,9,35] and one-stage meth-\nods [ 20,27]. Most two-stage methods detect instances (hu-\nmans and objects), and match the detected humans and ob-\njects one by one to form pair-wise proposals in the \ufb01rst\nstage. Next, in the second stage, such methods infer the\ninteractions based on the features of cropped human-object\n*Equal contribution\n\u2020Corresponding author (liusi@buaa.edu.cn)(a) Union boxes: verb \"direct\" in yellow, \"drive\" \nin purple, matched anchor in red.\n(c) Our adaptive set prediction method: verb \"drive\" in purple, \"direct\" in yellow. Interaction vectors \npoint from human centers to object centers. The features aggregated by queries are visual ized at left.Adaptive Feature Aggregation Adaptive Set-based Ground-truth Matching\ndrive\ndirect\nAggregated Features Ground- truth\n\u2026\u2026(b) Interaction midpoints: verb \"direct\" in yellow, \n\"drive\" in purple, matched point in red.\nInteraction \nQuery SetInteraction \nPrediction Set\nFigure 1. Both the anchor-based (a) and point-based (b) one-stage\nmethods infer two different interactions \u201cdrive\u201d and \u201cdirect\u201d are at\nsimilar location and concentrate on the similar features. Our set\nprediction method (c) maps an interaction query set to an inter-\naction prediction set by an interaction decoder. Then, interaction\npredictions are adaptively matched with ground-truth. To attain\nthis, we \ufb01rst train a set of learnable embeddings as an interaction\nquery set. Next, each interaction query adaptively aggregates the\ninteraction-relevant features by co-attention. Finally, we match\neach ground-truth with prediction for adaptive supervision. This\nmechanism empowers our method to accurately predict two inter-\nactions for \u201cdrive\u201d and \u201cdirect\u201d. Best viewed in color.\npair-wise proposals. Two-stage methods have made great\nprogress in HOI detection, however, their ef\ufb01ciency and ef-\nfectiveness are limited by their serial architectures. With the\ndevelopment of one-stage object detectors, one-stage HOI\ndetectors [ 20,27] have raised a new fashion. Existing one-\nstage HOI detectors formulate HOI detection as a parallel\ndetection problem, which detects the HOI triplets from an\nimage directly. One-stage methods have delivered great im-\nprovements in both ef\ufb01ciency and effectiveness.\nDetermining which regions to concentrate on is criti-\ncal and challenging for HOI detectors. To obtain essen-\ntial features for interaction prediction, conventional two-\n9004\n",
        "project": "",
        "github": "",
        "arxiv": "2103.05983"
    },
    {
        "title": "Region-Aware Adaptive Instance Normalization for Image Harmonization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ling_Region-Aware_Adaptive_Instance_Normalization_for_Image_Harmonization_CVPR_2021_paper.html",
        "author": "Jun Ling, Han Xue, Li Song, Rong Xie, Xiao Gu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ling_Region-Aware_Adaptive_Instance_Normalization_for_Image_Harmonization_CVPR_2021_paper.pdf",
        "aff": "Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, China; Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, China; MOE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China",
        "project": "",
        "github": "https://github.com/junleen/RainNet",
        "arxiv": "2106.02853"
    },
    {
        "title": "Regressive Domain Adaptation for Unsupervised Keypoint Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Regressive_Domain_Adaptation_for_Unsupervised_Keypoint_Detection_CVPR_2021_paper.html",
        "author": "Junguang Jiang, Yifei Ji, Ximei Wang, Yufeng Liu, Jianmin Wang, Mingsheng Long",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jiang_Regressive_Domain_Adaptation_for_Unsupervised_Keypoint_Detection_CVPR_2021_paper.pdf",
        "aff": "School of Software, BNRist, Tsinghua University, China; Y-tech, Kuaishou Technology",
        "project": "",
        "github": "",
        "arxiv": "2103.06175"
    },
    {
        "title": "Regularization Strategy for Point Cloud via Rigidly Mixed Sample",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.html",
        "author": "Dogyoon Lee, Jaeha Lee, Junhyeop Lee, Hyeongmin Lee, Minhyeok Lee, Sungmin Woo, Sangyoun Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf",
        "aff": "Yonsei University",
        "project": "",
        "github": "https://github.com/dogyoonlee/RSMix",
        "arxiv": "2102.01929"
    },
    {
        "title": "Regularizing Generative Adversarial Networks Under Limited Data",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tseng_Regularizing_Generative_Adversarial_Networks_Under_Limited_Data_CVPR_2021_paper.html",
        "author": "Hung-Yu Tseng, Lu Jiang, Ce Liu, Ming-Hsuan Yang, Weilong Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tseng_Regularizing_Generative_Adversarial_Networks_Under_Limited_Data_CVPR_2021_paper.pdf",
        "aff": "Google Research, University of California, Merced; Google Research, University of California, Merced, Yonsei University; Waymo; Google Research",
        "project": "",
        "github": "https://github.com/google/lecam-gan",
        "arxiv": "2104.03310"
    },
    {
        "title": "Regularizing Neural Networks via Adversarial Model Perturbation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Regularizing_Neural_Networks_via_Adversarial_Model_Perturbation_CVPR_2021_paper.html",
        "author": "Yaowei Zheng, Richong Zhang, Yongyi Mao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Regularizing_Neural_Networks_via_Adversarial_Model_Perturbation_CVPR_2021_paper.pdf",
        "aff": "School of EECS, University of Ottawa, Canada; BDBC and SKLSDE, Beihang University, China",
        "project": "",
        "github": "https://github.com/hiyouga/AMP-Regularizer",
        "arxiv": "2010.04925"
    },
    {
        "title": "Reinforced Attention for Few-Shot Learning and Beyond",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Reinforced_Attention_for_Few-Shot_Learning_and_Beyond_CVPR_2021_paper.html",
        "author": "Jie Hong, Pengfei Fang, Weihao Li, Tong Zhang, Christian Simon, Mehrtash Harandi, Lars Petersson",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Reinforced_Attention_for_Few-Shot_Learning_and_Beyond_CVPR_2021_paper.pdf",
        "aff": "EPFL; Australian National University, Data61-CSIRO; Data61-CSIRO; Monash University",
        "project": "",
        "github": "",
        "arxiv": "2104.04192"
    },
    {
        "title": "Relation-aware Instance Refinement for Weakly Supervised Visual Grounding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Relation-aware_Instance_Refinement_for_Weakly_Supervised_Visual_Grounding_CVPR_2021_paper.html",
        "author": "Yongfei Liu, Bo Wan, Lin Ma, Xuming He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Relation-aware_Instance_Refinement_for_Weakly_Supervised_Visual_Grounding_CVPR_2021_paper.pdf",
        "aff": "Meituan; Department of Electrical Engineering (ESAT), KU Leuven; School of Information Science and Technology, ShanghaiTech University; Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "project": "",
        "github": "https://github.com/youngfly11/ReIR-WeaklyGrounding.pytorch.git",
        "arxiv": "2103.12989"
    },
    {
        "title": "Relative Order Analysis and Optimization for Unsupervised Deep Metric Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kan_Relative_Order_Analysis_and_Optimization_for_Unsupervised_Deep_Metric_Learning_CVPR_2021_paper.html",
        "author": "Shichao Kan, Yigang Cen, Yang Li, Vladimir Mladenovic, Zhihai He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kan_Relative_Order_Analysis_and_Optimization_for_Unsupervised_Deep_Metric_Learning_CVPR_2021_paper.pdf",
        "aff": "Faculty of Technical Sciences University of Kragujevac, Cacak, Serbia; Institute of Information Science, Beijing Jiaotong University, Beijing 100044, China; Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing 100044, China; Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO 65211, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Relevance-CAM: Your Model Already Knows Where To Look",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Relevance-CAM_Your_Model_Already_Knows_Where_To_Look_CVPR_2021_paper.html",
        "author": "Jeong Ryong Lee, Sewon Kim, Inyong Park, Taejoon Eo, Dosik Hwang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Relevance-CAM_Your_Model_Already_Knows_Where_To_Look_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University",
        "project": "",
        "github": "https://github.com/mongeoroo/Relevance-CAM",
        "arxiv": ""
    },
    {
        "title": "Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Removing_Diffraction_Image_Artifacts_in_Under-Display_Camera_via_Dynamic_Skip_CVPR_2021_paper.html",
        "author": "Ruicheng Feng, Chongyi Li, Huaijin Chen, Shuai Li, Chen Change Loy, Jinwei Gu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Removing_Diffraction_Image_Artifacts_in_Under-Display_Camera_via_Dynamic_Skip_CVPR_2021_paper.pdf",
        "aff": "Tetras.AI; Tetras.AI, Shanghai Al Laboratory; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://jnjaby.github.io/projects/UDC",
        "arxiv": "2104.09556"
    },
    {
        "title": "Removing Raindrops and Rain Streaks in One Go",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Quan_Removing_Raindrops_and_Rain_Streaks_in_One_Go_CVPR_2021_paper.html",
        "author": "Ruijie Quan, Xin Yu, Yuanzhi Liang, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Quan_Removing_Raindrops_and_Rain_Streaks_in_One_Go_CVPR_2021_paper.pdf",
        "aff": "Baidu Research*; ReLER Lab, University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Removing the Background by Adding the Background: Towards Background Robust Self-Supervised Video Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Removing_the_Background_by_Adding_the_Background_Towards_Background_Robust_CVPR_2021_paper.html",
        "author": "Jinpeng Wang, Yuting Gao, Ke Li, Yiqi Lin, Andy J. Ma, Hao Cheng, Pai Peng, Feiyue Huang, Rongrong Ji, Xing Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Removing_the_Background_by_Adding_the_Background_Towards_Background_Robust_CVPR_2021_paper.pdf",
        "aff": "Tencent Youtu Lab; Sun Yat-sen University; Xiamen University",
        "project": "",
        "github": "",
        "arxiv": "2009.05769"
    },
    {
        "title": "RepVGG: Making VGG-Style ConvNets Great Again",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.html",
        "author": "Xiaohan Ding, Xiangyu Zhang, Ningning Ma, Jungong Han, Guiguang Ding, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.pdf",
        "aff": "MEGVII Technology; Hong Kong University of Science and Technology; Beijing National Research Center for Information Science and Technology (BNRist); School of Software, Tsinghua University, Beijing, China; Computer Science Department, Aberystwyth University, SY23 3FL, UK",
        "project": "",
        "github": "https://github.com/megvii-model/RepVGG",
        "arxiv": "2101.03697"
    },
    {
        "title": "Repetitive Activity Counting by Sight and Sound",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Repetitive_Activity_Counting_by_Sight_and_Sound_CVPR_2021_paper.html",
        "author": "Yunhua Zhang, Ling Shao, Cees G. M. Snoek",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Repetitive_Activity_Counting_by_Sight_and_Sound_CVPR_2021_paper.pdf",
        "aff": "Inception Institute of Arti\ufb01cial Intelligence; University of Amsterdam",
        "project": "",
        "github": "https://github.com/xiaobai1217/RepetitionCounting",
        "arxiv": "2103.13096"
    },
    {
        "title": "Repopulating Street Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Repopulating_Street_Scenes_CVPR_2021_paper.html",
        "author": "Yifan Wang, Andrew Liu, Richard Tucker, Jiajun Wu, Brian L. Curless, Steven M. Seitz, Noah Snavely",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Repopulating_Street_Scenes_CVPR_2021_paper.pdf",
        "aff": "Stanford University; University of Washington; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2103.16183"
    },
    {
        "title": "Representation Learning via Global Temporal Alignment and Cycle-Consistency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hadji_Representation_Learning_via_Global_Temporal_Alignment_and_Cycle-Consistency_CVPR_2021_paper.html",
        "author": "Isma Hadji, Konstantinos G. Derpanis, Allan D. Jepson",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hadji_Representation_Learning_via_Global_Temporal_Alignment_and_Cycle-Consistency_CVPR_2021_paper.pdf",
        "aff": "Samsung AI Centre Toronto",
        "project": "",
        "github": "",
        "arxiv": "2105.05217"
    },
    {
        "title": "Representative Batch Normalization With Feature Calibration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Representative_Batch_Normalization_With_Feature_Calibration_CVPR_2021_paper.html",
        "author": "Shang-Hua Gao, Qi Han, Duo Li, Ming-Ming Cheng, Pai Peng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Representative_Batch_Normalization_With_Feature_Calibration_CVPR_2021_paper.pdf",
        "aff": "HKUST; Tencent; TKLNDST, CS, Nankai University",
        "project": "",
        "github": "http://mmcheng.net/rbn",
        "arxiv": ""
    },
    {
        "title": "Representative Forgery Mining for Fake Face Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Representative_Forgery_Mining_for_Fake_Face_Detection_CVPR_2021_paper.html",
        "author": "Chengrui Wang, Weihong Deng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Representative_Forgery_Mining_for_Fake_Face_Detection_CVPR_2021_paper.pdf",
        "aff": "Beijing University of Posts and Telecommunications",
        "project": "",
        "github": "https://github.com/crywang/RFM",
        "arxiv": "2104.06609"
    },
    {
        "title": "Representing Videos As Discriminative Sub-Graphs for Action Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Representing_Videos_As_Discriminative_Sub-Graphs_for_Action_Recognition_CVPR_2021_paper.html",
        "author": "Dong Li, Zhaofan Qiu, Yingwei Pan, Ting Yao, Houqiang Li, Tao Mei",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Representing_Videos_As_Discriminative_Sub-Graphs_for_Action_Recognition_CVPR_2021_paper.pdf",
        "aff": "University of Science and Technology of China, Hefei, China; JD AI Research, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Repurposing GANs for One-Shot Semantic Part Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tritrong_Repurposing_GANs_for_One-Shot_Semantic_Part_Segmentation_CVPR_2021_paper.html",
        "author": "Nontawat Tritrong, Pitchaporn Rewatbowornwong, Supasorn Suwajanakorn",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tritrong_Repurposing_GANs_for_One-Shot_Semantic_Part_Segmentation_CVPR_2021_paper.pdf",
        "aff": "VISTEC, Thailand",
        "project": "https://RepurposeGANs.github.io/",
        "github": "https://github.com/RepurposeGANs",
        "arxiv": "2103.04379"
    },
    {
        "title": "Residential Floor Plan Recognition and Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Residential_Floor_Plan_Recognition_and_Reconstruction_CVPR_2021_paper.html",
        "author": "Xiaolei Lv, Shengchu Zhao, Xinyang Yu, Binqiang Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lv_Residential_Floor_Plan_Recognition_and_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Restore From Restored: Video Restoration With Pseudo Clean Video",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Restore_From_Restored_Video_Restoration_With_Pseudo_Clean_Video_CVPR_2021_paper.html",
        "author": "Seunghwan Lee, Donghyeon Cho, Jiwon Kim, Tae Hyun Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Restore_From_Restored_Video_Restoration_With_Pseudo_Clean_Video_CVPR_2021_paper.pdf",
        "aff": "Dept. of Electronic Engineering, Chungnam National University, Daejeon, Korea; Dept. of Computer Science, Hanyang University, Seoul, Korea; SKT Vision AI Labs/T-Brain X, Seoul, Korea",
        "project": "",
        "github": "https://github.com/shlee0/RFR-video-denoising",
        "arxiv": "2003.04279"
    },
    {
        "title": "Restoring Extremely Dark Images in Real Time",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lamba_Restoring_Extremely_Dark_Images_in_Real_Time_CVPR_2021_paper.html",
        "author": "Mohit Lamba, Kaushik Mitra",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lamba_Restoring_Extremely_Dark_Images_in_Real_Time_CVPR_2021_paper.pdf",
        "aff": "Indian Institute of Technology Madras",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Rethinking BiSeNet for Real-Time Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Rethinking_BiSeNet_for_Real-Time_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Mingyuan Fan, Shenqi Lai, Junshi Huang, Xiaoming Wei, Zhenhua Chai, Junfeng Luo, Xiaolin Wei",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_Rethinking_BiSeNet_for_Real-Time_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Meituan",
        "project": "",
        "github": "https://github.com/MichaelFan01/STDC-Seg",
        "arxiv": "2104.13188"
    },
    {
        "title": "Rethinking Channel Dimensions for Efficient Model Design",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Han_Rethinking_Channel_Dimensions_for_Efficient_Model_Design_CVPR_2021_paper.html",
        "author": "Dongyoon Han, Sangdoo Yun, Byeongho Heo, YoungJoon Yoo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Han_Rethinking_Channel_Dimensions_for_Efficient_Model_Design_CVPR_2021_paper.pdf",
        "aff": "NAVER AI Lab",
        "project": "",
        "github": "https://github.com/clovaai/rexnet",
        "arxiv": "2007.00992"
    },
    {
        "title": "Rethinking Class Relations: Absolute-Relative Supervised and Unsupervised Few-Shot Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Rethinking_Class_Relations_Absolute-Relative_Supervised_and_Unsupervised_Few-Shot_Learning_CVPR_2021_paper.html",
        "author": "Hongguang Zhang, Piotr Koniusz, Songlei Jian, Hongdong Li, Philip H. S. Torr",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Rethinking_Class_Relations_Absolute-Relative_Supervised_and_Unsupervised_Few-Shot_Learning_CVPR_2021_paper.pdf",
        "aff": "National University of Defense Technology; Australian National University; University of Oxford; Systems Engineering Institute, AMS, Australian National University; Data61/CSIRO",
        "project": "",
        "github": "",
        "arxiv": "2001.03919"
    },
    {
        "title": "Rethinking Graph Neural Architecture Search From Message-Passing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Rethinking_Graph_Neural_Architecture_Search_From_Message-Passing_CVPR_2021_paper.html",
        "author": "Shaofei Cai, Liang Li, Jincan Deng, Beichen Zhang, Zheng-Jun Zha, Li Su, Qingming Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cai_Rethinking_Graph_Neural_Architecture_Search_From_Message-Passing_CVPR_2021_paper.pdf",
        "aff": "Rethinking Graph Neural Architecture Search from Message-passing\nShaofei Cai1,2, Liang Li1*, Jincan Deng1,2, Beichen Zhang1,2, Zheng-Jun Zha3, Li Su2, Qingming Huang1,2,4\n1Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS, Beijing, China\n2University of Chinese Academy of Sciences, Beijing, China\n3University of Science and Technology of China, China,4Peng Cheng Laboratory, Shenzhen, China\n{shaofei.cai,jincan.deng,beichen.zhang }@vipl.ict.ac.cn,liang.li@ict.ac.cn,zhazj@ustc.edu.cn,\n{suli,qmhuang }@ucas.ac.cn\nAbstract\nGraph neural networks (GNNs) emerged recently as a\nstandard toolkit for learning from data on graphs. Cur-\nrent GNN designing works depend on immense human ex-\npertise to explore different message-passing mechanisms,\nand require manual enumeration to determine the proper\nmessage-passing depth. Inspired by the strong searching\ncapability of neural architecture search (NAS) in CNN, this\npaper proposes Graph Neural Architecture Search (GNAS)\nwith novel-designed search space. The GNAS can auto-\nmatically learn better architecture with the optimal depth\nof message passing on the graph. Speci\ufb01cally, we de-\nsign Graph Neural Architecture Paradigm (GAP) with tree-\ntopology computation procedure and two types of \ufb01ne-\ngrained atomic operations (feature \ufb01ltering & neighbor ag-\ngregation) from message-passing mechanism to construct\npowerful graph network search space. Feature \ufb01ltering per-\nforms adaptive feature selection, and neighbor aggregation\ncaptures structural information and calculates neighbors\u2019\nstatistics. Experiments show that our GNAS can search\nfor better GNNs with multiple message-passing mecha-\nnisms and optimal message-passing depth. The searched\nnetwork achieves remarkable improvement over state-of-\nthe-art manual designed and search-based GNNs on \ufb01ve\nlarge-scale datasets at three classical graph tasks. Codes\ncan be found at https://github.com/phython96/\nGNAS-MP .\n1. Introduction\nNeural architecture search automatically designs effec-\ntive neural networks and has achieved remarkable perfor-\nmance beyond manually designed networks. Most works\nfocus on searching CNN and RNN networks for vision and\n*Corresponding author.language tasks [ 15,20,36,38], including multi-label ob-\nject recognition [ 16,32], detection [ 8], and sequence pre-\ndiction [ 24]. Recently, bene\ufb01ting from the powerful rea-\nsoning capability, GNN has attracted much attention from\nresearchers. It has become the standard toolkit for analyz-\ning complex graph-structure data. In this paper, we intro-\nduce graph neural architecture search for improving GNNs\u2019\nreasoning capability.\nThe core of GNN is the message-passing mechanism on\nthe graph, which aggregates neighbors\u2019 information and up-\ndates center node representations. The common message-\npassing mechanisms can be divided into two classes: (1)\nisotropic mechanism (e.g. GCN [ 12], GraphSage [ 9]) treats\nevery \u201cedge direction\u201d equally in node update equation. (2)\nanisotropic mechanism (e.g. GAT [ 31], GatedGCN [ 4]) as-\nsigns weight for every edge according to joint representa-\ntions of adjacent nodes. For example, GAT and GatedGCN\ncompute edge weights based on sparse attention and dense\nattention mechanisms, respectively [ 5]. Each mechanism\nhas its characteristics of information transmission. Current\nGNNs are usually stacked to multiple layers with the same\nmessage-passing mechanism to capture long-range node de-\npendencies. An onefold message-passing mechanism limits\nthe reasoning power of graph networks. However, manu-\nally designing GNNs with multiple message-passing mech-\nanisms requires immense human expertise.\nAnother critical problem for GNN is determining the\nnumber of graph convolution layers, that is, the depth of\nmessage-passing. Different from CNN, recent works [ 17,\n29,33] show that GNN\u2019s reasoning capability degrades as\nthe network goes too deep. This results from that the rep-\nresentations of adjacent nodes become closer to each other\nafter each graph convolution. In theory, with an extreme\ndepth, all nodes\u2019 representations will converge to a station-\nary point. Further, the network depth is dataset-relevant.\nSpeci\ufb01cally, it depends on the diameter of the graph in the\nspeci\ufb01c dataset. In order to \ufb01nd the optimal network depth,\ncurrent works usually use enumeration with the high com-\n6657\n",
        "project": "",
        "github": "",
        "arxiv": "2103.14282"
    },
    {
        "title": "Rethinking Semantic Segmentation From a Sequence-to-Sequence Perspective With Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html",
        "author": "Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip H.S. Torr, Li Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.pdf",
        "aff": "Fudan University; Tencent Youtu Lab; University of Oxford; University of Surrey",
        "project": "https://fudan-zvg.github.io/SETR",
        "github": "https://github.com/fudan-zvg/SETR",
        "arxiv": "2012.15840"
    },
    {
        "title": "Rethinking Style Transfer: From Pixels to Parameterized Brushstrokes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kotovenko_Rethinking_Style_Transfer_From_Pixels_to_Parameterized_Brushstrokes_CVPR_2021_paper.html",
        "author": "Dmytro Kotovenko, Matthias Wright, Arthur Heimbrecht, Bjorn Ommer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kotovenko_Rethinking_Style_Transfer_From_Pixels_to_Parameterized_Brushstrokes_CVPR_2021_paper.pdf",
        "aff": "IWR, Heidelberg Collaboratory for Image Processing, Heidelberg University",
        "project": "",
        "github": "https://github.com/CompVis/brushstroke-parameterized-style-transfer",
        "arxiv": "2103.17185"
    },
    {
        "title": "Rethinking Text Segmentation: A Novel Dataset and a Text-Specific Refinement Approach",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Rethinking_Text_Segmentation_A_Novel_Dataset_and_a_Text-Specific_Refinement_CVPR_2021_paper.html",
        "author": "Xingqian Xu, Zhifei Zhang, Zhaowen Wang, Brian Price, Zhonghao Wang, Humphrey Shi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Rethinking_Text_Segmentation_A_Novel_Dataset_and_a_Text-Specific_Refinement_CVPR_2021_paper.pdf",
        "aff": "UIUC; Adobe Research; University of Oregon",
        "project": "",
        "github": "https://github.com/SHI-Labs/Rethinking-Text-Segmentation",
        "arxiv": "2011.14021"
    },
    {
        "title": "Rethinking and Improving the Robustness of Image Style Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Rethinking_and_Improving_the_Robustness_of_Image_Style_Transfer_CVPR_2021_paper.html",
        "author": "Pei Wang, Yijun Li, Nuno Vasconcelos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Rethinking_and_Improving_the_Robustness_of_Image_Style_Transfer_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; UC, San Diego",
        "project": "",
        "github": "",
        "arxiv": "2104.05623"
    },
    {
        "title": "Rethinking the Heatmap Regression for Bottom-Up Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Rethinking_the_Heatmap_Regression_for_Bottom-Up_Human_Pose_Estimation_CVPR_2021_paper.html",
        "author": "Zhengxiong Luo, Zhicheng Wang, Yan Huang, Liang Wang, Tieniu Tan, Erjin Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Rethinking_the_Heatmap_Regression_for_Bottom-Up_Human_Pose_Estimation_CVPR_2021_paper.pdf",
        "aff": "Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA); Megvii Inc, University of Chinese Academy of Sciences (UCAS), Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA); Megvii Inc",
        "project": "",
        "github": "https://github.com/greatlog/SWAHR-HumanPose",
        "arxiv": "2012.15175"
    },
    {
        "title": "Retinex-Inspired Unrolling With Cooperative Prior Architecture Search for Low-Light Image Enhancement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Retinex-Inspired_Unrolling_With_Cooperative_Prior_Architecture_Search_for_Low-Light_Image_CVPR_2021_paper.html",
        "author": "Risheng Liu, Long Ma, Jiaao Zhang, Xin Fan, Zhongxuan Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Retinex-Inspired_Unrolling_With_Cooperative_Prior_Architecture_Search_for_Low-Light_Image_CVPR_2021_paper.pdf",
        "aff": "School of Software Technology, Dalian University of Technology; International School of Information Science & Engineering, Dalian University of Technology",
        "project": "http://dutmedia.org/RUAS/",
        "github": "",
        "arxiv": "2012.05609"
    },
    {
        "title": "Revamping Cross-Modal Recipe Retrieval With Hierarchical Transformers and Self-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Salvador_Revamping_Cross-Modal_Recipe_Retrieval_With_Hierarchical_Transformers_and_Self-Supervised_Learning_CVPR_2021_paper.html",
        "author": "Amaia Salvador, Erhan Gundogdu, Loris Bazzani, Michael Donoser",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Salvador_Revamping_Cross-Modal_Recipe_Retrieval_With_Hierarchical_Transformers_and_Self-Supervised_Learning_CVPR_2021_paper.pdf",
        "aff": "Amazon",
        "project": "",
        "github": "https://github.com/amzn/image-to-recipe-transformers",
        "arxiv": "2103.13061"
    },
    {
        "title": "Revisiting Knowledge Distillation: An Inheritance and Exploration Framework",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Revisiting_Knowledge_Distillation_An_Inheritance_and_Exploration_Framework_CVPR_2021_paper.html",
        "author": "Zhen Huang, Xu Shen, Jun Xing, Tongliang Liu, Xinmei Tian, Houqiang Li, Bing Deng, Jianqiang Huang, Xian-Sheng Hua",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Revisiting_Knowledge_Distillation_An_Inheritance_and_Exploration_Framework_CVPR_2021_paper.pdf",
        "aff": "Revisiting Knowledge Distillation: An Inheritance and Exploration Framework\nZhen Huang1, 2*, Xu Shen2, Jun Xing3, Tongliang Liu4, Xinmei Tian1\u2020,\nHouqiang Li1, Bing Deng2, Jianqiang Huang2, Xian-Sheng Hua2\u2020\n1University of Science and Technology of China,2Alibaba Group\n3University of Southern California,4University of Sydney\nhz13@mail.ustc.edu.cn, junxnui@gmail.com, tongliang.liu@sydney.edu.au, {xinmei,lihq }@ustc.edu.cn,\n{shenxu.sx,dengbing.db,jianqiang.hjq,xiansheng.hxs }@alibaba-inc.com\nAbstract\nKnowledge Distillation (KD) is a popular technique to\ntransfer knowledge from a teacher model or ensemble to\na student model. Its success is generally attributed to the\nprivileged information on similarities/consistency between\nthe class distributions or intermediate feature representa-\ntions of the teacher model and the student model. How-\never, directly pushing the student model to mimic the prob-\nabilities/features of the teacher model to a large extent\nlimits the student model in learning undiscovered knowl-\nedge/features. In this paper, we propose a novel inheritance\nand exploration knowledge distillation framework (IE-KD),\nin which a student model is split into two parts - inheritance\nand exploration. The inheritance part is learned with a sim-\nilarity loss to transfer the existing learned knowledge from\nthe teacher model to the student model, while the explo-\nration part is encouraged to learn representations different\nfrom the inherited ones with a dis-similarity loss. Our IE-\nKD framework is generic and can be easily combined with\nexisting distillation or mutual learning methods for training\ndeep neural networks. Extensive experiments demonstrate\nthat these two parts can jointly push the student model to\nlearn more diversi\ufb01ed and effective representations, and\nour IE-KD can be a general technique to improve the stu-\ndent network to achieve SOTA performance. Furthermore,\nby applying our IE-KD to the training of two networks, the\nperformance of both can be improved w.r.t. deep mutual\nlearning.\n1. Introduction\nKnowledge distillation is one of the most popular meth-\nods for transferring knowledge from one network (teacher)\n*This work was done when the author was visiting Alibaba as a re-\nsearch intern.\n\u2020Corresponding author.to another (student). It was \ufb01rst proposed by Hinton et\nal. [10] to transfer knowledge from a large teacher network\n(or ensemble) to a small student network that is easier to\ndeploy. It works by training the student to predict the tar-\nget classi\ufb01cation labels and mimic the class probabilities\nof the teacher, as these features contain additional informa-\ntion about how the teacher tends to generalize [ 10]. All\nrecent distillation works follow this philosophy of an ad-\nditional consistency control between the class probabilities\nor intermediate representations of the teacher network and\nthe student network. KD [ 10] and Tf-KD [ 32] focus on the\nconsistency of output class probabilities. AT [ 33], AB [ 13],\nFT [16], OD [ 12], FEED [ 22] and FitNet [ 24] propose dif-\nferent consistency controls of intermediate features. FSP\n[31] proposes a consistency control of the intra-similarities\namong intermediate features. In summary, all recent distil-\nlation methods differ in the metric of consistency between\nthe student model and the teacher model.\nHowever, directly pushing the student model to mimic\nthe probabilities/features of the teacher model limits the stu-\ndent model in learning new knowledge/features. As shown\nin Fig. 1(a), the student model trained with KD learns\nvery similar patterns compared with the well-trained teacher\n(more results will be shown in supplementary materials). In\nthis case, the \u201ccheetah\u201d misclassi\ufb01ed as a \u201ccrocodile\u201d by\nthe teacher model is also misclassi\ufb01ed by the student model\ntrained by KD. The model attributes most of its prediction\nto the tail of the \u201ccheetah\u201d which resembles a \u201ccrocodile\u201d.\nAs a result, the student network fails to incorporate new rel-\nevant patterns on ears and mouth that are quite discrimina-\ntive between the \u201ccheetah\u201d and \u201ccrocodile\u201d. Therefore, we\nneed a mechanism to \ufb01nd more useful features for correct\npredictions that are omitted by the teacher network.\nIntuitively, simply mimicking outputs of the teacher net-\nwork will narrow the search space for the optimal parame-\nters of the student network and lead to a poor solution from\na feature learning view. Furthermore, we \ufb01nd that this phe-\nnomenon becomes more evident when transferring knowl-\n3579\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Revisiting Superpixels for Active Learning in Semantic Segmentation With Realistic Annotation Costs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Revisiting_Superpixels_for_Active_Learning_in_Semantic_Segmentation_With_Realistic_CVPR_2021_paper.html",
        "author": "Lile Cai, Xun Xu, Jun Hao Liew, Chuan Sheng Foo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cai_Revisiting_Superpixels_for_Active_Learning_in_Semantic_Segmentation_With_Realistic_CVPR_2021_paper.pdf",
        "aff": "Institute for Infocomm Research, Singapore; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "RfD-Net: Point Scene Understanding by Semantic Instance Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Nie_RfD-Net_Point_Scene_Understanding_by_Semantic_Instance_Reconstruction_CVPR_2021_paper.html",
        "author": "Yinyu Nie, Ji Hou, Xiaoguang Han, Matthias Niessner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nie_RfD-Net_Point_Scene_Understanding_by_Semantic_Instance_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "SRIBD, CUHKSZ and Bournemouth University; SRIBD, CUHKSZ; Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Rich Context Aggregation With Reflection Prior for Glass Surface Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Rich_Context_Aggregation_With_Reflection_Prior_for_Glass_Surface_Detection_CVPR_2021_paper.html",
        "author": "Jiaying Lin, Zebang He, Rynson W.H. Lau",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Rich_Context_Aggregation_With_Reflection_Prior_for_Glass_Surface_Detection_CVPR_2021_paper.pdf",
        "aff": "City University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Rich Features for Perceptual Quality Assessment of UGC Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Rich_Features_for_Perceptual_Quality_Assessment_of_UGC_Videos_CVPR_2021_paper.html",
        "author": "Yilin Wang, Junjie Ke, Hossein Talebi, Joong Gon Yim, Neil Birkbeck, Balu Adsumilli, Peyman Milanfar, Feng Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Rich_Features_for_Perceptual_Quality_Assessment_of_UGC_Videos_CVPR_2021_paper.pdf",
        "aff": "Google Inc.",
        "project": "https://media.withyoutube.com/ugc-dataset",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Riggable 3D Face Reconstruction via In-Network Optimization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bai_Riggable_3D_Face_Reconstruction_via_In-Network_Optimization_CVPR_2021_paper.html",
        "author": "Ziqian Bai, Zhaopeng Cui, Xiaoming Liu, Ping Tan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bai_Riggable_3D_Face_Reconstruction_via_In-Network_Optimization_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; State Key Lab of CAD & CG, Zhejiang University; Michigan State University",
        "project": "",
        "github": "https://github.com/zqbai-jeremy/INORig",
        "arxiv": "2104.03493"
    },
    {
        "title": "Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting With Their Explanations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Stammer_Right_for_the_Right_Concept_Revising_Neuro-Symbolic_Concepts_by_Interacting_CVPR_2021_paper.html",
        "author": "Wolfgang Stammer, Patrick Schramowski, Kristian Kersting",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Stammer_Right_for_the_Right_Concept_Revising_Neuro-Symbolic_Concepts_by_Interacting_CVPR_2021_paper.pdf",
        "aff": "Computer Science Department, TU Darmstadt, Germany; Computer Science Department, TU Darmstadt, Germany; Centre for Cognitive Science, TU Darmstadt, and Hessian Center for AI (hessian.AI)",
        "project": "",
        "github": "",
        "arxiv": "2011.12854"
    },
    {
        "title": "Robust Audio-Visual Instance Discrimination",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Morgado_Robust_Audio-Visual_Instance_Discrimination_CVPR_2021_paper.html",
        "author": "Pedro Morgado, Ishan Misra, Nuno Vasconcelos",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Morgado_Robust_Audio-Visual_Instance_Discrimination_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; UC San Diego",
        "project": "",
        "github": "",
        "arxiv": "2103.15916"
    },
    {
        "title": "Robust Bayesian Neural Networks by Spectral Expectation Bound Regularization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Robust_Bayesian_Neural_Networks_by_Spectral_Expectation_Bound_Regularization_CVPR_2021_paper.html",
        "author": "Jiaru Zhang, Yang Hua, Zhengui Xue, Tao Song, Chengyu Zheng, Ruhui Ma, Haibing Guan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Robust_Bayesian_Neural_Networks_by_Spectral_Expectation_Bound_Regularization_CVPR_2021_paper.pdf",
        "aff": "Queen\u2019s University Belfast; Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Robust Consistent Video Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kopf_Robust_Consistent_Video_Depth_Estimation_CVPR_2021_paper.html",
        "author": "Johannes Kopf, Xuejian Rong, Jia-Bin Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kopf_Robust_Consistent_Video_Depth_Estimation_CVPR_2021_paper.pdf",
        "aff": "Facebook; Virginia Tech",
        "project": "https://robust-cvd.github.io",
        "github": "",
        "arxiv": "2012.05901"
    },
    {
        "title": "Robust Instance Segmentation Through Reasoning About Multi-Object Occlusion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_Robust_Instance_Segmentation_Through_Reasoning_About_Multi-Object_Occlusion_CVPR_2021_paper.html",
        "author": "Xiaoding Yuan, Adam Kortylewski, Yihong Sun, Alan Yuille",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_Robust_Instance_Segmentation_Through_Reasoning_About_Multi-Object_Occlusion_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Tongji University",
        "project": "",
        "github": "https://github.com/XD7479/Multi-Object-Occlusion",
        "arxiv": "2012.02107"
    },
    {
        "title": "Robust Multimodal Vehicle Detection in Foggy Weather Using Complementary Lidar and Radar Signals",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qian_Robust_Multimodal_Vehicle_Detection_in_Foggy_Weather_Using_Complementary_Lidar_CVPR_2021_paper.html",
        "author": "Kun Qian, Shilin Zhu, Xinyu Zhang, Li Erran Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qian_Robust_Multimodal_Vehicle_Detection_in_Foggy_Weather_Using_Complementary_Lidar_CVPR_2021_paper.pdf",
        "aff": "University of California San Diego; Columbia University",
        "project": "",
        "github": "https://github.com/qiank10/MVDNet",
        "arxiv": ""
    },
    {
        "title": "Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dong_Robust_Neural_Routing_Through_Space_Partitions_for_Camera_Relocalization_in_CVPR_2021_paper.html",
        "author": "Siyan Dong, Qingnan Fan, He Wang, Ji Shi, Li Yi, Thomas Funkhouser, Baoquan Chen, Leonidas J. Guibas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dong_Robust_Neural_Routing_Through_Space_Partitions_for_Camera_Relocalization_in_CVPR_2021_paper.pdf",
        "aff": "Peking University; Stanford University; Google Research; Shandong University, AICFVE, Beijing Film Academy",
        "project": "",
        "github": "",
        "arxiv": "2012.04746"
    },
    {
        "title": "Robust Point Cloud Registration Framework Based on Deep Graph Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Robust_Point_Cloud_Registration_Framework_Based_on_Deep_Graph_Matching_CVPR_2021_paper.html",
        "author": "Kexue Fu, Shaolei Liu, Xiaoyuan Luo, Manning Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fu_Robust_Point_Cloud_Registration_Framework_Based_on_Deep_Graph_Matching_CVPR_2021_paper.pdf",
        "aff": "Digital Medical Research Center, School of Basic Medical Science, Fudan University; Shanghai Key Lab of Medical Image Computing and Computer Assisted Intervention",
        "project": "",
        "github": "https://github.com/fukexue/RGM",
        "arxiv": "2103.04256"
    },
    {
        "title": "Robust Reference-Based Super-Resolution via C2-Matching",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Robust_Reference-Based_Super-Resolution_via_C2-Matching_CVPR_2021_paper.html",
        "author": "Yuming Jiang, Kelvin C.K. Chan, Xintao Wang, Chen Change Loy, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jiang_Robust_Reference-Based_Super-Resolution_via_C2-Matching_CVPR_2021_paper.pdf",
        "aff": "Applied Research Center, Tencent PCG; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://github.com/yumingj/C2-Matching",
        "arxiv": "2106.01863"
    },
    {
        "title": "Robust Reflection Removal With Reflection-Free Flash-Only Cues",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lei_Robust_Reflection_Removal_With_Reflection-Free_Flash-Only_Cues_CVPR_2021_paper.html",
        "author": "Chenyang Lei, Qifeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lei_Robust_Reflection_Removal_With_Reflection-Free_Flash-Only_Cues_CVPR_2021_paper.pdf",
        "aff": "The Hong Kong University of Science and Technology",
        "project": "",
        "github": "github.com/ChenyangLEI/flash-reflection-removal",
        "arxiv": "2103.04273"
    },
    {
        "title": "Robust Representation Learning With Feedback for Single Image Deraining",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Robust_Representation_Learning_With_Feedback_for_Single_Image_Deraining_CVPR_2021_paper.html",
        "author": "Chenghao Chen, Hao Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Robust_Representation_Learning_With_Feedback_for_Single_Image_Deraining_CVPR_2021_paper.pdf",
        "aff": "Department of Automation, Shanghai Jiao Tong University (SJTU), Shanghai, 200240, China.; Department of Automation, Shanghai Jiao Tong University (SJTU), Shanghai, 200240, China. Ecole d\u2019Ing\u00e9nieurs SJTU-ParisTech (SPEIT), Shanghai, 200240, China.",
        "project": "",
        "github": "https://github.com/LI-Hao-SJTU/DerainRLNet",
        "arxiv": "2101.12463"
    },
    {
        "title": "Robust and Accurate Object Detection via Adversarial Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Robust_and_Accurate_Object_Detection_via_Adversarial_Learning_CVPR_2021_paper.html",
        "author": "Xiangning Chen, Cihang Xie, Mingxing Tan, Li Zhang, Cho-Jui Hsieh, Boqing Gong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Robust_and_Accurate_Object_Detection_via_Adversarial_Learning_CVPR_2021_paper.pdf",
        "aff": "Google; UCLA; UCSC",
        "project": "",
        "github": "",
        "arxiv": "2103.13886"
    },
    {
        "title": "RobustNet: Improving Domain Generalization in Urban-Scene Segmentation via Instance Selective Whitening",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Choi_RobustNet_Improving_Domain_Generalization_in_Urban-Scene_Segmentation_via_Instance_Selective_CVPR_2021_paper.html",
        "author": "Sungha Choi, Sanghun Jung, Huiwon Yun, Joanne T. Kim, Seungryong Kim, Jaegul Choo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Choi_RobustNet_Improving_Domain_Generalization_in_Urban-Scene_Segmentation_via_Instance_Selective_CVPR_2021_paper.pdf",
        "aff": "LG AI Research; Korea University; KAIST; Sogang University",
        "project": "",
        "github": "https://github.com/shachoi/RobustNet",
        "arxiv": "2103.15597"
    },
    {
        "title": "Roof-GAN: Learning To Generate Roof Geometry and Relations for Residential Houses",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qian_Roof-GAN_Learning_To_Generate_Roof_Geometry_and_Relations_for_Residential_CVPR_2021_paper.html",
        "author": "Yiming Qian, Hao Zhang, Yasutaka Furukawa",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qian_Roof-GAN_Learning_To_Generate_Roof_Geometry_and_Relations_for_Residential_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University",
        "project": "",
        "github": "https://github.com/yi-ming-qian/roofgan",
        "arxiv": ""
    },
    {
        "title": "Room-and-Object Aware Knowledge Reasoning for Remote Embodied Referring Expression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Room-and-Object_Aware_Knowledge_Reasoning_for_Remote_Embodied_Referring_Expression_CVPR_2021_paper.html",
        "author": "Chen Gao, Jinyu Chen, Si Liu, Luting Wang, Qiong Zhang, Qi Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Room-and-Object_Aware_Knowledge_Reasoning_for_Remote_Embodied_Referring_Expression_CVPR_2021_paper.pdf",
        "aff": "Room-and-Object Aware Knowledge Reasoning for\nRemote Embodied Referring Expression\nChen Gao1*, Jinyu Chen1*, Si Liu1\u2020, Luting Wang1, Qiong Zhang3, Qi Wu2\n1Institute of Arti\ufb01cial Intelligence, Beihang University\n2The University of Adelaide3Xiaomi AI Lab, Xiaomi Inc\nAbstract\nThe Remote Embodied Referring Expression (REVERIE)\nis a recently raised task that requires an agent to navi-\ngate to and localise a referred remote object according to\na high-level language instruction. Different from related\nVLN tasks, the key to REVERIE is to conduct goal-oriented\nexploration instead of strict instruction-following, due to\nthe lack of step-by-step navigation guidance. In this paper,\nwe propose a novel Cross-modality Knowledge Reasoning\n(CKR) model to address the unique challenges of this task.\nThe CKR, based on a transformer-architecture, learns to\ngenerate scene memory tokens and utilise these informa-\ntive history clues for exploration. Particularly, a Room-\nand-Object Aware Attention (ROAA) mechanism is devised\nto explicitly perceive the room- and object-type informa-\ntion from both linguistic and visual observations. More-\nover, through incorporating commonsense knowledge, we\npropose a Knowledge-enabled Entity Relationship Reason-\ning (KERR) module to learn the internal-external correla-\ntions among room- and object-entities for agent to make\nproper action at each viewpoint. Evaluation on REVERIE\nbenchmark demonstrates the superiority of the CKR model,\nwhich signi\ufb01cantly boosts SPL and REVERIE-success rate\nby64.67% and46.05%, respectively. Code is available at:\nhttps://github.com/alloldman/CKR .\n1. Introduction\nThe Embodied-AI (E-AI), where embodied agents per-\nform various egocentric perception tasks, has attracted a\nsurge of interest within both computer vision and natural\nlanguage processing communities. In recent years, numer-\nous datasets [ 1,6,16] and simulators [ 5,26,49] have been\nconstructed to provide 3D assets with annotations and simu-\nlate the agent respectively. These platforms support legions\nof tasks including Vision-Language Navigation (VLN) [ 1],\nEmbodied Question Answering [ 6],etc.\n*Equal contribution\n\u2020Corresponding author (liusi@buaa.edu.cn)\nFigure 1. At viewpoint A, our agent with commonsense turns right\ninto the \u2018meeting room\u2019 through perceived \u2018chair\u2019 and \u2018meeting-\ndesk\u2019. Then at viewpoint B, it seeks for easy-to-\ufb01nd related ob-\njects ( e.g., \u2018computer\u2019) at \ufb01rst for ef\ufb01cient exploration, where tar-\nget \u2018mouse\u2019 is usually around. Cis the \ufb01nal viewpoint it arrived.\nMost recently, a valuable task named Remote Embod-\nied Visual referring Expression in Real Indoor Environ-\nments (REVERIE) [ 37] was proposed to further facilitate\nthe E-AI \ufb01eld. The goal of REVERIE is for a robot in a\nphoto-realistic 3D indoor environment to navigate closer to\nand localise a referred target object according to the given\nhigh-level instruction, which is similar to VLN task. How-\never, simply utilising approaches in VLN is not capable of\ncompleting REVERIE task satisfactorily, which has been\nproved in [ 37] through extensive experiments.\nThe REVERIE contains several challenges. Firstly, es-\nsentially different from previous VLN tasks ( e.g., R2R [ 1])\nthat provide step-by-step navigation guidance, REVERIE\ntowards practicability only annotates high/semantic-level\ninstructions like \u2018Go to the corner of meeting room, bring\nme the mouse on the table\u2019, as shown in Fig. 1. This is\nmore natural and closer to the human needs from a home\nassistance function perspective, but it is more challeng-\ning. Therefore, instead of strict instruction-following, the\nagent needs to conduct goal-oriented exploration in an un-\n3064\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Roses Are Red, Violets Are Blue... but Should VQA Expect Them To?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kervadec_Roses_Are_Red_Violets_Are_Blue..._but_Should_VQA_Expect_CVPR_2021_paper.html",
        "author": "Corentin Kervadec, Grigory Antipov, Moez Baccouche, Christian Wolf",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kervadec_Roses_Are_Red_Violets_Are_Blue..._but_Should_VQA_Expect_CVPR_2021_paper.pdf",
        "aff": "Orange, Cesson-S \u00b4evign \u00b4e, France; LIRIS, INSA-Lyon, UMR CNRS 5205, France",
        "project": "corentinkervadec.github.io",
        "github": "",
        "arxiv": "2006.05121"
    },
    {
        "title": "Rotation Coordinate Descent for Fast Globally Optimal Rotation Averaging",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Parra_Rotation_Coordinate_Descent_for_Fast_Globally_Optimal_Rotation_Averaging_CVPR_2021_paper.html",
        "author": "Alvaro Parra, Shin-Fang Chng, Tat-Jun Chin, Anders Eriksson, Ian Reid",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Parra_Rotation_Coordinate_Descent_for_Fast_Globally_Optimal_Rotation_Averaging_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, The University of Adelaide; School of Information Technology and Electrical Engineering, University of Queensland",
        "project": "",
        "github": "https://github.com/sfchng/Rotation_Coordinate_Descent",
        "arxiv": "2103.08292"
    },
    {
        "title": "Rotation Equivariant Siamese Networks for Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gupta_Rotation_Equivariant_Siamese_Networks_for_Tracking_CVPR_2021_paper.html",
        "author": "Deepak K. Gupta, Devanshu Arya, Efstratios Gavves",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gupta_Rotation_Equivariant_Siamese_Networks_for_Tracking_CVPR_2021_paper.pdf",
        "aff": "QUV A Lab, University of Amsterdam, The Netherlands; Informatics Institute, University of Amsterdam, The Netherlands",
        "project": "",
        "github": "https://github.com/dkgupta90/re-siamnet",
        "arxiv": "2012.13078"
    },
    {
        "title": "Rotation-Only Bundle Adjustment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Rotation-Only_Bundle_Adjustment_CVPR_2021_paper.html",
        "author": "Seong Hun Lee, Javier Civera",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Rotation-Only_Bundle_Adjustment_CVPR_2021_paper.pdf",
        "aff": "I3A, University of Zaragoza, Spain",
        "project": "",
        "github": "https://seonghun-lee.github.io",
        "arxiv": "2011.11724"
    },
    {
        "title": "S2-BNN: Bridging the Gap Between Self-Supervised Real and 1-Bit Neural Networks via Guided Distribution Calibration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shen_S2-BNN_Bridging_the_Gap_Between_Self-Supervised_Real_and_1-Bit_Neural_CVPR_2021_paper.html",
        "author": "Zhiqiang Shen, Zechun Liu, Jie Qin, Lei Huang, Kwang-Ting Cheng, Marios Savvides",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_S2-BNN_Bridging_the_Gap_Between_Self-Supervised_Real_and_1-Bit_Neural_CVPR_2021_paper.pdf",
        "aff": "Inception Institute of Arti\ufb01cial Intelligence; Hong Kong University of Science and Technology; Carnegie Mellon University",
        "project": "",
        "github": "https://github.com/szq0214/S2-BNN",
        "arxiv": ""
    },
    {
        "title": "S2R-DepthNet: Learning a Generalizable Depth-Specific Structural Representation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_S2R-DepthNet_Learning_a_Generalizable_Depth-Specific_Structural_Representation_CVPR_2021_paper.html",
        "author": "Xiaotian Chen, Yuwang Wang, Xuejin Chen, Wenjun Zeng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_S2R-DepthNet_Learning_a_Generalizable_Depth-Specific_Structural_Representation_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "S3: Learnable Sparse Signal Superdensity for Guided Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_S3_Learnable_Sparse_Signal_Superdensity_for_Guided_Depth_Estimation_CVPR_2021_paper.html",
        "author": "Yu-Kai Huang, Yueh-Cheng Liu, Tsung-Han Wu, Hung-Ting Su, Yu-Cheng Chang, Tsung-Lin Tsou, Yu-An Wang, Winston H. Hsu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_S3_Learnable_Sparse_Signal_Superdensity_for_Guided_Depth_Estimation_CVPR_2021_paper.pdf",
        "aff": "National Taiwan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "S3: Neural Shape, Skeleton, and Skinning Fields for 3D Human Modeling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_S3_Neural_Shape_Skeleton_and_Skinning_Fields_for_3D_Human_CVPR_2021_paper.html",
        "author": "Ze Yang, Shenlong Wang, Sivabalan Manivasagam, Zeng Huang, Wei-Chiu Ma, Xinchen Yan, Ersin Yumer, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_S3_Neural_Shape_Skeleton_and_Skinning_Fields_for_3D_Human_CVPR_2021_paper.pdf",
        "aff": "Uber Advanced Technologies Group, University of Toronto; Massachusetts Institute of Technology; University of Southern California; Uber Advanced Technologies Group",
        "project": "",
        "github": "",
        "arxiv": "2101.06571"
    },
    {
        "title": "SAIL-VOS 3D: A Synthetic Dataset and Baselines for Object Detection and 3D Mesh Reconstruction From Video Data",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_SAIL-VOS_3D_A_Synthetic_Dataset_and_Baselines_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Yuan-Ting Hu, Jiahong Wang, Raymond A. Yeh, Alexander G. Schwing",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_SAIL-VOS_3D_A_Synthetic_Dataset_and_Baselines_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign",
        "project": "http://sailvos.web.illinois.edu",
        "github": "",
        "arxiv": "2105.08612"
    },
    {
        "title": "SCALE: Modeling Clothed Humans with a Surface Codec of Articulated Local Elements",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_SCALE_Modeling_Clothed_Humans_with_a_Surface_Codec_of_Articulated_CVPR_2021_paper.html",
        "author": "Qianli Ma, Shunsuke Saito, Jinlong Yang, Siyu Tang, Michael J. Black",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_SCALE_Modeling_Clothed_Humans_with_a_Surface_Codec_of_Articulated_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; ETH Z\u00fcrich",
        "project": "",
        "github": "https://qianlim.github.io/SCALE",
        "arxiv": "2104.07660"
    },
    {
        "title": "SCANimate: Weakly Supervised Learning of Skinned Clothed Avatar Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Saito_SCANimate_Weakly_Supervised_Learning_of_Skinned_Clothed_Avatar_Networks_CVPR_2021_paper.html",
        "author": "Shunsuke Saito, Jinlong Yang, Qianli Ma, Michael J. Black",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Saito_SCANimate_Weakly_Supervised_Learning_of_Skinned_Clothed_Avatar_Networks_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; ETH Z\u00fcrich",
        "project": "",
        "github": "https://scanimate.is.tue.mpg.de",
        "arxiv": "2104.03313"
    },
    {
        "title": "SCF-Net: Learning Spatial Contextual Features for Large-Scale Point Cloud Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fan_SCF-Net_Learning_Spatial_Contextual_Features_for_Large-Scale_Point_Cloud_Segmentation_CVPR_2021_paper.html",
        "author": "Siqi Fan, Qiulei Dong, Fenghua Zhu, Yisheng Lv, Peijun Ye, Fei-Yue Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_SCF-Net_Learning_Spatial_Contextual_Features_for_Large-Scale_Point_Cloud_Segmentation_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory for Management and Control of Complex Systems, CASIA; National Laboratory of Pattern Recognition, CASIA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SDD-FIQA: Unsupervised Face Image Quality Assessment With Similarity Distribution Distance",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ou_SDD-FIQA_Unsupervised_Face_Image_Quality_Assessment_With_Similarity_Distribution_Distance_CVPR_2021_paper.html",
        "author": "Fu-Zhao Ou, Xingyu Chen, Ruixin Zhang, Yuge Huang, Shaoxin Li, Jilin Li, Yong Li, Liujuan Cao, Yuan-Gen Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ou_SDD-FIQA_Unsupervised_Face_Image_Quality_Assessment_With_Similarity_Distribution_Distance_CVPR_2021_paper.pdf",
        "aff": "School of Informatics, Xiamen University; Youtu Lab, Tencent; School of Computer Science and Engineering, Nanjing University of Science and Technology; School of Computer Science and Cyber Engineering, Guangzhou University",
        "project": "",
        "github": "https://github.com/Slinene/SDD-FIQANeg-Sim",
        "arxiv": ""
    },
    {
        "title": "SE-SSD: Self-Ensembling Single-Stage Object Detector From Point Cloud",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_SE-SSD_Self-Ensembling_Single-Stage_Object_Detector_From_Point_Cloud_CVPR_2021_paper.html",
        "author": "Wu Zheng, Weiliang Tang, Li Jiang, Chi-Wing Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_SE-SSD_Self-Ensembling_Single-Stage_Object_Detector_From_Point_Cloud_CVPR_2021_paper.pdf",
        "aff": "; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/Vegeta2020/SE-SSD",
        "arxiv": ""
    },
    {
        "title": "SG-Net: Spatial Granularity Network for One-Stage Video Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_SG-Net_Spatial_Granularity_Network_for_One-Stage_Video_Instance_Segmentation_CVPR_2021_paper.html",
        "author": "Dongfang Liu, Yiming Cui, Wenbo Tan, Yingjie Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_SG-Net_Spatial_Granularity_Network_for_One-Stage_Video_Instance_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Hangzhou Dian Zi University, China; University of Florida, USA; Purdue University, USA",
        "project": "",
        "github": "https://github.com/goodproj13/SG-Net",
        "arxiv": ""
    },
    {
        "title": "SGCN: Sparse Graph Convolution Network for Pedestrian Trajectory Prediction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_SGCN_Sparse_Graph_Convolution_Network_for_Pedestrian_Trajectory_Prediction_CVPR_2021_paper.html",
        "author": "Liushuai Shi, Le Wang, Chengjiang Long, Sanping Zhou, Mo Zhou, Zhenxing Niu, Gang Hua",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_SGCN_Sparse_Graph_Convolution_Network_for_Pedestrian_Trajectory_Prediction_CVPR_2021_paper.pdf",
        "aff": "School of Software Engineering, Xi'an Jiaotong University; JD Finance America Corporation; Wormpex AI Research; Machine Intelligence Lab, Alibaba Group; Institute of Arti\ufb01cial Intelligence and Robotics, Xi'an Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": "2104.01528"
    },
    {
        "title": "SIPSA-Net: Shift-Invariant Pan Sharpening With Moving Object Alignment for Satellite Imagery",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_SIPSA-Net_Shift-Invariant_Pan_Sharpening_With_Moving_Object_Alignment_for_Satellite_CVPR_2021_paper.html",
        "author": "Jaehyup Lee, Soomin Seo, Munchurl Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_SIPSA-Net_Shift-Invariant_Pan_Sharpening_With_Moving_Object_Alignment_for_Satellite_CVPR_2021_paper.pdf",
        "aff": "Korea Advanced Institue of Science and Technology (KAIST)",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SKFAC: Training Neural Networks With Faster Kronecker-Factored Approximate Curvature",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tang_SKFAC_Training_Neural_Networks_With_Faster_Kronecker-Factored_Approximate_Curvature_CVPR_2021_paper.html",
        "author": "Zedong Tang, Fenlong Jiang, Maoguo Gong, Hao Li, Yue Wu, Fan Yu, Zidong Wang, Min Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_SKFAC_Training_Neural_Networks_With_Faster_Kronecker-Factored_Approximate_Curvature_CVPR_2021_paper.pdf",
        "aff": "School of Electronic and Engineering, Xidian University; Academy of Advanced Interdisciplinary Research, Xidian University; School of Computer Science and Technology, Xidian University; School of Electronic and Engineering, Xidian University; Central Software Institute, 2012 Lab, Huawei Technologies Co. Ltd",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SLADE: A Self-Training Framework for Distance Metric Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Duan_SLADE_A_Self-Training_Framework_for_Distance_Metric_Learning_CVPR_2021_paper.html",
        "author": "Jiali Duan, Yen-Liang Lin, Son Tran, Larry S. Davis, C.-C. Jay Kuo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Duan_SLADE_A_Self-Training_Framework_for_Distance_Metric_Learning_CVPR_2021_paper.pdf",
        "aff": "Amazon; University of Southern California",
        "project": "",
        "github": "",
        "arxiv": "2011.10269"
    },
    {
        "title": "SMD-Nets: Stereo Mixture Density Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tosi_SMD-Nets_Stereo_Mixture_Density_Networks_CVPR_2021_paper.html",
        "author": "Fabio Tosi, Yiyi Liao, Carolin Schmitt, Andreas Geiger",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tosi_SMD-Nets_Stereo_Mixture_Density_Networks_CVPR_2021_paper.pdf",
        "aff": "Autonomous Vision Group, MPI-IS / University of T\u00fcbingen; Department of Computer Science and Engineering (DISI), University of Bologna",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SMPLicit: Topology-Aware Generative Model for Clothed People",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Corona_SMPLicit_Topology-Aware_Generative_Model_for_Clothed_People_CVPR_2021_paper.html",
        "author": "Enric Corona, Albert Pumarola, Guillem Alenya, Gerard Pons-Moll, Francesc Moreno-Noguer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Corona_SMPLicit_Topology-Aware_Generative_Model_for_Clothed_People_CVPR_2021_paper.pdf",
        "aff": "University of T\u00fcbingen, Germany; Max Planck Institute for Informatics, Germany; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain",
        "project": "",
        "github": "http://www.iri.upc.edu/people/ecorona/smplicit/",
        "arxiv": "2103.06871"
    },
    {
        "title": "SMURF: Self-Teaching Multi-Frame Unsupervised RAFT With Full-Image Warping",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Stone_SMURF_Self-Teaching_Multi-Frame_Unsupervised_RAFT_With_Full-Image_Warping_CVPR_2021_paper.html",
        "author": "Austin Stone, Daniel Maurer, Alper Ayvaci, Anelia Angelova, Rico Jonschkowski",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Stone_SMURF_Self-Teaching_Multi-Frame_Unsupervised_RAFT_With_Full-Image_Warping_CVPR_2021_paper.pdf",
        "aff": "Waymo; Robotics at Google",
        "project": "",
        "github": "https://github.com/google-research/google-research/tree/master/smurf",
        "arxiv": "2105.07014"
    },
    {
        "title": "SOE-Net: A Self-Attention and Orientation Encoding Network for Point Cloud Based Place Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xia_SOE-Net_A_Self-Attention_and_Orientation_Encoding_Network_for_Point_Cloud_CVPR_2021_paper.html",
        "author": "Yan Xia, Yusheng Xu, Shuang Li, Rui Wang, Juan Du, Daniel Cremers, Uwe Stilla",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xia_SOE-Net_A_Self-Attention_and_Orientation_Encoding_Network_for_Point_Cloud_CVPR_2021_paper.pdf",
        "aff": "Technical University of Munich; Beijing Institute of Technology",
        "project": "",
        "github": "https://github.com/Yan-Xia/SOE-Net",
        "arxiv": ""
    },
    {
        "title": "SOLD2: Self-Supervised Occlusion-Aware Line Description and Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pautrat_SOLD2_Self-Supervised_Occlusion-Aware_Line_Description_and_Detection_CVPR_2021_paper.html",
        "author": "Remi Pautrat, Juan-Ting Lin, Viktor Larsson, Martin R. Oswald, Marc Pollefeys",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pautrat_SOLD2_Self-Supervised_Occlusion-Aware_Line_Description_and_Detection_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, ETH Zurich2Microsoft Mixed Reality and AI Zurich lab; Department of Computer Science, ETH Zurich",
        "project": "",
        "github": "https://github.com/cvg/SOLD2",
        "arxiv": "2104.03362"
    },
    {
        "title": "SOON: Scenario Oriented Object Navigation With Graph-Based Exploration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_SOON_Scenario_Oriented_Object_Navigation_With_Graph-Based_Exploration_CVPR_2021_paper.html",
        "author": "Fengda Zhu, Xiwen Liang, Yi Zhu, Qizhi Yu, Xiaojun Chang, Xiaodan Liang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_SOON_Scenario_Oriented_Object_Navigation_With_Graph-Based_Exploration_CVPR_2021_paper.pdf",
        "aff": "Zhijiang Laboratory; Sun Yat-sen University; Monash University; University of Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": "2103.17138"
    },
    {
        "title": "SPSG: Self-Supervised Photometric Scene Generation From RGB-D Scans",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_SPSG_Self-Supervised_Photometric_Scene_Generation_From_RGB-D_Scans_CVPR_2021_paper.html",
        "author": "Angela Dai, Yawar Siddiqui, Justus Thies, Julien Valentin, Matthias Niessner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_SPSG_Self-Supervised_Photometric_Scene_Generation_From_RGB-D_Scans_CVPR_2021_paper.pdf",
        "aff": "Google; Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SRDAN: Scale-Aware and Range-Aware Domain Adaptation Network for Cross-Dataset 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_SRDAN_Scale-Aware_and_Range-Aware_Domain_Adaptation_Network_for_Cross-Dataset_3D_CVPR_2021_paper.html",
        "author": "Weichen Zhang, Wen Li, Dong Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_SRDAN_Scale-Aware_and_Range-Aware_Domain_Adaptation_Network_for_Cross-Dataset_3D_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, University of Electronic Science and Technology of China; School of Electrical and Information Engineering, The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SRWarp: Generalized Image Super-Resolution under Arbitrary Transformation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Son_SRWarp_Generalized_Image_Super-Resolution_under_Arbitrary_Transformation_CVPR_2021_paper.html",
        "author": "Sanghyun Son, Kyoung Mu Lee",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Son_SRWarp_Generalized_Image_Super-Resolution_under_Arbitrary_Transformation_CVPR_2021_paper.pdf",
        "aff": "ASRI, Department of ECE, Seoul National University, Seoul, Korea",
        "project": "",
        "github": "",
        "arxiv": "2104.10325"
    },
    {
        "title": "SSAN: Separable Self-Attention Network for Video Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_SSAN_Separable_Self-Attention_Network_for_Video_Representation_Learning_CVPR_2021_paper.html",
        "author": "Xudong Guo, Xun Guo, Yan Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_SSAN_Separable_Self-Attention_Network_for_Video_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2105.13033"
    },
    {
        "title": "SSLayout360: Semi-Supervised Indoor Layout Estimation From 360deg Panorama",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tran_SSLayout360_Semi-Supervised_Indoor_Layout_Estimation_From_360deg_Panorama_CVPR_2021_paper.html",
        "author": "Phi Vu Tran",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tran_SSLayout360_Semi-Supervised_Indoor_Layout_Estimation_From_360deg_Panorama_CVPR_2021_paper.pdf",
        "aff": "Flyreel AI Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SSN: Soft Shadow Network for Image Compositing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sheng_SSN_Soft_Shadow_Network_for_Image_Compositing_CVPR_2021_paper.html",
        "author": "Yichen Sheng, Jianming Zhang, Bedrich Benes",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sheng_SSN_Soft_Shadow_Network_for_Image_Compositing_CVPR_2021_paper.pdf",
        "aff": "Purdue University; Adobe Research",
        "project": "https://shengcn.github.io/SSN",
        "github": "",
        "arxiv": "2007.08211"
    },
    {
        "title": "SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Duke_SSTVOS_Sparse_Spatiotemporal_Transformers_for_Video_Object_Segmentation_CVPR_2021_paper.html",
        "author": "Brendan Duke, Abdalla Ahmed, Christian Wolf, Parham Aarabi, Graham W. Taylor",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Duke_SSTVOS_Sparse_Spatiotemporal_Transformers_for_Video_Object_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Universit \u00b4e de Lyon, INSA-Lyon, LIRIS; University of Toronto, Modiface, Inc.; University of Toronto, Modiface, Inc., Vector Institute; Modiface, Inc.; University of Guelph, Vector Institute",
        "project": "",
        "github": "https://github.com/dukebw/SSTVOS",
        "arxiv": "2101.08833"
    },
    {
        "title": "ST3D: Self-Training for Unsupervised Domain Adaptation on 3D Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_ST3D_Self-Training_for_Unsupervised_Domain_Adaptation_on_3D_Object_Detection_CVPR_2021_paper.html",
        "author": "Jihan Yang, Shaoshuai Shi, Zhe Wang, Hongsheng Li, Xiaojuan Qi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_ST3D_Self-Training_for_Unsupervised_Domain_Adaptation_on_3D_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research; The University of Hong Kong; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/CVMI-Lab/ST3D",
        "arxiv": "2103.05346"
    },
    {
        "title": "STMTrack: Template-Free Visual Tracking With Space-Time Memory Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fu_STMTrack_Template-Free_Visual_Tracking_With_Space-Time_Memory_Networks_CVPR_2021_paper.html",
        "author": "Zhihong Fu, Qingjie Liu, Zehua Fu, Yunhong Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fu_STMTrack_Template-Free_Visual_Tracking_With_Space-Time_Memory_Networks_CVPR_2021_paper.pdf",
        "aff": "Hangzhou Innovation Institute, Beihang University; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China",
        "project": "",
        "github": "https://github.com/fzh0917/STMTrack",
        "arxiv": "2104.00324"
    },
    {
        "title": "STaR: Self-Supervised Tracking and Reconstruction of Rigid Objects in Motion With Neural Rendering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_STaR_Self-Supervised_Tracking_and_Reconstruction_of_Rigid_Objects_in_Motion_CVPR_2021_paper.html",
        "author": "Wentao Yuan, Zhaoyang Lv, Tanner Schmidt, Steven Lovegrove",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_STaR_Self-Supervised_Tracking_and_Reconstruction_of_Rigid_Objects_in_Motion_CVPR_2021_paper.pdf",
        "aff": "Facebook Reality Labs Research; University of Washington",
        "project": "https://wentaoyuan.github.io/star",
        "github": "https://github.com/wentaoyuan/star",
        "arxiv": "2101.01602"
    },
    {
        "title": "SUTD-TrafficQA: A Question Answering Benchmark and an Efficient Network for Video Reasoning Over Traffic Events",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_SUTD-TrafficQA_A_Question_Answering_Benchmark_and_an_Efficient_Network_for_CVPR_2021_paper.html",
        "author": "Li Xu, He Huang, Jun Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_SUTD-TrafficQA_A_Question_Answering_Benchmark_and_an_Efficient_Network_for_CVPR_2021_paper.pdf",
        "aff": "Information Systems Technology and Design, Singapore University of Technology and Design",
        "project": "",
        "github": "https://github.com/SUTDCV/SUTD-TrafficQA",
        "arxiv": ""
    },
    {
        "title": "Safe Local Motion Planning With Self-Supervised Freespace Forecasting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Safe_Local_Motion_Planning_With_Self-Supervised_Freespace_Forecasting_CVPR_2021_paper.html",
        "author": "Peiyun Hu, Aaron Huang, John Dolan, David Held, Deva Ramanan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Safe_Local_Motion_Planning_With_Self-Supervised_Freespace_Forecasting_CVPR_2021_paper.pdf",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University and Argo AI",
        "project": "",
        "github": "https://github.com/peiyunh/ff",
        "arxiv": ""
    },
    {
        "title": "Saliency-Guided Image Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Saliency-Guided_Image_Translation_CVPR_2021_paper.html",
        "author": "Lai Jiang, Mai Xu, Xiaofei Wang, Leonid Sigal",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jiang_Saliency-Guided_Image_Translation_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, University of British Columbia, Vancouver, BC Canada; School of Electronic and Information Engineering, Beihang University, Beijing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scalability vs. Utility: Do We Have To Sacrifice One for the Other in Data Importance Quantification?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jia_Scalability_vs._Utility_Do_We_Have_To_Sacrifice_One_for_CVPR_2021_paper.html",
        "author": "Ruoxi Jia, Fan Wu, Xuehui Sun, Jiacen Xu, David Dao, Bhavya Kailkhura, Ce Zhang, Bo Li, Dawn Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jia_Scalability_vs._Utility_Do_We_Have_To_Sacrifice_One_for_CVPR_2021_paper.pdf",
        "aff": "UC Irvine; ETH Zurich; UIUC; Shanghai Jiao Tong University; UC Berkeley; Lawrence Livermore National Laboratory; Virginia Tech",
        "project": "",
        "github": "https://github.com/AI-secure/Shapley-Study",
        "arxiv": "1911.07128"
    },
    {
        "title": "Scalable Differential Privacy With Sparse Network Finetuning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Scalable_Differential_Privacy_With_Sparse_Network_Finetuning_CVPR_2021_paper.html",
        "author": "Zelun Luo, Daniel J. Wu, Ehsan Adeli, Li Fei-Fei",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Scalable_Differential_Privacy_With_Sparse_Network_Finetuning_CVPR_2021_paper.pdf",
        "aff": "Stanford University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scale-Aware Automatic Augmentation for Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Scale-Aware_Automatic_Augmentation_for_Object_Detection_CVPR_2021_paper.html",
        "author": "Yukang Chen, Yanwei Li, Tao Kong, Lu Qi, Ruihang Chu, Lei Li, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Scale-Aware_Automatic_Augmentation_for_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "ByteDance AI Lab; The Chinese University of Hong Kong, SmartMore; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/Jia-Research-Lab/SA-AutoAug",
        "arxiv": "2103.17220"
    },
    {
        "title": "Scale-Aware Graph Neural Network for Few-Shot Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Scale-Aware_Graph_Neural_Network_for_Few-Shot_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Guo-Sen Xie, Jie Liu, Huan Xiong, Ling Shao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xie_Scale-Aware_Graph_Neural_Network_for_Few-Shot_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Harbin Institute of Technology, China; Inception Institute of Arti\ufb01cial Intelligence, UAE; Mohamed bin Zayed University of AI, UAE",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scale-Localized Abstract Reasoning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Benny_Scale-Localized_Abstract_Reasoning_CVPR_2021_paper.html",
        "author": "Yaniv Benny, Niv Pekar, Lior Wolf",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Benny_Scale-Localized_Abstract_Reasoning_CVPR_2021_paper.pdf",
        "aff": "The School of Computer Science, Tel Aviv University; Facebook AI Research (FAIR); The School of Computer Science, Tel Aviv University",
        "project": "",
        "github": "https://github.com/yanivbenny/MRNet",
        "arxiv": "2009.09405"
    },
    {
        "title": "Scaled-YOLOv4: Scaling Cross Stage Partial Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scaled-YOLOv4_Scaling_Cross_Stage_Partial_Network_CVPR_2021_paper.html",
        "author": "Chien-Yao Wang, Alexey Bochkovskiy, Hong-Yuan Mark Liao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Scaled-YOLOv4_Scaling_Cross_Stage_Partial_Network_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Information Engineering, Providence University, Taiwan; Institute of Information Science, Academia Sinica, Taiwan; Intel Intelligent Systems Lab",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Vaswani_Scaling_Local_Self-Attention_for_Parameter_Efficient_Visual_Backbones_CVPR_2021_paper.html",
        "author": "Ashish Vaswani, Prajit Ramachandran, Aravind Srinivas, Niki Parmar, Blake Hechtman, Jonathon Shlens",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Vaswani_Scaling_Local_Self-Attention_for_Parameter_Efficient_Visual_Backbones_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; Google Research",
        "project": "https://arxiv.org/abs/2103.12731",
        "github": "",
        "arxiv": "2103.12731"
    },
    {
        "title": "Scan2Cap: Context-Aware Dense Captioning in RGB-D Scans",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Scan2Cap_Context-Aware_Dense_Captioning_in_RGB-D_Scans_CVPR_2021_paper.html",
        "author": "Zhenyu Chen, Ali Gholami, Matthias Niessner, Angel X. Chang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Scan2Cap_Context-Aware_Dense_Captioning_in_RGB-D_Scans_CVPR_2021_paper.pdf",
        "aff": "Simon Fraser University; Technical University of Munich",
        "project": "https://daveredrum.github.io/Scan2Cap/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scene Essence",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_Scene_Essence_CVPR_2021_paper.html",
        "author": "Jiayan Qiu, Yiding Yang, Xinchao Wang, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qiu_Scene_Essence_CVPR_2021_paper.pdf",
        "aff": "Stevens Institute of Technology; National University of Singapore; The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scene Text Retrieval via Joint Text Detection and Similarity Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scene_Text_Retrieval_via_Joint_Text_Detection_and_Similarity_Learning_CVPR_2021_paper.html",
        "author": "Hao Wang, Xiang Bai, Mingkun Yang, Shenggao Zhu, Jing Wang, Wenyu Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Scene_Text_Retrieval_via_Joint_Text_Detection_and_Similarity_Learning_CVPR_2021_paper.pdf",
        "aff": "Huazhong University of Science and Technology; Huawei Cloud & AI",
        "project": "",
        "github": "https://github.com/lanfeng4659/STR-TDSL",
        "arxiv": "2104.01552"
    },
    {
        "title": "Scene Text Telescope: Text-Focused Scene Image Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Scene_Text_Telescope_Text-Focused_Scene_Image_Super-Resolution_CVPR_2021_paper.html",
        "author": "Jingye Chen, Bin Li, Xiangyang Xue",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Scene_Text_Telescope_Text-Focused_Scene_Image_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Scene-Aware Generative Network for Human Motion Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scene-Aware_Generative_Network_for_Human_Motion_Synthesis_CVPR_2021_paper.html",
        "author": "Jingbo Wang, Sijie Yan, Bo Dai, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Scene-Aware_Generative_Network_for_Human_Motion_Synthesis_CVPR_2021_paper.pdf",
        "aff": "CUHK - SenseTime Joint Lab, The Chinese University of Hong Kong; Centre of Perceptual and Interactive Intelligence, The Chinese University of Hong Kong; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "",
        "arxiv": "2105.14804"
    },
    {
        "title": "Scene-Intuitive Agent for Remote Embodied Visual Grounding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Scene-Intuitive_Agent_for_Remote_Embodied_Visual_Grounding_CVPR_2021_paper.html",
        "author": "Xiangru Lin, Guanbin Li, Yizhou Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Scene-Intuitive_Agent_for_Remote_Embodied_Visual_Grounding_CVPR_2021_paper.pdf",
        "aff": "Sun Yat-sen University; The University of Hong Kong; The University of Hong Kong and Deepwise AI Lab",
        "project": "",
        "github": "",
        "arxiv": "2103.12944"
    },
    {
        "title": "SceneGen: Learning To Generate Realistic Traffic Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tan_SceneGen_Learning_To_Generate_Realistic_Traffic_Scenes_CVPR_2021_paper.html",
        "author": "Shuhan Tan, Kelvin Wong, Shenlong Wang, Sivabalan Manivasagam, Mengye Ren, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_SceneGen_Learning_To_Generate_Realistic_Traffic_Scenes_CVPR_2021_paper.pdf",
        "aff": "Uber Advanced Technologies Group, University of Toronto; Uber Advanced Technologies Group, Sun Yat-Sen University",
        "project": "",
        "github": "",
        "arxiv": "2101.06541"
    },
    {
        "title": "SceneGraphFusion: Incremental 3D Scene Graph Prediction From RGB-D Sequences",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_SceneGraphFusion_Incremental_3D_Scene_Graph_Prediction_From_RGB-D_Sequences_CVPR_2021_paper.html",
        "author": "Shun-Cheng Wu, Johanna Wald, Keisuke Tateno, Nassir Navab, Federico Tombari",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_SceneGraphFusion_Incremental_3D_Scene_Graph_Prediction_From_RGB-D_Sequences_CVPR_2021_paper.pdf",
        "aff": "Technische Universit \u00a8at M \u00a8unchen; Google",
        "project": "",
        "github": "https://shunchengwu.github.io/SceneGraphFusion",
        "arxiv": ""
    },
    {
        "title": "Searching by Generating: Flexible and Efficient One-Shot NAS With Architecture Generator",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Searching_by_Generating_Flexible_and_Efficient_One-Shot_NAS_With_Architecture_CVPR_2021_paper.html",
        "author": "Sian-Yao Huang, Wei-Ta Chu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Searching_by_Generating_Flexible_and_Efficient_One-Shot_NAS_With_Architecture_CVPR_2021_paper.pdf",
        "aff": "National Cheng Kung University, Tainan, Taiwan",
        "project": "",
        "github": "https://github.com/eric8607242/SGNAS",
        "arxiv": "2103.07289"
    },
    {
        "title": "Searching for Fast Model Families on Datacenter Accelerators",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Searching_for_Fast_Model_Families_on_Datacenter_Accelerators_CVPR_2021_paper.html",
        "author": "Sheng Li, Mingxing Tan, Ruoming Pang, Andrew Li, Liqun Cheng, Quoc V. Le, Norman P. Jouppi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Searching_for_Fast_Model_Families_on_Datacenter_Accelerators_CVPR_2021_paper.pdf",
        "aff": "Google",
        "project": "",
        "github": "https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/tpu",
        "arxiv": "2102.05610"
    },
    {
        "title": "See Through Gradients: Image Batch Recovery via GradInversion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yin_See_Through_Gradients_Image_Batch_Recovery_via_GradInversion_CVPR_2021_paper.html",
        "author": "Hongxu Yin, Arun Mallya, Arash Vahdat, Jose M. Alvarez, Jan Kautz, Pavlo Molchanov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_See_Through_Gradients_Image_Batch_Recovery_via_GradInversion_CVPR_2021_paper.pdf",
        "aff": "NVIDIA",
        "project": "",
        "github": "",
        "arxiv": "2104.07586"
    },
    {
        "title": "Seeing Behind Objects for 3D Multi-Object Tracking in RGB-D Sequences",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Muller_Seeing_Behind_Objects_for_3D_Multi-Object_Tracking_in_RGB-D_Sequences_CVPR_2021_paper.html",
        "author": "Norman Muller, Yu-Shiang Wong, Niloy J. Mitra, Angela Dai, Matthias Niessner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Muller_Seeing_Behind_Objects_for_3D_Multi-Object_Tracking_in_RGB-D_Sequences_CVPR_2021_paper.pdf",
        "aff": "University College London; Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Seeing Out of the Box: End-to-End Pre-Training for Vision-Language Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Seeing_Out_of_the_Box_End-to-End_Pre-Training_for_Vision-Language_Representation_CVPR_2021_paper.html",
        "author": "Zhicheng Huang, Zhaoyang Zeng, Yupan Huang, Bei Liu, Dongmei Fu, Jianlong Fu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Seeing_Out_of_the_Box_End-to-End_Pre-Training_for_Vision-Language_Representation_CVPR_2021_paper.pdf",
        "aff": "Seeing Out of tHe bOx:\nEnd-to-End Pre-training for Vision-Language Representation Learning\nZhicheng Huang1,2*, Zhaoyang Zeng3*, Yupan Huang3*, Bei Liu4, Dongmei Fu1,2, Jianlong Fu4\n1School of Automation and Electrical Engineering, University of Science and Technology Beijing\n2Beijing Engineering Research Center of Industrial Spectrum Imaging\n3Sun Yat-sen University,4Microsoft Research Asia\nAbstract\nWe study joint learning of Convolutional Neural Network\n(CNN) and Transformer for vision-language pre-training\n(VLPT) which aims to learn cross-modal alignments from\nmillions of image-text pairs. State-of-the-art approaches\nextract salient image regions and align regions with words\nstep-by-step. As region-based visual features usually repre-\nsent parts of an im age, it is challenging for existing vision-\nlanguage models to fully understand the semantics from\npaired natural languages. In this paper, we propose SOHO\nto \u201cSeeing Out of t HebOx\u201d that takes a whole image as\ninput, and learns vision-language representation in an end-\nto-end manner. SOHO does not require bounding box anno-\ntations which enables inference 10 times faster than region-\nbased approaches. In particular, SOHO learns to extract\ncomprehensive yet compact image features through a visual\ndictionary (VD) that facilitates cross-modal understanding.\nVD is designed to represent consistent visual abstractions\nof similar semantics. It is updated on-the-\ufb02y and utilized\nin our proposed pre-training task Masked Visual Modeling\n(MVM). We conduct experiments on four well-established\nvision-language tasks by following standard VLPT settings.\nIn particular, SOHO achieves absolute gains of 2.0% R@1\nscore on MSCOCO text retrieval 5k test split, 1.5% accu-\nracy on NLVR2test-P split, 6.7% accuracy on SNLI-VE test\nsplit, respectively.\n1. Introduction\nWith the success of Transformer and self-supervised\nlearning, we have recently witnessed a boosting number\nof research works on cross-modal learning, especially on\nvision-language pre-training (VLPT) [ 7,22,23,27,34,37,\n48]. VLPT models learn better cross-modal representa-\ntion with large-scale easy-accessible image-text pairs. They\nhave established state-of-the-art results in many vision-\n*Equal Contribution. This work was performed when Zhicheng Huang,\nZhaoyang Zeng and Yupan Huang were visiting Microsoft Research Asia\nas research interns.\nTask I: TR\nBaseline:  A couple sit in a   \nboat on the sea.\nOurs: A couple sit on the \nshore next to a boat  on the sea.\nTask II: VQA \nQ: What are the people doing?\nBaseline:  Boating.\nOurs:  Chatting.\u200b\n\u221a\n\u221a\u00d7\u00d7 boat\nwomanman\nFigure 1: Comparisons of SOHO and region-based meth-\nods by top-1 image-to-text retrieval (TR) and visual ques-\ntion answering (VQA) results. Baselines lack global con-\ntext and fail to understand the image. SOHO discovers vi-\nsual clues out of region boxes and infers correct human ac-\ntivities. [Best viewed in color.]\nlanguage tasks, such as visual question answering (VQA)\n[3], image-text retrieval [ 25], natural language for visual\nreasoning (NLVR) [ 35], etc.\nVisual representation plays an important role in VLPT\nmodels. The recent success of VLPT models has been ac-\ncompanied by the usage of region-based image features,\nwhich are extracted by object detectors pre-trained on the\nVisual Genome dataset [ 2]. However, there are three chal-\nlenges to directly utilize region-based image features for\nvision-language understanding. Firstly, regions focus on\nobjects inside bounding boxes while neglecting the contex-\ntual information out of the boxes, which is important for\nrelation understanding and reasoning. For example in Fig-\nure1, we can easily detect \u201cman\u201d, \u201cwoman\u201d and \u201cboat\u201d in\nthe image. However, without the contextual information out\nof these boxes, a model will misunderstand the relation as\n\u201cpeople boating\u201d and result in an incorrect answer for ei-\nther text retrieval or VQA. Secondly, visual understanding\nof images will be limited to the pre-de\ufb01ned categories for\nregions. Thirdly, most region-based image features are ex-\ntracted by a detection model, which will suffer from low\nquality, noise, and over-sampling [ 2] and rely on large-scale\nboxes annotation data. Although some works try to train\ndetection model[ 38,46] with weakly-supervised, the per-\nformance is far below the requirements. Recently, some\n12976\n",
        "project": "",
        "github": "",
        "arxiv": "2104.03135"
    },
    {
        "title": "Seeing in Extra Darkness Using a Deep-Red Flash",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xiong_Seeing_in_Extra_Darkness_Using_a_Deep-Red_Flash_CVPR_2021_paper.html",
        "author": "Jinhui Xiong, Jian Wang, Wolfgang Heidrich, Shree Nayar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xiong_Seeing_in_Extra_Darkness_Using_a_Deep-Red_Flash_CVPR_2021_paper.pdf",
        "aff": "Snap Research; KAUST",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Seeking the Shape of Sound: An Adaptive Framework for Learning Voice-Face Association",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Seeking_the_Shape_of_Sound_An_Adaptive_Framework_for_Learning_CVPR_2021_paper.html",
        "author": "Peisong Wen, Qianqian Xu, Yangbangyan Jiang, Zhiyong Yang, Yuan He, Qingming Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wen_Seeking_the_Shape_of_Sound_An_Adaptive_Framework_for_Learning_CVPR_2021_paper.pdf",
        "aff": "Seeking the Shape of Sound: An Adaptive Framework for\nLearning Voice-Face Association\nPeisong Wen1,2Qianqian Xu1,\u2217Yangbangyan Jiang3,4\nZhiyong Yang3,4Yuan He5Qingming Huang1,2,6,7,\u2217\n1Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS, Beijing, China\n2School of Computer Science and Tech., University of Chinese Academy of Sciences, Beijing, China\n3State Key Laboratory of Info. Security (SKLOIS), Inst. of Info. Engin., CAS, Beijing, China\n4School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China\n5Alibaba Group, Beijing, China\n6BDKM, University of Chinese Academy of Sciences, Beijing, China\n7Peng Cheng Laboratory, Shenzhen, China\n{wenpeisong20z,xuqianqian }@ict.ac.cn {jiangyangbangyan,yangzhiyong }@iie.ac.cn\nheyuan.hy@alibaba-inc.com qmhuang@ucas.ac.cn\nAbstract\nNowadays, we have witnessed the early progress on\nlearning the association between voice and face automati-\ncally, which brings a new wave of studies to the computer vi-\nsion community. However, most of the prior arts along this\nline(a)merely adopt local information to perform modality\nalignment and (b)ignore the diversity of learning dif\ufb01culty\nacross different subjects. In this paper, we propose a novel\nframework to jointly address the above-mentioned issues.\nTargeting at (a), we propose a two-level modality alignment\nloss where both global and local information are consid-\nered. Compared with the existing methods, we introduce a\nglobal loss into the modality alignment process. The global\ncomponent of the loss is driven by the identity classi\ufb01ca-\ntion. Theoretically, we show that minimizing the loss could\nmaximize the distance between embeddings across differ-\nent identities while minimizing the distance between em-\nbeddings belonging to the same identity, in a global sense\n(instead of a mini-batch). Targeting at (b), we propose a\ndynamic reweighting scheme to better explore the hard but\nvaluable identities while \ufb01ltering out the unlearnable iden-\ntities. Experiments show that the proposed method outper-\nforms the previous methods in multiple settings, including\nvoice-face matching, veri\ufb01cation and retrieval.\n1. Introduction\nV oice and face share various potential characteristics,\ne.g., gender, ethnicity, age, which are helpful for identi\ufb01-\n\u2217Corresponding authorscation and matching. Literatures [ 23,10,15] show that hu-\nmans can hear the voice of an unknown person and match\nthe corresponding face with higher accuracy than chance,\nand vice versa. From the perspective of brain science, mul-\ntimodal brain regions exist in the human brain, which pro-\ncess both voices and faces to form person identity represen-\ntations [ 26]. Can machines learn such ability to recognize\nthe face with the same identity only by hearing the voice,\nor recognize the voice from the face? In recent years, re-\nsearchers have started to seek an answer to this interesting\nquestion [ 17,30]. The research of this technology is bene\ufb01-\ncial to many application scenarios, including criminal inves-\ntigation, synthesis or retrieval of human faces from voices\n[19,31,2,3],etc. This task can be specialized as cross-\nmodal matching, veri\ufb01cation and retrieval problems. Dif-\nferent from the audio-visual speech recognition task [ 34],\nthe voice-face association problem is aim to \ufb01nd the iden-\ntity relationship between face and voice, rather than the re-\nlationship between voice and facial action.\nIn recent years, we have witnessed some progress of\nearly studies along this line. As a representative exam-\nple, SVHF [ 17] regards the matching problem as a binary\nclassi\ufb01cation problem, and has achieved comparable perfor-\nmance with human baseline in both voice-to-face matching\nand face-to-voice matching. Bene\ufb01t from the development\nof deep learning and the cross-modal retrieval technology,\nsome recent work [ 11,27,8,33,16] has further veri\ufb01ed\nthe feasibility of this problem through deep metric learning.\nWen et al. [30] boost the performance with multiple super-\nvision.\nDespite previous methods have been able to reach the\n16347\n",
        "project": "",
        "github": "",
        "arxiv": "2103.07293"
    },
    {
        "title": "Seesaw Loss for Long-Tailed Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Seesaw_Loss_for_Long-Tailed_Instance_Segmentation_CVPR_2021_paper.html",
        "author": "Jiaqi Wang, Wenwei Zhang, Yuhang Zang, Yuhang Cao, Jiangmiao Pang, Tao Gong, Kai Chen, Ziwei Liu, Chen Change Loy, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Seesaw_Loss_for_Long-Tailed_Instance_Segmentation_CVPR_2021_paper.pdf",
        "aff": "SenseTime-CUHK Joint Lab, The Chinese University of Hong Kong; S-Lab, Nanyang Technological University; Zhejiang University; University of Science and Technology of China; SenseTime Research",
        "project": "",
        "github": "https://github.com/open-mmlab/mmdetection",
        "arxiv": "2008.10032"
    },
    {
        "title": "Self-Aligned Video Deraining With Transmission-Depth Consistency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Self-Aligned_Video_Deraining_With_Transmission-Depth_Consistency_CVPR_2021_paper.html",
        "author": "Wending Yan, Robby T. Tan, Wenhan Yang, Dengxin Dai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Self-Aligned_Video_Deraining_With_Transmission-Depth_Consistency_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; City University of Hong Kong; National University of Singapore, Yale-NUS College; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-Attention Based Text Knowledge Mining for Text Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wan_Self-Attention_Based_Text_Knowledge_Mining_for_Text_Detection_CVPR_2021_paper.html",
        "author": "Qi Wan, Haoqin Ji, Linlin Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wan_Self-Attention_Based_Text_Knowledge_Mining_for_Text_Detection_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Institute, School of Computer Science and Software Engineering, Shenzhen Institute of Arti\ufb01cial Intelligence and Robotics for Society, Guangdong Key Laboratory of Intelligent Information Processing, Nanhai Avenue 3688, Shenzhen University, Shenzhen, China",
        "project": "",
        "github": "https://github.com/CVI-SZU/STKM",
        "arxiv": ""
    },
    {
        "title": "Self-Generated Defocus Blur Detection via Dual Adversarial Discriminators",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Self-Generated_Defocus_Blur_Detection_via_Dual_Adversarial_Discriminators_CVPR_2021_paper.html",
        "author": "Wenda Zhao, Cai Shang, Huchuan Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Self-Generated_Defocus_Blur_Detection_via_Dual_Adversarial_Discriminators_CVPR_2021_paper.pdf",
        "aff": "School of Information and Communication Engineering, Dalian University of Technology, China",
        "project": "",
        "github": "https://github.com/shangcai1/SG",
        "arxiv": ""
    },
    {
        "title": "Self-Guided and Cross-Guided Learning for Few-Shot Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Self-Guided_and_Cross-Guided_Learning_for_Few-Shot_Segmentation_CVPR_2021_paper.html",
        "author": "Bingfeng Zhang, Jimin Xiao, Terry Qin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Self-Guided_and_Cross-Guided_Learning_for_Few-Shot_Segmentation_CVPR_2021_paper.pdf",
        "aff": "XJTLU; Dinnar Automation Technology; XJTLU, University of Liverpool",
        "project": "",
        "github": "https://github.com/zbf1991/SCL",
        "arxiv": "2103.16129"
    },
    {
        "title": "Self-Point-Flow: Self-Supervised Scene Flow Estimation From Point Clouds With Optimal Transport and Random Walk",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Self-Point-Flow_Self-Supervised_Scene_Flow_Estimation_From_Point_Clouds_With_Optimal_CVPR_2021_paper.html",
        "author": "Ruibo Li, Guosheng Lin, Lihua Xie",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Self-Point-Flow_Self-Supervised_Scene_Flow_Estimation_From_Point_Clouds_With_Optimal_CVPR_2021_paper.pdf",
        "aff": "S-Lab, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Self-Promoted_Prototype_Refinement_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.html",
        "author": "Kai Zhu, Yang Cao, Wei Zhai, Jie Cheng, Zheng-Jun Zha",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Self-Promoted_Prototype_Refinement_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.pdf",
        "aff": "Huawei Technologies Co. Ltd.; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-Supervised 3D Mesh Reconstruction From Single Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Self-Supervised_3D_Mesh_Reconstruction_From_Single_Images_CVPR_2021_paper.html",
        "author": "Tao Hu, Liwei Wang, Xiaogang Xu, Shu Liu, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Self-Supervised_3D_Mesh_Reconstruction_From_Single_Images_CVPR_2021_paper.pdf",
        "aff": "SmartMore; The Chinese University of Hong Kong, SmartMore; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/Jia-Research-Lab",
        "arxiv": ""
    },
    {
        "title": "Self-Supervised Augmentation Consistency for Adapting Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Araslanov_Self-Supervised_Augmentation_Consistency_for_Adapting_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Nikita Araslanov, Stefan Roth",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Araslanov_Self-Supervised_Augmentation_Consistency_for_Adapting_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, TU Darmstadt and hessian.AI; Department of Computer Science, TU Darmstadt",
        "project": "",
        "github": "https://github.com/visinf/da-sac",
        "arxiv": "2105.00097"
    },
    {
        "title": "Self-Supervised Collision Handling via Generative 3D Garment Models for Virtual Try-On",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Santesteban_Self-Supervised_Collision_Handling_via_Generative_3D_Garment_Models_for_Virtual_CVPR_2021_paper.html",
        "author": "Igor Santesteban, Nils Thuerey, Miguel A. Otaduy, Dan Casas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Santesteban_Self-Supervised_Collision_Handling_via_Generative_3D_Garment_Models_for_Virtual_CVPR_2021_paper.pdf",
        "aff": "Universidad Rey Juan Carlos, Spain; Technical University of Munich, Germany",
        "project": "",
        "github": "",
        "arxiv": "2105.06462"
    },
    {
        "title": "Self-Supervised Geometric Perception",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Self-Supervised_Geometric_Perception_CVPR_2021_paper.html",
        "author": "Heng Yang, Wei Dong, Luca Carlone, Vladlen Koltun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Self-Supervised_Geometric_Perception_CVPR_2021_paper.pdf",
        "aff": "Intel Labs; MIT LIDS; CMU RI",
        "project": "",
        "github": "https://github.com/theNded/SGP",
        "arxiv": "2103.03114"
    },
    {
        "title": "Self-Supervised Learning for Semi-Supervised Temporal Action Proposal",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Self-Supervised_Learning_for_Semi-Supervised_Temporal_Action_Proposal_CVPR_2021_paper.html",
        "author": "Xiang Wang, Shiwei Zhang, Zhiwu Qing, Yuanjie Shao, Changxin Gao, Nong Sang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Self-Supervised_Learning_for_Semi-Supervised_Temporal_Action_Proposal_CVPR_2021_paper.pdf",
        "aff": "DAMO Academy, Alibaba Group, China; Key Laboratory of Image Processing and Intelligent Control, School of Arti\ufb01cial Intelligence and Automation, Huazhong University of Science and Technology, China",
        "project": "",
        "github": "https://github.com/wangxiang1230/SSTAP",
        "arxiv": "2104.03214"
    },
    {
        "title": "Self-Supervised Learning of Depth Inference for Multi-View Stereo",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Self-Supervised_Learning_of_Depth_Inference_for_Multi-View_Stereo_CVPR_2021_paper.html",
        "author": "Jiayu Yang, Jose M. Alvarez, Miaomiao Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Self-Supervised_Learning_of_Depth_Inference_for_Multi-View_Stereo_CVPR_2021_paper.pdf",
        "aff": "NVIDIA; Australian National University",
        "project": "",
        "github": "https://github.com/JiayuYANG/Self-supervised-CVP-MVSNet",
        "arxiv": "2104.02972"
    },
    {
        "title": "Self-Supervised Learning on 3D Point Clouds by Learning Discrete Generative Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Eckart_Self-Supervised_Learning_on_3D_Point_Clouds_by_Learning_Discrete_Generative_CVPR_2021_paper.html",
        "author": "Benjamin Eckart, Wentao Yuan, Chao Liu, Jan Kautz",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Eckart_Self-Supervised_Learning_on_3D_Point_Clouds_by_Learning_Discrete_Generative_CVPR_2021_paper.pdf",
        "aff": "NVIDIA; University of Washington",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-Supervised Motion Learning From Static Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Self-Supervised_Motion_Learning_From_Static_Images_CVPR_2021_paper.html",
        "author": "Ziyuan Huang, Shiwei Zhang, Jianwen Jiang, Mingqian Tang, Rong Jin, Marcelo H. Ang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Self-Supervised_Motion_Learning_From_Static_Images_CVPR_2021_paper.pdf",
        "aff": "National University of Singapore, Singapore; Alibaba Group, China",
        "project": "",
        "github": "",
        "arxiv": "2104.00240"
    },
    {
        "title": "Self-Supervised Multi-Frame Monocular Scene Flow",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hur_Self-Supervised_Multi-Frame_Monocular_Scene_Flow_CVPR_2021_paper.html",
        "author": "Junhwa Hur, Stefan Roth",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hur_Self-Supervised_Multi-Frame_Monocular_Scene_Flow_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, TU Darmstadt, hessian.AI; Department of Computer Science, TU Darmstadt",
        "project": "",
        "github": "",
        "arxiv": "2105.02216"
    },
    {
        "title": "Self-Supervised Pillar Motion Learning for Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Self-Supervised_Pillar_Motion_Learning_for_Autonomous_Driving_CVPR_2021_paper.html",
        "author": "Chenxu Luo, Xiaodong Yang, Alan Yuille",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Self-Supervised_Pillar_Motion_Learning_for_Autonomous_Driving_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; QCraft",
        "project": "",
        "github": "",
        "arxiv": "2104.08683"
    },
    {
        "title": "Self-Supervised Simultaneous Multi-Step Prediction of Road Dynamics and Cost Map",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Amirloo_Self-Supervised_Simultaneous_Multi-Step_Prediction_of_Road_Dynamics_and_Cost_Map_CVPR_2021_paper.html",
        "author": "Elmira Amirloo, Mohsen Rohani, Ershad Banijamali, Jun Luo, Pascal Poupart",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Amirloo_Self-Supervised_Simultaneous_Multi-Step_Prediction_of_Road_Dynamics_and_Cost_Map_CVPR_2021_paper.pdf",
        "aff": "Noah\u2019s Ark Lab, Huawei, Toronto, Canada; School of Computer Science, University of Waterloo, Waterloo, Canada",
        "project": "",
        "github": "",
        "arxiv": "2103.01039"
    },
    {
        "title": "Self-Supervised Video GANs: Learning for Appearance Consistency and Motion Coherency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hyun_Self-Supervised_Video_GANs_Learning_for_Appearance_Consistency_and_Motion_Coherency_CVPR_2021_paper.html",
        "author": "Sangeek Hyun, Jihwan Kim, Jae-Pil Heo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hyun_Self-Supervised_Video_GANs_Learning_for_Appearance_Consistency_and_Motion_Coherency_CVPR_2021_paper.pdf",
        "aff": "Sungkyunkwan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-Supervised Video Hashing via Bidirectional Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Self-Supervised_Video_Hashing_via_Bidirectional_Transformers_CVPR_2021_paper.html",
        "author": "Shuyan Li, Xiu Li, Jiwen Lu, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Self-Supervised_Video_Hashing_via_Bidirectional_Transformers_CVPR_2021_paper.pdf",
        "aff": "Department of Automation, Tsinghua University, China; Beijing National Research Center for Information Science and Technology, China; Department of Automation, Tsinghua University, China; Graduate School at Shenzhen, Tsinghua University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Self-Supervised Video Representation Learning by Context and Motion Decoupling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Self-Supervised_Video_Representation_Learning_by_Context_and_Motion_Decoupling_CVPR_2021_paper.html",
        "author": "Lianghua Huang, Yu Liu, Bin Wang, Pan Pan, Yinghui Xu, Rong Jin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Self-Supervised_Video_Representation_Learning_by_Context_and_Motion_Decoupling_CVPR_2021_paper.pdf",
        "aff": "Machine Intelligence Technology Lab, Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": "2104.00862"
    },
    {
        "title": "Self-Supervised Visibility Learning for Novel View Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Self-Supervised_Visibility_Learning_for_Novel_View_Synthesis_CVPR_2021_paper.html",
        "author": "Yujiao Shi, Hongdong Li, Xin Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_Self-Supervised_Visibility_Learning_for_Novel_View_Synthesis_CVPR_2021_paper.pdf",
        "aff": "Australian National University and ACRV; University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": "2103.15407"
    },
    {
        "title": "Self-Supervised Wasserstein Pseudo-Labeling for Semi-Supervised Image Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Taherkhani_Self-Supervised_Wasserstein_Pseudo-Labeling_for_Semi-Supervised_Image_Classification_CVPR_2021_paper.html",
        "author": "Fariborz Taherkhani, Ali Dabouei, Sobhan Soleymani, Jeremy Dawson, Nasser M. Nasrabadi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Taherkhani_Self-Supervised_Wasserstein_Pseudo-Labeling_for_Semi-Supervised_Image_Classification_CVPR_2021_paper.pdf",
        "aff": "West Virginia University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SelfAugment: Automatic Augmentation Policies for Self-Supervised Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Reed_SelfAugment_Automatic_Augmentation_Policies_for_Self-Supervised_Learning_CVPR_2021_paper.html",
        "author": "Colorado J Reed, Sean Metzger, Aravind Srinivas, Trevor Darrell, Kurt Keutzer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Reed_SelfAugment_Automatic_Augmentation_Policies_for_Self-Supervised_Learning_CVPR_2021_paper.pdf",
        "aff": "BAIR, Department of Computer Science, UC Berkeley; Graduate Group in Bioengineering (Berkeley/UCSF), Weill Neurosciences Institute & UCSF Neurological Surgery",
        "project": "",
        "github": "",
        "arxiv": "2009.07724"
    },
    {
        "title": "SelfDoc: Self-Supervised Document Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_SelfDoc_Self-Supervised_Document_Representation_Learning_CVPR_2021_paper.html",
        "author": "Peizhao Li, Jiuxiang Gu, Jason Kuen, Vlad I. Morariu, Handong Zhao, Rajiv Jain, Varun Manjunatha, Hongfu Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_SelfDoc_Self-Supervised_Document_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Brandeis University; Adobe Research",
        "project": "",
        "github": "",
        "arxiv": "2106.03331"
    },
    {
        "title": "SelfSAGCN: Self-Supervised Semantic Alignment for Graph Convolution Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_SelfSAGCN_Self-Supervised_Semantic_Alignment_for_Graph_Convolution_Network_CVPR_2021_paper.html",
        "author": "Xu Yang, Cheng Deng, Zhiyuan Dang, Kun Wei, Junchi Yan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_SelfSAGCN_Self-Supervised_Semantic_Alignment_for_Graph_Convolution_Network_CVPR_2021_paper.pdf",
        "aff": "School of Electronic Engineering, Xidian University, Xian 710071, China; Department of CSE, and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Semantic Audio-Visual Navigation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Semantic_Audio-Visual_Navigation_CVPR_2021_paper.html",
        "author": "Changan Chen, Ziad Al-Halah, Kristen Grauman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Semantic_Audio-Visual_Navigation_CVPR_2021_paper.pdf",
        "aff": "UT Austin, Facebook AI Research; UT Austin",
        "project": "http://vision.cs.utexas.edu/projects/semantic-audio-visual-navigation",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Semantic Image Matting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Semantic_Image_Matting_CVPR_2021_paper.html",
        "author": "Yanan Sun, Chi-Keung Tang, Yu-Wing Tai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Semantic_Image_Matting_CVPR_2021_paper.pdf",
        "aff": "HKUST; Kuaishou Technology",
        "project": "",
        "github": "https://github.com/nowsyn/SIM",
        "arxiv": "2104.08201"
    },
    {
        "title": "Semantic Palette: Guiding Scene Generation With Class Proportions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Le_Moing_Semantic_Palette_Guiding_Scene_Generation_With_Class_Proportions_CVPR_2021_paper.html",
        "author": "Guillaume Le Moing, Tuan-Hung Vu, Himalaya Jain, Patrick Perez, Matthieu Cord",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Le_Moing_Semantic_Palette_Guiding_Scene_Generation_With_Class_Proportions_CVPR_2021_paper.pdf",
        "aff": "Valeo.ai; Inria\u2020",
        "project": "",
        "github": "",
        "arxiv": "2106.01629"
    },
    {
        "title": "Semantic Relation Reasoning for Shot-Stable Few-Shot Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Semantic_Relation_Reasoning_for_Shot-Stable_Few-Shot_Object_Detection_CVPR_2021_paper.html",
        "author": "Chenchen Zhu, Fangyi Chen, Uzair Ahmed, Zhiqiang Shen, Marios Savvides",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Semantic_Relation_Reasoning_for_Shot-Stable_Few-Shot_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2103.01903"
    },
    {
        "title": "Semantic Scene Completion via Integrating Instances and Scene In-the-Loop",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Semantic_Scene_Completion_via_Integrating_Instances_and_Scene_In-the-Loop_CVPR_2021_paper.html",
        "author": "Yingjie Cai, Xuesong Chen, Chao Zhang, Kwan-Yee Lin, Xiaogang Wang, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cai_Semantic_Scene_Completion_via_Integrating_Instances_and_Scene_In-the-Loop_CVPR_2021_paper.pdf",
        "aff": "CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong; SenseTime Research and Tetras.AI; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong; School of CST, Xidian University; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong; Samsung Research Institute China - Beijing (SRC-B)",
        "project": "",
        "github": "https://github.com/yjcaimeow/SISNet",
        "arxiv": "2104.03640"
    },
    {
        "title": "Semantic Segmentation With Generative Models: Semi-Supervised Learning and Strong Out-of-Domain Generalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Semantic_Segmentation_With_Generative_Models_Semi-Supervised_Learning_and_Strong_Out-of-Domain_CVPR_2021_paper.html",
        "author": "Daiqing Li, Junlin Yang, Karsten Kreis, Antonio Torralba, Sanja Fidler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Semantic_Segmentation_With_Generative_Models_Semi-Supervised_Learning_and_Strong_Out-of-Domain_CVPR_2021_paper.pdf",
        "aff": "NVIDIA, Yale University; NVIDIA, University of Toronto, Vector Institute; NVIDIA; MIT",
        "project": "https://nv-tlabs.github.io/semanticGAN/",
        "github": "",
        "arxiv": "2104.05833"
    },
    {
        "title": "Semantic Segmentation for Real Point Cloud Scenes via Bilateral Augmentation and Adaptive Fusion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_Semantic_Segmentation_for_Real_Point_Cloud_Scenes_via_Bilateral_Augmentation_CVPR_2021_paper.html",
        "author": "Shi Qiu, Saeed Anwar, Nick Barnes",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qiu_Semantic_Segmentation_for_Real_Point_Cloud_Scenes_via_Bilateral_Augmentation_CVPR_2021_paper.pdf",
        "aff": "Australian National University, Data61-CSIRO, Australia; Australian National University, Australia",
        "project": "",
        "github": "",
        "arxiv": "2103.07074"
    },
    {
        "title": "Semantic-Aware Knowledge Distillation for Few-Shot Class-Incremental Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheraghian_Semantic-Aware_Knowledge_Distillation_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.html",
        "author": "Ali Cheraghian, Shafin Rahman, Pengfei Fang, Soumava Kumar Roy, Lars Petersson, Mehrtash Harandi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheraghian_Semantic-Aware_Knowledge_Distillation_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.pdf",
        "aff": "North South University, Bangladesh; Australian National University, Data61-CSIRO, Australia; Data61-CSIRO, Australia, Monash University, Australia",
        "project": "",
        "github": "",
        "arxiv": "2103.04059"
    },
    {
        "title": "Semantic-Aware Video Text Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Semantic-Aware_Video_Text_Detection_CVPR_2021_paper.html",
        "author": "Wei Feng, Fei Yin, Xu-Yao Zhang, Cheng-Lin Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Semantic-Aware_Video_Text_Detection_CVPR_2021_paper.pdf",
        "aff": "National Laboratory of Pattern Recognition (NLPR), Institute of Automation of Chinese Academy of Sciences, Beijing 100190, China; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China; CAS Center for Excellence of Brain Science and Intelligence Technology, Beijing 100190, China; National Laboratory of Pattern Recognition (NLPR), Institute of Automation of Chinese Academy of Sciences, Beijing 100190, China; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Semi-Supervised 3D Hand-Object Poses Estimation With Interactions in Time",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Semi-Supervised_3D_Hand-Object_Poses_Estimation_With_Interactions_in_Time_CVPR_2021_paper.html",
        "author": "Shaowei Liu, Hanwen Jiang, Jiarui Xu, Sifei Liu, Xiaolong Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Semi-Supervised_3D_Hand-Object_Poses_Estimation_With_Interactions_in_Time_CVPR_2021_paper.pdf",
        "aff": "UC San Diego; NVIDIA",
        "project": "https://stevenlsw.github.io/Semi-Hand-Object",
        "github": "https://github.com/stevenlsw/Semi-Hand-Object",
        "arxiv": "2106.05266"
    },
    {
        "title": "Semi-Supervised Action Recognition With Temporal Contrastive Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Singh_Semi-Supervised_Action_Recognition_With_Temporal_Contrastive_Learning_CVPR_2021_paper.html",
        "author": "Ankit Singh, Omprakash Chakraborty, Ashutosh Varshney, Rameswar Panda, Rogerio Feris, Kate Saenko, Abir Das",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Singh_Semi-Supervised_Action_Recognition_With_Temporal_Contrastive_Learning_CVPR_2021_paper.pdf",
        "aff": "IIT Kharagpur; MIT-IBM Watson AI Lab, Boston University; MIT-IBM Watson AI Lab; IIT Madras",
        "project": "https://cvir.github.io/TCL/",
        "github": "",
        "arxiv": "2102.02751"
    },
    {
        "title": "Semi-Supervised Domain Adaptation Based on Dual-Level Domain Mixing for Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Semi-Supervised_Domain_Adaptation_Based_on_Dual-Level_Domain_Mixing_for_Semantic_CVPR_2021_paper.html",
        "author": "Shuaijun Chen, Xu Jia, Jianzhong He, Yongjie Shi, Jianzhuang Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Semi-Supervised_Domain_Adaptation_Based_on_Dual-Level_Domain_Mixing_for_Semantic_CVPR_2021_paper.pdf",
        "aff": "Dalian University of Technology; Data Storage and Intelligent Vision Technical Research Dept, Huawei Cloud; Noah\u2019s Ark Lab, Huawei Technologies; Key Lab of Machine Perception, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2103.04705"
    },
    {
        "title": "Semi-Supervised Semantic Segmentation With Cross Pseudo Supervision",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Semi-Supervised_Semantic_Segmentation_With_Cross_Pseudo_Supervision_CVPR_2021_paper.html",
        "author": "Xiaokang Chen, Yuhui Yuan, Gang Zeng, Jingdong Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Semi-Supervised_Semantic_Segmentation_With_Cross_Pseudo_Supervision_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; Key Laboratory of Machine Perception (MOE), Peking University",
        "project": "",
        "github": "",
        "arxiv": "2106.01226"
    },
    {
        "title": "Semi-Supervised Semantic Segmentation With Directional Context-Aware Consistency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lai_Semi-Supervised_Semantic_Segmentation_With_Directional_Context-Aware_Consistency_CVPR_2021_paper.html",
        "author": "Xin Lai, Zhuotao Tian, Li Jiang, Shu Liu, Hengshuang Zhao, Liwei Wang, Jiaya Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lai_Semi-Supervised_Semantic_Segmentation_With_Directional_Context-Aware_Consistency_CVPR_2021_paper.pdf",
        "aff": "SmartMore; The Chinese University of Hong Kong and SmartMore; University of Oxford; The Chinese University of Hong Kong",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Semi-Supervised Synthesis of High-Resolution Editable Textures for 3D Humans",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chaudhuri_Semi-Supervised_Synthesis_of_High-Resolution_Editable_Textures_for_3D_Humans_CVPR_2021_paper.html",
        "author": "Bindita Chaudhuri, Nikolaos Sarafianos, Linda Shapiro, Tony Tung",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chaudhuri_Semi-Supervised_Synthesis_of_High-Resolution_Editable_Textures_for_3D_Humans_CVPR_2021_paper.pdf",
        "aff": "Facebook Reality Labs Research, Sausalito; University of Washington",
        "project": "",
        "github": "",
        "arxiv": "2103.17266"
    },
    {
        "title": "Semi-Supervised Video Deraining With Dynamical Rain Generator",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yue_Semi-Supervised_Video_Deraining_With_Dynamical_Rain_Generator_CVPR_2021_paper.html",
        "author": "Zongsheng Yue, Jianwen Xie, Qian Zhao, Deyu Meng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yue_Semi-Supervised_Video_Deraining_With_Dynamical_Rain_Generator_CVPR_2021_paper.pdf",
        "aff": "Cognitive Computing Lab, Baidu Research, Bellevue, USA; Xi\u2019an Jiaotong University, Xi\u2019an, China; Xi\u2019an Jiaotong University, Xi\u2019an, China and The Macau University of Science and Technology, Macau, China",
        "project": "",
        "github": "https://github.com/zsyOAOA/S2VD",
        "arxiv": "2103.07939"
    },
    {
        "title": "Separating Skills and Concepts for Novel Visual Question Answering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Whitehead_Separating_Skills_and_Concepts_for_Novel_Visual_Question_Answering_CVPR_2021_paper.html",
        "author": "Spencer Whitehead, Hui Wu, Heng Ji, Rogerio Feris, Kate Saenko",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Whitehead_Separating_Skills_and_Concepts_for_Novel_Visual_Question_Answering_CVPR_2021_paper.pdf",
        "aff": "UIUC; MIT-IBM Watson AI Lab, IBM Research; Boston University",
        "project": "",
        "github": "https://github.com/SpencerWhitehead/novelvqa",
        "arxiv": ""
    },
    {
        "title": "Sequence-to-Sequence Contrastive Learning for Text Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Aberdam_Sequence-to-Sequence_Contrastive_Learning_for_Text_Recognition_CVPR_2021_paper.html",
        "author": "Aviad Aberdam, Ron Litman, Shahar Tsiper, Oron Anschel, Ron Slossberg, Shai Mazor, R. Manmatha, Pietro Perona",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Aberdam_Sequence-to-Sequence_Contrastive_Learning_for_Text_Recognition_CVPR_2021_paper.pdf",
        "aff": "Technion; Caltech and AWS; AWS",
        "project": "",
        "github": "",
        "arxiv": "2012.10873"
    },
    {
        "title": "Sequential Graph Convolutional Network for Active Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Caramalau_Sequential_Graph_Convolutional_Network_for_Active_Learning_CVPR_2021_paper.html",
        "author": "Razvan Caramalau, Binod Bhattarai, Tae-Kyun Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Caramalau_Sequential_Graph_Convolutional_Network_for_Active_Learning_CVPR_2021_paper.pdf",
        "aff": "Imperial College London, UK; Imperial College London, UK and KAIST, South Korea",
        "project": "",
        "github": "",
        "arxiv": "2006.10219"
    },
    {
        "title": "SetVAE: Learning Hierarchical Composition for Generative Modeling of Set-Structured Data",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_SetVAE_Learning_Hierarchical_Composition_for_Generative_Modeling_of_Set-Structured_Data_CVPR_2021_paper.html",
        "author": "Jinwoo Kim, Jaehoon Yoo, Juho Lee, Seunghoon Hong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_SetVAE_Learning_Hierarchical_Composition_for_Generative_Modeling_of_Set-Structured_Data_CVPR_2021_paper.pdf",
        "aff": "KAIST",
        "project": "",
        "github": "https://github.com/jw9730/setvae",
        "arxiv": "2103.15619"
    },
    {
        "title": "Sewer-ML: A Multi-Label Sewer Defect Classification Dataset and Benchmark",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Haurum_Sewer-ML_A_Multi-Label_Sewer_Defect_Classification_Dataset_and_Benchmark_CVPR_2021_paper.html",
        "author": "Joakim Bruslund Haurum, Thomas B. Moeslund",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Haurum_Sewer-ML_A_Multi-Label_Sewer_Defect_Classification_Dataset_and_Benchmark_CVPR_2021_paper.pdf",
        "aff": "Visual Analysis and Perception (VAP) Laboratory, Aalborg University, Denmark",
        "project": "http://vap.aau.dk/sewer-ml",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Shallow Feature Matters for Weakly Supervised Object Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wei_Shallow_Feature_Matters_for_Weakly_Supervised_Object_Localization_CVPR_2021_paper.html",
        "author": "Jun Wei, Qin Wang, Zhen Li, Sheng Wang, S. Kevin Zhou, Shuguang Cui",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wei_Shallow_Feature_Matters_for_Weakly_Supervised_Object_Localization_CVPR_2021_paper.pdf",
        "aff": "School of Science and Engineering, The Chinese University of Hong Kong (Shenzhen); Shenzhen Research Institute of Big Data; CryoEM Center, SUSTech; University of Science and Technology of China; Institute of Computing Technology, Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Shape From Sky: Polarimetric Normal Recovery Under the Sky",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ichikawa_Shape_From_Sky_Polarimetric_Normal_Recovery_Under_the_Sky_CVPR_2021_paper.html",
        "author": "Tomoki Ichikawa, Matthew Purri, Ryo Kawahara, Shohei Nobuhara, Kristin Dana, Ko Nishino",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ichikawa_Shape_From_Sky_Polarimetric_Normal_Recovery_Under_the_Sky_CVPR_2021_paper.pdf",
        "aff": "Rutgers University; Kyoto University",
        "project": "https://vision.ist.i.kyoto-u.ac.jp/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Shape and Material Capture at Home",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lichy_Shape_and_Material_Capture_at_Home_CVPR_2021_paper.html",
        "author": "Daniel Lichy, Jiaye Wu, Soumyadip Sengupta, David W. Jacobs",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lichy_Shape_and_Material_Capture_at_Home_CVPR_2021_paper.pdf",
        "aff": "University of Maryland, College Park; University of Washington",
        "project": "",
        "github": "",
        "arxiv": "2104.06397"
    },
    {
        "title": "Shared Cross-Modal Trajectory Prediction for Autonomous Driving",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Choi_Shared_Cross-Modal_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2021_paper.html",
        "author": "Chiho Choi, Joon Hee Choi, Jiachen Li, Srikanth Malla",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Choi_Shared_Cross-Modal_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2021_paper.pdf",
        "aff": "Sungkyunkwan University; Honda Research Institute USA; University of California, Berkeley",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Shelf-Supervised Mesh Prediction in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Shelf-Supervised_Mesh_Prediction_in_the_Wild_CVPR_2021_paper.html",
        "author": "Yufei Ye, Shubham Tulsiani, Abhinav Gupta",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ye_Shelf-Supervised_Mesh_Prediction_in_the_Wild_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; Carnegie Mellon University",
        "project": "https://judyye.github.io/ShSMesh/",
        "github": "",
        "arxiv": "2102.06195"
    },
    {
        "title": "Shot Contrastive Self-Supervised Learning for Scene Boundary Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Shot_Contrastive_Self-Supervised_Learning_for_Scene_Boundary_Detection_CVPR_2021_paper.html",
        "author": "Shixing Chen, Xiaohan Nie, David Fan, Dongqing Zhang, Vimal Bhat, Raffay Hamid",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Shot_Contrastive_Self-Supervised_Learning_for_Scene_Boundary_Detection_CVPR_2021_paper.pdf",
        "aff": "Amazon Prime Video",
        "project": "",
        "github": "",
        "arxiv": "2104.13537"
    },
    {
        "title": "SiamMOT: Siamese Multi-Object Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shuai_SiamMOT_Siamese_Multi-Object_Tracking_CVPR_2021_paper.html",
        "author": "Bing Shuai, Andrew Berneshawi, Xinyu Li, Davide Modolo, Joseph Tighe",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shuai_SiamMOT_Siamese_Multi-Object_Tracking_CVPR_2021_paper.pdf",
        "aff": "Amazon Web Services (AWS)",
        "project": "",
        "github": "",
        "arxiv": "2105.11595"
    },
    {
        "title": "Siamese Natural Language Tracker: Tracking by Natural Language Descriptions With Siamese Trackers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Siamese_Natural_Language_Tracker_Tracking_by_Natural_Language_Descriptions_With_CVPR_2021_paper.html",
        "author": "Qi Feng, Vitaly Ablavsky, Qinxun Bai, Stan Sclaroff",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Siamese_Natural_Language_Tracker_Tracking_by_Natural_Language_Descriptions_With_CVPR_2021_paper.pdf",
        "aff": "Horizon Robotics; Boston University; University of Washington",
        "project": "",
        "github": "https://github.com/fredfung007/snlt",
        "arxiv": "1912.02048"
    },
    {
        "title": "Sign-Agnostic Implicit Learning of Surface Self-Similarities for Shape Modeling and Reconstruction From Raw Point Clouds",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Sign-Agnostic_Implicit_Learning_of_Surface_Self-Similarities_for_Shape_Modeling_and_CVPR_2021_paper.html",
        "author": "Wenbin Zhao, Jiabao Lei, Yuxin Wen, Jianguo Zhang, Kui Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Sign-Agnostic_Implicit_Learning_of_Surface_Self-Similarities_for_Shape_Modeling_and_CVPR_2021_paper.pdf",
        "aff": "South China University of Technology; Department of Computer Science and Engineering, Southern University of Science and Technology; South China University of Technology, Pazhou Lab, Peng Cheng Lab",
        "project": "",
        "github": "",
        "arxiv": "2012.07498"
    },
    {
        "title": "SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_SimPLE_Similar_Pseudo_Label_Exploitation_for_Semi-Supervised_Classification_CVPR_2021_paper.html",
        "author": "Zijian Hu, Zhengyu Yang, Xuefeng Hu, Ram Nevatia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_SimPLE_Similar_Pseudo_Label_Exploitation_for_Semi-Supervised_Classification_CVPR_2021_paper.pdf",
        "aff": "University of Southern California",
        "project": "",
        "github": "github.com/zijian-hu/SimPLE",
        "arxiv": "2103.16725"
    },
    {
        "title": "SimPoE: Simulated Character Control for 3D Human Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_SimPoE_Simulated_Character_Control_for_3D_Human_Pose_Estimation_CVPR_2021_paper.html",
        "author": "Ye Yuan, Shih-En Wei, Tomas Simon, Kris Kitani, Jason Saragih",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_SimPoE_Simulated_Character_Control_for_3D_Human_Pose_Estimation_CVPR_2021_paper.pdf",
        "aff": "Facebook Reality Labs; Carnegie Mellon University",
        "project": "https://www.ye-yuan.com/simpoe",
        "github": "",
        "arxiv": "2104.00683"
    },
    {
        "title": "Simple Copy-Paste Is a Strong Data Augmentation Method for Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ghiasi_Simple_Copy-Paste_Is_a_Strong_Data_Augmentation_Method_for_Instance_CVPR_2021_paper.html",
        "author": "Golnaz Ghiasi, Yin Cui, Aravind Srinivas, Rui Qian, Tsung-Yi Lin, Ekin D. Cubuk, Quoc V. Le, Barret Zoph",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ghiasi_Simple_Copy-Paste_Is_a_Strong_Data_Augmentation_Method_for_Instance_CVPR_2021_paper.pdf",
        "aff": "Google Research, Brain Team",
        "project": "",
        "github": "https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/copy_paste",
        "arxiv": "2012.07177"
    },
    {
        "title": "Simpler Certified Radius Maximization by Propagating Covariances",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhen_Simpler_Certified_Radius_Maximization_by_Propagating_Covariances_CVPR_2021_paper.html",
        "author": "Xingjian Zhen, Rudrasis Chakraborty, Vikas Singh",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhen_Simpler_Certified_Radius_Maximization_by_Propagating_Covariances_CVPR_2021_paper.pdf",
        "aff": "University of Wisconsin-Madison; University of California, Berkeley",
        "project": "https://youtu.be/m1ya2oNf5iE",
        "github": "https://github.com/zhenxingjian/Propagating_Covariance",
        "arxiv": "2104.05888"
    },
    {
        "title": "Simulating Unknown Target Models for Query-Efficient Black-Box Attacks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Simulating_Unknown_Target_Models_for_Query-Efficient_Black-Box_Attacks_CVPR_2021_paper.html",
        "author": "Chen Ma, Li Chen, Jun-Hai Yong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_Simulating_Unknown_Target_Models_for_Query-Efficient_Black-Box_Attacks_CVPR_2021_paper.pdf",
        "aff": "School of Software, BNRist, Tsinghua University, Beijing, China",
        "project": "",
        "github": "https://github.com/machanic/SimulatorAttack",
        "arxiv": "2009.00960"
    },
    {
        "title": "Simultaneously Localize, Segment and Rank the Camouflaged Objects",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Simultaneously_Localize_Segment_and_Rank_the_Camouflaged_Objects_CVPR_2021_paper.html",
        "author": "Yunqiu Lv, Jing Zhang, Yuchao Dai, Aixuan Li, Bowen Liu, Nick Barnes, Deng-Ping Fan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lv_Simultaneously_Localize_Segment_and_Rank_the_Camouflaged_Objects_CVPR_2021_paper.pdf",
        "aff": "Australian National University, Australia; Northwestern Polytechnical University, China; Inception Institute of AI (IIAI), Abu Dhabi, UAE",
        "project": "http://dpfan.net/camouflage",
        "github": "https://github.com/JingZhang617/COD-Rank-Localize-and-Segment",
        "arxiv": "2103.04011"
    },
    {
        "title": "Single Image Depth Prediction With Wavelet Decomposition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ramamonjisoa_Single_Image_Depth_Prediction_With_Wavelet_Decomposition_CVPR_2021_paper.html",
        "author": "Michael Ramamonjisoa, Michael Firman, Jamie Watson, Vincent Lepetit, Daniyar Turmukhambetov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ramamonjisoa_Single_Image_Depth_Prediction_With_Wavelet_Decomposition_CVPR_2021_paper.pdf",
        "aff": "LIGM, IMAGINE, Ecole des Ponts, Univ Gustave Eiffel, CNRS; Niantic",
        "project": "",
        "github": "https://www.github.com/nianticlabs/wavelet-monodepth",
        "arxiv": ""
    },
    {
        "title": "Single Image Reflection Removal With Absorption Effect",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Single_Image_Reflection_Removal_With_Absorption_Effect_CVPR_2021_paper.html",
        "author": "Qian Zheng, Boxin Shi, Jinnan Chen, Xudong Jiang, Ling-Yu Duan, Alex C. Kot",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Single_Image_Reflection_Removal_With_Absorption_Effect_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; NELVT, Department of Computer Science and Technology, Peking University, Beijing, China",
        "project": "",
        "github": "https://github.com/q-zh/absorption",
        "arxiv": ""
    },
    {
        "title": "Single Pair Cross-Modality Super Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shacht_Single_Pair_Cross-Modality_Super_Resolution_CVPR_2021_paper.html",
        "author": "Guy Shacht, Dov Danon, Sharon Fogel, Daniel Cohen-Or",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shacht_Single_Pair_Cross-Modality_Super_Resolution_CVPR_2021_paper.pdf",
        "aff": "Tel Aviv University",
        "project": "",
        "github": "",
        "arxiv": "2004.09965"
    },
    {
        "title": "Single-Shot Freestyle Dance Reenactment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gafni_Single-Shot_Freestyle_Dance_Reenactment_CVPR_2021_paper.html",
        "author": "Oran Gafni, Oron Ashual, Lior Wolf",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gafni_Single-Shot_Freestyle_Dance_Reenactment_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; Facebook AI Research and Tel-Aviv University",
        "project": "",
        "github": "",
        "arxiv": "2012.01158"
    },
    {
        "title": "Single-Stage Instance Shadow Detection With Bidirectional Relation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Single-Stage_Instance_Shadow_Detection_With_Bidirectional_Relation_Learning_CVPR_2021_paper.html",
        "author": "Tianyu Wang, Xiaowei Hu, Chi-Wing Fu, Pheng-Ann Heng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Single-Stage_Instance_Shadow_Detection_With_Bidirectional_Relation_Learning_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy System, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Single-View 3D Object Reconstruction From Shape Priors in Memory",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Single-View_3D_Object_Reconstruction_From_Shape_Priors_in_Memory_CVPR_2021_paper.html",
        "author": "Shuo Yang, Min Xu, Haozhe Xie, Stuart Perry, Jiahao Xia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Single-View_3D_Object_Reconstruction_From_Shape_Priors_in_Memory_CVPR_2021_paper.pdf",
        "aff": "Harbin Institute of Technology; School of Electrical and Data Engineering, University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": "2003.03711"
    },
    {
        "title": "Single-View Robot Pose and Joint Angle Estimation via Render & Compare",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Labbe_Single-View_Robot_Pose_and_Joint_Angle_Estimation_via_Render__CVPR_2021_paper.html",
        "author": "Yann Labbe, Justin Carpentier, Mathieu Aubry, Josef Sivic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Labbe_Single-View_Robot_Pose_and_Joint_Angle_Estimation_via_Render__CVPR_2021_paper.pdf",
        "aff": "ENS/Inria; ENS/Inria and CIIRC CTU; LIGM, ENPC",
        "project": "https://www.di.ens.fr/willow/research/robopose",
        "github": "",
        "arxiv": "2104.09359"
    },
    {
        "title": "Skeleton Merger: An Unsupervised Aligned Keypoint Detector",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Skeleton_Merger_An_Unsupervised_Aligned_Keypoint_Detector_CVPR_2021_paper.html",
        "author": "Ruoxi Shi, Zhengrong Xue, Yang You, Cewu Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_Skeleton_Merger_An_Unsupervised_Aligned_Keypoint_Detector_CVPR_2021_paper.pdf",
        "aff": "Shanghai Jiao Tong University, Qing Yuan Research Institute, MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Qizhi Research Institute; Shanghai Jiao Tong University",
        "project": "",
        "github": "https://github.com/eliphatfs/SkeletonMerger",
        "arxiv": "2103.10814"
    },
    {
        "title": "Sketch, Ground, and Refine: Top-Down Dense Video Captioning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Sketch_Ground_and_Refine_Top-Down_Dense_Video_Captioning_CVPR_2021_paper.html",
        "author": "Chaorui Deng, Shizhe Chen, Da Chen, Yuan He, Qi Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Sketch_Ground_and_Refine_Top-Down_Dense_Video_Captioning_CVPR_2021_paper.pdf",
        "aff": "University of Adelaide; Alibaba Group; University of Adelaide, Alibaba Group; INRIA, Renmin University of China",
        "project": "",
        "github": "github.com/bearcatt/SGR",
        "arxiv": ""
    },
    {
        "title": "Sketch2Model: View-Aware 3D Modeling From Single Free-Hand Sketches",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Sketch2Model_View-Aware_3D_Modeling_From_Single_Free-Hand_Sketches_CVPR_2021_paper.html",
        "author": "Song-Hai Zhang, Yuan-Chen Guo, Qing-Wen Gu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Sketch2Model_View-Aware_3D_Modeling_From_Single_Free-Hand_Sketches_CVPR_2021_paper.pdf",
        "aff": "BNRist, Department of Computer Science and Technology, Tsinghua University, Beijing",
        "project": "",
        "github": "",
        "arxiv": "2105.06663"
    },
    {
        "title": "Skip-Convolutions for Efficient Video Processing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Habibian_Skip-Convolutions_for_Efficient_Video_Processing_CVPR_2021_paper.html",
        "author": "Amirhossein Habibian, Davide Abati, Taco S. Cohen, Babak Ehteshami Bejnordi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Habibian_Skip-Convolutions_for_Efficient_Video_Processing_CVPR_2021_paper.pdf",
        "aff": "Qualcomm AI Research",
        "project": "",
        "github": "",
        "arxiv": "2104.11487"
    },
    {
        "title": "SliceNet: Deep Dense Depth Estimation From a Single Indoor Panorama Using a Slice-Based Representation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pintore_SliceNet_Deep_Dense_Depth_Estimation_From_a_Single_Indoor_Panorama_CVPR_2021_paper.html",
        "author": "Giovanni Pintore, Marco Agus, Eva Almansa, Jens Schneider, Enrico Gobbetti",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pintore_SliceNet_Deep_Dense_Depth_Estimation_From_a_Single_Indoor_Panorama_CVPR_2021_paper.pdf",
        "aff": "Visual Computing, CRS4, Italy; CSE, HBKU, Doha, Qatar",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Slimmable Compressive Autoencoders for Practical Neural Image Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Slimmable_Compressive_Autoencoders_for_Practical_Neural_Image_Compression_CVPR_2021_paper.html",
        "author": "Fei Yang, Luis Herranz, Yongmei Cheng, Mikhail G. Mozerov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Slimmable_Compressive_Autoencoders_for_Practical_Neural_Image_Compression_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Center, Universitat Autonoma de Barcelona, Barcelona, Spain; School of Automation, Northwestern Polytechnical University, Xi\u2019an, China",
        "project": "",
        "github": "",
        "arxiv": "2103.15726"
    },
    {
        "title": "Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Smoothing_the_Disentangled_Latent_Style_Space_for_Unsupervised_Image-to-Image_Translation_CVPR_2021_paper.html",
        "author": "Yahui Liu, Enver Sangineto, Yajing Chen, Linchao Bao, Haoxian Zhang, Nicu Sebe, Bruno Lepri, Wei Wang, Marco De Nadai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Smoothing_the_Disentangled_Latent_Style_Space_for_Unsupervised_Image-to-Image_Translation_CVPR_2021_paper.pdf",
        "aff": "Tencent AI Lab, China; University of Trento, Italy; Fondazione Bruno Kessler, Italy",
        "project": "",
        "github": "",
        "arxiv": "2106.09016"
    },
    {
        "title": "Soft-IntroVAE: Analyzing and Improving the Introspective Variational Autoencoder",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Daniel_Soft-IntroVAE_Analyzing_and_Improving_the_Introspective_Variational_Autoencoder_CVPR_2021_paper.html",
        "author": "Tal Daniel, Aviv Tamar",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Daniel_Soft-IntroVAE_Analyzing_and_Improving_the_Introspective_Variational_Autoencoder_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical Engineering, Technion, Haifa, Israel",
        "project": "http://taldatech.github.io/soft-intro-vae-web",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Soteria: Provable Defense Against Privacy Leakage in Federated Learning From Representation Perspective",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Soteria_Provable_Defense_Against_Privacy_Leakage_in_Federated_Learning_From_CVPR_2021_paper.html",
        "author": "Jingwei Sun, Ang Li, Binghui Wang, Huanrui Yang, Hai Li, Yiran Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Soteria_Provable_Defense_Against_Privacy_Leakage_in_Federated_Learning_From_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, Duke University",
        "project": "",
        "github": "https://github.com/jeremy313/Soteria",
        "arxiv": ""
    },
    {
        "title": "Source-Free Domain Adaptation for Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Source-Free_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Yuang Liu, Wei Zhang, Jun Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Source-Free_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "East China Normal University, Shanghai, China",
        "project": "",
        "github": "",
        "arxiv": "2103.16372"
    },
    {
        "title": "Space-Time Distillation for Video Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_Space-Time_Distillation_for_Video_Super-Resolution_CVPR_2021_paper.html",
        "author": "Zeyu Xiao, Xueyang Fu, Jie Huang, Zhen Cheng, Zhiwei Xiong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xiao_Space-Time_Distillation_for_Video_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Space-Time Neural Irradiance Fields for Free-Viewpoint Video",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xian_Space-Time_Neural_Irradiance_Fields_for_Free-Viewpoint_Video_CVPR_2021_paper.html",
        "author": "Wenqi Xian, Jia-Bin Huang, Johannes Kopf, Changil Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xian_Space-Time_Neural_Irradiance_Fields_for_Free-Viewpoint_Video_CVPR_2021_paper.pdf",
        "aff": "Cornell Tech; Facebook; Virginia Tech",
        "project": "https://video-nerf.github.io",
        "github": "",
        "arxiv": "2011.12950"
    },
    {
        "title": "Sparse Auxiliary Networks for Unified Monocular Depth Prediction and Completion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guizilini_Sparse_Auxiliary_Networks_for_Unified_Monocular_Depth_Prediction_and_Completion_CVPR_2021_paper.html",
        "author": "Vitor Guizilini, Rares Ambrus, Wolfram Burgard, Adrien Gaidon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guizilini_Sparse_Auxiliary_Networks_for_Unified_Monocular_Depth_Prediction_and_Completion_CVPR_2021_paper.pdf",
        "aff": "Toyota Research Institute (TRI), Los Altos, CA",
        "project": "",
        "github": "",
        "arxiv": "2103.16690"
    },
    {
        "title": "Sparse Multi-Path Corrections in Fringe Projection Profilometry",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Sparse_Multi-Path_Corrections_in_Fringe_Projection_Profilometry_CVPR_2021_paper.html",
        "author": "Yu Zhang, Daniel Lau, David Wipf",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Sparse_Multi-Path_Corrections_in_Fringe_Projection_Profilometry_CVPR_2021_paper.pdf",
        "aff": "University of Kentucky; Amazon; Nanjing University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Sparse R-CNN: End-to-End Object Detection With Learnable Proposals",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Sparse_R-CNN_End-to-End_Object_Detection_With_Learnable_Proposals_CVPR_2021_paper.html",
        "author": "Peize Sun, Rufeng Zhang, Yi Jiang, Tao Kong, Chenfeng Xu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Zehuan Yuan, Changhu Wang, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Sparse_R-CNN_End-to-End_Object_Detection_With_Learnable_Proposals_CVPR_2021_paper.pdf",
        "aff": "ByteDance AI Lab; University of California, Berkeley; The University of Hong Kong; Tongji University",
        "project": "",
        "github": "https://github.com/PeizeSun/SparseR-CNN",
        "arxiv": ""
    },
    {
        "title": "Spatial Assembly Networks for Image Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Spatial_Assembly_Networks_for_Image_Representation_Learning_CVPR_2021_paper.html",
        "author": "Yang Li, Shichao Kan, Jianhe Yuan, Wenming Cao, Zhihai He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Spatial_Assembly_Networks_for_Image_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "University of Missouri, MO, USA; Beijing Jiaotong University, Beijing, China; Shenzhen University, Shenzhen, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Spatial Feature Calibration and Temporal Fusion for Effective One-Stage Video Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Spatial_Feature_Calibration_and_Temporal_Fusion_for_Effective_One-Stage_Video_CVPR_2021_paper.html",
        "author": "Minghan Li, Shuai Li, Lida Li, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Spatial_Feature_Calibration_and_Temporal_Fusion_for_Effective_One-Stage_Video_CVPR_2021_paper.pdf",
        "aff": "The HongKong Polytechnic University, DAMO Academy, Alibaba Group; The HongKong Polytechnic University",
        "project": "",
        "github": "https://github.com/MinghanLi/STMask",
        "arxiv": "2104.05606"
    },
    {
        "title": "Spatial-Phase Shallow Learning: Rethinking Face Forgery Detection in Frequency Domain",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Spatial-Phase_Shallow_Learning_Rethinking_Face_Forgery_Detection_in_Frequency_Domain_CVPR_2021_paper.html",
        "author": "Honggu Liu, Xiaodan Li, Wenbo Zhou, Yuefeng Chen, Yuan He, Hui Xue, Weiming Zhang, Nenghai Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Spatial-Phase_Shallow_Learning_Rethinking_Face_Forgery_Detection_in_Frequency_Domain_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group; CAS Key Laboratory of Electromagnetic Space Information, University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2103.01856"
    },
    {
        "title": "Spatial-Temporal Correlation and Topology Learning for Person Re-Identification in Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Spatial-Temporal_Correlation_and_Topology_Learning_for_Person_Re-Identification_in_Videos_CVPR_2021_paper.html",
        "author": "Jiawei Liu, Zheng-Jun Zha, Wei Wu, Kecheng Zheng, Qibin Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Spatial-Temporal_Correlation_and_Topology_Learning_for_Person_Re-Identification_in_Videos_CVPR_2021_paper.pdf",
        "aff": "University of Science and Technology of China, China",
        "project": "",
        "github": "",
        "arxiv": "2104.08241"
    },
    {
        "title": "Spatially Consistent Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Roh_Spatially_Consistent_Representation_Learning_CVPR_2021_paper.html",
        "author": "Byungseok Roh, Wuhyun Shin, Ildoo Kim, Sungwoong Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Roh_Spatially_Consistent_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Kakao Brain",
        "project": "",
        "github": "https://github.com/kakaobrain/scrl",
        "arxiv": "2103.06122"
    },
    {
        "title": "Spatially-Adaptive Pixelwise Networks for Fast Image Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shaham_Spatially-Adaptive_Pixelwise_Networks_for_Fast_Image_Translation_CVPR_2021_paper.html",
        "author": "Tamar Rott Shaham, Michael Gharbi, Richard Zhang, Eli Shechtman, Tomer Michaeli",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shaham_Spatially-Adaptive_Pixelwise_Networks_for_Fast_Image_Translation_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; Technion",
        "project": "",
        "github": "https://tamarott.github.io/ASAPNet_web",
        "arxiv": "2012.02992"
    },
    {
        "title": "Spatially-Invariant Style-Codes Controlled Makeup Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Spatially-Invariant_Style-Codes_Controlled_Makeup_Transfer_CVPR_2021_paper.html",
        "author": "Han Deng, Chu Han, Hongmin Cai, Guoqiang Han, Shengfeng He",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Spatially-Invariant_Style-Codes_Controlled_Makeup_Transfer_CVPR_2021_paper.pdf",
        "aff": "Guangdong Provincial People\u2019s Hospital, Guangdong Academy of Medical Sciences; School of Computer Science and Engineering, South China University of Technology",
        "project": "",
        "github": "https://github.com/makeuptransfer/SCGAN",
        "arxiv": ""
    },
    {
        "title": "Spatially-Varying Outdoor Lighting Estimation From Intrinsics",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Spatially-Varying_Outdoor_Lighting_Estimation_From_Intrinsics_CVPR_2021_paper.html",
        "author": "Yongjie Zhu, Yinda Zhang, Si Li, Boxin Shi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Spatially-Varying_Outdoor_Lighting_Estimation_From_Intrinsics_CVPR_2021_paper.pdf",
        "aff": "Institute for Arti\ufb01cial Intelligence, Peking University; Google; School of Arti\ufb01cial Intelligence, Beijing University of Posts and Telecommunications; NELVT, Department of Computer Science and Technology, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2104.04160"
    },
    {
        "title": "Spatio-temporal Contrastive Domain Adaptation for Action Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_Spatio-temporal_Contrastive_Domain_Adaptation_for_Action_Recognition_CVPR_2021_paper.html",
        "author": "Xiaolin Song, Sicheng Zhao, Jingyu Yang, Huanjing Yue, Pengfei Xu, Runbo Hu, Hua Chai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Spatio-temporal_Contrastive_Domain_Adaptation_for_Action_Recognition_CVPR_2021_paper.pdf",
        "aff": "Tianjin University; Didi Chuxing; University of California, Berkeley",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Spatiotemporal Contrastive Video Representation Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qian_Spatiotemporal_Contrastive_Video_Representation_Learning_CVPR_2021_paper.html",
        "author": "Rui Qian, Tianjian Meng, Boqing Gong, Ming-Hsuan Yang, Huisheng Wang, Serge Belongie, Yin Cui",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qian_Spatiotemporal_Contrastive_Video_Representation_Learning_CVPR_2021_paper.pdf",
        "aff": "Google Research, Cornell University, Cornell Tech; Google Research",
        "project": "",
        "github": "https://github.com/tensorflow/models/tree/master/official",
        "arxiv": "2008.03800"
    },
    {
        "title": "Spatiotemporal Registration for Event-Based Visual Odometry",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Spatiotemporal_Registration_for_Event-Based_Visual_Odometry_CVPR_2021_paper.html",
        "author": "Daqi Liu, Alvaro Parra, Tat-Jun Chin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Spatiotemporal_Registration_for_Event-Based_Visual_Odometry_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, The University of Adelaide",
        "project": "",
        "github": "https://github.com/liudaqikk/RobotEvt",
        "arxiv": "2103.05955"
    },
    {
        "title": "Spherical Confidence Learning for Face Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Spherical_Confidence_Learning_for_Face_Recognition_CVPR_2021_paper.html",
        "author": "Shen Li, Jianqing Xu, Xiaqing Xu, Pengcheng Shen, Shaoxin Li, Bryan Hooi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Spherical_Confidence_Learning_for_Face_Recognition_CVPR_2021_paper.pdf",
        "aff": "Institute of Data Science, National University of Singapore; Aibee; Youtu Lab, Tencent",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ao_SpinNet_Learning_a_General_Surface_Descriptor_for_3D_Point_Cloud_CVPR_2021_paper.html",
        "author": "Sheng Ao, Qingyong Hu, Bo Yang, Andrew Markham, Yulan Guo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ao_SpinNet_Learning_a_General_Surface_Descriptor_for_3D_Point_Cloud_CVPR_2021_paper.pdf",
        "aff": "Hong Kong Polytechnic University; Sun Yat-sen University; University of Oxford; National University of Defense Technology",
        "project": "",
        "github": "https://github.com/QingyongHu/SpinNet",
        "arxiv": "2011.12149"
    },
    {
        "title": "Spk2ImgNet: Learning To Reconstruct Dynamic Scene From Continuous Spike Stream",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Spk2ImgNet_Learning_To_Reconstruct_Dynamic_Scene_From_Continuous_Spike_Stream_CVPR_2021_paper.html",
        "author": "Jing Zhao, Ruiqin Xiong, Hangfan Liu, Jian Zhang, Tiejun Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Spk2ImgNet_Learning_To_Reconstruct_Dynamic_Scene_From_Continuous_Spike_Stream_CVPR_2021_paper.pdf",
        "aff": "School of Electronic Engineering and Computer Science, Peking University, China; Center for Biomedical Image Computing and Analytics, University of Pennsylvania, US; Shenzhen Graduate School, Peking University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Spoken Moments: Learning Joint Audio-Visual Representations From Video Descriptions",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Monfort_Spoken_Moments_Learning_Joint_Audio-Visual_Representations_From_Video_Descriptions_CVPR_2021_paper.html",
        "author": "Mathew Monfort, SouYoung Jin, Alexander Liu, David Harwath, Rogerio Feris, James Glass, Aude Oliva",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Monfort_Spoken_Moments_Learning_Joint_Audio-Visual_Representations_From_Video_Descriptions_CVPR_2021_paper.pdf",
        "aff": "IBM Research; UT Austin; MIT",
        "project": "http://moments.csail.mit.edu/spoken.html",
        "github": "",
        "arxiv": "2105.04489"
    },
    {
        "title": "Square Root Bundle Adjustment for Large-Scale Reconstruction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Demmel_Square_Root_Bundle_Adjustment_for_Large-Scale_Reconstruction_CVPR_2021_paper.html",
        "author": "Nikolaus Demmel, Christiane Sommer, Daniel Cremers, Vladyslav Usenko",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Demmel_Square_Root_Bundle_Adjustment_for_Large-Scale_Reconstruction_CVPR_2021_paper.pdf",
        "aff": "Technical University of Munich",
        "project": "",
        "github": "",
        "arxiv": "2103.01843"
    },
    {
        "title": "StEP: Style-Based Encoder Pre-Training for Multi-Modal Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Meshry_StEP_Style-Based_Encoder_Pre-Training_for_Multi-Modal_Image_Synthesis_CVPR_2021_paper.html",
        "author": "Moustafa Meshry, Yixuan Ren, Larry S. Davis, Abhinav Shrivastava",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Meshry_StEP_Style-Based_Encoder_Pre-Training_for_Multi-Modal_Image_Synthesis_CVPR_2021_paper.pdf",
        "aff": "University of Maryland, College Park",
        "project": "",
        "github": "",
        "arxiv": "2104.07098"
    },
    {
        "title": "Stable View Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Riegler_Stable_View_Synthesis_CVPR_2021_paper.html",
        "author": "Gernot Riegler, Vladlen Koltun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Riegler_Stable_View_Synthesis_CVPR_2021_paper.pdf",
        "aff": "Intel Labs",
        "project": "",
        "github": "https://github.com/intel-isl/StableViewSynthesis",
        "arxiv": "2011.07233"
    },
    {
        "title": "StablePose: Learning 6D Object Poses From Geometrically Stable Patches",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_StablePose_Learning_6D_Object_Poses_From_Geometrically_Stable_Patches_CVPR_2021_paper.html",
        "author": "Yifei Shi, Junwen Huang, Xin Xu, Yifan Zhang, Kai Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_StablePose_Learning_6D_Object_Poses_From_Geometrically_Stable_Patches_CVPR_2021_paper.pdf",
        "aff": "National University of Defense Technology",
        "project": "",
        "github": "",
        "arxiv": "2102.09334"
    },
    {
        "title": "Stay Positive: Non-Negative Image Synthesis for Augmented Reality",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Stay_Positive_Non-Negative_Image_Synthesis_for_Augmented_Reality_CVPR_2021_paper.html",
        "author": "Katie Luo, Guandao Yang, Wenqi Xian, Harald Haraldsson, Bharath Hariharan, Serge Belongie",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Stay_Positive_Non-Negative_Image_Synthesis_for_Augmented_Reality_CVPR_2021_paper.pdf",
        "aff": "Cornell University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chibane_Stereo_Radiance_Fields_SRF_Learning_View_Synthesis_for_Sparse_Views_CVPR_2021_paper.html",
        "author": "Julian Chibane, Aayush Bansal, Verica Lazova, Gerard Pons-Moll",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chibane_Stereo_Radiance_Fields_SRF_Learning_View_Synthesis_for_Sparse_Views_CVPR_2021_paper.pdf",
        "aff": "University of T\u00fcbingen, Germany; Max Planck Institute for Informatics, Germany; Carnegie Mellon University, USA",
        "project": "https://virtualhumans.mpi-inf.mpg.de/srf/",
        "github": "",
        "arxiv": "2104.06935"
    },
    {
        "title": "StereoPIFu: Depth Aware Clothed Human Digitization via Stereo Vision",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_StereoPIFu_Depth_Aware_Clothed_Human_Digitization_via_Stereo_Vision_CVPR_2021_paper.html",
        "author": "Yang Hong, Juyong Zhang, Boyi Jiang, Yudong Guo, Ligang Liu, Hujun Bao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_StereoPIFu_Depth_Aware_Clothed_Human_Digitization_via_Stereo_Vision_CVPR_2021_paper.pdf",
        "aff": "Zhejiang University; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2104.05289"
    },
    {
        "title": "StickyPillars: Robust and Efficient Feature Matching on Point Clouds Using Graph Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fischer_StickyPillars_Robust_and_Efficient_Feature_Matching_on_Point_Clouds_Using_CVPR_2021_paper.html",
        "author": "Kai Fischer, Martin Simon, Florian Olsner, Stefan Milz, Horst-Michael Gross, Patrick Mader",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fischer_StickyPillars_Robust_and_Efficient_Feature_Matching_on_Point_Clouds_Using_CVPR_2021_paper.pdf",
        "aff": "Spleenlab GmbH, Saalburg-Ebersdorf, Germany; Valeo Schalter und Sensoren GmbH, Kronach, Germany; Software Engineering for Safety-Critical Systems, Ilmenau University of Technology, Germany; Neuroinformatics and Cognitive Robotics Lab, Ilmenau University of Technology, Germany",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Stochastic Image-to-Video Synthesis Using cINNs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dorkenwald_Stochastic_Image-to-Video_Synthesis_Using_cINNs_CVPR_2021_paper.html",
        "author": "Michael Dorkenwald, Timo Milbich, Andreas Blattmann, Robin Rombach, Konstantinos G. Derpanis, Bjorn Ommer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dorkenwald_Stochastic_Image-to-Video_Synthesis_Using_cINNs_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, Ryerson University, Canada; IWR/HCI, Heidelberg University, Germany",
        "project": "https://bit.ly/3dg90fV",
        "github": "",
        "arxiv": "2105.04551"
    },
    {
        "title": "Stochastic Whitening Batch Normalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Stochastic_Whitening_Batch_Normalization_CVPR_2021_paper.html",
        "author": "Shengdong Zhang, Ehsan Nezhadarya, Homa Fashandi, Jiayi Liu, Darin Graham, Mohak Shah",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Stochastic_Whitening_Batch_Normalization_CVPR_2021_paper.pdf",
        "aff": "Toronto AI Lab, LG Electronics Canada; America R&D Lab, LG Electronics USA",
        "project": "",
        "github": "",
        "arxiv": "2106.04413"
    },
    {
        "title": "Strengthen Learning Tolerance for Weakly Supervised Object Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Strengthen_Learning_Tolerance_for_Weakly_Supervised_Object_Localization_CVPR_2021_paper.html",
        "author": "Guangyu Guo, Junwei Han, Fang Wan, Dingwen Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Strengthen_Learning_Tolerance_for_Weakly_Supervised_Object_Localization_CVPR_2021_paper.pdf",
        "aff": "The Brain and Artificial Intelligence Laboratory, Northwestern Polytechnical University, Xi'an, China; University of Chinese Academy of Sciences, Beijing, China",
        "project": "",
        "github": "https://nwpu-brainlab.gitee.io/index_en",
        "arxiv": ""
    },
    {
        "title": "StruMonoNet: Structure-Aware Monocular 3D Prediction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_StruMonoNet_Structure-Aware_Monocular_3D_Prediction_CVPR_2021_paper.html",
        "author": "Zhenpei Yang, Li Erran Li, Qixing Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_StruMonoNet_Structure-Aware_Monocular_3D_Prediction_CVPR_2021_paper.pdf",
        "aff": "Columbia University, Amazon; The University of Texas at Austin",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Structure-Aware Face Clustering on a Large-Scale Graph With 107 Nodes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Structure-Aware_Face_Clustering_on_a_Large-Scale_Graph_With_107_Nodes_CVPR_2021_paper.html",
        "author": "Shuai Shen, Wanhua Li, Zheng Zhu, Guan Huang, Dalong Du, Jiwen Lu, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_Structure-Aware_Face_Clustering_on_a_Large-Scale_Graph_With_107_Nodes_CVPR_2021_paper.pdf",
        "aff": "XForwardAI; Department of Automation, Tsinghua University, China; Beijing National Research Center for Information Science and Technology, China",
        "project": "",
        "github": "https://sstzal.github.io/STAR-FC/",
        "arxiv": ""
    },
    {
        "title": "Structured Multi-Level Interaction Network for Video Moment Localization via Language Query",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Structured_Multi-Level_Interaction_Network_for_Video_Moment_Localization_via_Language_CVPR_2021_paper.html",
        "author": "Hao Wang, Zheng-Jun Zha, Liang Li, Dong Liu, Jiebo Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Structured_Multi-Level_Interaction_Network_for_Video_Moment_Localization_via_Language_CVPR_2021_paper.pdf",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; University of Rochester; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Structured Scene Memory for Vision-Language Navigation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Structured_Scene_Memory_for_Vision-Language_Navigation_CVPR_2021_paper.html",
        "author": "Hanqing Wang, Wenguan Wang, Wei Liang, Caiming Xiong, Jianbing Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Structured_Scene_Memory_for_Vision-Language_Navigation_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; Inception Institute of Arti\ufb01cial Intelligence; Salesforce Research; Beijing Institute of Technology",
        "project": "",
        "github": "https://github.com/HanqingWangAI/SSM-VLN",
        "arxiv": "2103.03454"
    },
    {
        "title": "Student-Teacher Learning From Clean Inputs to Noisy Inputs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Student-Teacher_Learning_From_Clean_Inputs_to_Noisy_Inputs_CVPR_2021_paper.html",
        "author": "Guanzhe Hong, Zhiyuan Mao, Xiaojun Lin, Stanley H. Chan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Student-Teacher_Learning_From_Clean_Inputs_to_Noisy_Inputs_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Computer Engineering, Purdue University, West Lafayette, Indiana USA",
        "project": "",
        "github": "",
        "arxiv": "2103.07600"
    },
    {
        "title": "Style-Aware Normalized Loss for Improving Arbitrary Style Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Style-Aware_Normalized_Loss_for_Improving_Arbitrary_Style_Transfer_CVPR_2021_paper.html",
        "author": "Jiaxin Cheng, Ayush Jaiswal, Yue Wu, Pradeep Natarajan, Prem Natarajan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Style-Aware_Normalized_Loss_for_Improving_Arbitrary_Style_Transfer_CVPR_2021_paper.pdf",
        "aff": "USC Information Sciences Institute; Amazon Alexa Natural Understanding",
        "project": "",
        "github": "",
        "arxiv": "2104.10064"
    },
    {
        "title": "Style-Based Point Generator With Adversarial Rendering for Point Cloud Completion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Style-Based_Point_Generator_With_Adversarial_Rendering_for_Point_Cloud_Completion_CVPR_2021_paper.html",
        "author": "Chulin Xie, Chuxin Wang, Bo Zhang, Hao Yang, Dong Chen, Fang Wen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xie_Style-Based_Point_Generator_With_Adversarial_Rendering_for_Point_Cloud_Completion_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; University of Illinois at Urbana-Champaign; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2103.02535"
    },
    {
        "title": "StyleMeUp: Towards Style-Agnostic Sketch-Based Image Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sain_StyleMeUp_Towards_Style-Agnostic_Sketch-Based_Image_Retrieval_CVPR_2021_paper.html",
        "author": "Aneeshan Sain, Ayan Kumar Bhunia, Yongxin Yang, Tao Xiang, Yi-Zhe Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sain_StyleMeUp_Towards_Style-Agnostic_Sketch-Based_Image_Retrieval_CVPR_2021_paper.pdf",
        "aff": "SketchX, CVSSP, University of Surrey, United Kingdom.",
        "project": "",
        "github": "",
        "arxiv": "2103.15706"
    },
    {
        "title": "StyleMix: Separating Content and Style for Enhanced Data Augmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_StyleMix_Separating_Content_and_Style_for_Enhanced_Data_Augmentation_CVPR_2021_paper.html",
        "author": "Minui Hong, Jinwoo Choi, Gunhee Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_StyleMix_Separating_Content_and_Style_for_Enhanced_Data_Augmentation_CVPR_2021_paper.pdf",
        "aff": "Seoul National University, Seoul, Korea",
        "project": "",
        "github": "https://github.com/alsdml/StyleMix",
        "arxiv": ""
    },
    {
        "title": "StylePeople: A Generative Model of Fullbody Human Avatars",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Grigorev_StylePeople_A_Generative_Model_of_Fullbody_Human_Avatars_CVPR_2021_paper.html",
        "author": "Artur Grigorev, Karim Iskakov, Anastasia Ianina, Renat Bashirov, Ilya Zakharkin, Alexander Vakhitov, Victor Lempitsky",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Grigorev_StylePeople_A_Generative_Model_of_Fullbody_Human_Avatars_CVPR_2021_paper.pdf",
        "aff": "Samsung AI Center, Moscow; Skolkovo Institute of Science and Technology, Moscow; Samsung AI Center, Moscow",
        "project": "",
        "github": "https://saic-violet.github.io/style-people",
        "arxiv": "2104.08363"
    },
    {
        "title": "StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_StyleSpace_Analysis_Disentangled_Controls_for_StyleGAN_Image_Generation_CVPR_2021_paper.html",
        "author": "Zongze Wu, Dani Lischinski, Eli Shechtman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_StyleSpace_Analysis_Disentangled_Controls_for_StyleGAN_Image_Generation_CVPR_2021_paper.pdf",
        "aff": "Hebrew University; Adobe Research",
        "project": "",
        "github": "",
        "arxiv": "2011.12799"
    },
    {
        "title": "Stylized Neural Painting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zou_Stylized_Neural_Painting_CVPR_2021_paper.html",
        "author": "Zhengxia Zou, Tianyang Shi, Shuang Qiu, Yi Yuan, Zhenwei Shi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zou_Stylized_Neural_Painting_CVPR_2021_paper.pdf",
        "aff": "NetEase Fuxi AI Lab; University of Michigan, Ann Arbor; Beihang University",
        "project": "",
        "github": "https://jiupinjia.github.io/neuralpainter/",
        "arxiv": "2011.08114"
    },
    {
        "title": "SuperMix: Supervising the Mixing Data Augmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dabouei_SuperMix_Supervising_the_Mixing_Data_Augmentation_CVPR_2021_paper.html",
        "author": "Ali Dabouei, Sobhan Soleymani, Fariborz Taherkhani, Nasser M. Nasrabadi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dabouei_SuperMix_Supervising_the_Mixing_Data_Augmentation_CVPR_2021_paper.pdf",
        "aff": "West Virginia University",
        "project": "",
        "github": "https://github.com/alldbi/SuperMix",
        "arxiv": "2003.05034"
    },
    {
        "title": "SurFree: A Fast Surrogate-Free Black-Box Attack",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Maho_SurFree_A_Fast_Surrogate-Free_Black-Box_Attack_CVPR_2021_paper.html",
        "author": "Thibault Maho, Teddy Furon, Erwan Le Merrer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Maho_SurFree_A_Fast_Surrogate-Free_Black-Box_Attack_CVPR_2021_paper.pdf",
        "aff": "Univ. Rennes, Inria, CNRS, IRISA, Rennes, France",
        "project": "",
        "github": "https://github.com/t-maho/SurFree",
        "arxiv": "2011.12807"
    },
    {
        "title": "Surrogate Gradient Field for Latent Space Manipulation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Surrogate_Gradient_Field_for_Latent_Space_Manipulation_CVPR_2021_paper.html",
        "author": "Minjun Li, Yanghua Jin, Huachun Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Surrogate_Gradient_Field_for_Latent_Space_Manipulation_CVPR_2021_paper.pdf",
        "aff": "Preferred Networks",
        "project": "",
        "github": "",
        "arxiv": "2104.09065"
    },
    {
        "title": "SwiftNet: Real-Time Video Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_SwiftNet_Real-Time_Video_Object_Segmentation_CVPR_2021_paper.html",
        "author": "Haochen Wang, Xiaolong Jiang, Haibing Ren, Yao Hu, Song Bai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_SwiftNet_Real-Time_Video_Object_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Alibaba Youku Cognitive and Intelligent Lab; Alibaba Youku Cognitive and Intelligent Lab, University of Oxford",
        "project": "",
        "github": "https://github.com/haochenheheda/SwiftNet",
        "arxiv": "2102.04604"
    },
    {
        "title": "Synthesize-It-Classifier: Learning a Generative Classifier Through Recurrent Self-Analysis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pal_Synthesize-It-Classifier_Learning_a_Generative_Classifier_Through_Recurrent_Self-Analysis_CVPR_2021_paper.html",
        "author": "Arghya Pal, Raphael C.-W. Phan, KokSheik Wong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pal_Synthesize-It-Classifier_Learning_a_Generative_Classifier_Through_Recurrent_Self-Analysis_CVPR_2021_paper.pdf",
        "aff": "School of Information Technology, Monash University, Malaysia campus",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Synthesizing_Long-Term_3D_Human_Motion_and_Interaction_in_3D_Scenes_CVPR_2021_paper.html",
        "author": "Jiashun Wang, Huazhe Xu, Jingwei Xu, Sifei Liu, Xiaolong Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Synthesizing_Long-Term_3D_Human_Motion_and_Interaction_in_3D_Scenes_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley; UC San Diego; NVIDIA; Shanghai Jiao Tong University",
        "project": "https://jiashunwang.github.io/Long-term-Motion-in-3D-Scenes",
        "github": "",
        "arxiv": "2012.05522"
    },
    {
        "title": "T-vMF Similarity for Regularizing Intra-Class Feature Distribution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kobayashi_T-vMF_Similarity_for_Regularizing_Intra-Class_Feature_Distribution_CVPR_2021_paper.html",
        "author": "Takumi Kobayashi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kobayashi_T-vMF_Similarity_for_Regularizing_Intra-Class_Feature_Distribution_CVPR_2021_paper.pdf",
        "aff": "National Institute of Advanced Industrial Science and Technology, Japan",
        "project": "",
        "github": "https://github.com/tk1980/tvMF",
        "arxiv": ""
    },
    {
        "title": "T2VLAD: Global-Local Sequence Alignment for Text-Video Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_T2VLAD_Global-Local_Sequence_Alignment_for_Text-Video_Retrieval_CVPR_2021_paper.html",
        "author": "Xiaohan Wang, Linchao Zhu, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_T2VLAD_Global-Local_Sequence_Alignment_for_Text-Video_Retrieval_CVPR_2021_paper.pdf",
        "aff": "Zhejiang University, Baidu Research; ReLER, University of Technology Sydney",
        "project": "",
        "github": "",
        "arxiv": "2104.10054"
    },
    {
        "title": "TAP: Text-Aware Pre-Training for Text-VQA and Text-Caption",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_TAP_Text-Aware_Pre-Training_for_Text-VQA_and_Text-Caption_CVPR_2021_paper.html",
        "author": "Zhengyuan Yang, Yijuan Lu, Jianfeng Wang, Xi Yin, Dinei Florencio, Lijuan Wang, Cha Zhang, Lei Zhang, Jiebo Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_TAP_Text-Aware_Pre-Training_for_Text-VQA_and_Text-Caption_CVPR_2021_paper.pdf",
        "aff": "University of Rochester; Microsoft Corporation",
        "project": "",
        "github": "",
        "arxiv": "2012.04638"
    },
    {
        "title": "TDN: Temporal Difference Networks for Efficient Action Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_TDN_Temporal_Difference_Networks_for_Efficient_Action_Recognition_CVPR_2021_paper.html",
        "author": "Limin Wang, Zhan Tong, Bin Ji, Gangshan Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_TDN_Temporal_Difference_Networks_for_Efficient_Action_Recognition_CVPR_2021_paper.pdf",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "project": "",
        "github": "https://github.com/MCG-NJU/TDN",
        "arxiv": "2012.10071"
    },
    {
        "title": "TPCN: Temporal Point Cloud Networks for Motion Forecasting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ye_TPCN_Temporal_Point_Cloud_Networks_for_Motion_Forecasting_CVPR_2021_paper.html",
        "author": "Maosheng Ye, Tongyi Cao, Qifeng Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ye_TPCN_Temporal_Point_Cloud_Networks_for_Motion_Forecasting_CVPR_2021_paper.pdf",
        "aff": "Hong Kong University of Science and Technology; DEEPROUTE.AI",
        "project": "",
        "github": "",
        "arxiv": "2103.03067"
    },
    {
        "title": "TSGCNet: Discriminative Geometric Feature Learning With Two-Stream Graph Convolutional Network for 3D Dental Model Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_TSGCNet_Discriminative_Geometric_Feature_Learning_With_Two-Stream_Graph_Convolutional_Network_CVPR_2021_paper.html",
        "author": "Lingming Zhang, Yue Zhao, Deyu Meng, Zhiming Cui, Chenqiang Gao, Xinbo Gao, Chunfeng Lian, Dinggang Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_TSGCNet_Discriminative_Geometric_Feature_Learning_With_Two-Stream_Graph_Convolutional_Network_CVPR_2021_paper.pdf",
        "aff": "School of Biomedical Engineering, ShanghaiTech University, Shanghai, China; The University of Hong Kong, Hong Kong, China; Xi\u2019an Jiaotong University, Xi\u2019an, China; Chongqing University of Posts and Telecommunications, Chongqing, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Tackling the Ill-Posedness of Super-Resolution Through Adaptive Target Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jo_Tackling_the_Ill-Posedness_of_Super-Resolution_Through_Adaptive_Target_Generation_CVPR_2021_paper.html",
        "author": "Younghyun Jo, Seoung Wug Oh, Peter Vajda, Seon Joo Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jo_Tackling_the_Ill-Posedness_of_Super-Resolution_Through_Adaptive_Target_Generation_CVPR_2021_paper.pdf",
        "aff": "Yonsei University; Adobe Research; Facebook",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Taming Transformers for High-Resolution Image Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Esser_Taming_Transformers_for_High-Resolution_Image_Synthesis_CVPR_2021_paper.html",
        "author": "Patrick Esser, Robin Rombach, Bjorn Ommer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Esser_Taming_Transformers_for_High-Resolution_Image_Synthesis_CVPR_2021_paper.pdf",
        "aff": "Heidelberg Collaboratory for Image Processing, IWR, Heidelberg University, Germany",
        "project": "https://git.io/JLlvY",
        "github": "",
        "arxiv": "2012.09841"
    },
    {
        "title": "Tangent Space Backpropagation for 3D Transformation Groups",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Teed_Tangent_Space_Backpropagation_for_3D_Transformation_Groups_CVPR_2021_paper.html",
        "author": "Zachary Teed, Jia Deng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Teed_Tangent_Space_Backpropagation_for_3D_Transformation_Groups_CVPR_2021_paper.pdf",
        "aff": "Princeton University",
        "project": "",
        "github": "https://github.com/princeton-vl/lietorch",
        "arxiv": "2103.12032"
    },
    {
        "title": "Target-Aware Object Discovery and Association for Unsupervised Video Multi-Object Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Target-Aware_Object_Discovery_and_Association_for_Unsupervised_Video_Multi-Object_Segmentation_CVPR_2021_paper.html",
        "author": "Tianfei Zhou, Jianwu Li, Xueyi Li, Ling Shao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Target-Aware_Object_Discovery_and_Association_for_Unsupervised_Video_Multi-Object_Segmentation_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Technology, Beijing Institute of Technology, China; Computer Vision Laboratory, ETH Zurich, Switzerland; Inception Institute of Arti\ufb01cial Intelligence, UAE",
        "project": "",
        "github": "",
        "arxiv": "2104.04782"
    },
    {
        "title": "Task Programming: Learning Data Efficient Behavior Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Task_Programming_Learning_Data_Efficient_Behavior_Representations_CVPR_2021_paper.html",
        "author": "Jennifer J. Sun, Ann Kennedy, Eric Zhan, David J. Anderson, Yisong Yue, Pietro Perona",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Task_Programming_Learning_Data_Efficient_Behavior_Representations_CVPR_2021_paper.pdf",
        "aff": "Caltech; Northwestern University",
        "project": "https://sites.google.com/view/task-programming",
        "github": "",
        "arxiv": "2011.13917"
    },
    {
        "title": "Task-Aware Variational Adversarial Active Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Task-Aware_Variational_Adversarial_Active_Learning_CVPR_2021_paper.html",
        "author": "Kwanyoung Kim, Dongwon Park, Kwang In Kim, Se Young Chun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Task-Aware_Variational_Adversarial_Active_Learning_CVPR_2021_paper.pdf",
        "aff": "Dept of Bio & Brain Eng, KAIST; Dept of EE, UNIST; Dept of ECE, INMC, Seoul National University, South Korea; Dept of CSE, UNIST",
        "project": "",
        "github": "",
        "arxiv": "2002.04709"
    },
    {
        "title": "Taskology: Utilizing Task Relations at Scale",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Taskology_Utilizing_Task_Relations_at_Scale_CVPR_2021_paper.html",
        "author": "Yao Lu, Soren Pirk, Jan Dlabal, Anthony Brohan, Ankita Pasad, Zhao Chen, Vincent Casser, Anelia Angelova, Ariel Gordon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_Taskology_Utilizing_Task_Relations_at_Scale_CVPR_2021_paper.pdf",
        "aff": "Toyota Technological Institute at Chicago; Waymo LLC; Robotics at Google; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2005.07289"
    },
    {
        "title": "Teachers Do More Than Teach: Compressing Image-to-Image Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jin_Teachers_Do_More_Than_Teach_Compressing_Image-to-Image_Models_CVPR_2021_paper.html",
        "author": "Qing Jin, Jian Ren, Oliver J. Woodford, Jiazhuo Wang, Geng Yuan, Yanzhi Wang, Sergey Tulyakov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jin_Teachers_Do_More_Than_Teach_Compressing_Image-to-Image_Models_CVPR_2021_paper.pdf",
        "aff": "Northeastern University, USA; Snap Inc.",
        "project": "",
        "github": "https://github.com/snap-research/CAT",
        "arxiv": "2103.03467"
    },
    {
        "title": "TearingNet: Point Cloud Autoencoder To Learn Topology-Friendly Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pang_TearingNet_Point_Cloud_Autoencoder_To_Learn_Topology-Friendly_Representations_CVPR_2021_paper.html",
        "author": "Jiahao Pang, Duanshun Li, Dong Tian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pang_TearingNet_Point_Cloud_Autoencoder_To_Learn_Topology-Friendly_Representations_CVPR_2021_paper.pdf",
        "aff": "InterDigital, Princeton, NJ, USA",
        "project": "",
        "github": "",
        "arxiv": "2006.10187"
    },
    {
        "title": "TediGAN: Text-Guided Diverse Face Image Generation and Manipulation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xia_TediGAN_Text-Guided_Diverse_Face_Image_Generation_and_Manipulation_CVPR_2021_paper.html",
        "author": "Weihao Xia, Yujiu Yang, Jing-Hao Xue, Baoyuan Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xia_TediGAN_Text-Guided_Diverse_Face_Image_Generation_and_Manipulation_CVPR_2021_paper.pdf",
        "aff": "Department of Statistical Science, University College London, UK; School of Data Science, Chinese University of Hongkong, Shenzhen, China; Secure Computing Lab of Big Data, Shenzhen Research Institute of Big Data, Shenzhen, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, China",
        "project": "",
        "github": "https://github.com/weihaox/TediGAN",
        "arxiv": "2012.03308"
    },
    {
        "title": "Temporal Action Segmentation From Timestamp Supervision",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Temporal_Action_Segmentation_From_Timestamp_Supervision_CVPR_2021_paper.html",
        "author": "Zhe Li, Yazan Abu Farha, Jurgen Gall",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Temporal_Action_Segmentation_From_Timestamp_Supervision_CVPR_2021_paper.pdf",
        "aff": "University of Bonn, Germany",
        "project": "",
        "github": "",
        "arxiv": "2103.06669"
    },
    {
        "title": "Temporal Context Aggregation Network for Temporal Action Proposal Refinement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qing_Temporal_Context_Aggregation_Network_for_Temporal_Action_Proposal_Refinement_CVPR_2021_paper.html",
        "author": "Zhiwu Qing, Haisheng Su, Weihao Gan, Dongliang Wang, Wei Wu, Xiang Wang, Yu Qiao, Junjie Yan, Changxin Gao, Nong Sang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qing_Temporal_Context_Aggregation_Network_for_Temporal_Action_Proposal_Refinement_CVPR_2021_paper.pdf",
        "aff": "Key Laboratory of Image Processing and Intelligent Control, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2103.13141"
    },
    {
        "title": "Temporal Modulation Network for Controllable Space-Time Video Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Temporal_Modulation_Network_for_Controllable_Space-Time_Video_Super-Resolution_CVPR_2021_paper.html",
        "author": "Gang Xu, Jun Xu, Zhen Li, Liang Wang, Xing Sun, Ming-Ming Cheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Temporal_Modulation_Network_for_Controllable_Space-Time_Video_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "College of Computer Science, Nankai University, Tianjin, China; Youtu Lab., Tencent, Shanghai, China; School of Statistics and Data Science, Nankai University, Tianjin, China; National Lab of Pattern Recognition, Institute of Automation, CAS, Beijing, China",
        "project": "",
        "github": "https://github.com/CS-GangXu/TMNet",
        "arxiv": "2104.10642"
    },
    {
        "title": "Temporal Query Networks for Fine-Grained Video Understanding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Temporal_Query_Networks_for_Fine-Grained_Video_Understanding_CVPR_2021_paper.html",
        "author": "Chuhan Zhang, Ankush Gupta, Andrew Zisserman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Temporal_Query_Networks_for_Fine-Grained_Video_Understanding_CVPR_2021_paper.pdf",
        "aff": "University of Oxford; DeepMind, London",
        "project": "https://www.robots.ox.ac.uk/~vgg/research/tqn/",
        "github": "",
        "arxiv": "2104.09496"
    },
    {
        "title": "Temporal-Relational CrossTransformers for Few-Shot Action Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Perrett_Temporal-Relational_CrossTransformers_for_Few-Shot_Action_Recognition_CVPR_2021_paper.html",
        "author": "Toby Perrett, Alessandro Masullo, Tilo Burghardt, Majid Mirmehdi, Dima Damen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Perrett_Temporal-Relational_CrossTransformers_for_Few-Shot_Action_Recognition_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, University of Bristol, UK",
        "project": "",
        "github": "https://github.com/tobyperrett/TRX",
        "arxiv": "2101.06184"
    },
    {
        "title": "Temporally-Weighted Hierarchical Clustering for Unsupervised Action Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sarfraz_Temporally-Weighted_Hierarchical_Clustering_for_Unsupervised_Action_Segmentation_CVPR_2021_paper.html",
        "author": "Saquib Sarfraz, Naila Murray, Vivek Sharma, Ali Diba, Luc Van Gool, Rainer Stiefelhagen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sarfraz_Temporally-Weighted_Hierarchical_Clustering_for_Unsupervised_Action_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; KU Leuven, ETH Zurich; MIT, Harvard Medical School; Karlsruhe Institute of Technology, Daimler TSS; Karlsruhe Institute of Technology; KU Leuven",
        "project": "",
        "github": "https://github.com/ssarfraz/FINCH-Clustering/tree/master/TW-FINCH",
        "arxiv": "2103.11264"
    },
    {
        "title": "TesseTrack: End-to-End Learnable Multi-Person Articulated 3D Pose Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Reddy_TesseTrack_End-to-End_Learnable_Multi-Person_Articulated_3D_Pose_Tracking_CVPR_2021_paper.html",
        "author": "N Dinesh Reddy, Laurent Guigues, Leonid Pishchulin, Jayan Eledath, Srinivasa G. Narasimhan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Reddy_TesseTrack_End-to-End_Learnable_Multi-Person_Articulated_3D_Pose_Tracking_CVPR_2021_paper.pdf",
        "aff": "Amazon; Carnegie Mellon University",
        "project": "http://www.cs.cmu.edu/~ILIM/projects/IM/TesseTrack/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Test-Time Fast Adaptation for Dynamic Scene Deblurring via Meta-Auxiliary Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chi_Test-Time_Fast_Adaptation_for_Dynamic_Scene_Deblurring_via_Meta-Auxiliary_Learning_CVPR_2021_paper.html",
        "author": "Zhixiang Chi, Yang Wang, Yuanhao Yu, Jin Tang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chi_Test-Time_Fast_Adaptation_for_Dynamic_Scene_Deblurring_via_Meta-Auxiliary_Learning_CVPR_2021_paper.pdf",
        "aff": "Noah\u2019s Ark Lab, Huawei Technologies; Noah\u2019s Ark Lab, Huawei Technologies; University of Manitoba, Canada",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "TextOCR: Towards Large-Scale End-to-End Reasoning for Arbitrary-Shaped Scene Text",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Singh_TextOCR_Towards_Large-Scale_End-to-End_Reasoning_for_Arbitrary-Shaped_Scene_Text_CVPR_2021_paper.html",
        "author": "Amanpreet Singh, Guan Pang, Mandy Toh, Jing Huang, Wojciech Galuba, Tal Hassner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Singh_TextOCR_Towards_Large-Scale_End-to-End_Reasoning_for_Arbitrary-Shaped_Scene_Text_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research",
        "project": "https://textvqa.org/textocr",
        "github": "",
        "arxiv": "2105.05486"
    },
    {
        "title": "The Affective Growth of Computer Vision",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Su_The_Affective_Growth_of_Computer_Vision_CVPR_2021_paper.html",
        "author": "Norman Makoto Su, David J. Crandall",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Su_The_Affective_Growth_of_Computer_Vision_CVPR_2021_paper.pdf",
        "aff": "Luddy School of Informatics, Computing, and Engineering, Indiana University Bloomington",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "The Blessings of Unlabeled Background in Untrimmed Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_The_Blessings_of_Unlabeled_Background_in_Untrimmed_Videos_CVPR_2021_paper.html",
        "author": "Yuan Liu, Jingyuan Chen, Zhenfang Chen, Bing Deng, Jianqiang Huang, Hanwang Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_The_Blessings_of_Unlabeled_Background_in_Untrimmed_Videos_CVPR_2021_paper.pdf",
        "aff": "Nanyang Technological University; Alibaba Group; The University of Hong Kong",
        "project": "",
        "github": "https://github.com/liuyuancv/WTAL-blessing",
        "arxiv": "2103.13183"
    },
    {
        "title": "The Heterogeneity Hypothesis: Finding Layer-Wise Differentiated Network Architectures",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_The_Heterogeneity_Hypothesis_Finding_Layer-Wise_Differentiated_Network_Architectures_CVPR_2021_paper.html",
        "author": "Yawei Li, Wen Li, Martin Danelljan, Kai Zhang, Shuhang Gu, Luc Van Gool, Radu Timofte",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_The_Heterogeneity_Hypothesis_Finding_Layer-Wise_Differentiated_Network_Architectures_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Z\u00fcrich; Computer Vision Lab, ETH Z\u00fcrich, KU Leuven; UESTC; The University of Sydney",
        "project": "",
        "github": "https://github.com/ofsoundof/Heterogeneity_Hypothesis.git",
        "arxiv": "2006.16242"
    },
    {
        "title": "The Lottery Ticket Hypothesis for Object Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Girish_The_Lottery_Ticket_Hypothesis_for_Object_Recognition_CVPR_2021_paper.html",
        "author": "Sharath Girish, Shishira R Maiya, Kamal Gupta, Hao Chen, Larry S. Davis, Abhinav Shrivastava",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Girish_The_Lottery_Ticket_Hypothesis_for_Object_Recognition_CVPR_2021_paper.pdf",
        "aff": "University of Maryland, College Park",
        "project": "",
        "github": "",
        "arxiv": "2012.04643"
    },
    {
        "title": "The Lottery Tickets Hypothesis for Supervised and Self-Supervised Pre-Training in Computer Vision Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_The_Lottery_Tickets_Hypothesis_for_Supervised_and_Self-Supervised_Pre-Training_in_CVPR_2021_paper.html",
        "author": "Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang, Michael Carbin, Zhangyang Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_The_Lottery_Tickets_Hypothesis_for_Supervised_and_Self-Supervised_Pre-Training_in_CVPR_2021_paper.pdf",
        "aff": "The Lottery Tickets Hypothesis for Supervised and Self-supervised\nPre-training in Computer Vision Models\nTianlong Chen1, Jonathan Frankle2, Shiyu Chang3, Sijia Liu3,4, Yang Zhang3,\nMichael Carbin2, Zhangyang Wang1\n1University of Texas at Austin,2MIT CSAIL3MIT-IBM Watson AI Lab,4Michigan State University\n{tianlong.chen,atlaswang }@utexas.edu, {jfrankle,mcarbin }@csail.mit.edu,\n{shiyu.chang,yang.zhang2 }@ibm.com,liusiji5@msu.ed\nAbstract\nThe computer vision world has been re-gaining en-\nthusiasm in various pre-trained models, including both\nclassical ImageNet supervised pre-training and recently\nemerged self-supervised pre-training such as simCLR [ 10]\nand MoCo [ 40]. Pre-trained weights often boost a wide\nrange of downstream tasks including classi\ufb01cation, detection,\nand segmentation. Latest studies suggest that pre-training\nbene\ufb01ts from gigantic model capacity [ 11]. We are hereby\ncurious and ask: after pre-training, does a pre-trained model\nindeed have to stay large for its downstream transferability?\nIn this paper, we examine supervised and self-supervised\npre-trained models through the lens of the lottery ticket hy-\npothesis (LTH) [ 31]. LTH identi\ufb01es highly sparse matching\nsubnetworks that can be trained in isolation from (nearly)\nscratch yet still reach the full models\u2019 performance. We\nextend the scope of LTH and question whether matching\nsubnetworks still exist in pre-trained computer vision mod-\nels, that enjoy the same downstream transfer performance.\nOur extensive experiments convey an overall positive mes-\nsage: from all pre-trained weights obtained by ImageNet\nclassi\ufb01cation, simCLR, and MoCo, we are consistently able\nto locate such matching subnetworks at 59.04% to96.48%\nsparsity that transfer universally to multiple downstream\ntasks, whose performance see no degradation compared to\nusing full pre-trained weights. Further analyses reveal that\nsubnetworks found from different pre-training tend to yield\ndiverse mask structures and perturbation sensitivities. We\nconclude that the core LTH observations remain generally\nrelevant in the pre-training paradigm of computer vision, but\nmore delicate discussions are needed in some cases. Codes\nand pre-trained models will be made available at: https:\n//github.com/VITA-Group/CV_LTH_Pre-training .\n1. Introduction\nDeep neural networks pre-trained on large-scale datasets\nprevail as general-purpose feature extractors [ 23]. Moving\nbeyond the most traditional greedy unsupervised pre-training\n[2], the most popular pre-training in computer vision (CV)\nIterative \nPruning\nDense Model Matching SubnetworksPre-trainingClassification\nDetection\nSegmentationTransfer Learning\nCat ?\nFigure 1. Overview of our work paradigm: from pre-trained CV\nmodels (both supervised and self-supervised), we study the exis-\ntence of matching subnetworks that are transferable to many down-\nstream tasks, with little performance degradation compared to using\nfull pre-trained weights. We \ufb01nd task-agnostic, universally trans-\nferable subnetworks at pre-trained initialization, for classi\ufb01cation ,\ndetection , and segmentation tasks.\nis arguably to train the model for supervised classi\ufb01cation\non ImageNet [ 18]. Such supervised pre-training enables\nthe network to learn a hierarchy of generalizable features\n[46]; it is widely acknowledged [ 36] to not only bene\ufb01t the\nsubsequent \ufb01ne-tuning on other visual classi\ufb01cation datasets\n(especially in small datasets and few-shot learning [ 71,74]),\nbut also to accelerate/improve the training for different, more\ncomplicated types of downstream vision tasks, such as object\ndetection and semantic segmentation [ 63,41].\nSeveral state-of-the-art self-supervised pre-training , such\nas simCLR [ 10,11] and MoCo [ 40,16], have demonstrated\nthat it is instead possible to use unlabeled data in pre-training.\nTheir methods refer to no actual labels in pre-training, but\ninstead leverage self-generated pseudo labels [ 22,25] or con-\ntrasting augmented views [ 10]. Impressively, self-supervised\npre-training yields pre-trained weights with comparable or\neven better transferability and generalization, for various\ndownstream tasks, compared to their supervised pre-training\ncounterparts.\nA few recent efforts have shown to successfully scale\nuppre-training in CV . That is perhaps most natural for self-\n16306\n",
        "project": "",
        "github": "",
        "arxiv": "2012.06908"
    },
    {
        "title": "The Multi-Temporal Urban Development SpaceNet Dataset",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Van_Etten_The_Multi-Temporal_Urban_Development_SpaceNet_Dataset_CVPR_2021_paper.html",
        "author": "Adam Van Etten, Daniel Hogan, Jesus Martinez Manso, Jacob Shermeyer, Nicholas Weir, Ryan Lewis",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Van_Etten_The_Multi-Temporal_Urban_Development_SpaceNet_Dataset_CVPR_2021_paper.pdf",
        "aff": "Amazon; Planet; In-Q-Tel CosmiQ Works; Capella Space",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "The Neural Tangent Link Between CNN Denoisers and Non-Local Filters",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tachella_The_Neural_Tangent_Link_Between_CNN_Denoisers_and_Non-Local_Filters_CVPR_2021_paper.html",
        "author": "Julian Tachella, Junqi Tang, Mike Davies",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tachella_The_Neural_Tangent_Link_Between_CNN_Denoisers_and_Non-Local_Filters_CVPR_2021_paper.pdf",
        "aff": "School of Engineering, University of Edinburgh",
        "project": "",
        "github": "https://gitlab.com/Tachella/neural_tangent_denoiser",
        "arxiv": "2006.02379"
    },
    {
        "title": "The Spatially-Correlative Loss for Various Image Translation Tasks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_The_Spatially-Correlative_Loss_for_Various_Image_Translation_Tasks_CVPR_2021_paper.html",
        "author": "Chuanxia Zheng, Tat-Jen Cham, Jianfei Cai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_The_Spatially-Correlative_Loss_for_Various_Image_Translation_Tasks_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; Department of Data Science & AI, Monash University, Australia",
        "project": "",
        "github": "https://github.com/lyndonzheng/F-LSeSim",
        "arxiv": "2104.00854"
    },
    {
        "title": "The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Watson_The_Temporal_Opportunist_Self-Supervised_Multi-Frame_Monocular_Depth_CVPR_2021_paper.html",
        "author": "Jamie Watson, Oisin Mac Aodha, Victor Prisacariu, Gabriel Brostow, Michael Firman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Watson_The_Temporal_Opportunist_Self-Supervised_Multi-Frame_Monocular_Depth_CVPR_2021_paper.pdf",
        "aff": "Niantic; UCL; University of Edinburgh; University of Oxford",
        "project": "",
        "github": "www.github.com/nianticlabs/manydepth",
        "arxiv": "2104.14540"
    },
    {
        "title": "The Translucent Patch: A Physical and Universal Attack on Object Detectors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zolfi_The_Translucent_Patch_A_Physical_and_Universal_Attack_on_Object_CVPR_2021_paper.html",
        "author": "Alon Zolfi, Moshe Kravchik, Yuval Elovici, Asaf Shabtai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zolfi_The_Translucent_Patch_A_Physical_and_Universal_Attack_on_Object_CVPR_2021_paper.pdf",
        "aff": "Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev",
        "project": "",
        "github": "",
        "arxiv": "2012.12528"
    },
    {
        "title": "There Is More Than Meets the Eye: Self-Supervised Multi-Object Detection and Tracking With Sound by Distilling Multimodal Knowledge",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Valverde_There_Is_More_Than_Meets_the_Eye_Self-Supervised_Multi-Object_Detection_CVPR_2021_paper.html",
        "author": "Francisco Rivera Valverde, Juana Valeria Hurtado, Abhinav Valada",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Valverde_There_Is_More_Than_Meets_the_Eye_Self-Supervised_Multi-Object_Detection_CVPR_2021_paper.pdf",
        "aff": "University of Freiburg",
        "project": "",
        "github": "",
        "arxiv": "2103.01353"
    },
    {
        "title": "Thinking Fast and Slow: Efficient Text-to-Visual Retrieval With Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Miech_Thinking_Fast_and_Slow_Efficient_Text-to-Visual_Retrieval_With_Transformers_CVPR_2021_paper.html",
        "author": "Antoine Miech, Jean-Baptiste Alayrac, Ivan Laptev, Josef Sivic, Andrew Zisserman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Miech_Thinking_Fast_and_Slow_Efficient_Text-to-Visual_Retrieval_With_Transformers_CVPR_2021_paper.pdf",
        "aff": "CIIRC CTU; DeepMind; VGG Oxford; ENS/Inria",
        "project": "",
        "github": "",
        "arxiv": "2103.16553"
    },
    {
        "title": "Three Birds with One Stone: Multi-Task Temporal Action Detection via Recycling Temporal Annotations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Three_Birds_with_One_Stone_Multi-Task_Temporal_Action_Detection_via_CVPR_2021_paper.html",
        "author": "Zhihui Li, Lina Yao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Three_Birds_with_One_Stone_Multi-Task_Temporal_Action_Detection_via_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Engineering, University of New South Wales",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Three Ways To Improve Semantic Segmentation With Self-Supervised Depth Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hoyer_Three_Ways_To_Improve_Semantic_Segmentation_With_Self-Supervised_Depth_Estimation_CVPR_2021_paper.html",
        "author": "Lukas Hoyer, Dengxin Dai, Yuhua Chen, Adrian Koring, Suman Saha, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hoyer_Three_Ways_To_Improve_Semantic_Segmentation_With_Self-Supervised_Depth_Estimation_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; ETH Zurich & KU Leuven; University of Bonn",
        "project": "",
        "github": "https://github.com/lhoyer/improving_segmentation_with_selfsupervised_depth",
        "arxiv": "2012.10782"
    },
    {
        "title": "Time Adaptive Recurrent Neural Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kag_Time_Adaptive_Recurrent_Neural_Network_CVPR_2021_paper.html",
        "author": "Anil Kag, Venkatesh Saligrama",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kag_Time_Adaptive_Recurrent_Neural_Network_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, Boston University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Time Lens: Event-Based Video Frame Interpolation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tulyakov_Time_Lens_Event-Based_Video_Frame_Interpolation_CVPR_2021_paper.html",
        "author": "Stepan Tulyakov, Daniel Gehrig, Stamatios Georgoulis, Julius Erbach, Mathias Gehrig, Yuanyou Li, Davide Scaramuzza",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tulyakov_Time_Lens_Event-Based_Video_Frame_Interpolation_CVPR_2021_paper.pdf",
        "aff": "Huawei Technologies, Zurich Research Center; Dept. of Informatics, Univ. of Zurich and Dept. of Neuroinformatics, Univ. of Zurich and ETH Zurich",
        "project": "http://rpg.ifi.uzh.ch/timelens",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "To the Point: Efficient 3D Object Detection in the Range Image With Graph Convolution Kernels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chai_To_the_Point_Efficient_3D_Object_Detection_in_the_Range_CVPR_2021_paper.html",
        "author": "Yuning Chai, Pei Sun, Jiquan Ngiam, Weiyue Wang, Benjamin Caine, Vijay Vasudevan, Xiao Zhang, Dragomir Anguelov",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chai_To_the_Point_Efficient_3D_Object_Detection_in_the_Range_CVPR_2021_paper.pdf",
        "aff": "Google Brain; Waymo LLC",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Topological Planning With Transformers for Vision-and-Language Navigation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Topological_Planning_With_Transformers_for_Vision-and-Language_Navigation_CVPR_2021_paper.html",
        "author": "Kevin Chen, Junshen K. Chen, Jo Chuang, Marynel Vazquez, Silvio Savarese",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Topological_Planning_With_Transformers_for_Vision-and-Language_Navigation_CVPR_2021_paper.pdf",
        "aff": "Stanford University; Yale University",
        "project": "",
        "github": "",
        "arxiv": "2012.05292"
    },
    {
        "title": "Toward Accurate and Realistic Outfits Visualization With Attention to Details",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Toward_Accurate_and_Realistic_Outfits_Visualization_With_Attention_to_Details_CVPR_2021_paper.html",
        "author": "Kedan Li, Min Jin Chong, Jeffrey Zhang, Jingen Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Toward_Accurate_and_Realistic_Outfits_Visualization_With_Attention_to_Details_CVPR_2021_paper.pdf",
        "aff": "University of Illinois, Urbana Champaign; Revery AI Inc.; JD AI Research",
        "project": "",
        "github": "",
        "arxiv": "2106.06593"
    },
    {
        "title": "Toward Joint Thing-and-Stuff Mining for Weakly Supervised Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Toward_Joint_Thing-and-Stuff_Mining_for_Weakly_Supervised_Panoptic_Segmentation_CVPR_2021_paper.html",
        "author": "Yunhang Shen, Liujuan Cao, Zhiwei Chen, Feihong Lian, Baochang Zhang, Chi Su, Yongjian Wu, Feiyue Huang, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_Toward_Joint_Thing-and-Stuff_Mining_for_Weakly_Supervised_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Institute of Arti\ufb01cial Intelligence, Beihang University, Beijing, China; Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China; Tencent Youtu Lab, Shanghai, China; KingSoft Cloud Co. Ltd., Beijing, China; Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China; Institute of Arti\ufb01cial Intelligence, Xiamen University, Xiamen, China; Peng Cheng Laborotory, Shenzhen, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Accurate 3D Human Motion Prediction From Incomplete Observations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cui_Towards_Accurate_3D_Human_Motion_Prediction_From_Incomplete_Observations_CVPR_2021_paper.html",
        "author": "Qiongjie Cui, Huaijiang Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cui_Towards_Accurate_3D_Human_Motion_Prediction_From_Incomplete_Observations_CVPR_2021_paper.pdf",
        "aff": "Nanjing University of Science and Technology, Nanjing, PR China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Accurate Text-Based Image Captioning With Content Diversity Exploration",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Towards_Accurate_Text-Based_Image_Captioning_With_Content_Diversity_Exploration_CVPR_2021_paper.html",
        "author": "Guanghui Xu, Shuaicheng Niu, Mingkui Tan, Yucheng Luo, Qing Du, Qi Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Towards_Accurate_Text-Based_Image_Captioning_With_Content_Diversity_Exploration_CVPR_2021_paper.pdf",
        "aff": "South China University of Technology, Key Laboratory of Big Data and Intelligent Robot, Ministry of Education; South China University of Technology; South China University of Technology, Pazhou Laboratory; University of Adelaide",
        "project": "",
        "github": "",
        "arxiv": "2105.03236"
    },
    {
        "title": "Towards Bridging Event Captioner and Sentence Localizer for Weakly Supervised Dense Event Captioning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Towards_Bridging_Event_Captioner_and_Sentence_Localizer_for_Weakly_Supervised_CVPR_2021_paper.html",
        "author": "Shaoxiang Chen, Yu-Gang Jiang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Towards_Bridging_Event_Captioner_and_Sentence_Localizer_for_Weakly_Supervised_CVPR_2021_paper.pdf",
        "aff": "Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Compact CNNs via Collaborative Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Towards_Compact_CNNs_via_Collaborative_Compression_CVPR_2021_paper.html",
        "author": "Yuchao Li, Shaohui Lin, Jianzhuang Liu, Qixiang Ye, Mengdi Wang, Fei Chao, Fan Yang, Jincheng Ma, Qi Tian, Rongrong Ji",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Towards_Compact_CNNs_via_Collaborative_Compression_CVPR_2021_paper.pdf",
        "aff": "Towards Compact CNNs via Collaborative Compression\nYuchao Li1,2\u2217, Shaohui Lin3*, Jianzhuang Liu4, Qixiang Ye5, Mengdi Wang2\nFei Chao1, Fan Yang6, Jincheng Ma6, Qi Tian4, Rongrong Ji1,7,8\u2020\n1Media Analytics and Computing Laboratory, Department of Arti\ufb01cial Intelligence,\nSchool of Informatics, Xiamen University,2Alibaba Group,3East China Normal University\n4Huawei Noah\u2019s Ark Lab,5University of Chinese Academy of Sciences,6Huawei TechnologiesCo.,Ltd\n7Institute of Arti\ufb01cial Intelligence, Xiamen University,8Peng Cheng Laboratory\n{laiyin.lyc, didou.wmd }@alibaba-inc.com, shlin@cs.ecnu.edu.cn, qxye@ucas.ac.cn,\n{liu.jianzhuang, yangfan74 }@huawei.com, majincheng1@hisilicon.com, {fchao, rrji }@xmu.edu.cn\nAbstract\nChannel pruning and tensor decomposition have re-\nceived extensive attention in convolutional neural network\ncompression. However, these two techniques are tradition-\nally deployed in an isolated manner, leading to signi\ufb01cant\naccuracy drop when pursuing high compression rates. In\nthis paper, we propose a Collaborative Compression (CC)\nscheme, which joints channel pruning and tensor decom-\nposition to compress CNN models by simultaneously learn-\ning the model sparsity and low-rankness. Speci\ufb01cally, we\n\ufb01rst investigate the compression sensitivity of each layer\nin the network, and then propose a Global Compression\nRate Optimization that transforms the decision problem of\ncompression rate into an optimization problem. After that,\nwe propose multi-step heuristic compression to remove re-\ndundant compression units step-by-step, which fully con-\nsiders the effect of the remaining compression space (i.e.,\nunremoved compression units). Our method demonstrates\nsuperior performance gains over previous ones on vari-\nous datasets and backbone architectures. For example, we\nachieve 52.9% FLOPs reduction by removing 48.4% pa-\nrameters on ResNet-50 with only a Top-1 accuracy drop of\n0.56% on ImageNet 2012.\n1. Introduction\nRemarkable achievements have been attained by convo-\nlutional neural networks (CNNs), such as object classi\ufb01ca-\ntion [ 16,36,7], detection [ 34,33] and segmentation [ 1].\n*Equal contribution.\n\u2020Corresponding author.However, the explosive growth of parameters and computa-\ntional cost in CNN models has restricted their deployment\non resource-limited devices, such as mobile or wearable de-\nvices. To this end, extensive efforts have been made for\nCNN compression and acceleration, including but not lim-\nited to, parameter pruning [ 40,28,19], tensor decomposi-\ntion [ 17,22,41] and quantization [ 13,45].\nParameter pruning and tensor decomposition are two\nwidespread directions in CNN compression, which both\naim to remove intrinsic redundancy in parameters with dif-\nferent removing strategies. Parameter pruning removes\ncorrelated weight connections [ 5,6] or structured neurons\n[28,10,24] based on importance measurement methods,\nresulting in sparse weight structures. In contrast, tensor de-\ncomposition approximates weights of low-rank \ufb01lters based\non the intrinsic low-rankness of parameters [ 44,41,22,14].\nIt is thus a natural thought to combine these two compres-\nsion strategies, which might lead to the signi\ufb01cant accu-\nracy drop when pursuing high compression rate. For in-\nstance, Dubey et al. [4] proposed to compress the weights\nby sequentially employing pruning and tensor decomposi-\ntion, which assumes that they are complementary without\nany mutual in\ufb02uence. However, as demonstrated in pre-\nvious work [ 43], although the pruning and decomposition\nexplore different redundancy in parameters, they are not\ncompletely orthogonal. Thus, the above method [ 4] does\nnot exploit the complementary nature of pruning and de-\ncomposition, which is sub-optimal as exploring only within\neach sub-task ( i.e.,each compression method), not from the\nglobal compression scope.\nTo leverage the bene\ufb01ts of both compression operations,\ntraining-aware methods [ 43,29,20] use two regulariza-\ntions to separately handle the sparsity on channel pruning\n1\n6438\n",
        "project": "",
        "github": "",
        "arxiv": "2105.11228"
    },
    {
        "title": "Towards Diverse Paragraph Captioning for Untrimmed Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_Towards_Diverse_Paragraph_Captioning_for_Untrimmed_Videos_CVPR_2021_paper.html",
        "author": "Yuqing Song, Shizhe Chen, Qin Jin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Towards_Diverse_Paragraph_Captioning_for_Untrimmed_Videos_CVPR_2021_paper.pdf",
        "aff": "Renmin University of China; INRIA",
        "project": "",
        "github": "https://github.com/syuqings/video-paragraph",
        "arxiv": "2105.14477"
    },
    {
        "title": "Towards Efficient Tensor Decomposition-Based DNN Model Compression With Optimization Framework",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Towards_Efficient_Tensor_Decomposition-Based_DNN_Model_Compression_With_Optimization_Framework_CVPR_2021_paper.html",
        "author": "Miao Yin, Yang Sui, Siyu Liao, Bo Yuan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_Towards_Efficient_Tensor_Decomposition-Based_DNN_Model_Compression_With_Optimization_Framework_CVPR_2021_paper.pdf",
        "aff": "Department of ECE, Rutgers University; Amazon",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Evaluating and Training Verifiably Robust Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lyu_Towards_Evaluating_and_Training_Verifiably_Robust_Neural_Networks_CVPR_2021_paper.html",
        "author": "Zhaoyang Lyu, Minghao Guo, Tong Wu, Guodong Xu, Kehuan Zhang, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lyu_Towards_Evaluating_and_Training_Verifiably_Robust_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "SenseTime-CUHK Joint Lab, The Chinese University of Hong Kong; Centre of Perceptual and Interactive Intelligence, The Chinese University of Hong Kong; The Chinese University of Hong Kong",
        "project": "",
        "github": "https://github.com/ZhaoyangLyu/VerifiablyRobustNN",
        "arxiv": "2104.00447"
    },
    {
        "title": "Towards Extremely Compact RNNs for Video Recognition With Fully Decomposed Hierarchical Tucker Structure",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Towards_Extremely_Compact_RNNs_for_Video_Recognition_With_Fully_Decomposed_CVPR_2021_paper.html",
        "author": "Miao Yin, Siyu Liao, Xiao-Yang Liu, Xiaodong Wang, Bo Yuan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_Towards_Extremely_Compact_RNNs_for_Video_Recognition_With_Fully_Decomposed_CVPR_2021_paper.pdf",
        "aff": "Rutgers University; Amazon; Columbia University",
        "project": "",
        "github": "",
        "arxiv": "2104.05758"
    },
    {
        "title": "Towards Fast and Accurate Real-World Depth Super-Resolution: Benchmark Dataset and Baseline",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/He_Towards_Fast_and_Accurate_Real-World_Depth_Super-Resolution_Benchmark_Dataset_and_CVPR_2021_paper.html",
        "author": "Lingzhi He, Hongguang Zhu, Feng Li, Huihui Bai, Runmin Cong, Chunjie Zhang, Chunyu Lin, Meiqin Liu, Yao Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_Towards_Fast_and_Accurate_Real-World_Depth_Super-Resolution_Benchmark_Dataset_and_CVPR_2021_paper.pdf",
        "aff": "Institute of Information Science, Beijing Jiaotong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Good Practices for Efficiently Annotating Large-Scale Image Classification Datasets",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liao_Towards_Good_Practices_for_Efficiently_Annotating_Large-Scale_Image_Classification_Datasets_CVPR_2021_paper.html",
        "author": "Yuan-Hong Liao, Amlan Kar, Sanja Fidler",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liao_Towards_Good_Practices_for_Efficiently_Annotating_Large-Scale_Image_Classification_Datasets_CVPR_2021_paper.pdf",
        "aff": "University of Toronto, Vector Institute; University of Toronto, Vector Institute, NVIDIA",
        "project": "",
        "github": "https://github.com/fidler-lab/efficient-annotation-cookbook",
        "arxiv": "2104.12690"
    },
    {
        "title": "Towards High Fidelity Face Relighting With Realistic Shadows",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Towards_High_Fidelity_Face_Relighting_With_Realistic_Shadows_CVPR_2021_paper.html",
        "author": "Andrew Hou, Ze Zhang, Michel Sarkis, Ning Bi, Yiying Tong, Xiaoming Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Towards_High_Fidelity_Face_Relighting_With_Realistic_Shadows_CVPR_2021_paper.pdf",
        "aff": "Michigan State University; Qualcomm Technologies Inc.",
        "project": "",
        "github": "https://github.com/andrewhou1/Shadow-Mask-Face-Relighting",
        "arxiv": "2104.00825"
    },
    {
        "title": "Towards Improving the Consistency, Efficiency, and Flexibility of Differentiable Neural Architecture Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Towards_Improving_the_Consistency_Efficiency_and_Flexibility_of_Differentiable_Neural_CVPR_2021_paper.html",
        "author": "Yibo Yang, Shan You, Hongyang Li, Fei Wang, Chen Qian, Zhouchen Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Towards_Improving_the_Consistency_Efficiency_and_Flexibility_of_Differentiable_Neural_CVPR_2021_paper.pdf",
        "aff": "Key Laboratory of Machine Perception (MOE), School of EECS, Peking University; Center for Data Science, Academy for Advanced Interdisciplinary Studies, Peking University; SenseTime",
        "project": "",
        "github": "",
        "arxiv": "2101.11342"
    },
    {
        "title": "Towards Long-Form Video Understanding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Towards_Long-Form_Video_Understanding_CVPR_2021_paper.html",
        "author": "Chao-Yuan Wu, Philipp Krahenbuhl",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Towards_Long-Form_Video_Understanding_CVPR_2021_paper.pdf",
        "aff": "The University of Texas at Austin",
        "project": "",
        "github": "",
        "arxiv": "2106.11310"
    },
    {
        "title": "Towards More Flexible and Accurate Object Tracking With Natural Language: Algorithms and Benchmark",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Towards_More_Flexible_and_Accurate_Object_Tracking_With_Natural_Language_CVPR_2021_paper.html",
        "author": "Xiao Wang, Xiujun Shu, Zhipeng Zhang, Bo Jiang, Yaowei Wang, Yonghong Tian, Feng Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Towards_More_Flexible_and_Accurate_Object_Tracking_With_Natural_Language_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science and Technology, Anhui University, Hefei, China; NLPR, Institute of Automation, Chinese Academy of Sciences; University of Science and Technology of China, Hefei, China; Department of Computer Science and Technology, Peking University, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; School of Electronic and Computer Engineering, Peking University, Shenzhen, China",
        "project": "https://sites.google.com/view/langtrackbenchmark/",
        "github": "https://github.com/wangxiao5791509/Single_Object_Tracking_Paper_List",
        "arxiv": "2103.16746"
    },
    {
        "title": "Towards Open World Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Joseph_Towards_Open_World_Object_Detection_CVPR_2021_paper.html",
        "author": "K J Joseph, Salman Khan, Fahad Shahbaz Khan, Vineeth N Balasubramanian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Joseph_Towards_Open_World_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Mohamed bin Zayed University of AI, UAE; Link\u00f6ping University, Sweden; Indian Institute of Technology Hyderabad, India; Mohamed bin Zayed University of AI, UAE; Indian Institute of Technology Hyderabad, India; Mohamed bin Zayed University of AI, UAE; Australian National University, Australia",
        "project": "",
        "github": "https://github.com/JosephKJ/OWOD",
        "arxiv": "2103.02603"
    },
    {
        "title": "Towards Part-Based Understanding of RGB-D Scans",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bokhovkin_Towards_Part-Based_Understanding_of_RGB-D_Scans_CVPR_2021_paper.html",
        "author": "Alexey Bokhovkin, Vladislav Ishimtsev, Emil Bogomolov, Denis Zorin, Alexey Artemov, Evgeny Burnaev, Angela Dai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bokhovkin_Towards_Part-Based_Understanding_of_RGB-D_Scans_CVPR_2021_paper.pdf",
        "aff": "Skolkovo Institute of Science and Technology; Technical University of Munich; New York University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Towards Real-World Blind Face Restoration With Generative Facial Prior",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Towards_Real-World_Blind_Face_Restoration_With_Generative_Facial_Prior_CVPR_2021_paper.html",
        "author": "Xintao Wang, Yu Li, Honglun Zhang, Ying Shan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Towards_Real-World_Blind_Face_Restoration_With_Generative_Facial_Prior_CVPR_2021_paper.pdf",
        "aff": "Applied Research Center (ARC), Tencent PCG",
        "project": "",
        "github": "",
        "arxiv": "2101.04061"
    },
    {
        "title": "Towards Robust Classification Model by Counterfactual and Invariant Data Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Towards_Robust_Classification_Model_by_Counterfactual_and_Invariant_Data_Generation_CVPR_2021_paper.html",
        "author": "Chun-Hao Chang, George Alexandru Adam, Anna Goldenberg",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chang_Towards_Robust_Classification_Model_by_Counterfactual_and_Invariant_Data_Generation_CVPR_2021_paper.pdf",
        "aff": "University of Toronto; University of Toronto, Vector Institute, The Hospital for Sick Children",
        "project": "",
        "github": "",
        "arxiv": "2106.01127"
    },
    {
        "title": "Towards Rolling Shutter Correction and Deblurring in Dynamic Scenes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Towards_Rolling_Shutter_Correction_and_Deblurring_in_Dynamic_Scenes_CVPR_2021_paper.html",
        "author": "Zhihang Zhong, Yinqiang Zheng, Imari Sato",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_Towards_Rolling_Shutter_Correction_and_Deblurring_in_Dynamic_Scenes_CVPR_2021_paper.pdf",
        "aff": "1. The University of Tokyo, Japan; 1. The University of Tokyo, Japan 2. National Institute of Informatics, Japan",
        "project": "",
        "github": "https://github.com/zzh-tech/RSCD",
        "arxiv": "2104.01601"
    },
    {
        "title": "Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset, Benchmarks and Challenges",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Towards_Semantic_Segmentation_of_Urban-Scale_3D_Point_Clouds_A_Dataset_CVPR_2021_paper.html",
        "author": "Qingyong Hu, Bo Yang, Sheikh Khalid, Wen Xiao, Niki Trigoni, Andrew Markham",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Towards_Semantic_Segmentation_of_Urban-Scale_3D_Point_Clouds_A_Dataset_CVPR_2021_paper.pdf",
        "aff": "Newcastle University; The Hong Kong Polytechnic University; University of Oxford; Sensat Ltd",
        "project": "",
        "github": "https://github.com/QingyongHu/SensatUrban",
        "arxiv": "2009.03137"
    },
    {
        "title": "Towards Unified Surgical Skill Assessment",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Towards_Unified_Surgical_Skill_Assessment_CVPR_2021_paper.html",
        "author": "Daochang Liu, Qiyue Li, Tingting Jiang, Yizhou Wang, Rulin Miao, Fei Shan, Ziyu Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Towards_Unified_Surgical_Skill_Assessment_CVPR_2021_paper.pdf",
        "aff": "Center on Frontiers of Computing Studies, Peking University; Peking University Cancer Hospital; NELVT, Department of Computer Science, Peking University",
        "project": "",
        "github": "",
        "arxiv": "2106.01035"
    },
    {
        "title": "Track To Detect and Segment: An Online Multi-Object Tracker",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Track_To_Detect_and_Segment_An_Online_Multi-Object_Tracker_CVPR_2021_paper.html",
        "author": "Jialian Wu, Jiale Cao, Liangchen Song, Yu Wang, Ming Yang, Junsong Yuan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Track_To_Detect_and_Segment_An_Online_Multi-Object_Tracker_CVPR_2021_paper.pdf",
        "aff": "SUNY Buffalo; Horizon Robotics; TJU",
        "project": "https://jialianwu.com/projects/TraDeS.html",
        "github": "",
        "arxiv": "2103.08808"
    },
    {
        "title": "Track, Check, Repeat: An EM Approach to Unsupervised Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Harley_Track_Check_Repeat_An_EM_Approach_to_Unsupervised_Tracking_CVPR_2021_paper.html",
        "author": "Adam W. Harley, Yiming Zuo, Jing Wen, Ayush Mangal, Shubhankar Potdar, Ritwick Chaudhry, Katerina Fragkiadaki",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Harley_Track_Check_Repeat_An_EM_Approach_to_Unsupervised_Tracking_CVPR_2021_paper.pdf",
        "aff": "Indian Institute of Technology Roorkee; Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2104.03424"
    },
    {
        "title": "Tracking Pedestrian Heads in Dense Crowd",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sundararaman_Tracking_Pedestrian_Heads_in_Dense_Crowd_CVPR_2021_paper.html",
        "author": "Ramana Sundararaman, Cedric De Almeida Braga, Eric Marchand, Julien Pettre",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sundararaman_Tracking_Pedestrian_Heads_in_Dense_Crowd_CVPR_2021_paper.pdf",
        "aff": "Univ Rennes, Inria, CNRS, Irisa, Rennes, France",
        "project": "https://project.inria.fr/crowdscience/project/dense-crowd-head-tracking/",
        "github": "",
        "arxiv": "2103.13516"
    },
    {
        "title": "TrafficSim: Learning To Simulate Realistic Multi-Agent Behaviors",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Suo_TrafficSim_Learning_To_Simulate_Realistic_Multi-Agent_Behaviors_CVPR_2021_paper.html",
        "author": "Simon Suo, Sebastian Regalado, Sergio Casas, Raquel Urtasun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Suo_TrafficSim_Learning_To_Simulate_Realistic_Multi-Agent_Behaviors_CVPR_2021_paper.pdf",
        "aff": "University of Waterloo; Uber ATG, University of Toronto",
        "project": "",
        "github": "",
        "arxiv": "2101.06557"
    },
    {
        "title": "Training Generative Adversarial Networks in One Stage",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Training_Generative_Adversarial_Networks_in_One_Stage_CVPR_2021_paper.html",
        "author": "Chengchao Shen, Youtan Yin, Xinchao Wang, Xubin Li, Jie Song, Mingli Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_Training_Generative_Adversarial_Networks_in_One_Stage_CVPR_2021_paper.pdf",
        "aff": "Alibaba Group; Zhejiang University; National University of Singapore",
        "project": "",
        "github": "https://github.com/zju-vipa/OSGAN",
        "arxiv": "2103.00430"
    },
    {
        "title": "Training Networks in Null Space of Feature Covariance for Continual Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Training_Networks_in_Null_Space_of_Feature_Covariance_for_Continual_CVPR_2021_paper.html",
        "author": "Shipeng Wang, Xiaorong Li, Jian Sun, Zongben Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Training_Networks_in_Null_Space_of_Feature_Covariance_for_Continual_CVPR_2021_paper.pdf",
        "aff": "School of Mathematics and Statistics, Xi\u2019an Jiaotong University, Xi\u2019an, 710049, China; National Engineering Laboratory of Big Data Algorithm and Analysis Technology, Xi\u2019an, 710049, China; Pazhou Lab, Guangzhou, Guangdong, 510335, China; School of Mathematics and Statistics, Xi\u2019an Jiaotong University, Xi\u2019an, 710049, China",
        "project": "",
        "github": "",
        "arxiv": "2103.07113"
    },
    {
        "title": "Trajectory Prediction With Latent Belief Energy-Based Model",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pang_Trajectory_Prediction_With_Latent_Belief_Energy-Based_Model_CVPR_2021_paper.html",
        "author": "Bo Pang, Tianyang Zhao, Xu Xie, Ying Nian Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pang_Trajectory_Prediction_With_Latent_Belief_Energy-Based_Model_CVPR_2021_paper.pdf",
        "aff": "Department of Statistics, University of California, Los Angeles (UCLA)",
        "project": "",
        "github": "",
        "arxiv": "2104.03086"
    },
    {
        "title": "TransFill: Reference-Guided Image Inpainting by Merging Multiple Color and Spatial Transformations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_TransFill_Reference-Guided_Image_Inpainting_by_Merging_Multiple_Color_and_Spatial_CVPR_2021_paper.html",
        "author": "Yuqian Zhou, Connelly Barnes, Eli Shechtman, Sohrab Amirghodsi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_TransFill_Reference-Guided_Image_Inpainting_by_Merging_Multiple_Color_and_Spatial_CVPR_2021_paper.pdf",
        "aff": "Adobe Research; IFP, UIUC",
        "project": "",
        "github": "",
        "arxiv": "2103.15982"
    },
    {
        "title": "TransNAS-Bench-101: Improving Transferability and Generalizability of Cross-Task Neural Architecture Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Duan_TransNAS-Bench-101_Improving_Transferability_and_Generalizability_of_Cross-Task_Neural_Architecture_Search_CVPR_2021_paper.html",
        "author": "Yawen Duan, Xin Chen, Hang Xu, Zewei Chen, Xiaodan Liang, Tong Zhang, Zhenguo Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Duan_TransNAS-Bench-101_Improving_Transferability_and_Generalizability_of_Cross-Task_Neural_Architecture_Search_CVPR_2021_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab; Sun Yat-sen University; The University of Hong Kong; The Hong Kong University of Science and Technology",
        "project": "https://download.mindspore.cn/dataset/TransNAS-Bench-101",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Transferable Query Selection for Active Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Transferable_Query_Selection_for_Active_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Bo Fu, Zhangjie Cao, Jianmin Wang, Mingsheng Long",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fu_Transferable_Query_Selection_for_Active_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "School of Software, BNRist, Tsinghua University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Transferable Semantic Augmentation for Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Transferable_Semantic_Augmentation_for_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Shuang Li, Mixue Xie, Kaixiong Gong, Chi Harold Liu, Yulin Wang, Wei Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Transferable_Semantic_Augmentation_for_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "Beijing Institute of Technology; Tsinghua University; Inceptio Tech",
        "project": "",
        "github": "",
        "arxiv": "2103.12562"
    },
    {
        "title": "Transformation Driven Visual Reasoning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Transformation_Driven_Visual_Reasoning_CVPR_2021_paper.html",
        "author": "Xin Hong, Yanyan Lan, Liang Pang, Jiafeng Guo, Xueqi Cheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Transformation_Driven_Visual_Reasoning_CVPR_2021_paper.pdf",
        "aff": "CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China and University of Chinese Academy of Sciences, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China",
        "project": "",
        "github": "https://hongxin2019.github.io/TVR",
        "arxiv": "2011.13160"
    },
    {
        "title": "Transformation Invariant Few-Shot Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Transformation_Invariant_Few-Shot_Object_Detection_CVPR_2021_paper.html",
        "author": "Aoxue Li, Zhenguo Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Transformation_Invariant_Few-Shot_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Transformer Interpretability Beyond Attention Visualization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chefer_Transformer_Interpretability_Beyond_Attention_Visualization_CVPR_2021_paper.html",
        "author": "Hila Chefer, Shir Gur, Lior Wolf",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chefer_Transformer_Interpretability_Beyond_Attention_Visualization_CVPR_2021_paper.pdf",
        "aff": "The School of Computer Science, Tel Aviv University; Facebook AI Research (FAIR); The School of Computer Science, Tel Aviv University",
        "project": "",
        "github": "https://github.com/hila-chefer/Transformer-Explainability",
        "arxiv": "2012.09838"
    },
    {
        "title": "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Transformer_Meets_Tracker_Exploiting_Temporal_Context_for_Robust_Visual_Tracking_CVPR_2021_paper.html",
        "author": "Ning Wang, Wengang Zhou, Jie Wang, Houqiang Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Transformer_Meets_Tracker_Exploiting_Temporal_Context_for_Robust_Visual_Tracking_CVPR_2021_paper.pdf",
        "aff": "Institute of Arti\ufb01cial Intelligence, Hefei Comprehensive National Science Center; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China (USTC)",
        "project": "",
        "github": "https://github.com/594422814/TransformerTrack",
        "arxiv": "2103.11681"
    },
    {
        "title": "Transformer Tracking",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Transformer_Tracking_CVPR_2021_paper.html",
        "author": "Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Xiaoyun Yang, Huchuan Lu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Transformer_Tracking_CVPR_2021_paper.pdf",
        "aff": "Remark AI; School of Information and Communication Engineering, Dalian University of Technology, China; School of Information and Communication Engineering, Dalian University of Technology, China; Peng Cheng Laboratory",
        "project": "",
        "github": "https://github.com/chenxin-dlut/TransT",
        "arxiv": "2103.15436"
    },
    {
        "title": "Transitional Adaptation of Pretrained Models for Visual Storytelling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Transitional_Adaptation_of_Pretrained_Models_for_Visual_Storytelling_CVPR_2021_paper.html",
        "author": "Youngjae Yu, Jiwan Chung, Heeseung Yun, Jongseok Kim, Gunhee Kim",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_Transitional_Adaptation_of_Pretrained_Models_for_Visual_Storytelling_CVPR_2021_paper.pdf",
        "aff": "Allen Institute for AI; Violet; Seoul National University",
        "project": "https://vision.snu.ac.kr/projects/TAPM",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Tree-Like Decision Distillation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Song_Tree-Like_Decision_Distillation_CVPR_2021_paper.html",
        "author": "Jie Song, Haofei Zhang, Xinchao Wang, Mengqi Xue, Ying Chen, Li Sun, Dacheng Tao, Mingli Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Tree-Like_Decision_Distillation_CVPR_2021_paper.pdf",
        "aff": "The University of Sydney; Zhejiang University; National University of Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Triple-Cooperative Video Shadow Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Triple-Cooperative_Video_Shadow_Detection_CVPR_2021_paper.html",
        "author": "Zhihao Chen, Liang Wan, Lei Zhu, Jia Shen, Huazhu Fu, Wennan Liu, Jing Qin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Triple-Cooperative_Video_Shadow_Detection_CVPR_2021_paper.pdf",
        "aff": "Triple-cooperative Video Shadow Detection\nZhihao Chen1\u2217, Liang Wan1*, Lei Zhu2\u2020, Jia Shen1, Huazhu Fu3, Wennan Liu4, Jing Qin5\n1College of Intelligence and Computing, Tianjin University\n2Department of Applied Mathematics and Theoretical Physics, University of Cambridge\n3Inception Institute of Arti\ufb01cial Intelligence, UAE\n4Academy of Medical Engineering and Translational Medicine, Tianjin University\n5The Hong Kong Polytechnic University\nAbstract\nShadow detection in a single image has received signif-\nicant research interests in recent years. However, much\nfewer works have been explored in shadow detection over\ndynamic scenes. The bottleneck is the lack of a well-\nestablished dataset with high-quality annotations for video\nshadow detection. In this work, we collect a new video\nshadow detection dataset (ViSha), which contains 120\nvideos with 11,685frames, covering 60 object categories,\nvarying lengths, and different motion/lighting conditions.\nAll the frames are annotated with a high-quality pixel-level\nshadow mask. To the best of our knowledge, this is the \ufb01rst\nlearning-oriented dataset for video shadow detection. Fur-\nthermore, we develop a new baseline model, named triple-\ncooperative video shadow detection network (TVSD-Net).\nIt utilizes triple parallel networks in a cooperative man-\nner to learn discriminative representations at intra-video\nand inter-video levels. Within the network, a dual gated\nco-attention module is proposed to constrain features from\nneighboring frames in the same video, while an auxiliary\nsimilarity loss is introduced to mine semantic information\nbetween different videos. Finally, we conduct a comprehen-\nsive study on ViSha, evaluating 12 state-of-the-art models\n(including single image shadow detectors, video object seg-\nmentation, and saliency detection methods). Experiments\ndemonstrate that our model outperforms SOTA competitors.\n1. Introduction\nAs a common phenomenon in our daily life, shadows\nin natural images provide hints for extracting scene geom-\netry [ 41,24], light direction [ 27], and camera location and\nits parameters [ 23]. Shadows can also bene\ufb01t diverse im-\nage understanding tasks, e.g., image segmentation [ 10], ob-\n*Zhihao Chen and Liang Wan are the joint \ufb01rst authors of this work.\n\u2020Lei Zhu (lz437@cam.ac.uk) is the corresponding author of this work.ject detection [ 8], and object tracking [ 37]. The last decade\nhas witnessed a growing interest in image shadow detec-\ntion. Many methods have been developed by examining\ncolor and illumination priors [ 14,13], by developing data-\ndriven approaches with hand-crafted features [ 21,28,54],\nor by learning discriminative features from a convolutional\nneural network (CNN) [ 25,43,39,20,29,56,19,53].\nHowever, in striking contrast with the \ufb02ourishing devel-\nopment of image shadow detection, much fewer works have\nbeen explored in shadow detection over dynamic scenes.\nOn the other hand, we also notice that video processing has\nbecome an urgent topic in recent years, and a lot of methods\nwere proposed for video salient object detection [ 30,47,11]\nand video object segmentation [ 35,40]. What makes video\nshadow detection lag far behind these video processing\ntasks? Compared with shadow detection of a single image,\nvideo shadow detection (VSD) needs to utilize temporal in-\nformation to identify shadow pixels of each video frame.\nAlthough there exist multiple datasets for image shadow\ndetection, video salient object detection, and video object\nsegmentation, such standard widespread benchmark (with a\nsuf\ufb01cient number of video clips, covering diverse content)\nis missing for video shadow detection. What\u2019s more, CNN-\nbased methods have not been exploited for this problem due\nto the lack of such a dataset.\nIn this work, we \ufb01rst collect a new video shadow detec-\ntion (ViSha) dataset. It contains 120 videos with 11,685\nimage frames and 390 seconds duration, covering shad-\nows of 7 object classes and 60 object categories, various\nmotion/lighting conditions, and different instance numbers.\nAll the video frames are carefully annotated with a high-\nquality pixel-level shadow mask. To the best of our knowl-\nedge, this is the \ufb01rst learning-oriented dataset for video\nshadow detection, which could facilitate the community to\nexplore further in this \ufb01eld. Second, we develop a new\nbaseline model, a triple-cooperative video shadow de-\ntection network (TVSD-Net), for this task. Instead of\njust exploiting temporal information within one video clip\n2715\n",
        "project": "",
        "github": "",
        "arxiv": "2103.06533"
    },
    {
        "title": "Troubleshooting Blind Image Quality Models in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Troubleshooting_Blind_Image_Quality_Models_in_the_Wild_CVPR_2021_paper.html",
        "author": "Zhihua Wang, Haotao Wang, Tianlong Chen, Zhangyang Wang, Kede Ma",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Troubleshooting_Blind_Image_Quality_Models_in_the_Wild_CVPR_2021_paper.pdf",
        "aff": "City University of Hong Kong; University of Texas at Austin",
        "project": "",
        "github": "",
        "arxiv": "2105.06747"
    },
    {
        "title": "Truly Shift-Invariant Convolutional Neural Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chaman_Truly_Shift-Invariant_Convolutional_Neural_Networks_CVPR_2021_paper.html",
        "author": "Anadi Chaman, Ivan Dokmanic",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chaman_Truly_Shift-Invariant_Convolutional_Neural_Networks_CVPR_2021_paper.pdf",
        "aff": "University of Illinois at Urbana-Champaign; University of Basel",
        "project": "",
        "github": "https://github.com/achaman2/truly_shift_invariant_cnns",
        "arxiv": "2011.14214"
    },
    {
        "title": "Tuning IR-Cut Filter for Illumination-Aware Spectral Reconstruction From RGB",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Tuning_IR-Cut_Filter_for_Illumination-Aware_Spectral_Reconstruction_From_RGB_CVPR_2021_paper.html",
        "author": "Bo Sun, Junchi Yan, Xiao Zhou, Yinqiang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Tuning_IR-Cut_Filter_for_Illumination-Aware_Spectral_Reconstruction_From_RGB_CVPR_2021_paper.pdf",
        "aff": "Shanghai Jiao Tong University, China; Anhui Normal University, China; University of Southern California, USA; The University of Tokyo, Japan",
        "project": "",
        "github": "",
        "arxiv": "2103.14708"
    },
    {
        "title": "Turning Frequency to Resolution: Video Super-Resolution via Event Cameras",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jing_Turning_Frequency_to_Resolution_Video_Super-Resolution_via_Event_Cameras_CVPR_2021_paper.html",
        "author": "Yongcheng Jing, Yiding Yang, Xinchao Wang, Mingli Song, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jing_Turning_Frequency_to_Resolution_Video_Super-Resolution_via_Event_Cameras_CVPR_2021_paper.pdf",
        "aff": "Stevens Institute of Technology; Zhejiang University; National University of Singapore; The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "UAV-Human: A Large Benchmark for Human Behavior Understanding With Unmanned Aerial Vehicles",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_UAV-Human_A_Large_Benchmark_for_Human_Behavior_Understanding_With_Unmanned_CVPR_2021_paper.html",
        "author": "Tianjiao Li, Jun Liu, Wei Zhang, Yun Ni, Wenqian Wang, Zhiheng Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_UAV-Human_A_Large_Benchmark_for_Human_Behavior_Understanding_With_Unmanned_CVPR_2021_paper.pdf",
        "aff": "School of Control Science and Engineering, Shandong University, Jinan, Shandong; Information Systems Technology and Design, Singapore University of Technology and Design, Singapore",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "UC2: Universal Cross-Lingual Cross-Modal Vision-and-Language Pre-Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_UC2_Universal_Cross-Lingual_Cross-Modal_Vision-and-Language_Pre-Training_CVPR_2021_paper.html",
        "author": "Mingyang Zhou, Luowei Zhou, Shuohang Wang, Yu Cheng, Linjie Li, Zhou Yu, Jingjing Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_UC2_Universal_Cross-Lingual_Cross-Modal_Vision-and-Language_Pre-Training_CVPR_2021_paper.pdf",
        "aff": "Microsoft Dynamics 365 AI Research; University of California, Davis",
        "project": "",
        "github": "",
        "arxiv": "2104.00332"
    },
    {
        "title": "UP-DETR: Unsupervised Pre-Training for Object Detection With Transformers",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Dai_UP-DETR_Unsupervised_Pre-Training_for_Object_Detection_With_Transformers_CVPR_2021_paper.html",
        "author": "Zhigang Dai, Bolun Cai, Yugeng Lin, Junying Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_UP-DETR_Unsupervised_Pre-Training_for_Object_Detection_With_Transformers_CVPR_2021_paper.pdf",
        "aff": "School of Software Engineering, South China University of Technology; Key Laboratory of Big Data and Intelligent Robot (South China University of Technology), Ministry of Education; Tencent Wechat AI; School of Software Engineering, South China University of Technology",
        "project": "",
        "github": "https://github.com/dddzg/up-detr",
        "arxiv": ""
    },
    {
        "title": "UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Luo_UPFlow_Upsampling_Pyramid_for_Unsupervised_Optical_Flow_Learning_CVPR_2021_paper.html",
        "author": "Kunming Luo, Chuan Wang, Shuaicheng Liu, Haoqiang Fan, Jue Wang, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_UPFlow_Upsampling_Pyramid_for_Unsupervised_Optical_Flow_Learning_CVPR_2021_paper.pdf",
        "aff": "University of Electronic Science and Technology of China; Megvii Technology",
        "project": "",
        "github": "https://github.com/coolbeam/UPFlow_pytorch",
        "arxiv": "2012.00212"
    },
    {
        "title": "UV-Net: Learning From Boundary Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Jayaraman_UV-Net_Learning_From_Boundary_Representations_CVPR_2021_paper.html",
        "author": "Pradeep Kumar Jayaraman, Aditya Sanghi, Joseph G. Lambourne, Karl D.D. Willis, Thomas Davies, Hooman Shayani, Nigel Morris",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jayaraman_UV-Net_Learning_From_Boundary_Representations_CVPR_2021_paper.pdf",
        "aff": "Autodesk; Autodesk Research",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Ultra-High-Definition Image Dehazing via Multi-Guided Bilateral Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Ultra-High-Definition_Image_Dehazing_via_Multi-Guided_Bilateral_Learning_CVPR_2021_paper.html",
        "author": "Zhuoran Zheng, Wenqi Ren, Xiaochun Cao, Xiaobin Hu, Tao Wang, Fenglong Song, Xiuyi Jia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Ultra-High-Definition_Image_Dehazing_via_Multi-Guided_Bilateral_Learning_CVPR_2021_paper.pdf",
        "aff": "Informatic, Technische Universit \u00a8at M \u00a8unchen; SKLOIS, IIE, CAS; CSE, Nanjing University of Science and Technology; Huawei Noah\u2019s Ark Lab",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Unbalanced Feature Transport for Exemplar-Based Image Translation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhan_Unbalanced_Feature_Transport_for_Exemplar-Based_Image_Translation_CVPR_2021_paper.html",
        "author": "Fangneng Zhan, Yingchen Yu, Kaiwen Cui, Gongjie Zhang, Shijian Lu, Jianxiong Pan, Changgong Zhang, Feiying Ma, Xuansong Xie, Chunyan Miao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhan_Unbalanced_Feature_Transport_for_Exemplar-Based_Image_Translation_CVPR_2021_paper.pdf",
        "aff": "Nanyang Technological University; DAMO Academy, Alibaba Group",
        "project": "",
        "github": "",
        "arxiv": "2106.10482"
    },
    {
        "title": "Unbiased Mean Teacher for Cross-Domain Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Unbiased_Mean_Teacher_for_Cross-Domain_Object_Detection_CVPR_2021_paper.html",
        "author": "Jinhong Deng, Wen Li, Yuhua Chen, Lixin Duan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Unbiased_Mean_Teacher_for_Cross-Domain_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Zurich; University of Electronic Science and Technology of China",
        "project": "",
        "github": "https://github.com/kinredon/umt",
        "arxiv": "2003.00707"
    },
    {
        "title": "Uncalibrated Neural Inverse Rendering for Photometric Stereo of General Surfaces",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kaya_Uncalibrated_Neural_Inverse_Rendering_for_Photometric_Stereo_of_General_Surfaces_CVPR_2021_paper.html",
        "author": "Berk Kaya, Suryansh Kumar, Carlos Oliveira, Vittorio Ferrari, Luc Van Gool",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kaya_Uncalibrated_Neural_Inverse_Rendering_for_Photometric_Stereo_of_General_Surfaces_CVPR_2021_paper.pdf",
        "aff": "Computer Vision Lab, ETH Z\u00fcrich; Computer Vision Lab, ETH Z\u00fcrich, KU Leuven; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2012.06777"
    },
    {
        "title": "Uncertainty Guided Collaborative Training for Weakly Supervised Temporal Action Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Uncertainty_Guided_Collaborative_Training_for_Weakly_Supervised_Temporal_Action_Detection_CVPR_2021_paper.html",
        "author": "Wenfei Yang, Tianzhu Zhang, Xiaoyuan Yu, Tian Qi, Yongdong Zhang, Feng Wu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Uncertainty_Guided_Collaborative_Training_for_Weakly_Supervised_Temporal_Action_Detection_CVPR_2021_paper.pdf",
        "aff": "53\n",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Uncertainty Reduction for Model Adaptation in Semantic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/S_Uncertainty_Reduction_for_Model_Adaptation_in_Semantic_Segmentation_CVPR_2021_paper.html",
        "author": "Prabhu Teja S, Francois Fleuret",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/S_Uncertainty_Reduction_for_Model_Adaptation_in_Semantic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "EPFL, University of Geneva; Idiap Research Institute",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Uncertainty-Aware Camera Pose Estimation From Points and Lines",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Vakhitov_Uncertainty-Aware_Camera_Pose_Estimation_From_Points_and_Lines_CVPR_2021_paper.html",
        "author": "Alexander Vakhitov, Luis Ferraz, Antonio Agudo, Francesc Moreno-Noguer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Vakhitov_Uncertainty-Aware_Camera_Pose_Estimation_From_Points_and_Lines_CVPR_2021_paper.pdf",
        "aff": "Institut de Rob `otica i Inform `atica Industrial, CSIC-UPC, Spain; Kognia Sports Intelligence, Spain; SLAMCore Ltd., UK",
        "project": "",
        "github": "https://alexandervakhitov.github.io/uncertain-pnp/",
        "arxiv": ""
    },
    {
        "title": "Uncertainty-Aware Joint Salient Object and Camouflaged Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Uncertainty-Aware_Joint_Salient_Object_and_Camouflaged_Object_Detection_CVPR_2021_paper.html",
        "author": "Aixuan Li, Jing Zhang, Yunqiu Lv, Bowen Liu, Tong Zhang, Yuchao Dai",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Uncertainty-Aware_Joint_Salient_Object_and_Camouflaged_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "EPFL, Switzerland; Australian National University, Australia; Northwestern Polytechnical University, China",
        "project": "",
        "github": "https://github.com/JingZhang617/Joint_COD_SOD",
        "arxiv": "2104.02628"
    },
    {
        "title": "Uncertainty-Guided Model Generalization to Unseen Domains",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qiao_Uncertainty-Guided_Model_Generalization_to_Unseen_Domains_CVPR_2021_paper.html",
        "author": "Fengchun Qiao, Xi Peng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qiao_Uncertainty-Guided_Model_Generalization_to_Unseen_Domains_CVPR_2021_paper.pdf",
        "aff": "University of Delaware",
        "project": "",
        "github": "https://github.com/joffery/UMGUD",
        "arxiv": "2103.07531"
    },
    {
        "title": "Understanding Failures of Deep Networks via Robust Feature Extraction",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Singla_Understanding_Failures_of_Deep_Networks_via_Robust_Feature_Extraction_CVPR_2021_paper.html",
        "author": "Sahil Singla, Besmira Nushi, Shital Shah, Ece Kamar, Eric Horvitz",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Singla_Understanding_Failures_of_Deep_Networks_via_Robust_Feature_Extraction_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research; University of Maryland",
        "project": "",
        "github": "https://github.com/singlasahil14/barlow",
        "arxiv": "2012.01750"
    },
    {
        "title": "Understanding Object Dynamics for Interactive Image-to-Video Synthesis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Blattmann_Understanding_Object_Dynamics_for_Interactive_Image-to-Video_Synthesis_CVPR_2021_paper.html",
        "author": "Andreas Blattmann, Timo Milbich, Michael Dorkenwald, Bjorn Ommer",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Blattmann_Understanding_Object_Dynamics_for_Interactive_Image-to-Video_Synthesis_CVPR_2021_paper.pdf",
        "aff": "Interdisciplinary Center for Scienti\ufb01c Computing, HCI, Heidelberg University, Germany",
        "project": "https://bit.ly/3cxfA2L",
        "github": "",
        "arxiv": "2106.11303"
    },
    {
        "title": "Understanding and Simplifying Perceptual Distances",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Amir_Understanding_and_Simplifying_Perceptual_Distances_CVPR_2021_paper.html",
        "author": "Dan Amir, Yair Weiss",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Amir_Understanding_and_Simplifying_Perceptual_Distances_CVPR_2021_paper.pdf",
        "aff": "The Hebrew University of Jerusalem",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Understanding the Behaviour of Contrastive Loss",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Understanding_the_Behaviour_of_Contrastive_Loss_CVPR_2021_paper.html",
        "author": "Feng Wang, Huaping Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Understanding_the_Behaviour_of_Contrastive_Loss_CVPR_2021_paper.pdf",
        "aff": "Beijing National Research Center for Information Science and Technology(BNRist), Department of Computer Science and Technology, Tsinghua University",
        "project": "",
        "github": "",
        "arxiv": "2012.09740"
    },
    {
        "title": "Understanding the Robustness of Skeleton-Based Action Recognition Under Adversarial Attack",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Understanding_the_Robustness_of_Skeleton-Based_Action_Recognition_Under_Adversarial_Attack_CVPR_2021_paper.html",
        "author": "He Wang, Feixiang He, Zhexi Peng, Tianjia Shao, Yong-Liang Yang, Kun Zhou, David Hogg",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Understanding_the_Robustness_of_Skeleton-Based_Action_Recognition_Under_Adversarial_Attack_CVPR_2021_paper.pdf",
        "aff": "State Key Lab of CAD&CG, Zhejiang University, China; University of Leeds, UK; University of Bath, UK",
        "project": "https://youtu.be/DeMkN3efp9s",
        "github": "",
        "arxiv": "2103.05347"
    },
    {
        "title": "UniT: Unified Knowledge Transfer for Any-Shot Object Detection and Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Khandelwal_UniT_Unified_Knowledge_Transfer_for_Any-Shot_Object_Detection_and_Segmentation_CVPR_2021_paper.html",
        "author": "Siddhesh Khandelwal, Raghav Goyal, Leonid Sigal",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Khandelwal_UniT_Unified_Knowledge_Transfer_for_Any-Shot_Object_Detection_and_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Department of Computer Science, University of British Columbia; Vector Institute for AI; CIFAR AI Chair",
        "project": "",
        "github": "https://github.com/ubc-vision/UniT",
        "arxiv": "2006.07502"
    },
    {
        "title": "Universal Spectral Adversarial Attacks for Deformable Shapes",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Rampini_Universal_Spectral_Adversarial_Attacks_for_Deformable_Shapes_CVPR_2021_paper.html",
        "author": "Arianna Rampini, Franco Pestarini, Luca Cosmo, Simone Melzi, Emanuele Rodola",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Rampini_Universal_Spectral_Adversarial_Attacks_for_Deformable_Shapes_CVPR_2021_paper.pdf",
        "aff": "Sapienza University of Rome",
        "project": "",
        "github": "",
        "arxiv": "2104.03356"
    },
    {
        "title": "Unpaired Image-to-Image Translation via Latent Energy Transport",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Unpaired_Image-to-Image_Translation_via_Latent_Energy_Transport_CVPR_2021_paper.html",
        "author": "Yang Zhao, Changyou Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Unpaired_Image-to-Image_Translation_via_Latent_Energy_Transport_CVPR_2021_paper.pdf",
        "aff": "University at Buffalo, SUNY",
        "project": "",
        "github": "https://github.com/YangNaruto/latent-energy-transport",
        "arxiv": "2012.00649"
    },
    {
        "title": "UnrealPerson: An Adaptive Pipeline Towards Costless Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_UnrealPerson_An_Adaptive_Pipeline_Towards_Costless_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Tianyu Zhang, Lingxi Xie, Longhui Wei, Zijie Zhuang, Yongfei Zhang, Bo Li, Qi Tian",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_UnrealPerson_An_Adaptive_Pipeline_Towards_Costless_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Xidian University; Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, Beihang University, State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Pengcheng Laboratory; Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, Beihang University; Tsinghua University; University of Science and Technology of China",
        "project": "",
        "github": "https://github.com/FlyHighest/UnrealPerson",
        "arxiv": "2012.04268"
    },
    {
        "title": "Unsupervised 3D Shape Completion Through GAN Inversion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Unsupervised_3D_Shape_Completion_Through_GAN_Inversion_CVPR_2021_paper.html",
        "author": "Junzhe Zhang, Xinyi Chen, Zhongang Cai, Liang Pan, Haiyu Zhao, Shuai Yi, Chai Kiat Yeo, Bo Dai, Chen Change Loy",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Unsupervised_3D_Shape_Completion_Through_GAN_Inversion_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research; Nanyang Technological University; S-Lab, Nanyang Technological University; Shanghai AI Laboratory",
        "project": "https://junzhezhang.github.io/projects/ShapeInversion/",
        "github": "https://github.com/junzhezhang",
        "arxiv": "2104.13366"
    },
    {
        "title": "Unsupervised Degradation Representation Learning for Blind Super-Resolution",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Unsupervised_Degradation_Representation_Learning_for_Blind_Super-Resolution_CVPR_2021_paper.html",
        "author": "Longguang Wang, Yingqian Wang, Xiaoyu Dong, Qingyu Xu, Jungang Yang, Wei An, Yulan Guo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Unsupervised_Degradation_Representation_Learning_for_Blind_Super-Resolution_CVPR_2021_paper.pdf",
        "aff": "The University of Tokyo, RIKEN AIP; National University of Defense Technology",
        "project": "",
        "github": "https://github.com/LongguangWang/DASR",
        "arxiv": "2104.00416"
    },
    {
        "title": "Unsupervised Discovery of the Long-Tail in Instance Segmentation Using Hierarchical Self-Supervision",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Weng_Unsupervised_Discovery_of_the_Long-Tail_in_Instance_Segmentation_Using_Hierarchical_CVPR_2021_paper.html",
        "author": "Zhenzhen Weng, Mehmet Giray Ogut, Shai Limonchik, Serena Yeung",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Weng_Unsupervised_Discovery_of_the_Long-Tail_in_Instance_Segmentation_Using_Hierarchical_CVPR_2021_paper.pdf",
        "aff": "Stanford University",
        "project": "",
        "github": "",
        "arxiv": "2104.01257"
    },
    {
        "title": "Unsupervised Disentanglement of Linear-Encoded Facial Semantics",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Unsupervised_Disentanglement_of_Linear-Encoded_Facial_Semantics_CVPR_2021_paper.html",
        "author": "Yutong Zheng, Yu-Kai Huang, Ran Tao, Zhiqiang Shen, Marios Savvides",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Unsupervised_Disentanglement_of_Linear-Encoded_Facial_Semantics_CVPR_2021_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2103.16605"
    },
    {
        "title": "Unsupervised Feature Learning by Cross-Level Instance-Group Discrimination",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Unsupervised_Feature_Learning_by_Cross-Level_Instance-Group_Discrimination_CVPR_2021_paper.html",
        "author": "Xudong Wang, Ziwei Liu, Stella X. Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Unsupervised_Feature_Learning_by_Cross-Level_Instance-Group_Discrimination_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley / ICSI; S-Lab, NTU",
        "project": "",
        "github": "https://github.com/frank-xwang/CLD-UnsupervisedLearning",
        "arxiv": "2008.03813"
    },
    {
        "title": "Unsupervised Human Pose Estimation Through Transforming Shape Templates",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Schmidtke_Unsupervised_Human_Pose_Estimation_Through_Transforming_Shape_Templates_CVPR_2021_paper.html",
        "author": "Luca Schmidtke, Athanasios Vlontzos, Simon Ellershaw, Anna Lukens, Tomoki Arichi, Bernhard Kainz",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Schmidtke_Unsupervised_Human_Pose_Estimation_Through_Transforming_Shape_Templates_CVPR_2021_paper.pdf",
        "aff": "King\u2019s College London; Imperial College London; Evelina London Children\u2019s Hospital",
        "project": "http://infantmotion.github.io",
        "github": "",
        "arxiv": "2105.04154"
    },
    {
        "title": "Unsupervised Hyperbolic Metric Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Unsupervised_Hyperbolic_Metric_Learning_CVPR_2021_paper.html",
        "author": "Jiexi Yan, Lei Luo, Cheng Deng, Heng Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Unsupervised_Hyperbolic_Metric_Learning_CVPR_2021_paper.pdf",
        "aff": "School of Electronic Engineering, Xidian University, Xi\u2019an 710071, China; JD Finance America Corporation, Mountain View, CA 94043, USA; Department of Electrical and Computer Engineering, University of Pittsburgh, PA 15260, USA",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Unsupervised Hyperbolic Representation Learning via Message Passing Auto-Encoders",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Park_Unsupervised_Hyperbolic_Representation_Learning_via_Message_Passing_Auto-Encoders_CVPR_2021_paper.html",
        "author": "Jiwoong Park, Junho Cho, Hyung Jin Chang, Jin Young Choi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Park_Unsupervised_Hyperbolic_Representation_Learning_via_Message_Passing_Auto-Encoders_CVPR_2021_paper.pdf",
        "aff": "School of Computer Science, University of Birmingham; ASRI, Dept. of ECE., Seoul National University",
        "project": "",
        "github": "https://github.com/junhocho/HGCAE",
        "arxiv": "2103.16046"
    },
    {
        "title": "Unsupervised Learning for Robust Fitting: A Reinforcement Learning Approach",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Truong_Unsupervised_Learning_for_Robust_Fitting_A_Reinforcement_Learning_Approach_CVPR_2021_paper.html",
        "author": "Giang Truong, Huu Le, David Suter, Erchuan Zhang, Syed Zulqarnain Gilani",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Truong_Unsupervised_Learning_for_Robust_Fitting_A_Reinforcement_Learning_Approach_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical Engineering, Chalmers University of Technology; School of Science, Edith Cowan University, Australia",
        "project": "",
        "github": "https://github.com/hagianga21/MaxCon_RL8751",
        "arxiv": "2103.03501"
    },
    {
        "title": "Unsupervised Learning of 3D Object Categories From Videos in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Henzler_Unsupervised_Learning_of_3D_Object_Categories_From_Videos_in_the_CVPR_2021_paper.html",
        "author": "Philipp Henzler, Jeremy Reizenstein, Patrick Labatut, Roman Shapovalov, Tobias Ritschel, Andrea Vedaldi, David Novotny",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Henzler_Unsupervised_Learning_of_3D_Object_Categories_From_Videos_in_the_CVPR_2021_paper.pdf",
        "aff": "Facebook AI Research; University College London",
        "project": "https://henzler.github.io/publication/unsupervised_videos/",
        "github": "https://github.com/henzler",
        "arxiv": "2103.16552"
    },
    {
        "title": "Unsupervised Learning of Depth and Depth-of-Field Effect From Natural Images With Aperture Rendering Generative Adversarial Networks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kaneko_Unsupervised_Learning_of_Depth_and_Depth-of-Field_Effect_From_Natural_Images_CVPR_2021_paper.html",
        "author": "Takuhiro Kaneko",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kaneko_Unsupervised_Learning_of_Depth_and_Depth-of-Field_Effect_From_Natural_Images_CVPR_2021_paper.pdf",
        "aff": "NTT Communication Science Laboratories, NTT Corporation",
        "project": "http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/ar-gan/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Unsupervised Multi-Source Domain Adaptation Without Access to Source Data",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ahmed_Unsupervised_Multi-Source_Domain_Adaptation_Without_Access_to_Source_Data_CVPR_2021_paper.html",
        "author": "Sk Miraj Ahmed, Dripta S. Raychaudhuri, Sujoy Paul, Samet Oymak, Amit K. Roy-Chowdhury",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ahmed_Unsupervised_Multi-Source_Domain_Adaptation_Without_Access_to_Source_Data_CVPR_2021_paper.pdf",
        "aff": "University of California, Riverside; Google Research",
        "project": "",
        "github": "",
        "arxiv": "2104.01845"
    },
    {
        "title": "Unsupervised Multi-Source Domain Adaptation for Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bai_Unsupervised_Multi-Source_Domain_Adaptation_for_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Zechen Bai, Zhigang Wang, Jian Wang, Di Hu, Errui Ding",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bai_Unsupervised_Multi-Source_Domain_Adaptation_for_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China, Beijing 100872, China; Department of Computer Vision Technology (VIS), Baidu Inc., China",
        "project": "",
        "github": "",
        "arxiv": "2104.12961"
    },
    {
        "title": "Unsupervised Object Detection With LIDAR Clues",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Unsupervised_Object_Detection_With_LIDAR_Clues_CVPR_2021_paper.html",
        "author": "Hao Tian, Yuntao Chen, Jifeng Dai, Zhaoxiang Zhang, Xizhou Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_Unsupervised_Object_Detection_With_LIDAR_Clues_CVPR_2021_paper.pdf",
        "aff": "University of Chinese Academy of Sciences, Center for Research on Intelligent Perception and Computing, CASIA, Center for Excellence in Brain Science and Intelligence Technology, CAS; SenseTime Research",
        "project": "",
        "github": "",
        "arxiv": "2011.12953"
    },
    {
        "title": "Unsupervised Part Segmentation Through Disentangling Appearance and Shape",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Unsupervised_Part_Segmentation_Through_Disentangling_Appearance_and_Shape_CVPR_2021_paper.html",
        "author": "Shilong Liu, Lei Zhang, Xiao Yang, Hang Su, Jun Zhu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Unsupervised_Part_Segmentation_Through_Disentangling_Appearance_and_Shape_CVPR_2021_paper.pdf",
        "aff": "/0 /1 /2 /3 /4 /5 /6 /7 /8 /2 /5 /9/10 /11 /6 /12 /13 /5 /14 /15/5 /1 /12 /11 /12 /8 /16 /1/12 /17 /6 /16 /3 /14 /17/18 /8 /2 /5 /1 /12 /11 /1 /14 /19 /8 /1 /14\n/20 /4 /4 /5 /11 /6 /11 /1 /21 /5 /11 /1 /9/13 /17 /11 /4 /5\n/22 /23 /24 /25 /26 /27 /28/29 /24 /30/31/32 /29 /33 /24 /34 /23 /35 /27 /28/36/32 /37 /24 /35 /26/38 /35 /27 /28/31/32 /39 /35 /27 /28/22 /30/31/32 /40 /30 /27/34 /23 /30/31 /41\n/31/42 /33 /43 /44 /45 /26 /46 /47 /26 /48/43 /45 /22 /49 /24 /45 /35 /27 /50/51 /33 /49 /23 /45 /32 /52 /53 /54 /24 /55 /44 /47 /33 /27 /44 /33 /56 /32 /57 /27 /55 /44 /24 /44 /30 /44 /33 /46 /26 /56 /58 /57 /32 /51 /55 /24 /27 /28 /23 /30 /35 /59 /52 /26 /55 /49 /23/40 /26 /24 /27 /44 /60 /29/47 /33 /27 /44 /33 /56\n/31/51 /55 /24 /27 /28 /23 /30 /35 /61 /27 /24 /62 /33 /56 /55 /24 /44 /63 /32 /52 /33 /24 /64 /24 /27 /28 /32 /65 /66 /66 /66 /67 /68 /32 /47 /23 /24 /27 /35/36/60/24 /49 /56 /26 /55 /26 /46 /44 /47 /26 /56 /43 /26 /56 /35 /44 /24 /26 /27\n/69 /25 /24 /30 /55 /25 /70 /66 /32 /63 /35 /27 /28 /71 /24 /35 /26 /65 /72 /73 /74/48 /35 /24 /25 /55 /45 /44 /55 /24 /27 /28 /23 /30 /35 /45 /33 /50 /30 /45 /49 /27 /32 /25 /33 /24 /75 /23 /35 /27 /28 /74/48 /24 /49 /56 /26 /55 /26 /46 /44 /45 /49 /26 /48/32 /69 /55 /30 /23 /35 /27 /28 /55 /55 /32 /50 /49 /55 /75 /64 /73 /74/48 /35 /24 /25 /45 /44 /55 /24 /27 /28 /23 /30 /35 /45 /33 /50 /30 /45 /49 /27\n/20 /76 /2 /12 /6 /11 /21 /12\n/77 /78 /79 /80 /81 /82 /83 /80 /84 /78 /85 /86 /87 /88 /89 /78 /90/87 /91 /81 /92 /79 /81 /85 /78 /86 /93 /94 /79 /78 /82 /82 /94 /79 /95 /87 /93 /78 /86 /83 /96 /92 /82 /79 /78 /97 /98\n/90 /78 /92 /80 /96 /80 /94 /87 /92/87 /91 /87 /88 /99 /78 /95 /80 /85 /96 /86 /80 /79 /100 /101 /84 /94 /95 /84 /100 /96 /79/96 /92/94 /92 /80 /78 /86 /90 /78 /82 /94 /96 /80 /78/89 /87 /98\n/95 /96 /89 /86 /78 /85 /86 /78 /79 /78 /92 /80 /96 /80 /94 /87 /92 /100 /96 /86 /78/95 /96 /85 /96 /88 /89 /78/87 /91 /102 /92 /82 /94 /92 /97/94 /92 /80 /86 /94 /92 /79 /94 /95/87 /88 /99 /78 /95 /80\n/79 /80 /86 /81 /95 /80 /81 /86 /78/96 /92 /82/85 /86 /87 /93 /94 /82 /94 /92 /97/90 /87 /86 /78/78 /103 /85 /89 /96 /94 /92 /96 /88 /89 /78/86 /78 /95 /87 /97 /92 /94 /80 /94 /87 /92/86 /78 /98\n/79 /81 /89 /80 /79 /104/105 /78 /95 /78 /92 /80 /81 /92 /79 /81 /85 /78 /86 /93 /94 /79 /78 /82/90 /78 /80 /84 /87 /82 /79/84 /96 /93 /78/97 /86 /78 /96 /80 /89 /83/86 /78 /89 /96 /103 /78 /82\n/80 /84 /78/82 /78 /85 /78 /92 /82 /78 /92 /95 /83/87 /92/96 /92 /92 /87 /80 /96 /80 /78 /82/82 /96 /80 /96/101 /84 /94 /95 /84/96 /86 /78/95 /87 /79 /80 /89 /83/80 /87/87 /88 /98\n/80 /96 /94 /92 /100 /88 /81 /80 /79 /80 /94 /89 /89 /86 /78 /89 /83 /87 /92/96 /82 /82 /94 /80 /94 /87 /92 /96 /89 /94 /92 /91 /87 /86 /90 /96 /80 /94 /87 /92/79 /81 /95 /84/96 /79 /87 /88 /99 /78 /95 /80\n/79 /78 /97 /90 /78 /92 /80 /96 /80 /94 /87 /92 /90 /96 /79 /106 /87 /86 /79 /96 /89 /94 /78 /92 /95 /83 /90 /96 /85 /104 /107 /87/86 /78 /90 /87 /93 /78 /79 /81 /95 /84/96/82 /78 /98\n/85 /78 /92 /82 /78 /92 /95 /83 /96 /92 /82 /91 /81 /86 /80 /84 /78 /86 /94 /90 /85 /86 /87 /93 /78 /80 /84 /78 /85 /96 /86 /80 /79 /78 /97 /90 /78 /92 /80 /96 /80 /94 /87 /92 /85 /78 /86 /91 /87 /86 /98\n/90 /96 /92 /95 /78 /100 /101 /78/82 /78 /93 /78 /89 /87 /85/96/92 /87 /93 /78 /89 /96 /85 /85 /86 /87 /96 /95 /84/88 /83/82 /94 /79 /78 /92 /80 /96 /92 /97 /89 /94 /92 /97/80 /84 /78\n/96 /85 /85 /78 /96 /86 /96 /92 /95 /78 /96 /92 /82/79 /84 /96 /85 /78/86 /78 /85 /86 /78 /79 /78 /92 /80 /96 /80 /94 /87 /92 /79 /87 /91 /87 /88 /99 /78 /95 /80 /85 /96 /86 /80 /79 /91 /87 /89 /98\n/89 /87 /101 /78 /82/101 /94 /80 /84/86 /78 /95 /87 /92 /79 /80 /86 /81 /95 /80 /94 /87 /92/89 /87 /79 /79 /78 /79 /101 /94 /80 /84 /87 /81 /80 /81 /79 /94 /92 /97/96 /82 /82 /94 /80 /94 /87 /92 /96 /89\n/87 /88 /99 /78 /95 /80 /90 /96 /79 /106 /94 /92 /91 /87 /86 /90 /96 /80 /94 /87 /92 /104 /107 /87/96 /93 /87 /94 /82/82 /78 /97 /78 /92 /78 /86 /96 /80 /78 /82/79 /87 /89 /81 /80 /94 /87 /92 /79 /100 /96\n/88 /87 /80 /80 /89 /78 /92 /78 /95 /106 /88 /89 /87 /95 /106 /94 /79 /82 /78 /79 /94 /97 /92 /78 /82/80 /87/79 /108 /81 /78 /78 /109 /78 /96 /92 /82/78 /103 /85 /96 /92 /82/80 /84 /78 /96 /85 /98\n/85 /78 /96 /86 /96 /92 /95 /78 /86 /78 /85 /86 /78 /79 /78 /92 /80 /96 /80 /94 /87 /92 /100 /89 /78 /96 /82 /94 /92 /97/80 /87/96/90 /87 /86 /78 /78 /91 /91 /78 /95 /80 /94 /93 /78 /82 /94 /79 /78 /92 /98\n/80 /96 /92 /97 /89 /78 /90 /78 /92 /80 /88 /78 /80 /101 /78 /78 /92/97 /78 /87 /90 /78 /80 /86 /83/96 /92 /82/96 /85 /85 /78 /96 /86 /96 /92 /95 /78 /104 /110 /87 /90 /88 /94 /92 /78 /82\n/101 /94 /80 /84/96/79 /78 /89 /91 /98 /79 /81 /85 /78 /86 /93 /94 /79 /78 /82/85 /96 /86 /80 /95 /89 /96 /79 /79 /94 /102 /95 /96 /80 /94 /87 /92/89 /87 /79 /79/96 /92 /82/96 /92/94 /90 /98\n/85 /86 /87 /93 /78 /82/97 /78 /87 /90 /78 /80 /86 /83 /95 /87 /92 /95 /78 /92 /80 /86 /96 /80 /94 /87 /92/95 /87 /92 /79 /80 /86 /96 /94 /92 /80 /100 /101 /78 /95 /96 /92/79 /78 /97 /90 /78 /92 /80\n/90 /87 /86 /78 /95 /87 /92 /79 /94 /79 /80 /78 /92 /80 /85 /96 /86 /80 /79 /101 /94 /80 /84 /79 /78 /90 /96 /92 /80 /94 /95 /90 /78 /96 /92 /94 /92 /97 /79 /104 /110 /87 /90 /85 /86 /78 /84 /78 /92 /98\n/79 /94 /93 /78 /78 /103 /85 /78 /86 /94 /90 /78 /92 /80 /79 /87 /92/96/101 /94 /82 /78 /93 /96 /86 /94 /78 /80 /83 /87 /91 /87 /88 /99 /78 /95 /80 /79 /79 /81 /95 /84/96 /79 /91 /96 /95 /78 /100\n/88 /94 /86 /82 /100 /96 /92 /82/111 /112 /113 /110 /112 /114/115 /116 /110/87 /88 /99 /78 /95 /80 /79 /82 /78 /90 /87 /92 /79 /80 /86 /96 /80 /78/80 /84 /78/78 /91 /91 /78 /95 /80 /94 /93 /78 /98\n/92 /78 /79 /79 /87 /91 /80 /84 /78 /85 /86 /87 /85 /87 /79 /78 /82/90 /78 /80 /84 /87 /82 /104\n/117 /118 /119 /1 /12 /6 /16 /9 /3 /21 /12 /8 /16 /1\n/120 /121 /64 /33 /49 /44 /43 /35 /56 /44 /55 /35 /27 /50 /25 /35 /27 /50 /48/35 /56 /122 /55 /35 /56 /33 /44 /123 /26 /123 /24 /50 /33 /25 /63 /30 /55 /33 /50 /24 /27 /44 /33 /56 /48/33 /59\n/50 /24 /35 /44 /33 /56 /33 /43 /56 /33 /55 /33 /27 /44 /35 /44 /24 /26 /27 /55 /26 /46 /26 /121 /64 /33 /49 /44 /25 /26 /49 /35 /25 /55 /44 /56 /30 /49 /44 /30 /56 /33 /55 /32 /123 /23 /24 /49 /23/23 /35 /62 /33\n/56 /33 /49 /33 /24 /62 /33 /50/24 /27 /49 /56 /33 /35 /55 /24 /27 /28/35 /44 /44 /33 /27 /44 /24 /26 /27/56 /33 /49 /33 /27 /44 /25 /63/46 /26 /56 /44 /23 /33 /24 /56 /56 /26 /121 /30 /55 /44 /27 /33 /55 /55\n/44 /26/44 /23 /33/62 /35 /56 /24 /35 /44 /24 /26 /27 /55 /26 /46 /62 /24 /33 /123 /43 /26 /24 /27 /44 /35 /27 /50/35 /43 /43 /33 /35 /56 /35 /27 /49 /33/124 /65 /70 /125 /45 /126/23 /24 /25 /33\n/44 /23 /33 /56 /33 /23 /35 /62 /33 /121 /33 /33 /27 /48/35 /27 /63 /56 /33 /25 /35 /44 /33 /50 /123 /26 /56 /122 /55 /26 /27 /26 /121 /64 /33 /49 /44 /25 /35 /27 /50 /48/35 /56 /122 /50 /33 /59\n/44 /33 /49 /44 /24 /26 /27/121 /63/33 /24 /44 /23 /33 /56 /55 /30 /43 /33 /56 /62 /24 /55 /33 /50/25 /33 /35 /56 /27 /24 /27 /28/124 /68 /65 /32 /70 /127 /125 /26 /56 /30 /27 /55 /30 /43 /33 /56 /59\n/62 /24 /55 /33 /50 /50 /24 /55 /49 /26 /62 /33 /56 /63 /124 /65 /128 /32 /68 /66 /125 /32 /55 /33 /48/35 /27 /44 /24 /49 /43 /35 /56 /44 /55 /33 /28 /48/33 /27 /44 /35 /44 /24 /26 /27 /24 /55 /56 /33 /25 /59\n/35 /44 /24 /62 /33 /25 /63/25 /33 /55 /55 /55 /44 /30 /50 /24 /33 /50/124 /65 /70 /125 /50 /30 /33/44 /26/44 /23 /33/49 /26 /55 /44 /25 /63/33 /46 /46 /26 /56 /44 /55 /56 /33 /129 /30 /24 /56 /33 /50\n/46 /26 /56 /50 /35 /44 /35 /35 /27 /27 /26 /44 /35 /44 /24 /26 /27 /45\n/41 /47 /26 /56 /56 /33 /55 /43 /26 /27 /50 /24 /27 /28/35 /30 /44 /23 /26 /56\n/130 /131 /132 /133 /133 /i255\n/135 /136 /133 /137 /138 /136 /139 /140\n/141 /142/138 /143 /140 /i255\n/137 /131 /138 /136 /133 /144 /132 /131 /142/138 /137 /135 /132 /136\n/145 /138 /131 /143 /140 /i255\n/146 /138 /131 /135 /138 /136 /139 /140/147 /138 /131 /137 /i255 /135 /133 /i255 /135 /136 /146 /138 /131 /135 /138 /136 /137 /i255 /137 /132 /148\n/149 /24 /28 /30 /56 /33 /65 /150 /22 /33 /48/35 /27 /44 /24 /49 /49 /26 /27 /55 /24 /55 /44 /33 /27 /49 /63/26 /46 /26 /121 /64 /33 /49 /44 /43 /35 /56 /44 /55 /45 /22 /33 /28 /48/33 /27 /44 /35 /59\n/44 /24 /26 /27/56 /33 /28 /24 /26 /27 /55 /26 /46 /44 /23 /33/55 /35 /48/33 /43 /35 /56 /44 /55 /23 /26 /30 /25 /50/121 /33/55 /33 /48/35 /27 /44 /24 /49 /35 /25 /25 /63/49 /26 /27 /59\n/55 /24 /55 /44 /33 /27 /44 /35 /49 /56 /26 /55 /55 /26 /121 /64 /33 /49 /44 /24 /27 /55 /44 /35 /27 /49 /33 /55 /35 /27 /50 /56 /26 /121 /30 /55 /44 /44 /26 /35 /43 /43 /33 /35 /56 /35 /27 /49 /33 /35 /27 /50\n/55 /23 /35 /43 /33 /49 /23 /35 /27 /28 /33 /55 /45 /52 /33 /55 /44 /62 /24 /33 /123/24 /27/49 /26 /25 /26 /56 /55 /45\n/51 /23 /24 /55/43 /35 /43 /33 /56/43 /56 /24 /48/35 /56 /24 /25 /63/46 /26 /49 /30 /55 /33 /55/26 /27/30 /27 /55 /30 /43 /33 /56 /62 /24 /55 /33 /50 /55 /33 /48/35 /27 /59\n/44 /24 /49/43 /35 /56 /44 /55 /33 /28 /48/33 /27 /44 /35 /44 /24 /26 /27 /32 /35 /55 /26 /121 /64 /33 /49 /44 /43 /35 /56 /44 /55 /43 /56 /26 /62 /24 /50 /33/56 /24 /49 /23 /33 /56 /24 /27 /46 /26 /56 /59\n/48/35 /44 /24 /26 /27/35 /121 /26 /30 /44 /24 /27 /44 /56 /24 /27 /55 /24 /49/26 /121 /64 /33 /49 /44 /55 /44 /56 /30 /49 /44 /30 /56 /33 /55 /123 /23 /24 /49 /23/35 /56 /33 /49 /26 /48/43 /25 /33 /59\n/48/33 /27 /44 /35 /56 /63/44 /26/25 /35 /27 /50 /48/35 /56 /122/43 /26 /24 /27 /44 /55 /45 /51 /26/35 /25 /25 /33 /62 /24 /35 /44 /33/44 /23 /33/33 /46 /46 /26 /56 /44 /55 /24 /27/35 /27 /59\n/27 /26 /44 /35 /44 /24 /26 /27 /55 /32 /123 /33/24 /27 /62 /33 /55 /44 /24 /28 /35 /44 /33/44 /23 /33/30 /27 /55 /30 /43 /33 /56 /62 /24 /55 /33 /50/25 /33 /35 /56 /27 /24 /27 /28/55 /44 /56 /35 /44 /59\n/33 /28 /63/46 /26 /56 /35 /30 /44 /26 /48/35 /44 /24 /49/55 /33 /48/35 /27 /44 /24 /49/43 /35 /56 /44 /55 /33 /28 /48/33 /27 /44 /35 /44 /24 /26 /27/124 /65 /70 /125 /45/57 /44 /23 /35 /55\n/35 /25 /55 /26/55 /23 /26 /123 /27/35 /27/33 /27 /49 /26 /30 /56 /35 /28 /24 /27 /28/24 /48/43 /35 /49 /44 /26 /27/55 /24 /27 /28 /25 /33 /59 /62 /24 /33 /123 /128 /42/26 /121 /59\n/64 /33 /49 /44 /56 /33 /49 /26 /27 /55 /44 /56 /30 /49 /44 /24 /26 /27/121 /63 /30 /55 /24 /27 /28/55 /33 /25 /46 /59 /55 /30 /43 /33 /56 /62 /24 /55 /33 /50 /25 /33 /35 /56 /27 /33 /50 /55 /33 /48/35 /27 /59\n/44 /24 /49/43 /35 /56 /44 /55 /123 /23 /24 /49 /23/33 /27 /46 /26 /56 /49 /33 /55 /55 /33 /48/35 /27 /44 /24 /49/49 /26 /27 /55 /24 /55 /44 /33 /27 /49 /63/121 /33 /44 /123 /33 /33 /27/44 /23 /33\n/56 /33 /49 /26 /27 /55 /44 /56 /30 /49 /44 /33 /50/128 /42/48 /33 /55 /23/35 /27 /50/26 /56 /24 /28 /24 /27 /35 /25 /70 /42/24 /48/35 /28 /33 /55 /124 /65 /67 /125 /45\n/58/28 /26 /26 /50/26 /121 /64 /33 /49 /44 /43 /35 /56 /44 /55 /33 /28 /48/33 /27 /44 /35 /44 /24 /26 /27/55 /23 /26 /30 /25 /50/55 /35 /44 /24 /55 /46 /63 /44 /123 /26/33 /55 /59\n/55 /33 /27 /44 /24 /35 /25 /49 /26 /27 /55 /44 /56 /35 /24 /27 /44 /55 /26 /27 /79 /78 /90 /96 /92 /80 /94 /95 /79 /35 /27 /50 /97 /78 /87 /90 /78 /80 /86 /83 /32 /123 /23 /24 /49 /23 /49 /26 /56 /56 /33 /59\n/55 /43 /26 /27 /50/44 /26/26 /121 /64 /33 /49 /44 /35 /43 /43 /33 /35 /56 /35 /27 /49 /33/35 /27 /50/55 /23 /35 /43 /33 /32 /56 /33 /55 /43 /33 /49 /44 /24 /62 /33 /25 /63 /45/51 /23 /33\n/79 /78 /90 /96 /92 /80 /94 /95/95 /87 /92 /79 /80 /86 /96 /94 /92 /80/48 /33 /35 /27 /55/44 /23 /35 /44/55 /33 /28 /48/33 /27 /44 /35 /44 /24 /26 /27/56 /33 /28 /24 /26 /27 /55/26 /46\n/44 /23 /33 /55 /35 /48/33 /43 /35 /56 /44 /55 /23 /26 /30 /25 /50/121 /33 /55 /33 /48/35 /27 /44 /24 /49 /35 /25 /25 /63/49 /26 /27 /55 /24 /55 /44 /33 /27 /44 /35 /49 /56 /26 /55 /55 /26 /121 /59\n/64 /33 /49 /44 /24 /27 /55 /44 /35 /27 /49 /33 /55 /35 /27 /50/56 /26 /121 /30 /55 /44 /44 /26/35 /43 /43 /33 /35 /56 /35 /27 /49 /33 /35 /27 /50/55 /23 /35 /43 /33 /49 /23 /35 /27 /28 /33 /55 /45\n/51 /23 /33 /97 /78 /87 /90 /78 /80 /86 /94 /95 /95 /87 /92 /79 /80 /86 /96 /94 /92 /80 /48/33 /35 /27 /55 /35 /43 /35 /56 /44 /55 /33 /28 /48/33 /27 /44 /35 /44 /24 /26 /27 /56 /33 /28 /24 /26 /27\n/55 /23 /26 /30 /25 /50 /121 /33 /25 /26 /49 /35 /25 /25 /63 /49 /26 /27 /27 /33 /49 /44 /33 /50 /35 /27 /50 /44 /23 /33 /30 /27 /24 /26 /27 /26 /46 /35 /25 /25 /43 /35 /56 /44 /55 /55 /23 /26 /30 /25 /50\n/33 /27 /44 /24 /56 /33 /25 /63/49 /26 /62 /33 /56 /44 /23 /33/49 /26 /56 /56 /33 /55 /43 /26 /27 /50 /24 /27 /28/26 /121 /64 /33 /49 /44 /45/51 /23 /33 /55 /33/44 /123 /26/49 /26 /27 /59\n/55 /44 /56 /35 /24 /27 /44 /55 /49 /35 /27/121 /33/55 /33 /33 /27/24 /27/149 /24 /28 /45 /65 /32 /24 /27/123 /23 /24 /49 /23/44 /23 /33/43 /35 /56 /44 /55 /123 /24 /44 /23/44 /23 /33\n/55 /35 /48/33 /55 /33 /48/35 /27 /44 /24 /49/24 /27 /46 /26 /56 /48/35 /44 /24 /26 /27/151 /33 /45 /28 /45 /32 /23 /33 /35 /50 /55/26 /46 /121 /24 /56 /50 /152 /35 /56 /33/49 /26 /62 /59\n/33 /56 /33 /50/121 /63/44 /23 /33 /55 /35 /48/33 /55 /33 /28 /48/33 /27 /44 /35 /44 /24 /26 /27/49 /26 /25 /26 /56 /151 /33 /45 /28 /45 /32 /56 /33 /50 /152 /24 /27/50 /24 /46 /46 /33 /56 /33 /27 /44\n8355\n",
        "project": "",
        "github": "",
        "arxiv": "2105.12405"
    },
    {
        "title": "Unsupervised Pre-Training for Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Unsupervised_Pre-Training_for_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Dengpan Fu, Dongdong Chen, Jianmin Bao, Hao Yang, Lu Yuan, Lei Zhang, Houqiang Li, Dong Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fu_Unsupervised_Pre-Training_for_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2012.03753"
    },
    {
        "title": "Unsupervised Real-World Image Super Resolution via Domain-Distance Aware Training",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wei_Unsupervised_Real-World_Image_Super_Resolution_via_Domain-Distance_Aware_Training_CVPR_2021_paper.html",
        "author": "Yunxuan Wei, Shuhang Gu, Yawei Li, Radu Timofte, Longcun Jin, Hengjie Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wei_Unsupervised_Real-World_Image_Super_Resolution_via_Domain-Distance_Aware_Training_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; South China University of Technology; The University of Sydney",
        "project": "",
        "github": "https://github.com/ShuhangGu/DASR",
        "arxiv": "2004.01178"
    },
    {
        "title": "Unsupervised Visual Attention and Invariance for Reinforcement Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Unsupervised_Visual_Attention_and_Invariance_for_Reinforcement_Learning_CVPR_2021_paper.html",
        "author": "Xudong Wang, Long Lian, Stella X. Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Unsupervised_Visual_Attention_and_Invariance_for_Reinforcement_Learning_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley / ICSI",
        "project": "",
        "github": "",
        "arxiv": "2104.02921"
    },
    {
        "title": "Unsupervised Visual Representation Learning by Tracking Patches in Video",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Unsupervised_Visual_Representation_Learning_by_Tracking_Patches_in_Video_CVPR_2021_paper.html",
        "author": "Guangting Wang, Yizhou Zhou, Chong Luo, Wenxuan Xie, Wenjun Zeng, Zhiwei Xiong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Unsupervised_Visual_Representation_Learning_by_Tracking_Patches_in_Video_CVPR_2021_paper.pdf",
        "aff": "Microsoft Research Asia; University of Science and Technology of China",
        "project": "",
        "github": "",
        "arxiv": "2105.02545"
    },
    {
        "title": "UnsupervisedR&R: Unsupervised Point Cloud Registration via Differentiable Rendering",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Banani_UnsupervisedRR_Unsupervised_Point_Cloud_Registration_via_Differentiable_Rendering_CVPR_2021_paper.html",
        "author": "Mohamed El Banani, Luya Gao, Justin Johnson",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Banani_UnsupervisedRR_Unsupervised_Point_Cloud_Registration_via_Differentiable_Rendering_CVPR_2021_paper.pdf",
        "aff": "University of Michigan",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Unveiling the Potential of Structure Preserving for Weakly Supervised Object Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pan_Unveiling_the_Potential_of_Structure_Preserving_for_Weakly_Supervised_Object_CVPR_2021_paper.html",
        "author": "Xingjia Pan, Yingguo Gao, Zhiwen Lin, Fan Tang, Weiming Dong, Haolei Yuan, Feiyue Huang, Changsheng Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_Unveiling_the_Potential_of_Structure_Preserving_for_Weakly_Supervised_Object_CVPR_2021_paper.pdf",
        "aff": "Jilin University; NLPR, Institute of Automation, CAS; Youtu Lab, Tencent",
        "project": "",
        "github": "github.com/Panxjia/SPA",
        "arxiv": "2103.04523"
    },
    {
        "title": "User-Guided Line Art Flat Filling With Split Filling Mechanism",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_User-Guided_Line_Art_Flat_Filling_With_Split_Filling_Mechanism_CVPR_2021_paper.html",
        "author": "Lvmin Zhang, Chengze Li, Edgar Simo-Serra, Yi Ji, Tien-Tsin Wong, Chunping Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_User-Guided_Line_Art_Flat_Filling_With_Split_Filling_Mechanism_CVPR_2021_paper.pdf",
        "aff": "Soochow University / Style2Paints Research, China; The Chinese University of Hong Kong, China; Waseda University / JST PRESTO, Japan; The Chinese University of Hong Kong / Style2Paints Research, China; Soochow University, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Using Shape To Categorize: Low-Shot Learning With an Explicit Shape Bias",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Stojanov_Using_Shape_To_Categorize_Low-Shot_Learning_With_an_Explicit_Shape_CVPR_2021_paper.html",
        "author": "Stefan Stojanov, Anh Thai, James M. Rehg",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Stojanov_Using_Shape_To_Categorize_Low-Shot_Learning_With_an_Explicit_Shape_CVPR_2021_paper.pdf",
        "aff": "Georgia Institute of Technology",
        "project": "https://rehg-lab.github.io/publication-pages/lowshot-shapebias/",
        "github": "https://github.com/rehg-lab",
        "arxiv": "2101.07296"
    },
    {
        "title": "VDSM: Unsupervised Video Disentanglement With State-Space Modeling and Deep Mixtures of Experts",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Vowels_VDSM_Unsupervised_Video_Disentanglement_With_State-Space_Modeling_and_Deep_Mixtures_CVPR_2021_paper.html",
        "author": "Matthew J. Vowels, Necati Cihan Camgoz, Richard Bowden",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Vowels_VDSM_Unsupervised_Video_Disentanglement_With_State-Space_Modeling_and_Deep_Mixtures_CVPR_2021_paper.pdf",
        "aff": "Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK",
        "project": "",
        "github": "",
        "arxiv": "2103.07292"
    },
    {
        "title": "VIGOR: Cross-View Image Geo-Localization Beyond One-to-One Retrieval",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_VIGOR_Cross-View_Image_Geo-Localization_Beyond_One-to-One_Retrieval_CVPR_2021_paper.html",
        "author": "Sijie Zhu, Taojiannan Yang, Chen Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_VIGOR_Cross-View_Image_Geo-Localization_Beyond_One-to-One_Retrieval_CVPR_2021_paper.pdf",
        "aff": "University of North Carolina at Charlotte",
        "project": "",
        "github": "https://github.com/Jeff-Zilence/VIGOR",
        "arxiv": "2011.12172"
    },
    {
        "title": "VIP-DeepLab: Learning Visual Perception With Depth-Aware Video Panoptic Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Qiao_VIP-DeepLab_Learning_Visual_Perception_With_Depth-Aware_Video_Panoptic_Segmentation_CVPR_2021_paper.html",
        "author": "Siyuan Qiao, Yukun Zhu, Hartwig Adam, Alan Yuille, Liang-Chieh Chen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qiao_VIP-DeepLab_Learning_Visual_Perception_With_Depth-Aware_Video_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Google Research",
        "project": "",
        "github": "https://github.com/joe-siyuan-qiao/ViP-DeepLab",
        "arxiv": ""
    },
    {
        "title": "VITON-HD: High-Resolution Virtual Try-On via Misalignment-Aware Normalization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Choi_VITON-HD_High-Resolution_Virtual_Try-On_via_Misalignment-Aware_Normalization_CVPR_2021_paper.html",
        "author": "Seunghwan Choi, Sunghyun Park, Minsoo Lee, Jaegul Choo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Choi_VITON-HD_High-Resolution_Virtual_Try-On_via_Misalignment-Aware_Normalization_CVPR_2021_paper.pdf",
        "aff": "KAIST, Daejeon, South Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "VLN BERT: A Recurrent Vision-and-Language BERT for Navigation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hong_VLN_BERT_A_Recurrent_Vision-and-Language_BERT_for_Navigation_CVPR_2021_paper.html",
        "author": "Yicong Hong, Qi Wu, Yuankai Qi, Cristian Rodriguez-Opazo, Stephen Gould",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_VLN_BERT_A_Recurrent_Vision-and-Language_BERT_for_Navigation_CVPR_2021_paper.pdf",
        "aff": "The University of Adelaide; The Australian National University",
        "project": "",
        "github": "https://github.com/YicongHong/Recurrent-VLN-BERT",
        "arxiv": ""
    },
    {
        "title": "VS-Net: Voting With Segmentation for Visual Localization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_VS-Net_Voting_With_Segmentation_for_Visual_Localization_CVPR_2021_paper.html",
        "author": "Zhaoyang Huang, Han Zhou, Yijin Li, Bangbang Yang, Yan Xu, Xiaowei Zhou, Hujun Bao, Guofeng Zhang, Hongsheng Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_VS-Net_Voting_With_Segmentation_for_Visual_Localization_CVPR_2021_paper.pdf",
        "aff": "CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong; School of CST, Xidian University; State Key Lab of CAD&CG, Zhejiang University; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong; CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong; State Key Lab of CAD&CG, Zhejiang University",
        "project": "",
        "github": "https://github.com/zju3dv/VS-Net",
        "arxiv": ""
    },
    {
        "title": "VSPW: A Large-scale Dataset for Video Scene Parsing in the Wild",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Miao_VSPW_A_Large-scale_Dataset_for_Video_Scene_Parsing_in_the_CVPR_2021_paper.html",
        "author": "Jiaxu Miao, Yunchao Wei, Yu Wu, Chen Liang, Guangrui Li, Yi Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Miao_VSPW_A_Large-scale_Dataset_for_Video_Scene_Parsing_in_the_CVPR_2021_paper.pdf",
        "aff": "Baidu Research, ReLER, University of Technology Sydney; Zhejiang University, Baidu Research; Zhejiang University; ReLER, University of Technology Sydney",
        "project": "https://www.vspwdataset.com/",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "VaB-AL: Incorporating Class Imbalance and Difficulty With Variational Bayes for Active Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Choi_VaB-AL_Incorporating_Class_Imbalance_and_Difficulty_With_Variational_Bayes_for_CVPR_2021_paper.html",
        "author": "Jongwon Choi, Kwang Moo Yi, Jihoon Kim, Jinho Choo, Byoungjip Kim, Jinyeop Chang, Youngjune Gwon, Hyung Jin Chang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Choi_VaB-AL_Incorporating_Class_Imbalance_and_Difficulty_With_Variational_Bayes_for_CVPR_2021_paper.pdf",
        "aff": "University of British Columbia, Canada; Samsung SDS, South Korea; University of Birmingham, United Kingdom; Chung-Ang University, South Korea",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Variational Pedestrian Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Variational_Pedestrian_Detection_CVPR_2021_paper.html",
        "author": "Yuang Zhang, Huanyu He, Jianguo Li, Yuxi Li, John See, Weiyao Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Variational_Pedestrian_Detection_CVPR_2021_paper.pdf",
        "aff": "Shanghai Jiao Tong University, China; Heriot-Watt University, Malaysia; Ant Group",
        "project": "",
        "github": "",
        "arxiv": "2104.12389"
    },
    {
        "title": "Variational Prototype Learning for Deep Face Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Variational_Prototype_Learning_for_Deep_Face_Recognition_CVPR_2021_paper.html",
        "author": "Jiankang Deng, Jia Guo, Jing Yang, Alexandros Lattas, Stefanos Zafeiriou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Variational_Prototype_Learning_for_Deep_Face_Recognition_CVPR_2021_paper.pdf",
        "aff": "University of Nottingham; InsightFace; Huawei, Imperial College",
        "project": "",
        "github": "https://github.com/InsightFace/InsightFace",
        "arxiv": ""
    },
    {
        "title": "Variational Relational Point Completion Network",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pan_Variational_Relational_Point_Completion_Network_CVPR_2021_paper.html",
        "author": "Liang Pan, Xinyi Chen, Zhongang Cai, Junzhe Zhang, Haiyu Zhao, Shuai Yi, Ziwei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_Variational_Relational_Point_Completion_Network_CVPR_2021_paper.pdf",
        "aff": "SenseTime Research; S-Lab, Nanyang Technological University; Shanghai AI Laboratory",
        "project": "https://paul007pl.github.io/projects/VRCNet",
        "github": "",
        "arxiv": "2104.10154"
    },
    {
        "title": "Variational Transformer Networks for Layout Generation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Arroyo_Variational_Transformer_Networks_for_Layout_Generation_CVPR_2021_paper.html",
        "author": "Diego Martin Arroyo, Janis Postels, Federico Tombari",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Arroyo_Variational_Transformer_Networks_for_Layout_Generation_CVPR_2021_paper.pdf",
        "aff": "Technische Universit\u00e4t M\u00fcnchen; ETH Z\u00fcrich; Google, Inc",
        "project": "",
        "github": "",
        "arxiv": "2104.02416"
    },
    {
        "title": "VarifocalNet: An IoU-Aware Dense Object Detector",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_VarifocalNet_An_IoU-Aware_Dense_Object_Detector_CVPR_2021_paper.html",
        "author": "Haoyang Zhang, Ying Wang, Feras Dayoub, Niko Sunderhauf",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_VarifocalNet_An_IoU-Aware_Dense_Object_Detector_CVPR_2021_paper.pdf",
        "aff": "Australian Centre for Robotic Vision, Queensland University of Technology; University of Queensland",
        "project": "",
        "github": "https://github.com/hyz-xmaster/VarifocalNet",
        "arxiv": "2008.13367"
    },
    {
        "title": "Vectorization and Rasterization: Self-Supervised Learning for Sketch and Handwriting",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bhunia_Vectorization_and_Rasterization_Self-Supervised_Learning_for_Sketch_and_Handwriting_CVPR_2021_paper.html",
        "author": "Ayan Kumar Bhunia, Pinaki Nath Chowdhury, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bhunia_Vectorization_and_Rasterization_Self-Supervised_Learning_for_Sketch_and_Handwriting_CVPR_2021_paper.pdf",
        "aff": "University of Edinburgh, United Kingdom; SketchX, CVSSP, University of Surrey, United Kingdom",
        "project": "",
        "github": "",
        "arxiv": "2103.13716"
    },
    {
        "title": "Verifiability and Predictability: Interpreting Utilities of Network Architectures for Point Cloud Processing",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Verifiability_and_Predictability_Interpreting_Utilities_of_Network_Architectures_for_Point_CVPR_2021_paper.html",
        "author": "Wen Shen, Zhihua Wei, Shikun Huang, Binbin Zhang, Panyue Chen, Ping Zhao, Quanshi Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_Verifiability_and_Predictability_Interpreting_Utilities_of_Network_Architectures_for_Point_CVPR_2021_paper.pdf",
        "aff": "Tongji University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China",
        "project": "",
        "github": "",
        "arxiv": "1911.09053"
    },
    {
        "title": "ViPNAS: Efficient Video Pose Estimation via Neural Architecture Search",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_ViPNAS_Efficient_Video_Pose_Estimation_via_Neural_Architecture_Search_CVPR_2021_paper.html",
        "author": "Lumin Xu, Yingda Guan, Sheng Jin, Wentao Liu, Chen Qian, Ping Luo, Wanli Ouyang, Xiaogang Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_ViPNAS_Efficient_Video_Pose_Estimation_via_Neural_Architecture_Search_CVPR_2021_paper.pdf",
        "aff": "ViPNAS: Ef\ufb01cient Video Pose Estimation via Neural Architecture Search\nLumin Xu1,2Yingda Guan2Sheng Jin3,2Wentao Liu4Chen Qian4\nPing Luo3Wanli Ouyang5Xiaogang Wang1,2\n1The Chinese University of Hong Kong2SenseTime Research3The University of Hong Kong\n4SenseTime Research and Tetras.AI5The University of Sydney\nluminxu@link.cuhk.edu.hk {guanyingda, jinsheng, liuwentao, qianchen }@sensetime.com\npluo@cs.hku.hk wanli.ouyang@sydney.edu.au xgwang@ee.cuhk.edu.hk\nAbstract\nHuman pose estimation has achieved signi\ufb01cant\nprogress in recent years. However, most of the recent meth-\nods focus on improving accuracy using complicated mod-\nels and ignoring real-time ef\ufb01ciency. To achieve a better\ntrade-off between accuracy and ef\ufb01ciency, we propose a\nnovel neural architecture search (NAS) method, termed ViP-\nNAS, to search networks in both spatial and temporal levels\nfor fast online video pose estimation. In the spatial level,\nwe carefully design the search space with \ufb01ve different di-\nmensions including network depth, width, kernel size, group\nnumber, and attentions. In the temporal level, we search\nfrom a series of temporal feature fusions to optimize the to-\ntal accuracy and speed across multiple video frames. To\nthe best of our knowledge, we are the \ufb01rst to search for the\ntemporal feature fusion and automatic computation alloca-\ntion in videos. Extensive experiments demonstrate the ef-\nfectiveness of our approach on the challenging COCO2017\nand PoseTrack2018 datasets. Our discovered model fam-\nily, S-ViPNAS and T-ViPNAS, achieve signi\ufb01cantly higher\ninference speed (CPU real-time) without sacri\ufb01cing the ac-\ncuracy compared to the previous state-of-the-art methods.\n1. Introduction\nHuman pose estimation has made impressive progress in\nrecent years with the development of stronger neural net-\nworks. Most state-of-the-art models [ 36,49,56] only focus\non improving the accuracy, but ignore the computational\ncomplexity and real-time performance. However, both ac-\ncuracy and ef\ufb01ciency are critical for real-world applications\nof video pose estimation. In this paper, we aim to build\na lightweight pose estimator that achieves state-of-the-art\nperformance with signi\ufb01cant model complexity reduction.\nFor video pose estimation, there is commonly consider-\nFigure 1. Speed-accuracy trade-off on PoseTrack2018 [ 1] val-\nidation set. Methods involve SBL [ 56], LightTrack [ 38] and our\nViPNAS with various backbones. With accuracy comparable to\nstate-of-the-art networks, ViPNAS achieves CPU real-time with\nsigni\ufb01cantly lower computation.\nable temporal redundancy that leads to super\ufb02uous compu-\ntation, i.e. adjacent frames in a video share similar global\ncontext information. The temporal contextual information\ncan be used for improving pose estimation. Therefore, it is\ncritical to fuse features from adjacent frames to the current\nframe in order to effectively utilize the temporal contextual\ninformation for balancing accuracy and ef\ufb01ciency. How-\never, there are still several open questions:\n1. Low-level local features are important for accurate\nlocalization, while higher-level global features are robust to\nocclusion and large pose variations. Which stage of features\nshould be fused?\n2. For temporal feature fusion, various fusion operations\n(e.g. addition, multiplication, or concatenation) are chosen\nby trial-and-error. How to choose the optimal operation?\n3. The goal is to optimize the total accuracy subject to\nthe total computation complexity (Flops) constraints over\n16072\n",
        "project": "",
        "github": "",
        "arxiv": "2105.10154"
    },
    {
        "title": "Video Object Segmentation Using Global and Instance Embedding Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ge_Video_Object_Segmentation_Using_Global_and_Instance_Embedding_Learning_CVPR_2021_paper.html",
        "author": "Wenbin Ge, Xiankai Lu, Jianbing Shen",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_Video_Object_Segmentation_Using_Global_and_Instance_Embedding_Learning_CVPR_2021_paper.pdf",
        "aff": "Inception Institute of Arti\ufb01cial Intelligence; Beijing Institute of Technology; School of Software, Shandong University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Video Prediction Recalling Long-Term Motion Context via Memory Alignment Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Video_Prediction_Recalling_Long-Term_Motion_Context_via_Memory_Alignment_Learning_CVPR_2021_paper.html",
        "author": "Sangmin Lee, Hak Gu Kim, Dae Hwi Choi, Hyung-Il Kim, Yong Man Ro",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Video_Prediction_Recalling_Long-Term_Motion_Context_via_Memory_Alignment_Learning_CVPR_2021_paper.pdf",
        "aff": "ETRI, South Korea; EPFL, Switzerland; Image and Video Systems Lab, KAIST, South Korea",
        "project": "",
        "github": "https://github.com/sangmin-git/LMC-Memory",
        "arxiv": "2104.00924"
    },
    {
        "title": "Video Rescaling Networks With Joint Optimization Strategies for Downscaling and Upscaling",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Video_Rescaling_Networks_With_Joint_Optimization_Strategies_for_Downscaling_and_CVPR_2021_paper.html",
        "author": "Yan-Cheng Huang, Yi-Hsin Chen, Cheng-You Lu, Hui-Po Wang, Wen-Hsiao Peng, Ching-Chun Huang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Video_Rescaling_Networks_With_Joint_Optimization_Strategies_for_Downscaling_and_CVPR_2021_paper.pdf",
        "aff": "CISPA Helmholtz Center for Information Security; National Yang Ming Chiao Tung University, Taiwan",
        "project": "",
        "github": "",
        "arxiv": "2103.14858"
    },
    {
        "title": "VideoMoCo: Contrastive Video Representation Learning With Temporally Adversarial Examples",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Pan_VideoMoCo_Contrastive_Video_Representation_Learning_With_Temporally_Adversarial_Examples_CVPR_2021_paper.html",
        "author": "Tian Pan, Yibing Song, Tianyu Yang, Wenhao Jiang, Wei Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_VideoMoCo_Contrastive_Video_Representation_Learning_With_Temporally_Adversarial_Examples_CVPR_2021_paper.pdf",
        "aff": "Tencent AI Lab; Tencent Data Platform",
        "project": "",
        "github": "https://github.com/tinapan-pt/VideoMoCo",
        "arxiv": "2103.05905"
    },
    {
        "title": "View Generalization for Single Image Textured 3D Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bhattad_View_Generalization_for_Single_Image_Textured_3D_Models_CVPR_2021_paper.html",
        "author": "Anand Bhattad, Aysegul Dundar, Guilin Liu, Andrew Tao, Bryan Catanzaro",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bhattad_View_Generalization_for_Single_Image_Textured_3D_Models_CVPR_2021_paper.pdf",
        "aff": "NVIDIA; University of Illinois at Urbana-Champaign; Bilkent University",
        "project": "",
        "github": "",
        "arxiv": "2106.06533"
    },
    {
        "title": "View-Guided Point Cloud Completion",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_View-Guided_Point_Cloud_Completion_CVPR_2021_paper.html",
        "author": "Xuancheng Zhang, Yutong Feng, Siqi Li, Changqing Zou, Hai Wan, Xibin Zhao, Yandong Guo, Yue Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_View-Guided_Point_Cloud_Completion_CVPR_2021_paper.pdf",
        "aff": "OPPO Research Institute; School of Software, Tsinghua University, China; BNRist, KLISS, School of Software, Tsinghua University, China; BNRist, KLISS, School of Software, Tsinghua University, China; THUICBS, Tsinghua University; Huawei Technologies Canada Co., Ltd",
        "project": "",
        "github": "",
        "arxiv": "2104.05666"
    },
    {
        "title": "VinVL: Revisiting Visual Representations in Vision-Language Models",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_VinVL_Revisiting_Visual_Representations_in_Vision-Language_Models_CVPR_2021_paper.html",
        "author": "Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang, Yejin Choi, Jianfeng Gao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_VinVL_Revisiting_Visual_Representations_in_Vision-Language_Models_CVPR_2021_paper.pdf",
        "aff": "University of Washington; Microsoft Corporation",
        "project": "",
        "github": "https://github.com/pzzhang/VinVL",
        "arxiv": "2101.00529"
    },
    {
        "title": "VirFace: Enhancing Face Recognition via Unlabeled Shallow Data",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_VirFace_Enhancing_Face_Recognition_via_Unlabeled_Shallow_Data_CVPR_2021_paper.html",
        "author": "Wenyu Li, Tianchu Guo, Pengyu Li, Binghui Chen, Biao Wang, Wangmeng Zuo, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_VirFace_Enhancing_Face_Recognition_via_Unlabeled_Shallow_Data_CVPR_2021_paper.pdf",
        "aff": "Not provided in the text; School of Computer Science and Technology, Harbin Institute of Technology, China; Hong Kong Polytechnic University, Hong Kong, China",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "VirTex: Learning Visual Representations From Textual Annotations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Desai_VirTex_Learning_Visual_Representations_From_Textual_Annotations_CVPR_2021_paper.html",
        "author": "Karan Desai, Justin Johnson",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Desai_VirTex_Learning_Visual_Representations_From_Textual_Annotations_CVPR_2021_paper.pdf",
        "aff": "University of Michigan",
        "project": "",
        "github": "",
        "arxiv": "2006.06666"
    },
    {
        "title": "Virtual Fully-Connected Layer: Training a Large-Scale Face Recognition Dataset With Limited Computational Resources",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Li_Virtual_Fully-Connected_Layer_Training_a_Large-Scale_Face_Recognition_Dataset_With_CVPR_2021_paper.html",
        "author": "Pengyu Li, Biao Wang, Lei Zhang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Virtual_Fully-Connected_Layer_Training_a_Large-Scale_Face_Recognition_Dataset_With_CVPR_2021_paper.pdf",
        "aff": "Department of Computing, Hong Kong Polytechnic University; Artificial Intelligence Center, DAMO Academy, Alibaba Group",
        "project": "",
        "github": "https://github.com/pengyuLPY/Virtual-Fully-Connected-Layer.git",
        "arxiv": ""
    },
    {
        "title": "Visual Navigation With Spatial Attention",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Mayo_Visual_Navigation_With_Spatial_Attention_CVPR_2021_paper.html",
        "author": "Bar Mayo, Tamir Hazan, Ayellet Tal",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Mayo_Visual_Navigation_With_Spatial_Attention_CVPR_2021_paper.pdf",
        "aff": "Technion",
        "project": "",
        "github": "",
        "arxiv": "2104.09807"
    },
    {
        "title": "Visual Room Rearrangement",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Weihs_Visual_Room_Rearrangement_CVPR_2021_paper.html",
        "author": "Luca Weihs, Matt Deitke, Aniruddha Kembhavi, Roozbeh Mottaghi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Weihs_Visual_Room_Rearrangement_CVPR_2021_paper.pdf",
        "aff": "PRIOR @ Allen Institute for AI; University of Washington",
        "project": "ai2thor.allenai.org/rearrangement",
        "github": "",
        "arxiv": "2103.16544"
    },
    {
        "title": "Visual Semantic Role Labeling for Video Understanding",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Sadhu_Visual_Semantic_Role_Labeling_for_Video_Understanding_CVPR_2021_paper.html",
        "author": "Arka Sadhu, Tanmay Gupta, Mark Yatskar, Ram Nevatia, Aniruddha Kembhavi",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sadhu_Visual_Semantic_Role_Labeling_for_Video_Understanding_CVPR_2021_paper.pdf",
        "aff": "University of Pennsylvania; PRIOR @ Allen Institute for AI; University of Southern California",
        "project": "vidsitu.org",
        "github": "",
        "arxiv": "2104.00990"
    },
    {
        "title": "VisualVoice: Audio-Visual Speech Separation With Cross-Modal Consistency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_VisualVoice_Audio-Visual_Speech_Separation_With_Cross-Modal_Consistency_CVPR_2021_paper.html",
        "author": "Ruohan Gao, Kristen Grauman",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_VisualVoice_Audio-Visual_Speech_Separation_With_Cross-Modal_Consistency_CVPR_2021_paper.pdf",
        "aff": "1The University of Texas at Austin, 2Stanford University; 1The University of Texas at Austin, 3Facebook AI Research",
        "project": "http://vision.cs.utexas.edu/projects/VisualVoice/",
        "github": "",
        "arxiv": "2101.03149"
    },
    {
        "title": "Visualizing Adapted Knowledge in Domain Transfer",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Visualizing_Adapted_Knowledge_in_Domain_Transfer_CVPR_2021_paper.html",
        "author": "Yunzhong Hou, Liang Zheng",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Visualizing_Adapted_Knowledge_in_Domain_Transfer_CVPR_2021_paper.pdf",
        "aff": "Australian National University",
        "project": "",
        "github": "https://github.com/hou-yz/DA_visualization",
        "arxiv": "2104.10602"
    },
    {
        "title": "Visually Informed Binaural Audio Generation without Binaural Audios",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Visually_Informed_Binaural_Audio_Generation_without_Binaural_Audios_CVPR_2021_paper.html",
        "author": "Xudong Xu, Hang Zhou, Ziwei Liu, Bo Dai, Xiaogang Wang, Dahua Lin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Visually_Informed_Binaural_Audio_Generation_without_Binaural_Audios_CVPR_2021_paper.pdf",
        "aff": "CUHK - SenseTime Joint Lab, The Chinese University of Hong Kong; S-Lab, Nanyang Technological University",
        "project": "",
        "github": "https://sheldontsui.github.io/projects/PseudoBinaural",
        "arxiv": "2104.06162"
    },
    {
        "title": "VoxelContext-Net: An Octree Based Framework for Point Cloud Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Que_VoxelContext-Net_An_Octree_Based_Framework_for_Point_Cloud_Compression_CVPR_2021_paper.html",
        "author": "Zizheng Que, Guo Lu, Dong Xu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Que_VoxelContext-Net_An_Octree_Based_Framework_for_Point_Cloud_Compression_CVPR_2021_paper.pdf",
        "aff": "University of Sydney; Beijing Institute of Technology; Beihang University",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Vx2Text: End-to-End Learning of Video-Based Text Generation From Multimodal Inputs",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Vx2Text_End-to-End_Learning_of_Video-Based_Text_Generation_From_Multimodal_Inputs_CVPR_2021_paper.html",
        "author": "Xudong Lin, Gedas Bertasius, Jue Wang, Shih-Fu Chang, Devi Parikh, Lorenzo Torresani",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Vx2Text_End-to-End_Learning_of_Video-Based_Text_Generation_From_Multimodal_Inputs_CVPR_2021_paper.pdf",
        "aff": "Facebook AI; Columbia University",
        "project": "",
        "github": "",
        "arxiv": "2101.12059"
    },
    {
        "title": "WOAD: Weakly Supervised Online Action Detection in Untrimmed Videos",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gao_WOAD_Weakly_Supervised_Online_Action_Detection_in_Untrimmed_Videos_CVPR_2021_paper.html",
        "author": "Mingfei Gao, Yingbo Zhou, Ran Xu, Richard Socher, Caiming Xiong",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_WOAD_Weakly_Supervised_Online_Action_Detection_in_Untrimmed_Videos_CVPR_2021_paper.pdf",
        "aff": "Salesforce Research",
        "project": "",
        "github": "",
        "arxiv": "2006.03732"
    },
    {
        "title": "Wasserstein Barycenter for Multi-Source Domain Adaptation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Montesuma_Wasserstein_Barycenter_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.html",
        "author": "Eduardo Fernandes Montesuma, Fred Maurice Ngole Mboula",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Montesuma_Wasserstein_Barycenter_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.pdf",
        "aff": "Universit\u00e9 Paris-Saclay, Institut LIST, CEA, F-91120 Palaiseau, France; Universidade Federal do Cear\u00e1, Fortaleza, Brazil",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "Wasserstein Contrastive Representation Distillation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Wasserstein_Contrastive_Representation_Distillation_CVPR_2021_paper.html",
        "author": "Liqun Chen, Dong Wang, Zhe Gan, Jingjing Liu, Ricardo Henao, Lawrence Carin",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Wasserstein_Contrastive_Representation_Distillation_CVPR_2021_paper.pdf",
        "aff": "Duke University; Microsoft Corporation",
        "project": "",
        "github": "",
        "arxiv": "2012.08674"
    },
    {
        "title": "Watching You: Global-Guided Reciprocal Learning for Video-Based Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Watching_You_Global-Guided_Reciprocal_Learning_for_Video-Based_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Xuehu Liu, Pingping Zhang, Chenyang Yu, Huchuan Lu, Xiaoyun Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Watching_You_Global-Guided_Reciprocal_Learning_for_Video-Based_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Remark Holdings; School of Information and Communication Engineering, Dalian University of Technology; Ningbo Institute, Dalian University of Technology; School of Information and Communication Engineering, Dalian University of Technology; Ningbo Institute, Dalian University of Technology; Pengcheng Lab; School of Information and Communication Engineering, Dalian University of Technology; School of Arti\ufb01cial Intelligence, Dalian University of Technology",
        "project": "",
        "github": "https://github.com/\ufb02ysnowtiger/GRL",
        "arxiv": "2103.04337"
    },
    {
        "title": "We Are More Than Our Joints: Predicting How 3D Bodies Move",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_We_Are_More_Than_Our_Joints_Predicting_How_3D_Bodies_CVPR_2021_paper.html",
        "author": "Yan Zhang, Michael J. Black, Siyu Tang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_We_Are_More_Than_Our_Joints_Predicting_How_3D_Bodies_CVPR_2021_paper.pdf",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; ETH Z\u00fcrich, Switzerland",
        "project": "",
        "github": "https://yz-cnsdqz.github.io/MOJO/MOJO.html",
        "arxiv": "2012.00619"
    },
    {
        "title": "Weakly Supervised Action Selection Learning in Video",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Weakly_Supervised_Action_Selection_Learning_in_Video_CVPR_2021_paper.html",
        "author": "Junwei Ma, Satya Krishna Gorti, Maksims Volkovs, Guangwei Yu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_Weakly_Supervised_Action_Selection_Learning_in_Video_CVPR_2021_paper.pdf",
        "aff": "Layer6 AI",
        "project": "",
        "github": "https://github.com/layer6ai-labs/ASL",
        "arxiv": "2105.02439"
    },
    {
        "title": "Weakly Supervised Instance Segmentation for Videos With Temporal Mask Consistency",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Weakly_Supervised_Instance_Segmentation_for_Videos_With_Temporal_Mask_Consistency_CVPR_2021_paper.html",
        "author": "Qing Liu, Vignesh Ramanathan, Dhruv Mahajan, Alan Yuille, Zhenheng Yang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Weakly_Supervised_Instance_Segmentation_for_Videos_With_Temporal_Mask_Consistency_CVPR_2021_paper.pdf",
        "aff": "Johns Hopkins University; Facebook",
        "project": "",
        "github": "",
        "arxiv": "2103.12886"
    },
    {
        "title": "Weakly Supervised Learning of Rigid 3D Scene Flow",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Gojcic_Weakly_Supervised_Learning_of_Rigid_3D_Scene_Flow_CVPR_2021_paper.html",
        "author": "Zan Gojcic, Or Litany, Andreas Wieser, Leonidas J. Guibas, Tolga Birdal",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gojcic_Weakly_Supervised_Learning_of_Rigid_3D_Scene_Flow_CVPR_2021_paper.pdf",
        "aff": "ETH Zurich; Stanford University",
        "project": "3dsceneflow.github.io",
        "github": "github.com/zgojcic/Rigid3DSceneFlow",
        "arxiv": "2102.08945"
    },
    {
        "title": "Weakly Supervised Video Salient Object Detection",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Weakly_Supervised_Video_Salient_Object_Detection_CVPR_2021_paper.html",
        "author": "Wangbo Zhao, Jing Zhang, Long Li, Nick Barnes, Nian Liu, Junwei Han",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Weakly_Supervised_Video_Salient_Object_Detection_CVPR_2021_paper.pdf",
        "aff": "Weakly Supervised Video Salient Object Detection\nWangbo Zhao1Jing Zhang2,3Long Li1Nick Barnes2Nian Liu4Junwei Han1/enc-12\u2217\n1The Brain and Arti\ufb01cial Intelligence Laboratory, Northwestern Polytechnical University\n2Australian National University3CSIRO, Australia\n4Inception Institute of Arti\ufb01cial Intelligence\n{wangbo.zhao96, zjnwpu, longli.nwpu, liunian228, junweihan2010 }@gmail.com,\nnick.barnes@anu.edu.au\nAbstract\nSigni\ufb01cant performance improvement has been achieved\nfor fully-supervised video salient object detection with\nthe pixel-wise labeled training datasets, which are time-\nconsuming and expensive to obtain. To relieve the bur-\nden of data annotation, we present the \ufb01rst weakly super-\nvised video salient object detection model based on rela-\nbeled \u201c\ufb01xation guided scribble annotations\u201d. Speci\ufb01cally,\nan \u201cAppearance-motion fusion module\u201d and bidirectional\nConvLSTM based framework are proposed to achieve ef-\nfective multi-modal learning and long-term temporal con-\ntext modeling based on our new weak annotations. Fur-\nther, we design a novel foreground-background similarity\nloss to further explore the labeling similarity across frames.\nA weak annotation boosting strategy is also introduced to\nboost our model performance with a new pseudo-label gen-\neration technique. Extensive experimental results on six\nbenchmark video saliency detection datasets illustrate the\neffectiveness of our solution1.\n1. Introduction\nVideo salient object detection (VSOD) models are de-\nsigned to segment salient objects in both the spatial domain\nand the temporal domain. Existing VSOD methods focus\non two different solutions: 1) encoding temporal informa-\ntion using a recurrent network [ 30,10,44],e.g. LSTM; and\n2) encoding geometric information using the optical \ufb02ow\nconstraint [ 18,29]. Although considerable performance im-\nprovements have been achieved, we argue that the huge bur-\nden of pixel-wise labeling makes VSOD a much more ex-\npensive task than the RGB image-based saliency detection\ntask [ 14,23,22,48,43].\nThe standard pipeline to train a deep video saliency\n\u2217Corresponding author: Junwei Han (junweihan2010@gmail.com)\n1Our code and data is publicly available at: https://github.\ncom/wangbo-zhao/WSVSOD .\n(a) Image (b) Full Anno. (c) Weak Anno.\n(d) Image (e) TENet[ 29] (f) Ours\nFigure 1. Training with our weak annotation (c), we achieve com-\npetitive performance (f) compared with TENet[ 29] (e).\ndetection model involves two main steps. Firstly, the\nnetwork is pre-trained on an existing static RGB image-\nbased saliency detection training dataset, e.g. DUTS [ 35] or\nMSRA10K [ 6]. Then, it is \ufb01ne-tuned on video saliency de-\ntection datasets, e.g. DA VSOD [ 10] and DA VIS [ 28]. The\nmain reason for using this strategy is that video saliency\ndatasets usually have limited scene diversity. Although the\nlargest DA VSOD dataset [ 10] has more than 10K frames\nfor training, the large redundancy across the frames of each\nclip makes it still insuf\ufb01cient to effectively train deep video\nsaliency models. Speci\ufb01cally, DA VSOD has a total of\n107 clips for training and validation, which only indicates\naround 107 diverse scenes. Hence, directly training with a\nVSOD dataset may lead to poor model generalization abil-\nity, as the model may over\ufb01t on the highly redundant data.\nTo obtain an effective video saliency detection model,\nexisting fully supervised VSOD methods [ 18,29,10] rely\non both RGB image saliency datasets and VSOD training\ndatasets. The problem behind the above pipeline is the\nhuge requirement for pixel-wise labeling, which is time-\nconsuming and expensive to obtain. For example, RGB\nimage saliency training datasets have more than 10K la-\nbeled samples [ 35,6]. Further, as shown in Tab. 1, widely\nused VSOD training datasets (DA VSOD and DA VIS) con-\n16826\n",
        "project": "",
        "github": "",
        "arxiv": "2104.02391"
    },
    {
        "title": "Weakly-Supervised Instance Segmentation via Class-Agnostic Learning With Salient Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Weakly-Supervised_Instance_Segmentation_via_Class-Agnostic_Learning_With_Salient_Images_CVPR_2021_paper.html",
        "author": "Xinggang Wang, Jiapei Feng, Bin Hu, Qi Ding, Longjin Ran, Xiaoxin Chen, Wenyu Liu",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Weakly-Supervised_Instance_Segmentation_via_Class-Agnostic_Learning_With_Salient_Images_CVPR_2021_paper.pdf",
        "aff": "VIVO Inc.; Huazhong University of Science and Technology",
        "project": "",
        "github": "https://github.com/hustvl/BoxCaseg",
        "arxiv": "2104.01526"
    },
    {
        "title": "Weakly-Supervised Physically Unconstrained Gaze Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kothari_Weakly-Supervised_Physically_Unconstrained_Gaze_Estimation_CVPR_2021_paper.html",
        "author": "Rakshit Kothari, Shalini De Mello, Umar Iqbal, Wonmin Byeon, Seonwook Park, Jan Kautz",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kothari_Weakly-Supervised_Physically_Unconstrained_Gaze_Estimation_CVPR_2021_paper.pdf",
        "aff": "NVIDIA, Rochester Institute of Technology; NVIDIA; Lunit Inc.",
        "project": "",
        "github": "https://github.com/NVlabs/weakly-supervised-gaze",
        "arxiv": "2105.09803"
    },
    {
        "title": "WebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_WebFace260M_A_Benchmark_Unveiling_the_Power_of_Million-Scale_Deep_Face_CVPR_2021_paper.html",
        "author": "Zheng Zhu, Guan Huang, Jiankang Deng, Yun Ye, Junjie Huang, Xinze Chen, Jiagang Zhu, Tian Yang, Jiwen Lu, Dalong Du, Jie Zhou",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_WebFace260M_A_Benchmark_Unveiling_the_Power_of_Million-Scale_Deep_Face_CVPR_2021_paper.pdf",
        "aff": "XForwardAI; Imperial College London; Tsinghua University",
        "project": "https://www.face-benchmark.org",
        "github": "",
        "arxiv": "2103.04098"
    },
    {
        "title": "What Can Style Transfer and Paintings Do for Model Robustness?",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Lin_What_Can_Style_Transfer_and_Paintings_Do_for_Model_Robustness_CVPR_2021_paper.html",
        "author": "Hubert Lin, Mitchell van Zuijlen, Sylvia C. Pont, Maarten W.A. Wijntjes, Kavita Bala",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_What_Can_Style_Transfer_and_Paintings_Do_for_Model_Robustness_CVPR_2021_paper.pdf",
        "aff": "Delft University of Technology; Cornell University",
        "project": "",
        "github": "https://github.com/hubertsgithub/style_painting_robustness",
        "arxiv": "2011.14477"
    },
    {
        "title": "What if We Only Use Real Datasets for Scene Text Recognition? Toward Scene Text Recognition With Fewer Labels",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Baek_What_if_We_Only_Use_Real_Datasets_for_Scene_Text_CVPR_2021_paper.html",
        "author": "Jeonghun Baek, Yusuke Matsui, Kiyoharu Aizawa",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Baek_What_if_We_Only_Use_Real_Datasets_for_Scene_Text_CVPR_2021_paper.pdf",
        "aff": "The University of Tokyo",
        "project": "",
        "github": "https://github.com/ku21fan/STR-Fewer-Labels",
        "arxiv": "2103.04400"
    },
    {
        "title": "What's in the Image? Explorable Decoding of Compressed Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Bahat_Whats_in_the_Image_Explorable_Decoding_of_Compressed_Images_CVPR_2021_paper.html",
        "author": "Yuval Bahat, Tomer Michaeli",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Bahat_Whats_in_the_Image_Explorable_Decoding_of_Compressed_Images_CVPR_2021_paper.pdf",
        "aff": "Technion - Israel Institute of Technology, Haifa, Israel",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "When Age-Invariant Face Recognition Meets Face Age Synthesis: A Multi-Task Learning Framework",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Huang_When_Age-Invariant_Face_Recognition_Meets_Face_Age_Synthesis_A_Multi-Task_CVPR_2021_paper.html",
        "author": "Zhizhong Huang, Junping Zhang, Hongming Shan",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_When_Age-Invariant_Face_Recognition_Meets_Face_Age_Synthesis_A_Multi-Task_CVPR_2021_paper.pdf",
        "aff": "Institute of Science and Technology for Brain-inspired Intelligence and MOE Frontiers Center for Brain Science, Fudan University, Shanghai 200433, China; Shanghai Center for Brain Science and Brain-inspired Technology, Shanghai 200031, China; Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai 200433, China",
        "project": "",
        "github": "https://github.com/Hzzone/MTLFace",
        "arxiv": "2103.01520"
    },
    {
        "title": "When Human Pose Estimation Meets Robustness: Adversarial Algorithms and Benchmarks",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_When_Human_Pose_Estimation_Meets_Robustness_Adversarial_Algorithms_and_Benchmarks_CVPR_2021_paper.html",
        "author": "Jiahang Wang, Sheng Jin, Wentao Liu, Weizhong Liu, Chen Qian, Ping Luo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_When_Human_Pose_Estimation_Meets_Robustness_Adversarial_Algorithms_and_Benchmarks_CVPR_2021_paper.pdf",
        "aff": "When Human Pose Estimation Meets Robustness:\nAdversarial Algorithms and Benchmarks\nJiahang Wang1\u2020Sheng Jin2,3Wentao Liu4Weizhong Liu1Chen Qian4Ping Luo2\n1Huazhong University of Science and Technology2The University of Hong Kong\n3SenseTime Research4SenseTime Research and Tetras.AI\njiahangwangchn@gmail.com {jinsheng, liuwentao, qianchen }@sensetime.com\nliuweizhong@mail.hust.edu.cn pluo@cs.hku.hk\nAbstract\nHuman pose estimation is a fundamental yet challeng-\ning task in computer vision, which aims at localizing hu-\nman anatomical keypoints. However, unlike human vision\nthat is robust to various data corruptions such as blur and\npixelation, current pose estimators are easily confused by\nthese corruptions. This work comprehensively studies and\naddresses this problem by building rigorous robust bench-\nmarks, termed COCO-C, MPII-C, and OCHuman-C, to\nevaluate the weaknesses of current advanced pose estima-\ntors, and a new algorithm termed AdvMix is proposed to\nimprove their robustness in different corruptions. Our work\nhas several unique bene\ufb01ts. (1) AdvMix is model-agnostic\nand capable in a wide-spectrum of pose estimation mod-\nels. (2) AdvMix consists of adversarial augmentation and\nknowledge distillation. Adversarial augmentation contains\ntwo neural network modules that are trained jointly and\ncompetitively in an adversarial manner, where a genera-\ntor network mixes different corrupted images to confuse a\npose estimator, improving the robustness of the pose estima-\ntor by learning from harder samples. To compensate for the\nnoise patterns by adversarial augmentation, knowledge dis-\ntillation is applied to transfer clean pose structure knowl-\nedge to the target pose estimator. (3) Extensive experiments\nshow that AdvMix signi\ufb01cantly increases the robustness of\npose estimations across a wide range of corruptions, while\nmaintaining accuracy on clean data in various challenging\nbenchmark datasets.\n1. Introduction\nHuman pose estimation (HPE) is a fundamental task\nfor action recognition and video surveillance [ 28,38,25].\nAlthough convolutional neural networks (CNNs) achieved\ngreat progress [ 39,40,36,5,30,7] on challenging datasets\n\u2020The work was done during an internship at SenseTime Research.\n/uni0000002b/uni00000055/uni0000002b/uni00000035/uni0000005a/uni00000016/uni00000015\n /uni00000035/uni00000048/uni00000056/uni00000018/uni00000013\n /uni00000035/uni00000048/uni00000056/uni00000014/uni00000013/uni00000014\n /uni00000035/uni00000048/uni00000056/uni00000014/uni00000018/uni00000015\n /uni0000002b/uni00000035/uni0000005a/uni00000016/uni00000015\n /uni0000002b/uni00000035/uni0000005a/uni00000017/uni0000001b\n/uni00000017/uni00000013/uni00000011/uni00000013\n/uni00000017/uni00000015/uni00000011/uni00000018\n/uni00000017/uni00000018/uni00000011/uni00000013\n/uni00000017/uni0000001a/uni00000011/uni00000018\n/uni00000018/uni00000013/uni00000011/uni00000013\n/uni00000018/uni00000015/uni00000011/uni00000018\n/uni00000018/uni00000018/uni00000011/uni00000013\n/uni00000018/uni0000001a/uni00000011/uni00000018/uni00000050/uni00000033/uni00000026\n/uni00000036/uni00000057/uni00000044/uni00000051/uni00000047/uni00000044/uni00000055/uni00000047\n/uni00000024/uni00000047/uni00000059/uni00000030/uni0000004c/uni0000005bFigure 1. Improvements of model robustness (mPC) when Ad-\nvMix is applied to the state-of-the-art methods.\n[26,1,47], which only contain clean and high-resolution\nimages, deploying models in the real world requires not\nonly good performance on clean data, but also robustness\nto commonly occurring image corruptions. For example,\nwhile tracking and estimating the keypoints of a moving\nperson in outdoor environments, current pose estimators\nsuffer severe performance drop due to the noise or blur\ncaused by weather conditions or camera systems. There-\nfore, analyzing and enhancing the robustness of pose esti-\nmators are important and are the purposes of this work.\nUnlike previous studies on common robustness for clas-\nsi\ufb01cation, detection and segmentation [ 17,29,23], human\npose estimation uses a blend of classi\ufb01cation and regression\nmethods to model the structures of the human body, mak-\ning it a challenging and collaborative \ufb01eld that is worthy of\nspecial investigations. The key challenges of robust human\npose estimation are three folds. First, the lack of a bench-\nmark for evaluating the robustness of state-of-the-art human\npose estimation methods makes it dif\ufb01cult to construct rig-\norous comparisons between different models, not to men-\ntion to improve model robustness. Second, accuracy of\nclean data and corrupted data are trade-offs. Improving the\nrobustness of the model while maintaining its performance\n11855\n",
        "project": "",
        "github": "",
        "arxiv": "2105.06152"
    },
    {
        "title": "Where and What? Examining Interpretable Disentangled Representations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Where_and_What_Examining_Interpretable_Disentangled_Representations_CVPR_2021_paper.html",
        "author": "Xinqi Zhu, Chang Xu, Dacheng Tao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Where_and_What_Examining_Interpretable_Disentangled_Representations_CVPR_2021_paper.pdf",
        "aff": "The University of Sydney",
        "project": "",
        "github": "",
        "arxiv": "2104.05622"
    },
    {
        "title": "Wide-Baseline Multi-Camera Calibration Using Person Re-Identification",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Wide-Baseline_Multi-Camera_Calibration_Using_Person_Re-Identification_CVPR_2021_paper.html",
        "author": "Yan Xu, Yu-Jhe Li, Xinshuo Weng, Kris Kitani",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Wide-Baseline_Multi-Camera_Calibration_Using_Person_Re-Identification_CVPR_2021_paper.pdf",
        "aff": "Carnegie Mellon University",
        "project": "",
        "github": "",
        "arxiv": "2104.08568"
    },
    {
        "title": "Wide-Baseline Relative Camera Pose Estimation With Directional Learning",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Wide-Baseline_Relative_Camera_Pose_Estimation_With_Directional_Learning_CVPR_2021_paper.html",
        "author": "Kefan Chen, Noah Snavely, Ameesh Makadia",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Wide-Baseline_Relative_Camera_Pose_Estimation_With_Directional_Learning_CVPR_2021_paper.pdf",
        "aff": "Google Research",
        "project": "",
        "github": "",
        "arxiv": "2106.03336"
    },
    {
        "title": "Wide-Depth-Range 6D Object Pose Estimation in Space",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Wide-Depth-Range_6D_Object_Pose_Estimation_in_Space_CVPR_2021_paper.html",
        "author": "Yinlin Hu, Sebastien Speierer, Wenzel Jakob, Pascal Fua, Mathieu Salzmann",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Wide-Depth-Range_6D_Object_Pose_Estimation_in_Space_CVPR_2021_paper.pdf",
        "aff": "EPFL Computer Vision Lab; EPFL Realistic Graphics Lab; EPFL Computer Vision Lab, ClearSpace SA",
        "project": "",
        "github": "",
        "arxiv": "2104.00337"
    },
    {
        "title": "XProtoNet: Diagnosis in Chest Radiography With Global and Local Explanations",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kim_XProtoNet_Diagnosis_in_Chest_Radiography_With_Global_and_Local_Explanations_CVPR_2021_paper.html",
        "author": "Eunji Kim, Siwon Kim, Minji Seo, Sungroh Yoon",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_XProtoNet_Diagnosis_in_Chest_Radiography_With_Global_and_Local_Explanations_CVPR_2021_paper.pdf",
        "aff": "Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; ASRI, INMC, ISRC, and Institute of Engineering Research, Seoul National University",
        "project": "",
        "github": "",
        "arxiv": "2103.10663"
    },
    {
        "title": "You Only Look One-Level Feature",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chen_You_Only_Look_One-Level_Feature_CVPR_2021_paper.html",
        "author": "Qiang Chen, Yingming Wang, Tong Yang, Xiangyu Zhang, Jian Cheng, Jian Sun",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_You_Only_Look_One-Level_Feature_CVPR_2021_paper.pdf",
        "aff": "MEGVII Technology; NLPR, Institute of Automation, Chinese Academy of Sciences and School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences and CAS Center for Excellence in Brain Science and Intelligence Technology",
        "project": "",
        "github": "https://github.com/megvii-model/YOLOF",
        "arxiv": "2103.09460"
    },
    {
        "title": "You See What I Want You To See: Exploring Targeted Black-Box Transferability Attack for Hash-Based Image Retrieval Systems",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_You_See_What_I_Want_You_To_See_Exploring_Targeted_CVPR_2021_paper.html",
        "author": "Yanru Xiao, Cong Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xiao_You_See_What_I_Want_You_To_See_Exploring_Targeted_CVPR_2021_paper.pdf",
        "aff": "Old Dominion University, Norfolk, VA",
        "project": "",
        "github": "https://github.com/SugarRuy/CVPR21 Transferred Hash",
        "arxiv": ""
    },
    {
        "title": "Your \"Flamingo\" is My \"Bird\": Fine-Grained, or Not",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Your_Flamingo_is_My_Bird_Fine-Grained_or_Not_CVPR_2021_paper.html",
        "author": "Dongliang Chang, Kaiyue Pang, Yixiao Zheng, Zhanyu Ma, Yi-Zhe Song, Jun Guo",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chang_Your_Flamingo_is_My_Bird_Fine-Grained_or_Not_CVPR_2021_paper.pdf",
        "aff": "The Pattern Recognition and Intelligent System Laboratory, School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; SketchX, CVSSP, University of Surrey, United Kingdom",
        "project": "",
        "github": "",
        "arxiv": "2011.09040"
    },
    {
        "title": "Zero-Shot Adversarial Quantization",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Zero-Shot_Adversarial_Quantization_CVPR_2021_paper.html",
        "author": "Yuang Liu, Wei Zhang, Jun Wang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Zero-Shot_Adversarial_Quantization_CVPR_2021_paper.pdf",
        "aff": "East China Normal University, Shanghai, China",
        "project": "",
        "github": "https://git.io/Jqc0y",
        "arxiv": "2103.15263"
    },
    {
        "title": "Zero-Shot Instance Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Zero-Shot_Instance_Segmentation_CVPR_2021_paper.html",
        "author": "Ye Zheng, Jiahong Wu, Yongqiang Qin, Faen Zhang, Li Cui",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Zero-Shot_Instance_Segmentation_CVPR_2021_paper.pdf",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; AInnovation Technology Co., Ltd; University of Chinese Academy of Sciences",
        "project": "ZSI",
        "github": "Not provided",
        "arxiv": "2104.06601"
    },
    {
        "title": "Zero-Shot Single Image Restoration Through Controlled Perturbation of Koschmieder's Model",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Kar_Zero-Shot_Single_Image_Restoration_Through_Controlled_Perturbation_of_Koschmieders_Model_CVPR_2021_paper.html",
        "author": "Aupendu Kar, Sobhan Kanti Dhara, Debashis Sen, Prabir Kumar Biswas",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kar_Zero-Shot_Single_Image_Restoration_Through_Controlled_Perturbation_of_Koschmieders_Model_CVPR_2021_paper.pdf",
        "aff": "Indian Institute of Technology Kharagpur, WB, India",
        "project": "",
        "github": "https://aupendu.github.io/zero-restore",
        "arxiv": ""
    },
    {
        "title": "ZeroScatter: Domain Transfer for Long Distance Imaging and Vision Through Scattering Media",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shi_ZeroScatter_Domain_Transfer_for_Long_Distance_Imaging_and_Vision_Through_CVPR_2021_paper.html",
        "author": "Zheng Shi, Ethan Tseng, Mario Bijelic, Werner Ritter, Felix Heide",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_ZeroScatter_Domain_Transfer_for_Long_Distance_Imaging_and_Vision_Through_CVPR_2021_paper.pdf",
        "aff": "Mercedes-Benz AG; Princeton University; Princeton University, Algolux",
        "project": "",
        "github": "",
        "arxiv": "2102.05847"
    },
    {
        "title": "Zillow Indoor Dataset: Annotated Floor Plans With 360deg Panoramas and 3D Room Layouts",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Cruz_Zillow_Indoor_Dataset_Annotated_Floor_Plans_With_360deg_Panoramas_and_CVPR_2021_paper.html",
        "author": "Steve Cruz, Will Hutchcroft, Yuguang Li, Naji Khosravan, Ivaylo Boyadzhiev, Sing Bing Kang",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cruz_Zillow_Indoor_Dataset_Annotated_Floor_Plans_With_360deg_Panoramas_and_CVPR_2021_paper.pdf",
        "aff": "Zillow Group; University of Colorado Colorado Springs",
        "project": "",
        "github": "https://github.com/zillow/zind",
        "arxiv": ""
    },
    {
        "title": "clDice - A Novel Topology-Preserving Loss Function for Tubular Structure Segmentation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Shit_clDice_-_A_Novel_Topology-Preserving_Loss_Function_for_Tubular_Structure_CVPR_2021_paper.html",
        "author": "Suprosanna Shit, Johannes C. Paetzold, Anjany Sekuboyina, Ivan Ezhov, Alexander Unger, Andrey Zhylka, Josien P. W. Pluim, Ulrich Bauer, Bjoern H. Menze",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shit_clDice_-_A_Novel_Topology-Preserving_Loss_Function_for_Tubular_Structure_CVPR_2021_paper.pdf",
        "aff": "Technical University of Munich; Eindhoven University of Technology",
        "project": "",
        "github": "",
        "arxiv": ""
    },
    {
        "title": "i3DMM: Deep Implicit 3D Morphable Model of Human Heads",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yenamandra_i3DMM_Deep_Implicit_3D_Morphable_Model_of_Human_Heads_CVPR_2021_paper.html",
        "author": "Tarun Yenamandra, Ayush Tewari, Florian Bernard, Hans-Peter Seidel, Mohamed Elgharib, Daniel Cremers, Christian Theobalt",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yenamandra_i3DMM_Deep_Implicit_3D_Morphable_Model_of_Human_Heads_CVPR_2021_paper.pdf",
        "aff": "2MPI Informatics, Saarland Informatics Campus; 1TU Munich; 1TU Munich, 2MPI Informatics, Saarland Informatics Campus",
        "project": "http://gvv.mpi-inf.mpg.de/projects/i3DMM/",
        "github": "",
        "arxiv": "2011.14143"
    },
    {
        "title": "iMiGUE: An Identity-Free Video Dataset for Micro-Gesture Understanding and Emotion Analysis",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Liu_iMiGUE_An_Identity-Free_Video_Dataset_for_Micro-Gesture_Understanding_and_Emotion_CVPR_2021_paper.html",
        "author": "Xin Liu, Henglin Shi, Haoyu Chen, Zitong Yu, Xiaobai Li, Guoying Zhao",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_iMiGUE_An_Identity-Free_Video_Dataset_for_Micro-Gesture_Understanding_and_Emotion_CVPR_2021_paper.pdf",
        "aff": "School of Electrical and Information Engineering, Tianjin University, China; Center for Machine Vision and Signal Analysis, University of Oulu, Finland",
        "project": "",
        "github": "https://github.com/linuxsino/iMiGUE",
        "arxiv": ""
    },
    {
        "title": "iVPF: Numerical Invertible Volume Preserving Flow for Efficient Lossless Compression",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_iVPF_Numerical_Invertible_Volume_Preserving_Flow_for_Efficient_Lossless_Compression_CVPR_2021_paper.html",
        "author": "Shifeng Zhang, Chen Zhang, Ning Kang, Zhenguo Li",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_iVPF_Numerical_Invertible_Volume_Preserving_Flow_for_Efficient_Lossless_Compression_CVPR_2021_paper.pdf",
        "aff": "Huawei Noah\u2019s Ark Lab",
        "project": "",
        "github": "",
        "arxiv": "2103.16211"
    },
    {
        "title": "img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Albiero_img2pose_Face_Alignment_and_Detection_via_6DoF_Face_Pose_Estimation_CVPR_2021_paper.html",
        "author": "Vitor Albiero, Xingyu Chen, Xi Yin, Guan Pang, Tal Hassner",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Albiero_img2pose_Face_Alignment_and_Detection_via_6DoF_Face_Pose_Estimation_CVPR_2021_paper.pdf",
        "aff": "University of Notre Dame; Facebook AI",
        "project": "",
        "github": "",
        "arxiv": "2012.07791"
    },
    {
        "title": "pixelNeRF: Neural Radiance Fields From One or Few Images",
        "site": "https://openaccess.thecvf.com/content/CVPR2021/html/Yu_pixelNeRF_Neural_Radiance_Fields_From_One_or_Few_Images_CVPR_2021_paper.html",
        "author": "Alex Yu, Vickie Ye, Matthew Tancik, Angjoo Kanazawa",
        "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_pixelNeRF_Neural_Radiance_Fields_From_One_or_Few_Images_CVPR_2021_paper.pdf",
        "aff": "UC Berkeley",
        "project": "https://alexyu.net/pixelnerf",
        "github": "",
        "arxiv": "2012.02190"
    }
]